{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of TSD, DANN, SCADANN models across 3 wearing locations \n",
    "\n",
    "Library used can be downloaded from https://github.com/aonai/long_term_EMG_myo   \n",
    "&emsp; Original by UlysseCoteAllard https://github.com/UlysseCoteAllard/LongTermEMG   \n",
    "Dataset recorded by https://github.com/Suguru55/Wearable_Sensor_Long-term_sEMG_Dataset   \n",
    "Extended robot project can be found in https://github.com/aonai/myo_robot_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* weights for TSD are total of 15 training models, 3 for each subject\n",
    "* weights for DANN and SCADANN are total of 10 trianing models, 2 for each subject \n",
    "\n",
    "\n",
    "* training examples should have shape (5, 3, 40, 572, 252)\n",
    "* training labels should have shape (5, 3, 40, 572)\n",
    "\n",
    "\n",
    "* location 0, 1, and 2 corresponds to neutral position, inward rotation, and outward rotation respectively\n",
    "* session mentioned below is wearing location, so number of sessions is 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data\n",
    "\n",
    "### specify the directories used for running the code:\n",
    "* `code_diar`: path to long_term_EMG_myo library\n",
    "* `data_dir`: where raw dataset is loaded; raw data is in csv format\n",
    "* `processed_data_dir`: where processed dataset is loaded; processed data is in npy pickle format\n",
    "    * processed data should be a ndarray of shape   \n",
    "    (controlling_factor_1 x controlling_factor_2 x num_sessions_per_gesture x #examples_window*#mov(26*22=572) x processed_channel_shape(252 for TSD, (4,8,10) for ConvNet)\n",
    "* `path_<model_name>`: where model weights are saved\n",
    "    * weights should be saved in folder `/Weights/<model_name>`. Each folder has subfolders containing weights for the first controlling factor.\n",
    "    * weights for base model (TSD or ConvNet) contain m set of training model\n",
    "    * weights for DANN and SCADANN contain m-1 set of trianing model (these models are trianed based on TSD, so they do not have a best_state_0.pt model). \n",
    "* `save_<model_name>`: where model results are saved\n",
    "    * each result for testing a model on a group of dataset is saved in folder `results`. Each result has corresponding \n",
    "        * `<model_name>.txt` includes predictions, ground truths, array of accuracies for each participant and each session, and overall accuracy\n",
    "        * `predictions_<model_name>.npy` includes array of accuracies, ground truths, predictions, and model outputs (probability array for each prediction)\n",
    "        * remember to make blank files in these names before saving\n",
    "\n",
    "\n",
    "\n",
    "* use `read_data_training` to process raw dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo\"\n",
    "os.chdir(code_dir)\n",
    "from PrepareAndLoadData.process_data import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/laiy/gitrepos/msr_final/Wearable_Sensor_Long-term_sEMG_Dataset/data\"\n",
    "processed_data_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Processed_datasets_across_loc\"\n",
    "save_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Results\"\n",
    "\n",
    "path_TSD =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_across_loc/TSD\"\n",
    "save_TSD = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\"\n",
    "\n",
    "path_DANN =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_across_loc/DANN\"\n",
    "save_DANN = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\"\n",
    "\n",
    "path_SCADANN =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_across_loc/SCADANN\"\n",
    "save_SCADANN = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_data_training(path=data_dir, store_path = processed_data_dir, num_participant=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning examples  (5, 3, 40, 572, 252)\n",
      "traning labels  (5, 3, 40, 572)\n"
     ]
    }
   ],
   "source": [
    "# check stored pickle \n",
    "with open(processed_data_dir + \"/training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "print('traning examples ', np.shape(examples_datasets_train))\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "print('traning labels ', np.shape(labels_datasets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify params used for training and testing\n",
    "\n",
    "During training and testing, processed datasets are first put into pytorch dataloders, then feed to the model trainer; following are params for TSD model and dataloaders\n",
    "\n",
    "* `num_kernels`: list of integers defining number of neurons used in each linear layer (linear block has `dropout`=0.5)\n",
    "* `number_of_cycles_total`: number of trails performed for each session (assuming that all session have the same trail size)\n",
    "    * 40 for myo\n",
    "* `number_of_classes`: total number of gestures performed in dataset\n",
    "    * 22 for myo\n",
    "* `batch_size`: number of examples stored in each batch\n",
    "* `feature_vector_input_length`: length of input array or each processed signal; i.e. size of one training example \n",
    "    * 252 for TSD\n",
    "* `learning_rate`= 0.002515\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_cycles_total  40\n"
     ]
    }
   ],
   "source": [
    "num_kernels=[200, 200, 200]                       \n",
    "number_of_cycles_total=np.shape(examples_datasets_train[0][0])[0]              \n",
    "print(\"number_of_cycles_total \", number_of_cycles_total)\n",
    "number_of_classes=22\n",
    "batch_size=128          \n",
    "feature_vector_input_length=252                    \n",
    "learning_rate=0.002515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TSD_DNN\n",
    "* `train_fine_tuning`: used to train data using a base model (TSD or ConvNet)\n",
    "    * running this function will save num_sessions sets of TSD model weights (each is fine tuned based on the previous training)  \n",
    "    \n",
    "* `test_standard_model_on_training_sessions`: test model result\n",
    "\n",
    "\n",
    "### check if dataloaders are loaded correctly:\n",
    "* each participant has shape (num_session x 40 x 572 x 252)\n",
    "* each session has shape (40 x 572 x 252)\n",
    "* put these data into on group ends up with shape (40*572=22880, 252)\n",
    "    * shuffle on group of data and put into dataloaders\n",
    "    * each participant should have num_sessions sets of dataloaders, each correspond to one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_standard import \\\n",
    "            test_standard_model_on_training_sessions, train_fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fine_tuning(examples_datasets_train, labels_datasets_train,\n",
    "#                   num_kernels=num_kernels, path_weight_to_save_to=path_TSD,\n",
    "#                   number_of_classes=number_of_classes, number_of_cycles_total=number_of_cycles_total,\n",
    "#                   batch_size=batch_size,\n",
    "#                   feature_vector_input_length=feature_vector_input_length,\n",
    "#                   learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (2, 3)\n",
      "   valid  (2, 3)\n",
      "   test  (2, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (3, 3)\n",
      "   valid  (3, 3)\n",
      "   test  (3, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (4, 3)\n",
      "   valid  (4, 3)\n",
      "   test  (4, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (5, 3)\n",
      "   valid  (5, 3)\n",
      "   test  (5, 3)\n",
      "0  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.875\n",
      "1  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.6987762237762237\n",
      "2  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.6506993006993007\n",
      "ACCURACY PARTICIPANT  0 :  [0.875, 0.6987762237762237, 0.6506993006993007]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  1  Accuracy:  0.8910839160839161\n",
      "1  SESSION   data =  5720\n",
      "Participant:  1  Accuracy:  0.7519230769230769\n",
      "2  SESSION   data =  5720\n",
      "Participant:  1  Accuracy:  0.7701048951048951\n",
      "ACCURACY PARTICIPANT  1 :  [0.8910839160839161, 0.7519230769230769, 0.7701048951048951]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  2  Accuracy:  0.7136363636363636\n",
      "1  SESSION   data =  5720\n",
      "Participant:  2  Accuracy:  0.5986013986013986\n",
      "2  SESSION   data =  5720\n",
      "Participant:  2  Accuracy:  0.5409090909090909\n",
      "ACCURACY PARTICIPANT  2 :  [0.7136363636363636, 0.5986013986013986, 0.5409090909090909]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  3  Accuracy:  0.8566433566433567\n",
      "1  SESSION   data =  5720\n",
      "Participant:  3  Accuracy:  0.7323426573426574\n",
      "2  SESSION   data =  5720\n",
      "Participant:  3  Accuracy:  0.6437062937062937\n",
      "ACCURACY PARTICIPANT  3 :  [0.8566433566433567, 0.7323426573426574, 0.6437062937062937]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  4  Accuracy:  0.8926573426573426\n",
      "1  SESSION   data =  5720\n",
      "Participant:  4  Accuracy:  0.6722027972027972\n",
      "2  SESSION   data =  5720\n",
      "Participant:  4  Accuracy:  0.5671328671328671\n",
      "ACCURACY PARTICIPANT  4 :  [0.8926573426573426, 0.6722027972027972, 0.5671328671328671]\n",
      "[array([0.875     , 0.69877622, 0.6506993 ]), array([0.89108392, 0.75192308, 0.7701049 ]), array([0.71363636, 0.5986014 , 0.54090909]), array([0.85664336, 0.73234266, 0.64370629]), array([0.89265734, 0.6722028 , 0.56713287])]\n",
      "OVERALL ACCURACY: 0.7236946386946387\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"standard_TSD\"\n",
    "test_standard_model_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=num_kernels, use_only_first_training=True,\n",
    "                                  path_weights=path_TSD,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  save_path = save_TSD, algo_name=algo_name,\n",
    "                                  number_of_cycles_total=number_of_cycles_total,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.732343</td>\n",
       "      <td>0.672203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.770105</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.567133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.698776      0.751923      0.598601      0.732343      0.672203\n",
       "Loc_2      0.650699      0.770105      0.540909      0.643706      0.567133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_TSD + '/predictions_' + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "TSD_acc = results[0]\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc.transpose(), \n",
    "                       index = [f'Loc_{i}' for i in range(TSD_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(TSD_acc.shape[0])])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.utils import get_gesture_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (5, 3)\n",
      "predictions =  (5, 3)\n",
      "index_participant_list  [-1, 0, 1, 2]\n",
      "accuracies_gestures =  (22, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc-1</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub1_Loc-1</th>\n",
       "      <th>Sub1_Loc0</th>\n",
       "      <th>Sub1_Loc1</th>\n",
       "      <th>Sub2_Loc-1</th>\n",
       "      <th>Sub2_Loc0</th>\n",
       "      <th>Sub2_Loc1</th>\n",
       "      <th>Sub3_Loc-1</th>\n",
       "      <th>Sub3_Loc0</th>\n",
       "      <th>Sub3_Loc1</th>\n",
       "      <th>Sub4_Loc-1</th>\n",
       "      <th>Sub4_Loc0</th>\n",
       "      <th>Sub4_Loc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.088462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.542308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.561538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.669231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.334615</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.226923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.665385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.546154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M6</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M7</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.396154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.511538</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.488462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M10</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M11</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.188462</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.511538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M12</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.411538</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M13</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M14</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.373077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.203846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.703846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M17</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.911538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.734615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M18</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M19</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.588462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M20</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M21</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.392308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.770105</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.732343</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.892657</td>\n",
       "      <td>0.672203</td>\n",
       "      <td>0.567133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sub0_Loc-1  Sub0_Loc0  Sub0_Loc1  Sub1_Loc-1  Sub1_Loc0  \\\n",
       "0          M0    1.000000   1.000000   1.000000    1.000000   1.000000   \n",
       "1          M1    0.973077   0.780769   0.907692    0.976923   0.953846   \n",
       "2          M2    0.707692   0.415385   0.550000    0.969231   0.880769   \n",
       "3          M3    0.919231   0.469231   0.996154    1.000000   0.950000   \n",
       "4          M4    0.865385   0.907692   0.430769    1.000000   0.996154   \n",
       "5          M5    0.953846   0.646154   0.753846    1.000000   0.992308   \n",
       "6          M6    0.992308   0.707692   0.726923    0.826923   0.896154   \n",
       "7          M7    0.926923   0.630769   0.611538    0.969231   0.600000   \n",
       "8          M8    1.000000   0.973077   0.723077    0.823077   0.946154   \n",
       "9          M9    1.000000   0.750000   0.769231    0.950000   0.823077   \n",
       "10        M10    0.961538   0.930769   0.684615    0.603846   0.896154   \n",
       "11        M11    0.946154   0.807692   0.730769    0.919231   0.719231   \n",
       "12        M12    0.930769   0.700000   0.573077    0.796154   0.403846   \n",
       "13        M13    0.919231   0.553846   0.176923    0.784615   0.503846   \n",
       "14        M14    0.719231   0.496154   0.630769    0.738462   0.365385   \n",
       "15        M15    0.576923   0.296154   0.473077    0.819231   0.346154   \n",
       "16        M16    0.750000   0.800000   0.165385    0.976923   0.953846   \n",
       "17        M17    0.988462   0.815385   0.953846    0.950000   0.711538   \n",
       "18        M18    0.980769   0.842308   0.792308    0.907692   0.934615   \n",
       "19        M19    0.492308   0.534615   0.273077    0.996154   0.646154   \n",
       "20        M20    0.873077   0.715385   0.761538    0.757692   0.753846   \n",
       "21        M21    0.773077   0.600000   0.630769    0.838462   0.269231   \n",
       "22       Mean    0.875000   0.698776   0.650699    0.891084   0.751923   \n",
       "\n",
       "    Sub1_Loc1  Sub2_Loc-1  Sub2_Loc0  Sub2_Loc1  Sub3_Loc-1  Sub3_Loc0  \\\n",
       "0    1.000000    1.000000   0.980769   1.000000    1.000000   1.000000   \n",
       "1    0.903846    0.342308   0.088462   0.700000    0.803846   0.846154   \n",
       "2    0.988462    0.515385   0.461538   0.246154    0.892308   0.476923   \n",
       "3    0.984615    0.830769   0.723077   0.550000    0.865385   0.346154   \n",
       "4    0.492308    0.819231   0.334615   0.426923    0.830769   0.803846   \n",
       "5    0.953846    0.865385   0.984615   0.292308    0.980769   0.957692   \n",
       "6    0.726923    0.926923   0.838462   0.803846    0.942308   0.884615   \n",
       "7    0.684615    0.584615   0.746154   0.284615    0.934615   0.373077   \n",
       "8    0.703846    0.826923   0.876923   0.511538    0.773077   0.600000   \n",
       "9    0.530769    0.803846   0.696154   0.842308    0.888462   0.803846   \n",
       "10   0.653846    0.761538   0.584615   0.265385    0.734615   0.607692   \n",
       "11   0.850000    0.430769   0.692308   0.188462    0.788462   0.738462   \n",
       "12   0.711538    0.573077   0.365385   0.411538    0.696154   0.746154   \n",
       "13   0.342308    0.000000   0.057692   0.000000    0.834615   0.903846   \n",
       "14   0.780769    0.565385   0.307692   0.488462    0.861538   0.723077   \n",
       "15   0.750000    0.673077   0.284615   0.250000    0.480769   0.634615   \n",
       "16   0.973077    0.892308   0.857692   0.842308    0.919231   0.969231   \n",
       "17   0.911538    1.000000   0.803846   0.938462    0.953846   0.892308   \n",
       "18   0.661538    0.942308   0.961538   0.680769    0.938462   0.703846   \n",
       "19   0.938462    0.973077   0.446154   0.965385    0.984615   0.965385   \n",
       "20   0.634615    0.976923   0.746154   0.703846    0.861538   0.311538   \n",
       "21   0.765385    0.396154   0.330769   0.507692    0.880769   0.823077   \n",
       "22   0.770105    0.713636   0.598601   0.540909    0.856643   0.732343   \n",
       "\n",
       "    Sub3_Loc1  Sub4_Loc-1  Sub4_Loc0  Sub4_Loc1  \n",
       "0    1.000000    1.000000   1.000000   1.000000  \n",
       "1    0.423077    0.961538   0.788462   0.542308  \n",
       "2    0.803846    0.915385   0.873077   0.561538  \n",
       "3    0.903846    0.946154   0.542308   0.669231  \n",
       "4    0.496154    0.853846   0.353846   0.226923  \n",
       "5    0.665385    0.976923   0.684615   0.546154  \n",
       "6    0.853846    0.961538   0.776923   0.596154  \n",
       "7    0.603846    0.915385   0.623077   0.396154  \n",
       "8    0.192308    0.861538   0.680769   0.488462  \n",
       "9    0.442308    0.757692   0.557692   0.550000  \n",
       "10   0.773077    0.865385   0.326923   0.646154  \n",
       "11   0.553846    0.834615   0.273077   0.511538  \n",
       "12   0.619231    0.692308   0.634615   0.442308  \n",
       "13   0.765385    0.815385   0.750000   0.461538  \n",
       "14   0.388462    0.907692   0.346154   0.373077  \n",
       "15   0.530769    0.696154   0.438462   0.203846  \n",
       "16   0.403846    0.957692   0.930769   0.703846  \n",
       "17   0.734615    0.973077   0.961538   0.734615  \n",
       "18   0.930769    0.976923   0.726923   0.984615  \n",
       "19   0.773077    0.957692   0.780769   0.588462  \n",
       "20   0.523077    0.915385   0.800000   0.857692  \n",
       "21   0.780769    0.896154   0.938462   0.392308  \n",
       "22   0.643706    0.892657   0.672203   0.567133  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_TSD, algo_name=algo_name)\n",
    "df = pd.read_csv(save_TSD+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DANN\n",
    "* `train_DANN`: train DANN model using the first set of training weights from base model\n",
    "    * num_sessions-1 sets of training weights will be saved\n",
    "* `test_DANN_on_training_sessions`: test DANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_DA import train_DANN, test_DANN_on_training_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_DANN(examples_datasets_train, labels_datasets_train, \n",
    "#           num_kernels=num_kernels,\n",
    "#           path_weights_fine_tuning=path_TSD,\n",
    "#           number_of_classes=number_of_classes,\n",
    "#           number_of_cycles_total = number_of_cycles_total,\n",
    "#           batch_size=batch_size,\n",
    "#           feature_vector_input_length=feature_vector_input_length,\n",
    "#           path_weights_to_save_to=path_DANN, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (2, 3)\n",
      "   valid  (2, 3)\n",
      "   test  (2, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (3, 3)\n",
      "   valid  (3, 3)\n",
      "   test  (3, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (4, 3)\n",
      "   valid  (4, 3)\n",
      "   test  (4, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (5, 3)\n",
      "   valid  (5, 3)\n",
      "   test  (5, 3)\n",
      "(3,)\n",
      "Participant ID:  0  Session ID:  0  Accuracy:  0.875\n",
      "Participant ID:  0  Session ID:  1  Accuracy:  0.6947552447552447\n",
      "Participant ID:  0  Session ID:  2  Accuracy:  0.7141608391608392\n",
      "ACCURACY PARTICIPANT:  [0.875, 0.6947552447552447, 0.7141608391608392]\n",
      "(3,)\n",
      "Participant ID:  1  Session ID:  0  Accuracy:  0.8910839160839161\n",
      "Participant ID:  1  Session ID:  1  Accuracy:  0.8708041958041958\n",
      "Participant ID:  1  Session ID:  2  Accuracy:  0.8732517482517482\n",
      "ACCURACY PARTICIPANT:  [0.8910839160839161, 0.8708041958041958, 0.8732517482517482]\n",
      "(3,)\n",
      "Participant ID:  2  Session ID:  0  Accuracy:  0.7136363636363636\n",
      "Participant ID:  2  Session ID:  1  Accuracy:  0.6765734265734266\n",
      "Participant ID:  2  Session ID:  2  Accuracy:  0.6019230769230769\n",
      "ACCURACY PARTICIPANT:  [0.7136363636363636, 0.6765734265734266, 0.6019230769230769]\n",
      "(3,)\n",
      "Participant ID:  3  Session ID:  0  Accuracy:  0.8566433566433567\n",
      "Participant ID:  3  Session ID:  1  Accuracy:  0.7646853146853146\n",
      "Participant ID:  3  Session ID:  2  Accuracy:  0.6903846153846154\n",
      "ACCURACY PARTICIPANT:  [0.8566433566433567, 0.7646853146853146, 0.6903846153846154]\n",
      "(3,)\n",
      "Participant ID:  4  Session ID:  0  Accuracy:  0.8926573426573426\n",
      "Participant ID:  4  Session ID:  1  Accuracy:  0.7398601398601399\n",
      "Participant ID:  4  Session ID:  2  Accuracy:  0.5937062937062937\n",
      "ACCURACY PARTICIPANT:  [0.8926573426573426, 0.7398601398601399, 0.5937062937062937]\n",
      "[[0.875      0.69475524 0.71416084]\n",
      " [0.89108392 0.8708042  0.87325175]\n",
      " [0.71363636 0.67657343 0.60192308]\n",
      " [0.85664336 0.76468531 0.69038462]\n",
      " [0.89265734 0.73986014 0.59370629]]\n",
      "[array([0.875     , 0.69475524, 0.71416084]), array([0.89108392, 0.8708042 , 0.87325175]), array([0.71363636, 0.67657343, 0.60192308]), array([0.85664336, 0.76468531, 0.69038462]), array([0.89265734, 0.73986014, 0.59370629])]\n",
      "OVERALL ACCURACY: 0.7632750582750583\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"DANN\"\n",
    "test_DANN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              num_neurons=num_kernels, path_weights_DA=path_DANN,\n",
    "                              algo_name=algo_name, save_path = save_DANN, \n",
    "                              number_of_cycles_total=number_of_cycles_total,\n",
    "                              path_weights_normal=path_TSD, number_of_classes=number_of_classes,\n",
    "                              cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.676573</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.73986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.694755      0.870804      0.676573      0.764685       0.73986\n",
       "Loc_2      0.714161      0.873252      0.601923      0.690385      0.593706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_DANN + '/predictions_' + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "DANN_acc = results[0]\n",
    "DANN_acc_overall = np.mean(DANN_acc)\n",
    "DANN_df = pd.DataFrame(DANN_acc.transpose(), \n",
    "                       index = [f'Loc_{i}' for i in range(DANN_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(DANN_acc.shape[0])])\n",
    "DANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"DANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (5, 3)\n",
      "predictions =  (5, 3)\n",
      "index_participant_list  [-1, 0, 1, 2]\n",
      "accuracies_gestures =  (22, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc-1</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub1_Loc-1</th>\n",
       "      <th>Sub1_Loc0</th>\n",
       "      <th>Sub1_Loc1</th>\n",
       "      <th>Sub2_Loc-1</th>\n",
       "      <th>Sub2_Loc0</th>\n",
       "      <th>Sub2_Loc1</th>\n",
       "      <th>Sub3_Loc-1</th>\n",
       "      <th>Sub3_Loc0</th>\n",
       "      <th>Sub3_Loc1</th>\n",
       "      <th>Sub4_Loc-1</th>\n",
       "      <th>Sub4_Loc0</th>\n",
       "      <th>Sub4_Loc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.580769</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.911538</td>\n",
       "      <td>0.511538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.742308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.257692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.415385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.607692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M6</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M7</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.365385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.465385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M10</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.742308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M11</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.603846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M12</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.419231</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.592308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M13</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.357692</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.334615</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M14</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.430769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.419231</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.126923</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.457692</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.619231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M17</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M18</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.965385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M19</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.911538</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.569231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M20</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.665385</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.719231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M21</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.676573</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.892657</td>\n",
       "      <td>0.739860</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sub0_Loc-1  Sub0_Loc0  Sub0_Loc1  Sub1_Loc-1  Sub1_Loc0  \\\n",
       "0          M0    1.000000   1.000000   1.000000    1.000000   1.000000   \n",
       "1          M1    0.973077   0.703846   0.753846    0.976923   0.873077   \n",
       "2          M2    0.707692   0.469231   0.876923    0.969231   0.957692   \n",
       "3          M3    0.919231   0.496154   0.992308    1.000000   0.953846   \n",
       "4          M4    0.865385   0.742308   0.257692    1.000000   0.973077   \n",
       "5          M5    0.953846   0.561538   0.915385    1.000000   0.900000   \n",
       "6          M6    0.992308   0.619231   0.715385    0.826923   0.992308   \n",
       "7          M7    0.926923   0.650000   0.473077    0.969231   0.773077   \n",
       "8          M8    1.000000   0.930769   0.930769    0.823077   1.000000   \n",
       "9          M9    1.000000   0.838462   0.846154    0.950000   0.988462   \n",
       "10        M10    0.961538   0.938462   0.700000    0.603846   0.961538   \n",
       "11        M11    0.946154   0.519231   0.765385    0.919231   0.942308   \n",
       "12        M12    0.930769   0.696154   0.419231    0.796154   0.884615   \n",
       "13        M13    0.919231   0.561538   0.357692    0.784615   0.946154   \n",
       "14        M14    0.719231   0.557692   0.761538    0.738462   0.600000   \n",
       "15        M15    0.576923   0.419231   0.526923    0.819231   0.607692   \n",
       "16        M16    0.750000   0.938462   0.507692    0.976923   0.950000   \n",
       "17        M17    0.988462   0.869231   0.892308    0.950000   0.919231   \n",
       "18        M18    0.980769   0.884615   0.753846    0.907692   0.961538   \n",
       "19        M19    0.492308   0.603846   0.607692    0.996154   0.619231   \n",
       "20        M20    0.873077   0.780769   0.900000    0.757692   0.976923   \n",
       "21        M21    0.773077   0.503846   0.757692    0.838462   0.376923   \n",
       "22       Mean    0.875000   0.694755   0.714161    0.891084   0.870804   \n",
       "\n",
       "    Sub1_Loc1  Sub2_Loc-1  Sub2_Loc0  Sub2_Loc1  Sub3_Loc-1  Sub3_Loc0  \\\n",
       "0    1.000000    1.000000   0.957692   1.000000    1.000000   1.000000   \n",
       "1    0.965385    0.342308   0.576923   0.661538    0.803846   0.711538   \n",
       "2    0.830769    0.515385   0.876923   0.442308    0.892308   0.592308   \n",
       "3    0.969231    0.830769   0.792308   0.953846    0.865385   0.469231   \n",
       "4    0.784615    0.819231   0.465385   0.519231    0.830769   0.761538   \n",
       "5    0.734615    0.865385   0.984615   0.842308    0.980769   0.942308   \n",
       "6    0.750000    0.926923   0.796154   0.776923    0.942308   0.919231   \n",
       "7    0.503846    0.584615   0.961538   0.130769    0.934615   0.592308   \n",
       "8    0.923077    0.826923   0.715385   0.542308    0.773077   0.692308   \n",
       "9    1.000000    0.803846   0.326923   0.603846    0.888462   0.838462   \n",
       "10   0.973077    0.761538   0.703846   0.361538    0.734615   0.680769   \n",
       "11   0.969231    0.430769   0.726923   0.365385    0.788462   0.730769   \n",
       "12   0.907692    0.573077   0.342308   0.603846    0.696154   0.826923   \n",
       "13   0.919231    0.000000   0.361538   0.334615    0.834615   0.842308   \n",
       "14   0.838462    0.565385   0.503846   0.423077    0.861538   0.726923   \n",
       "15   0.907692    0.673077   0.284615   0.126923    0.480769   0.719231   \n",
       "16   0.950000    0.892308   0.853846   0.865385    0.919231   0.946154   \n",
       "17   0.842308    1.000000   0.888462   0.869231    0.953846   0.930769   \n",
       "18   0.838462    0.942308   0.942308   0.723077    0.938462   0.773077   \n",
       "19   0.919231    0.973077   0.792308   0.911538    0.984615   0.953846   \n",
       "20   0.950000    0.976923   0.665385   0.503846    0.861538   0.353846   \n",
       "21   0.734615    0.396154   0.365385   0.680769    0.880769   0.819231   \n",
       "22   0.873252    0.713636   0.676573   0.601923    0.856643   0.764685   \n",
       "\n",
       "    Sub3_Loc1  Sub4_Loc-1  Sub4_Loc0  Sub4_Loc1  \n",
       "0    1.000000    1.000000   1.000000   1.000000  \n",
       "1    0.580769    0.961538   0.780769   0.576923  \n",
       "2    0.896154    0.915385   0.911538   0.511538  \n",
       "3    0.942308    0.946154   0.703846   0.742308  \n",
       "4    0.634615    0.853846   0.507692   0.415385  \n",
       "5    0.842308    0.976923   0.838462   0.607692  \n",
       "6    0.850000    0.961538   0.938462   0.673077  \n",
       "7    0.446154    0.915385   0.757692   0.365385  \n",
       "8    0.430769    0.861538   0.653846   0.465385  \n",
       "9    0.546154    0.757692   0.692308   0.642308  \n",
       "10   0.753846    0.865385   0.619231   0.742308  \n",
       "11   0.603846    0.834615   0.480769   0.603846  \n",
       "12   0.553846    0.692308   0.719231   0.592308  \n",
       "13   0.753846    0.815385   0.873077   0.423077  \n",
       "14   0.442308    0.907692   0.361538   0.430769  \n",
       "15   0.584615    0.696154   0.457692   0.250000  \n",
       "16   0.615385    0.957692   0.930769   0.619231  \n",
       "17   0.761538    0.973077   0.969231   0.700000  \n",
       "18   0.934615    0.976923   0.684615   0.965385  \n",
       "19   0.600000    0.957692   0.926923   0.569231  \n",
       "20   0.650000    0.915385   0.684615   0.719231  \n",
       "21   0.765385    0.896154   0.784615   0.446154  \n",
       "22   0.690385    0.892657   0.739860   0.593706  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_DANN, algo_name=algo_name)\n",
    "df = pd.read_csv(save_DANN+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCADANN\n",
    "* `run_SCADANN_training_sessions`: train SCADANN model. The first session uses TSD model_0 wegits; others use DANN weights\n",
    "    * specify `percentage_same_gesture_stable` based on the performance of most pseudo labels: \n",
    "        * print accuracies out and check what percentage will optimize `ACCURACY MODEL` and `ACCURACY PSEUDO` without cutting out too much data \n",
    "    * num_sessions-1 sets of training weights will be saved\n",
    "* `test_network_SLADANN`: test DANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_SCADANN import \\\n",
    "    run_SCADANN_training_sessions, test_network_SCADANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_same_gesture_stable = 0.75 \n",
    "# run_SCADANN_training_sessions(examples_datasets=examples_datasets_train, labels_datasets=labels_datasets_train,\n",
    "#                               num_kernels=num_kernels, feature_vector_input_length=feature_vector_input_length,\n",
    "#                               path_weights_to_save_to=path_SCADANN,\n",
    "#                               path_weights_Adversarial_training=path_DANN,\n",
    "#                               path_weights_Normal_training=path_TSD,\n",
    "#                               number_of_cycles_total = number_of_cycles_total, \n",
    "#                               number_of_classes=number_of_classes,\n",
    "#                               learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (2, 3)\n",
      "   valid  (2, 3)\n",
      "   test  (2, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (3, 3)\n",
      "   valid  (3, 3)\n",
      "   test  (3, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (4, 3)\n",
      "   valid  (4, 3)\n",
      "   test  (4, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (5, 3)\n",
      "   valid  (5, 3)\n",
      "   test  (5, 3)\n",
      "Participant:  0  Accuracy:  0.875\n",
      "Participant:  0  Accuracy:  0.7347902097902098\n",
      "Participant:  0  Accuracy:  0.7513986013986014\n",
      "ACCURACY PARTICIPANT:  [0.875, 0.7347902097902098, 0.7513986013986014]\n",
      "Participant:  1  Accuracy:  0.8910839160839161\n",
      "Participant:  1  Accuracy:  0.8993006993006993\n",
      "Participant:  1  Accuracy:  0.9068181818181819\n",
      "ACCURACY PARTICIPANT:  [0.8910839160839161, 0.8993006993006993, 0.9068181818181819]\n",
      "Participant:  2  Accuracy:  0.7136363636363636\n",
      "Participant:  2  Accuracy:  0.6970279720279721\n",
      "Participant:  2  Accuracy:  0.6361888111888112\n",
      "ACCURACY PARTICIPANT:  [0.7136363636363636, 0.6970279720279721, 0.6361888111888112]\n",
      "Participant:  3  Accuracy:  0.8566433566433567\n",
      "Participant:  3  Accuracy:  0.7839160839160839\n",
      "Participant:  3  Accuracy:  0.7496503496503496\n",
      "ACCURACY PARTICIPANT:  [0.8566433566433567, 0.7839160839160839, 0.7496503496503496]\n",
      "Participant:  4  Accuracy:  0.8926573426573426\n",
      "Participant:  4  Accuracy:  0.7809440559440559\n",
      "Participant:  4  Accuracy:  0.6157342657342657\n",
      "ACCURACY PARTICIPANT:  [0.8926573426573426, 0.7809440559440559, 0.6157342657342657]\n",
      "[[0.875      0.73479021 0.7513986 ]\n",
      " [0.89108392 0.8993007  0.90681818]\n",
      " [0.71363636 0.69702797 0.63618881]\n",
      " [0.85664336 0.78391608 0.74965035]\n",
      " [0.89265734 0.78094406 0.61573427]]\n",
      "[array([0.875     , 0.73479021, 0.7513986 ]), array([0.89108392, 0.8993007 , 0.90681818]), array([0.71363636, 0.69702797, 0.63618881]), array([0.85664336, 0.78391608, 0.74965035]), array([0.89265734, 0.78094406, 0.61573427])]\n",
      "OVERALL ACCURACY: 0.7856526806526808\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"SCADANN\"\n",
    "test_network_SCADANN(examples_datasets_train=examples_datasets_train, labels_datasets_train=labels_datasets_train,\n",
    "                     num_neurons=num_kernels, feature_vector_input_length=feature_vector_input_length,\n",
    "                     path_weights_SCADANN =path_SCADANN, path_weights_normal=path_TSD,\n",
    "                     algo_name=algo_name, cycle_test=3, number_of_cycles_total=number_of_cycles_total,\n",
    "                     number_of_classes=number_of_classes, save_path = save_SCADANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.73479</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.783916</td>\n",
       "      <td>0.780944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.751399</td>\n",
       "      <td>0.906818</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.74965</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1       0.73479      0.899301      0.697028      0.783916      0.780944\n",
       "Loc_2      0.751399      0.906818      0.636189       0.74965      0.615734"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_SCADANN + '/predictions_' + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "SCADANN_acc = results[0]\n",
    "SCADANN_acc_overall = np.mean(SCADANN_acc)\n",
    "SCADANN_df = pd.DataFrame(SCADANN_acc.transpose(), \n",
    "                       index = [f'Loc_{i}' for i in range(SCADANN_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(SCADANN_acc.shape[0])])\n",
    "SCADANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SCADANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"SCADANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (5, 3)\n",
      "predictions =  (5, 3)\n",
      "index_participant_list  [-1, 0, 1, 2]\n",
      "accuracies_gestures =  (22, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc-1</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub1_Loc-1</th>\n",
       "      <th>Sub1_Loc0</th>\n",
       "      <th>Sub1_Loc1</th>\n",
       "      <th>Sub2_Loc-1</th>\n",
       "      <th>Sub2_Loc0</th>\n",
       "      <th>Sub2_Loc1</th>\n",
       "      <th>Sub3_Loc-1</th>\n",
       "      <th>Sub3_Loc0</th>\n",
       "      <th>Sub3_Loc1</th>\n",
       "      <th>Sub4_Loc-1</th>\n",
       "      <th>Sub4_Loc0</th>\n",
       "      <th>Sub4_Loc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.569231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.473077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.588462</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.703846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M6</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.761538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M7</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.511538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M10</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.626923</td>\n",
       "      <td>0.742308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M11</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.642308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M12</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M13</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.457692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M14</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.669231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M17</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.696154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M18</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.915385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M19</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.580769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M20</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M21</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.469231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.734790</td>\n",
       "      <td>0.751399</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.906818</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.783916</td>\n",
       "      <td>0.749650</td>\n",
       "      <td>0.892657</td>\n",
       "      <td>0.780944</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sub0_Loc-1  Sub0_Loc0  Sub0_Loc1  Sub1_Loc-1  Sub1_Loc0  \\\n",
       "0          M0    1.000000   1.000000   1.000000    1.000000   1.000000   \n",
       "1          M1    0.973077   0.780769   0.850000    0.976923   0.903846   \n",
       "2          M2    0.707692   0.415385   0.953846    0.969231   0.973077   \n",
       "3          M3    0.919231   0.519231   0.996154    1.000000   0.969231   \n",
       "4          M4    0.865385   0.815385   0.242308    1.000000   1.000000   \n",
       "5          M5    0.953846   0.588462   0.969231    1.000000   0.957692   \n",
       "6          M6    0.992308   0.615385   0.876923    0.826923   0.996154   \n",
       "7          M7    0.926923   0.696154   0.584615    0.969231   0.776923   \n",
       "8          M8    1.000000   0.946154   0.969231    0.823077   1.000000   \n",
       "9          M9    1.000000   0.888462   0.842308    0.950000   0.992308   \n",
       "10        M10    0.961538   0.950000   0.726923    0.603846   0.950000   \n",
       "11        M11    0.946154   0.600000   0.800000    0.919231   0.996154   \n",
       "12        M12    0.930769   0.769231   0.400000    0.796154   0.965385   \n",
       "13        M13    0.919231   0.607692   0.442308    0.784615   0.969231   \n",
       "14        M14    0.719231   0.584615   0.615385    0.738462   0.684615   \n",
       "15        M15    0.576923   0.488462   0.615385    0.819231   0.623077   \n",
       "16        M16    0.750000   0.957692   0.476923    0.976923   0.961538   \n",
       "17        M17    0.988462   0.888462   0.930769    0.950000   0.973077   \n",
       "18        M18    0.980769   0.896154   0.830769    0.907692   0.965385   \n",
       "19        M19    0.492308   0.600000   0.723077    0.996154   0.669231   \n",
       "20        M20    0.873077   0.842308   0.915385    0.757692   0.996154   \n",
       "21        M21    0.773077   0.715385   0.769231    0.838462   0.461538   \n",
       "22       Mean    0.875000   0.734790   0.751399    0.891084   0.899301   \n",
       "\n",
       "    Sub1_Loc1  Sub2_Loc-1  Sub2_Loc0  Sub2_Loc1  Sub3_Loc-1  Sub3_Loc0  \\\n",
       "0    1.000000    1.000000   0.957692   1.000000    1.000000   1.000000   \n",
       "1    1.000000    0.342308   0.657692   0.611538    0.803846   0.742308   \n",
       "2    0.857692    0.515385   1.000000   0.623077    0.892308   0.584615   \n",
       "3    0.992308    0.830769   0.865385   0.980769    0.865385   0.503846   \n",
       "4    0.900000    0.819231   0.561538   0.569231    0.830769   0.838462   \n",
       "5    0.711538    0.865385   0.980769   0.946154    0.980769   0.996154   \n",
       "6    0.776923    0.926923   0.869231   0.769231    0.942308   0.934615   \n",
       "7    0.565385    0.584615   0.973077   0.034615    0.934615   0.634615   \n",
       "8    0.996154    0.826923   0.715385   0.673077    0.773077   0.723077   \n",
       "9    0.996154    0.803846   0.200000   0.688462    0.888462   0.853846   \n",
       "10   0.988462    0.761538   0.761538   0.507692    0.734615   0.734615   \n",
       "11   0.950000    0.430769   0.792308   0.450000    0.788462   0.746154   \n",
       "12   0.961538    0.573077   0.338462   0.634615    0.696154   0.884615   \n",
       "13   0.950000    0.000000   0.007692   0.007692    0.834615   0.907692   \n",
       "14   0.915385    0.565385   0.496154   0.426923    0.861538   0.765385   \n",
       "15   0.919231    0.673077   0.242308   0.153846    0.480769   0.573077   \n",
       "16   0.976923    0.892308   0.961538   0.892308    0.919231   0.919231   \n",
       "17   0.815385    1.000000   0.938462   0.984615    0.953846   0.884615   \n",
       "18   0.919231    0.942308   0.950000   0.803846    0.938462   0.884615   \n",
       "19   0.907692    0.973077   0.950000   0.961538    0.984615   0.973077   \n",
       "20   0.965385    0.976923   0.742308   0.546154    0.861538   0.311538   \n",
       "21   0.884615    0.396154   0.373077   0.730769    0.880769   0.850000   \n",
       "22   0.906818    0.713636   0.697028   0.636189    0.856643   0.783916   \n",
       "\n",
       "    Sub3_Loc1  Sub4_Loc-1  Sub4_Loc0  Sub4_Loc1  \n",
       "0    1.000000    1.000000   1.000000   1.000000  \n",
       "1    0.788462    0.961538   0.873077   0.569231  \n",
       "2    0.915385    0.915385   0.973077   0.550000  \n",
       "3    0.950000    0.946154   0.684615   0.800000  \n",
       "4    0.750000    0.853846   0.592308   0.473077  \n",
       "5    0.915385    0.976923   0.930769   0.703846  \n",
       "6    0.880769    0.961538   0.992308   0.761538  \n",
       "7    0.342308    0.915385   0.838462   0.350000  \n",
       "8    0.396154    0.861538   0.730769   0.511538  \n",
       "9    0.688462    0.757692   0.742308   0.646154  \n",
       "10   0.800000    0.865385   0.626923   0.742308  \n",
       "11   0.657692    0.834615   0.542308   0.642308  \n",
       "12   0.673077    0.692308   0.776923   0.596154  \n",
       "13   0.780769    0.815385   0.892308   0.457692  \n",
       "14   0.465385    0.907692   0.403846   0.446154  \n",
       "15   0.726923    0.696154   0.392308   0.234615  \n",
       "16   0.753846    0.957692   0.923077   0.669231  \n",
       "17   0.850000    0.973077   0.996154   0.696154  \n",
       "18   0.938462    0.976923   0.765385   0.915385  \n",
       "19   0.615385    0.957692   0.965385   0.580769  \n",
       "20   0.757692    0.915385   0.723077   0.730769  \n",
       "21   0.846154    0.896154   0.815385   0.469231  \n",
       "22   0.749650    0.892657   0.780944   0.615734  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_SCADANN, algo_name=algo_name)\n",
    "df = pd.read_csv(save_SCADANN+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Suppose there is a ndarray of NxM dataloaders, then N group of models will be trained, and each group will have M model. Each group is independent of the other, and each model within a group is dependent on its previous training weights.\n",
    "\n",
    "In general, overall accuracies of SCADANN are better than DANN, and DANN is better than TSD.\n",
    "Occasionally accuracies of SCADANN end up a little smaller than DANN, reasons may be lack of datasets put into training model (fixed) and non-optimal percentage_same_gesture_sable (fixed). Code should be reproducible if processed dataset sticks to the shape defined above.  \n",
    "\n",
    "The amount of increase in accuracies from DANN to SCADANN looks random. But if the base model is better at classifying one session, then its corresponding SCADANN is also better at classifying the same session. Given such result, to obtain the best performance from SCADANN, a good model trained with good data should be the starting point.\n",
    "\n",
    "* What to check if sth goes wrong:\n",
    "    * percentage_same_gesture_sable\n",
    "    * number of cycles or sessions\n",
    "    * shape of dataloaders (combination of train, test, valid should include all dataset)\n",
    "    * shape of procssed datasets\n",
    "    * directory paths of weights and results\n",
    "    * if weights are stored or loaded correclty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.732343</td>\n",
       "      <td>0.672203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.770105</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.567133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.698776      0.751923      0.598601      0.732343      0.672203\n",
       "Loc_2      0.650699      0.770105      0.540909      0.643706      0.567133"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.676573</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.73986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.694755      0.870804      0.676573      0.764685       0.73986\n",
       "Loc_2      0.714161      0.873252      0.601923      0.690385      0.593706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCADANN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.73479</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.783916</td>\n",
       "      <td>0.780944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.751399</td>\n",
       "      <td>0.906818</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.74965</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1       0.73479      0.899301      0.697028      0.783916      0.780944\n",
       "Loc_2      0.751399      0.906818      0.636189       0.74965      0.615734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"TSD\")\n",
    "display(TSD_df)\n",
    "print(\"DANN\")\n",
    "display(DANN_df)\n",
    "print(\"SCADANN\")\n",
    "display(SCADANN_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.147378</td>\n",
       "      <td>0.098427</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.108741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.136713</td>\n",
       "      <td>0.09528</td>\n",
       "      <td>0.105944</td>\n",
       "      <td>0.048601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_1      0.036014      0.147378      0.098427      0.051573      0.108741\n",
       "Loc_2      0.100699      0.136713       0.09528      0.105944      0.048601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_df = SCADANN_df-TSD_df\n",
    "diff_df = diff_df.drop('Loc_0')\n",
    "display(diff_df)\n",
    "diff_df.to_csv(save_TSD+'/diff_results/across_loc_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSD</th>\n",
       "      <td>0.723695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.763275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCADANN</th>\n",
       "      <td>0.785653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Overall_Acc\n",
       "TSD         0.723695\n",
       "DANN        0.763275\n",
       "SCADANN     0.785653"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc_df = pd.DataFrame([TSD_acc_overall, DANN_acc_overall, SCADANN_acc_overall],\n",
    "                             index = [\"TSD\", \"DANN\", \"SCADANN\"],\n",
    "                             columns = [\"Overall_Acc\"])\n",
    "overall_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,20))\n",
    "acc_list = [TSD_df, DANN_df, SCADANN_df, overall_acc_df]\n",
    "title_list = [\"TSD\", \"DANN\", \"SCADANN\", \"Overall\"]\n",
    "for idx, ax in enumerate(axes.reshape(-1)): \n",
    "    acc_list[idx].transpose().plot.bar(ax = ax, rot=0)\n",
    "    ax.set_title(title_list[idx])\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(str(np.round(p.get_height(),2)), (p.get_x()+p.get_width()/2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 8),textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking only at the average accuracy of individual participants among all sessions above, both overall and individual accuracies are increasing (the overall accuracy increases from 72% to 79%), so SCADANN is feasible in improving accuracy when trained across wearing locations. The overall acurracy for across location training is generally better than other cases. Though wearing location is to decrease the model performance, it has less effect than other controlling factor such as subjects and days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
