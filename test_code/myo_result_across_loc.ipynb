{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of TSD, DANN, SCADANN models across 3 wearing locations \n",
    "\n",
    "Library used can be downloaded from https://github.com/aonai/long_term_EMG_myo   \n",
    "&emsp; Original by UlysseCoteAllard https://github.com/UlysseCoteAllard/LongTermEMG   \n",
    "Dataset recorded by https://github.com/Suguru55/Wearable_Sensor_Long-term_sEMG_Dataset   \n",
    "Extended robot project can be found in https://github.com/aonai/myo_robot_arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* weights for TSD are total of 15 training models, 3 for each subject\n",
    "* weights for DANN and SCADANN are total of 10 trianing models, 2 for each subject \n",
    "\n",
    "\n",
    "* training examples should have shape (5, 3, 40, 572, 252)\n",
    "* training labels should have shape (5, 3, 40, 572)\n",
    "\n",
    "\n",
    "* location 0, 1, and 2 corresponds to neutral position, inward rotation, and outward rotation respectively\n",
    "* session mentioned below is wearing location, so number of sessions is 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data\n",
    "\n",
    "### specify the directories used for running the code:\n",
    "* `code_diar`: path to long_term_EMG_myo library\n",
    "* `data_dir`: where raw dataset is loaded; raw data is in csv format\n",
    "* `processed_data_dir`: where processed dataset is loaded; processed data is in npy pickle format\n",
    "    * processed data should be a ndarray of shape   \n",
    "    (controlling_factor_1 x controlling_factor_2 x num_sessions_per_gesture x #examples_window*#mov(26*22=572) x processed_channel_shape(252 for TSD, (4,8,10) for ConvNet)\n",
    "* `path_<model_name>`: where model weights are saved\n",
    "    * weights should be saved in folder `/Weights/<model_name>`. Each folder has subfolders containing weights for the first controlling factor.\n",
    "    * weights for base model (TSD or ConvNet) contain m set of training model\n",
    "    * weights for DANN and SCADANN contain m-1 set of trianing model (these models are trianed based on TSD, so they do not have a best_state_0.pt model). \n",
    "* `save_<model_name>`: where model results are saved\n",
    "    * each result for testing a model on a group of dataset is saved in folder `results`. Each result has corresponding \n",
    "        * `<model_name>.txt` includes predictions, ground truths, array of accuracies for each participant and each session, and overall accuracy\n",
    "        * `predictions_<model_name>.npy` includes array of accuracies, ground truths, predictions, and model outputs (probability array for each prediction)\n",
    "        * remember to make blank files in these names before saving\n",
    "\n",
    "\n",
    "\n",
    "* use `read_data_training` to process raw dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo\"\n",
    "os.chdir(code_dir)\n",
    "from PrepareAndLoadData.process_data import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/laiy/gitrepos/msr_final/Wearable_Sensor_Long-term_sEMG_Dataset/data\"\n",
    "processed_data_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Processed_datasets_across_loc\"\n",
    "save_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Results\"\n",
    "\n",
    "path_TSD =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_across_loc/TSD\"\n",
    "save_TSD = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\"\n",
    "\n",
    "path_DANN =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_across_loc/DANN\"\n",
    "save_DANN = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\"\n",
    "\n",
    "path_SCADANN =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_across_loc/SCADANN\"\n",
    "save_SCADANN = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_data_training(path=data_dir, store_path = processed_data_dir, num_participant=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning examples  (5, 3, 40, 572, 252)\n",
      "traning labels  (5, 3, 40, 572)\n"
     ]
    }
   ],
   "source": [
    "# check stored pickle \n",
    "with open(processed_data_dir + \"/training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "print('traning examples ', np.shape(examples_datasets_train))\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "print('traning labels ', np.shape(labels_datasets_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify params used for training and testing\n",
    "\n",
    "During training and testing, processed datasets are first put into pytorch dataloders, then feed to the model trainer; following are params for TSD model and dataloaders\n",
    "\n",
    "* `num_kernels`: list of integers defining number of neurons used in each linear layer (linear block has `dropout`=0.5)\n",
    "* `number_of_cycles_total`: number of trails performed for each session (assuming that all session have the same trail size)\n",
    "    * 40 for myo\n",
    "* `number_of_classes`: total number of gestures performed in dataset\n",
    "    * 22 for myo\n",
    "* `batch_size`: number of examples stored in each batch\n",
    "* `feature_vector_input_length`: length of input array or each processed signal; i.e. size of one training example \n",
    "    * 252 for TSD\n",
    "* `learning_rate`= 0.002515\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_cycles_total  40\n"
     ]
    }
   ],
   "source": [
    "num_kernels=[200, 200, 200]                       \n",
    "number_of_cycles_total=np.shape(examples_datasets_train[0][0])[0]              \n",
    "print(\"number_of_cycles_total \", number_of_cycles_total)\n",
    "number_of_classes=22\n",
    "batch_size=128          \n",
    "feature_vector_input_length=252                    \n",
    "learning_rate=0.002515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TSD_DNN\n",
    "* `train_fine_tuning`: used to train data using a base model (TSD or ConvNet)\n",
    "    * running this function will save num_sessions sets of TSD model weights (each is fine tuned based on the previous training)  \n",
    "    \n",
    "* `test_standard_model_on_training_sessions`: test model result\n",
    "\n",
    "\n",
    "### check if dataloaders are loaded correctly:\n",
    "* each participant has shape (num_session x 40 x 572 x 252)\n",
    "* each session has shape (40 x 572 x 252)\n",
    "* put these data into on group ends up with shape (40*572=22880, 252)\n",
    "    * shuffle on group of data and put into dataloaders\n",
    "    * each participant should have num_sessions sets of dataloaders, each correspond to one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_standard import \\\n",
    "            test_standard_model_on_training_sessions, train_fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fine_tuning(examples_datasets_train, labels_datasets_train,\n",
    "#                   num_kernels=num_kernels, path_weight_to_save_to=path_TSD,\n",
    "#                   number_of_classes=number_of_classes, number_of_cycles_total=number_of_cycles_total,\n",
    "#                   batch_size=batch_size,\n",
    "#                   feature_vector_input_length=feature_vector_input_length,\n",
    "#                   learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (2, 3)\n",
      "   valid  (2, 3)\n",
      "   test  (2, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (3, 3)\n",
      "   valid  (3, 3)\n",
      "   test  (3, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (4, 3)\n",
      "   valid  (4, 3)\n",
      "   test  (4, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (5, 3)\n",
      "   valid  (5, 3)\n",
      "   test  (5, 3)\n",
      "0  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.875\n",
      "1  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.6987762237762237\n",
      "2  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.6506993006993007\n",
      "ACCURACY PARTICIPANT  0 :  [0.875, 0.6987762237762237, 0.6506993006993007]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  1  Accuracy:  0.8910839160839161\n",
      "1  SESSION   data =  5720\n",
      "Participant:  1  Accuracy:  0.7519230769230769\n",
      "2  SESSION   data =  5720\n",
      "Participant:  1  Accuracy:  0.7701048951048951\n",
      "ACCURACY PARTICIPANT  1 :  [0.8910839160839161, 0.7519230769230769, 0.7701048951048951]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  2  Accuracy:  0.7136363636363636\n",
      "1  SESSION   data =  5720\n",
      "Participant:  2  Accuracy:  0.5986013986013986\n",
      "2  SESSION   data =  5720\n",
      "Participant:  2  Accuracy:  0.5409090909090909\n",
      "ACCURACY PARTICIPANT  2 :  [0.7136363636363636, 0.5986013986013986, 0.5409090909090909]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  3  Accuracy:  0.8566433566433567\n",
      "1  SESSION   data =  5720\n",
      "Participant:  3  Accuracy:  0.7323426573426574\n",
      "2  SESSION   data =  5720\n",
      "Participant:  3  Accuracy:  0.6437062937062937\n",
      "ACCURACY PARTICIPANT  3 :  [0.8566433566433567, 0.7323426573426574, 0.6437062937062937]\n",
      "0  SESSION   data =  5720\n",
      "Participant:  4  Accuracy:  0.8926573426573426\n",
      "1  SESSION   data =  5720\n",
      "Participant:  4  Accuracy:  0.6722027972027972\n",
      "2  SESSION   data =  5720\n",
      "Participant:  4  Accuracy:  0.5671328671328671\n",
      "ACCURACY PARTICIPANT  4 :  [0.8926573426573426, 0.6722027972027972, 0.5671328671328671]\n",
      "[array([0.875     , 0.69877622, 0.6506993 ]), array([0.89108392, 0.75192308, 0.7701049 ]), array([0.71363636, 0.5986014 , 0.54090909]), array([0.85664336, 0.73234266, 0.64370629]), array([0.89265734, 0.6722028 , 0.56713287])]\n",
      "OVERALL ACCURACY: 0.7236946386946387\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"standard_TSD\"\n",
    "test_standard_model_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=num_kernels, use_only_first_training=True,\n",
    "                                  path_weights=path_TSD,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  save_path = save_TSD, algo_name=algo_name,\n",
    "                                  number_of_cycles_total=number_of_cycles_total,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.732343</td>\n",
       "      <td>0.672203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.770105</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.567133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.698776      0.751923      0.598601      0.732343      0.672203\n",
       "Loc_2      0.650699      0.770105      0.540909      0.643706      0.567133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_TSD + '/predictions_' + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "TSD_acc = results[0]\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc.transpose(), \n",
    "                       index = [f'Loc_{i}' for i in range(TSD_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(TSD_acc.shape[0])])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.utils import get_gesture_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (5, 3)\n",
      "predictions =  (5, 3)\n",
      "index_participant_list  [0, 1, 2, 3, 4]\n",
      "accuracies_gestures =  (22, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub0_Loc2</th>\n",
       "      <th>Sub1_Loc0</th>\n",
       "      <th>Sub1_Loc1</th>\n",
       "      <th>Sub1_Loc2</th>\n",
       "      <th>Sub2_Loc0</th>\n",
       "      <th>Sub2_Loc1</th>\n",
       "      <th>Sub2_Loc2</th>\n",
       "      <th>Sub3_Loc0</th>\n",
       "      <th>Sub3_Loc1</th>\n",
       "      <th>Sub3_Loc2</th>\n",
       "      <th>Sub4_Loc0</th>\n",
       "      <th>Sub4_Loc1</th>\n",
       "      <th>Sub4_Loc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.088462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.542308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.561538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.669231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.334615</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.226923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.665385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.546154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M6</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M7</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.396154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.511538</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.488462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M10</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M11</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.188462</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.511538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M12</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.411538</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M13</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M14</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.373077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.203846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.703846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M17</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.911538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.734615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M18</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M19</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.588462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M20</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M21</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.392308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.770105</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.732343</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.892657</td>\n",
       "      <td>0.672203</td>\n",
       "      <td>0.567133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sub0_Loc0  Sub0_Loc1  Sub0_Loc2  Sub1_Loc0  Sub1_Loc1  \\\n",
       "0          M0   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "1          M1   0.973077   0.780769   0.907692   0.976923   0.953846   \n",
       "2          M2   0.707692   0.415385   0.550000   0.969231   0.880769   \n",
       "3          M3   0.919231   0.469231   0.996154   1.000000   0.950000   \n",
       "4          M4   0.865385   0.907692   0.430769   1.000000   0.996154   \n",
       "5          M5   0.953846   0.646154   0.753846   1.000000   0.992308   \n",
       "6          M6   0.992308   0.707692   0.726923   0.826923   0.896154   \n",
       "7          M7   0.926923   0.630769   0.611538   0.969231   0.600000   \n",
       "8          M8   1.000000   0.973077   0.723077   0.823077   0.946154   \n",
       "9          M9   1.000000   0.750000   0.769231   0.950000   0.823077   \n",
       "10        M10   0.961538   0.930769   0.684615   0.603846   0.896154   \n",
       "11        M11   0.946154   0.807692   0.730769   0.919231   0.719231   \n",
       "12        M12   0.930769   0.700000   0.573077   0.796154   0.403846   \n",
       "13        M13   0.919231   0.553846   0.176923   0.784615   0.503846   \n",
       "14        M14   0.719231   0.496154   0.630769   0.738462   0.365385   \n",
       "15        M15   0.576923   0.296154   0.473077   0.819231   0.346154   \n",
       "16        M16   0.750000   0.800000   0.165385   0.976923   0.953846   \n",
       "17        M17   0.988462   0.815385   0.953846   0.950000   0.711538   \n",
       "18        M18   0.980769   0.842308   0.792308   0.907692   0.934615   \n",
       "19        M19   0.492308   0.534615   0.273077   0.996154   0.646154   \n",
       "20        M20   0.873077   0.715385   0.761538   0.757692   0.753846   \n",
       "21        M21   0.773077   0.600000   0.630769   0.838462   0.269231   \n",
       "22       Mean   0.875000   0.698776   0.650699   0.891084   0.751923   \n",
       "\n",
       "    Sub1_Loc2  Sub2_Loc0  Sub2_Loc1  Sub2_Loc2  Sub3_Loc0  Sub3_Loc1  \\\n",
       "0    1.000000   1.000000   0.980769   1.000000   1.000000   1.000000   \n",
       "1    0.903846   0.342308   0.088462   0.700000   0.803846   0.846154   \n",
       "2    0.988462   0.515385   0.461538   0.246154   0.892308   0.476923   \n",
       "3    0.984615   0.830769   0.723077   0.550000   0.865385   0.346154   \n",
       "4    0.492308   0.819231   0.334615   0.426923   0.830769   0.803846   \n",
       "5    0.953846   0.865385   0.984615   0.292308   0.980769   0.957692   \n",
       "6    0.726923   0.926923   0.838462   0.803846   0.942308   0.884615   \n",
       "7    0.684615   0.584615   0.746154   0.284615   0.934615   0.373077   \n",
       "8    0.703846   0.826923   0.876923   0.511538   0.773077   0.600000   \n",
       "9    0.530769   0.803846   0.696154   0.842308   0.888462   0.803846   \n",
       "10   0.653846   0.761538   0.584615   0.265385   0.734615   0.607692   \n",
       "11   0.850000   0.430769   0.692308   0.188462   0.788462   0.738462   \n",
       "12   0.711538   0.573077   0.365385   0.411538   0.696154   0.746154   \n",
       "13   0.342308   0.000000   0.057692   0.000000   0.834615   0.903846   \n",
       "14   0.780769   0.565385   0.307692   0.488462   0.861538   0.723077   \n",
       "15   0.750000   0.673077   0.284615   0.250000   0.480769   0.634615   \n",
       "16   0.973077   0.892308   0.857692   0.842308   0.919231   0.969231   \n",
       "17   0.911538   1.000000   0.803846   0.938462   0.953846   0.892308   \n",
       "18   0.661538   0.942308   0.961538   0.680769   0.938462   0.703846   \n",
       "19   0.938462   0.973077   0.446154   0.965385   0.984615   0.965385   \n",
       "20   0.634615   0.976923   0.746154   0.703846   0.861538   0.311538   \n",
       "21   0.765385   0.396154   0.330769   0.507692   0.880769   0.823077   \n",
       "22   0.770105   0.713636   0.598601   0.540909   0.856643   0.732343   \n",
       "\n",
       "    Sub3_Loc2  Sub4_Loc0  Sub4_Loc1  Sub4_Loc2  \n",
       "0    1.000000   1.000000   1.000000   1.000000  \n",
       "1    0.423077   0.961538   0.788462   0.542308  \n",
       "2    0.803846   0.915385   0.873077   0.561538  \n",
       "3    0.903846   0.946154   0.542308   0.669231  \n",
       "4    0.496154   0.853846   0.353846   0.226923  \n",
       "5    0.665385   0.976923   0.684615   0.546154  \n",
       "6    0.853846   0.961538   0.776923   0.596154  \n",
       "7    0.603846   0.915385   0.623077   0.396154  \n",
       "8    0.192308   0.861538   0.680769   0.488462  \n",
       "9    0.442308   0.757692   0.557692   0.550000  \n",
       "10   0.773077   0.865385   0.326923   0.646154  \n",
       "11   0.553846   0.834615   0.273077   0.511538  \n",
       "12   0.619231   0.692308   0.634615   0.442308  \n",
       "13   0.765385   0.815385   0.750000   0.461538  \n",
       "14   0.388462   0.907692   0.346154   0.373077  \n",
       "15   0.530769   0.696154   0.438462   0.203846  \n",
       "16   0.403846   0.957692   0.930769   0.703846  \n",
       "17   0.734615   0.973077   0.961538   0.734615  \n",
       "18   0.930769   0.976923   0.726923   0.984615  \n",
       "19   0.773077   0.957692   0.780769   0.588462  \n",
       "20   0.523077   0.915385   0.800000   0.857692  \n",
       "21   0.780769   0.896154   0.938462   0.392308  \n",
       "22   0.643706   0.892657   0.672203   0.567133  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_TSD, algo_name=algo_name)\n",
    "df = pd.read_csv(save_TSD+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DANN\n",
    "* `train_DANN`: train DANN model using the first set of training weights from base model\n",
    "    * num_sessions-1 sets of training weights will be saved\n",
    "* `test_DANN_on_training_sessions`: test DANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_DA import train_DANN, test_DANN_on_training_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_DANN(examples_datasets_train, labels_datasets_train, \n",
    "#           num_kernels=num_kernels,\n",
    "#           path_weights_fine_tuning=path_TSD,\n",
    "#           number_of_classes=number_of_classes,\n",
    "#           number_of_cycles_total = number_of_cycles_total,\n",
    "#           batch_size=batch_size,\n",
    "#           feature_vector_input_length=feature_vector_input_length,\n",
    "#           path_weights_to_save_to=path_DANN, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (2, 3)\n",
      "   valid  (2, 3)\n",
      "   test  (2, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (3, 3)\n",
      "   valid  (3, 3)\n",
      "   test  (3, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (4, 3)\n",
      "   valid  (4, 3)\n",
      "   test  (4, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (5, 3)\n",
      "   valid  (5, 3)\n",
      "   test  (5, 3)\n",
      "(3,)\n",
      "Participant ID:  0  Session ID:  0  Accuracy:  0.875\n",
      "Participant ID:  0  Session ID:  1  Accuracy:  0.6947552447552447\n",
      "Participant ID:  0  Session ID:  2  Accuracy:  0.7141608391608392\n",
      "ACCURACY PARTICIPANT:  [0.875, 0.6947552447552447, 0.7141608391608392]\n",
      "(3,)\n",
      "Participant ID:  1  Session ID:  0  Accuracy:  0.8910839160839161\n",
      "Participant ID:  1  Session ID:  1  Accuracy:  0.8708041958041958\n",
      "Participant ID:  1  Session ID:  2  Accuracy:  0.8732517482517482\n",
      "ACCURACY PARTICIPANT:  [0.8910839160839161, 0.8708041958041958, 0.8732517482517482]\n",
      "(3,)\n",
      "Participant ID:  2  Session ID:  0  Accuracy:  0.7136363636363636\n",
      "Participant ID:  2  Session ID:  1  Accuracy:  0.6765734265734266\n",
      "Participant ID:  2  Session ID:  2  Accuracy:  0.6019230769230769\n",
      "ACCURACY PARTICIPANT:  [0.7136363636363636, 0.6765734265734266, 0.6019230769230769]\n",
      "(3,)\n",
      "Participant ID:  3  Session ID:  0  Accuracy:  0.8566433566433567\n",
      "Participant ID:  3  Session ID:  1  Accuracy:  0.7646853146853146\n",
      "Participant ID:  3  Session ID:  2  Accuracy:  0.6903846153846154\n",
      "ACCURACY PARTICIPANT:  [0.8566433566433567, 0.7646853146853146, 0.6903846153846154]\n",
      "(3,)\n",
      "Participant ID:  4  Session ID:  0  Accuracy:  0.8926573426573426\n",
      "Participant ID:  4  Session ID:  1  Accuracy:  0.7398601398601399\n",
      "Participant ID:  4  Session ID:  2  Accuracy:  0.5937062937062937\n",
      "ACCURACY PARTICIPANT:  [0.8926573426573426, 0.7398601398601399, 0.5937062937062937]\n",
      "[[0.875      0.69475524 0.71416084]\n",
      " [0.89108392 0.8708042  0.87325175]\n",
      " [0.71363636 0.67657343 0.60192308]\n",
      " [0.85664336 0.76468531 0.69038462]\n",
      " [0.89265734 0.73986014 0.59370629]]\n",
      "[array([0.875     , 0.69475524, 0.71416084]), array([0.89108392, 0.8708042 , 0.87325175]), array([0.71363636, 0.67657343, 0.60192308]), array([0.85664336, 0.76468531, 0.69038462]), array([0.89265734, 0.73986014, 0.59370629])]\n",
      "OVERALL ACCURACY: 0.7632750582750583\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"DANN\"\n",
    "test_DANN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              num_neurons=num_kernels, path_weights_DA=path_DANN,\n",
    "                              algo_name=algo_name, save_path = save_DANN, \n",
    "                              number_of_cycles_total=number_of_cycles_total,\n",
    "                              path_weights_normal=path_TSD, number_of_classes=number_of_classes,\n",
    "                              cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.676573</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.73986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.694755      0.870804      0.676573      0.764685       0.73986\n",
       "Loc_2      0.714161      0.873252      0.601923      0.690385      0.593706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_DANN + '/predictions_' + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "DANN_acc = results[0]\n",
    "DANN_acc_overall = np.mean(DANN_acc)\n",
    "DANN_df = pd.DataFrame(DANN_acc.transpose(), \n",
    "                       index = [f'Loc_{i}' for i in range(DANN_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(DANN_acc.shape[0])])\n",
    "DANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"DANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (5, 3)\n",
      "predictions =  (5, 3)\n",
      "index_participant_list  [0, 1, 2, 3, 4]\n",
      "accuracies_gestures =  (22, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub0_Loc2</th>\n",
       "      <th>Sub1_Loc0</th>\n",
       "      <th>Sub1_Loc1</th>\n",
       "      <th>Sub1_Loc2</th>\n",
       "      <th>Sub2_Loc0</th>\n",
       "      <th>Sub2_Loc1</th>\n",
       "      <th>Sub2_Loc2</th>\n",
       "      <th>Sub3_Loc0</th>\n",
       "      <th>Sub3_Loc1</th>\n",
       "      <th>Sub3_Loc2</th>\n",
       "      <th>Sub4_Loc0</th>\n",
       "      <th>Sub4_Loc1</th>\n",
       "      <th>Sub4_Loc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.580769</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.911538</td>\n",
       "      <td>0.511538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.742308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.257692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.415385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.607692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M6</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.673077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M7</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.365385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.465385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M10</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.703846</td>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.742308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M11</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.603846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M12</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.419231</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.592308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M13</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.357692</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.334615</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M14</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.361538</td>\n",
       "      <td>0.430769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.419231</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>0.126923</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.457692</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.619231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M17</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M18</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.965385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M19</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.911538</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.569231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M20</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.665385</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.719231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M21</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.376923</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.676573</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.892657</td>\n",
       "      <td>0.739860</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sub0_Loc0  Sub0_Loc1  Sub0_Loc2  Sub1_Loc0  Sub1_Loc1  \\\n",
       "0          M0   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "1          M1   0.973077   0.703846   0.753846   0.976923   0.873077   \n",
       "2          M2   0.707692   0.469231   0.876923   0.969231   0.957692   \n",
       "3          M3   0.919231   0.496154   0.992308   1.000000   0.953846   \n",
       "4          M4   0.865385   0.742308   0.257692   1.000000   0.973077   \n",
       "5          M5   0.953846   0.561538   0.915385   1.000000   0.900000   \n",
       "6          M6   0.992308   0.619231   0.715385   0.826923   0.992308   \n",
       "7          M7   0.926923   0.650000   0.473077   0.969231   0.773077   \n",
       "8          M8   1.000000   0.930769   0.930769   0.823077   1.000000   \n",
       "9          M9   1.000000   0.838462   0.846154   0.950000   0.988462   \n",
       "10        M10   0.961538   0.938462   0.700000   0.603846   0.961538   \n",
       "11        M11   0.946154   0.519231   0.765385   0.919231   0.942308   \n",
       "12        M12   0.930769   0.696154   0.419231   0.796154   0.884615   \n",
       "13        M13   0.919231   0.561538   0.357692   0.784615   0.946154   \n",
       "14        M14   0.719231   0.557692   0.761538   0.738462   0.600000   \n",
       "15        M15   0.576923   0.419231   0.526923   0.819231   0.607692   \n",
       "16        M16   0.750000   0.938462   0.507692   0.976923   0.950000   \n",
       "17        M17   0.988462   0.869231   0.892308   0.950000   0.919231   \n",
       "18        M18   0.980769   0.884615   0.753846   0.907692   0.961538   \n",
       "19        M19   0.492308   0.603846   0.607692   0.996154   0.619231   \n",
       "20        M20   0.873077   0.780769   0.900000   0.757692   0.976923   \n",
       "21        M21   0.773077   0.503846   0.757692   0.838462   0.376923   \n",
       "22       Mean   0.875000   0.694755   0.714161   0.891084   0.870804   \n",
       "\n",
       "    Sub1_Loc2  Sub2_Loc0  Sub2_Loc1  Sub2_Loc2  Sub3_Loc0  Sub3_Loc1  \\\n",
       "0    1.000000   1.000000   0.957692   1.000000   1.000000   1.000000   \n",
       "1    0.965385   0.342308   0.576923   0.661538   0.803846   0.711538   \n",
       "2    0.830769   0.515385   0.876923   0.442308   0.892308   0.592308   \n",
       "3    0.969231   0.830769   0.792308   0.953846   0.865385   0.469231   \n",
       "4    0.784615   0.819231   0.465385   0.519231   0.830769   0.761538   \n",
       "5    0.734615   0.865385   0.984615   0.842308   0.980769   0.942308   \n",
       "6    0.750000   0.926923   0.796154   0.776923   0.942308   0.919231   \n",
       "7    0.503846   0.584615   0.961538   0.130769   0.934615   0.592308   \n",
       "8    0.923077   0.826923   0.715385   0.542308   0.773077   0.692308   \n",
       "9    1.000000   0.803846   0.326923   0.603846   0.888462   0.838462   \n",
       "10   0.973077   0.761538   0.703846   0.361538   0.734615   0.680769   \n",
       "11   0.969231   0.430769   0.726923   0.365385   0.788462   0.730769   \n",
       "12   0.907692   0.573077   0.342308   0.603846   0.696154   0.826923   \n",
       "13   0.919231   0.000000   0.361538   0.334615   0.834615   0.842308   \n",
       "14   0.838462   0.565385   0.503846   0.423077   0.861538   0.726923   \n",
       "15   0.907692   0.673077   0.284615   0.126923   0.480769   0.719231   \n",
       "16   0.950000   0.892308   0.853846   0.865385   0.919231   0.946154   \n",
       "17   0.842308   1.000000   0.888462   0.869231   0.953846   0.930769   \n",
       "18   0.838462   0.942308   0.942308   0.723077   0.938462   0.773077   \n",
       "19   0.919231   0.973077   0.792308   0.911538   0.984615   0.953846   \n",
       "20   0.950000   0.976923   0.665385   0.503846   0.861538   0.353846   \n",
       "21   0.734615   0.396154   0.365385   0.680769   0.880769   0.819231   \n",
       "22   0.873252   0.713636   0.676573   0.601923   0.856643   0.764685   \n",
       "\n",
       "    Sub3_Loc2  Sub4_Loc0  Sub4_Loc1  Sub4_Loc2  \n",
       "0    1.000000   1.000000   1.000000   1.000000  \n",
       "1    0.580769   0.961538   0.780769   0.576923  \n",
       "2    0.896154   0.915385   0.911538   0.511538  \n",
       "3    0.942308   0.946154   0.703846   0.742308  \n",
       "4    0.634615   0.853846   0.507692   0.415385  \n",
       "5    0.842308   0.976923   0.838462   0.607692  \n",
       "6    0.850000   0.961538   0.938462   0.673077  \n",
       "7    0.446154   0.915385   0.757692   0.365385  \n",
       "8    0.430769   0.861538   0.653846   0.465385  \n",
       "9    0.546154   0.757692   0.692308   0.642308  \n",
       "10   0.753846   0.865385   0.619231   0.742308  \n",
       "11   0.603846   0.834615   0.480769   0.603846  \n",
       "12   0.553846   0.692308   0.719231   0.592308  \n",
       "13   0.753846   0.815385   0.873077   0.423077  \n",
       "14   0.442308   0.907692   0.361538   0.430769  \n",
       "15   0.584615   0.696154   0.457692   0.250000  \n",
       "16   0.615385   0.957692   0.930769   0.619231  \n",
       "17   0.761538   0.973077   0.969231   0.700000  \n",
       "18   0.934615   0.976923   0.684615   0.965385  \n",
       "19   0.600000   0.957692   0.926923   0.569231  \n",
       "20   0.650000   0.915385   0.684615   0.719231  \n",
       "21   0.765385   0.896154   0.784615   0.446154  \n",
       "22   0.690385   0.892657   0.739860   0.593706  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_DANN, algo_name=algo_name)\n",
    "df = pd.read_csv(save_DANN+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCADANN\n",
    "* `run_SCADANN_training_sessions`: train SCADANN model. The first session uses TSD model_0 wegits; others use DANN weights\n",
    "    * specify `percentage_same_gesture_stable` based on the performance of most pseudo labels: \n",
    "        * print accuracies out and check what percentage will optimize `ACCURACY MODEL` and `ACCURACY PSEUDO` without cutting out too much data \n",
    "    * num_sessions-1 sets of training weights will be saved\n",
    "* `test_network_SLADANN`: test DANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_SCADANN import \\\n",
    "    run_SCADANN_training_sessions, test_network_SCADANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage_same_gesture_stable = 0.75 \n",
    "# run_SCADANN_training_sessions(examples_datasets=examples_datasets_train, labels_datasets=labels_datasets_train,\n",
    "#                               num_kernels=num_kernels, feature_vector_input_length=feature_vector_input_length,\n",
    "#                               path_weights_to_save_to=path_SCADANN,\n",
    "#                               path_weights_Adversarial_training=path_DANN,\n",
    "#                               path_weights_Normal_training=path_TSD,\n",
    "#                               number_of_cycles_total = number_of_cycles_total, \n",
    "#                               number_of_classes=number_of_classes,\n",
    "#                               learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (2, 3)\n",
      "   valid  (2, 3)\n",
      "   test  (2, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (3, 3)\n",
      "   valid  (3, 3)\n",
      "   test  (3, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (4, 3)\n",
      "   valid  (4, 3)\n",
      "   test  (4, 3)\n",
      "GET one participant_examples  (3, 40, 572, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  0\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  1\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "   GET one training_index_examples  (40, 572, 252)  at  2\n",
      "   GOT one group XY  (22880, 252)    (22880,)\n",
      "       one group XY test  (5720, 252)    (5720, 252)\n",
      "       one group XY train (20592, 252)    (20592,)\n",
      "       one group XY valid (2288, 252)    (2288, 252)\n",
      "dataloaders: \n",
      "   train  (5, 3)\n",
      "   valid  (5, 3)\n",
      "   test  (5, 3)\n",
      "Participant:  0  Accuracy:  0.875\n",
      "Participant:  0  Accuracy:  0.7347902097902098\n",
      "Participant:  0  Accuracy:  0.7513986013986014\n",
      "ACCURACY PARTICIPANT:  [0.875, 0.7347902097902098, 0.7513986013986014]\n",
      "Participant:  1  Accuracy:  0.8910839160839161\n",
      "Participant:  1  Accuracy:  0.8993006993006993\n",
      "Participant:  1  Accuracy:  0.9068181818181819\n",
      "ACCURACY PARTICIPANT:  [0.8910839160839161, 0.8993006993006993, 0.9068181818181819]\n",
      "Participant:  2  Accuracy:  0.7136363636363636\n",
      "Participant:  2  Accuracy:  0.6970279720279721\n",
      "Participant:  2  Accuracy:  0.6361888111888112\n",
      "ACCURACY PARTICIPANT:  [0.7136363636363636, 0.6970279720279721, 0.6361888111888112]\n",
      "Participant:  3  Accuracy:  0.8566433566433567\n",
      "Participant:  3  Accuracy:  0.7839160839160839\n",
      "Participant:  3  Accuracy:  0.7496503496503496\n",
      "ACCURACY PARTICIPANT:  [0.8566433566433567, 0.7839160839160839, 0.7496503496503496]\n",
      "Participant:  4  Accuracy:  0.8926573426573426\n",
      "Participant:  4  Accuracy:  0.7809440559440559\n",
      "Participant:  4  Accuracy:  0.6157342657342657\n",
      "ACCURACY PARTICIPANT:  [0.8926573426573426, 0.7809440559440559, 0.6157342657342657]\n",
      "[[0.875      0.73479021 0.7513986 ]\n",
      " [0.89108392 0.8993007  0.90681818]\n",
      " [0.71363636 0.69702797 0.63618881]\n",
      " [0.85664336 0.78391608 0.74965035]\n",
      " [0.89265734 0.78094406 0.61573427]]\n",
      "[array([0.875     , 0.73479021, 0.7513986 ]), array([0.89108392, 0.8993007 , 0.90681818]), array([0.71363636, 0.69702797, 0.63618881]), array([0.85664336, 0.78391608, 0.74965035]), array([0.89265734, 0.78094406, 0.61573427])]\n",
      "OVERALL ACCURACY: 0.7856526806526808\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"SCADANN\"\n",
    "test_network_SCADANN(examples_datasets_train=examples_datasets_train, labels_datasets_train=labels_datasets_train,\n",
    "                     num_neurons=num_kernels, feature_vector_input_length=feature_vector_input_length,\n",
    "                     path_weights_SCADANN =path_SCADANN, path_weights_normal=path_TSD,\n",
    "                     algo_name=algo_name, cycle_test=3, number_of_cycles_total=number_of_cycles_total,\n",
    "                     number_of_classes=number_of_classes, save_path = save_SCADANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.73479</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.783916</td>\n",
       "      <td>0.780944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.751399</td>\n",
       "      <td>0.906818</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.74965</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1       0.73479      0.899301      0.697028      0.783916      0.780944\n",
       "Loc_2      0.751399      0.906818      0.636189       0.74965      0.615734"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_SCADANN + '/predictions_' + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "SCADANN_acc = results[0]\n",
    "SCADANN_acc_overall = np.mean(SCADANN_acc)\n",
    "SCADANN_df = pd.DataFrame(SCADANN_acc.transpose(), \n",
    "                       index = [f'Loc_{i}' for i in range(SCADANN_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(SCADANN_acc.shape[0])])\n",
    "SCADANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SCADANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"SCADANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (5, 3)\n",
      "predictions =  (5, 3)\n",
      "index_participant_list  [0, 1, 2, 3, 4]\n",
      "accuracies_gestures =  (22, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub0_Loc2</th>\n",
       "      <th>Sub1_Loc0</th>\n",
       "      <th>Sub1_Loc1</th>\n",
       "      <th>Sub1_Loc2</th>\n",
       "      <th>Sub2_Loc0</th>\n",
       "      <th>Sub2_Loc1</th>\n",
       "      <th>Sub2_Loc2</th>\n",
       "      <th>Sub3_Loc0</th>\n",
       "      <th>Sub3_Loc1</th>\n",
       "      <th>Sub3_Loc2</th>\n",
       "      <th>Sub4_Loc0</th>\n",
       "      <th>Sub4_Loc1</th>\n",
       "      <th>Sub4_Loc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.569231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.503846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.561538</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.473077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.588462</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.703846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M6</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.761538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M7</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.511538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M10</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.603846</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.761538</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.734615</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.626923</td>\n",
       "      <td>0.742308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M11</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.642308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M12</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M13</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.607692</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.457692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M14</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.565385</td>\n",
       "      <td>0.496154</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.465385</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M15</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.623077</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.234615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M16</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.669231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M17</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.930769</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.696154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M18</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.919231</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.915385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M19</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.973077</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.580769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M20</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.742308</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M21</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.715385</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.880769</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.469231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.734790</td>\n",
       "      <td>0.751399</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.906818</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.783916</td>\n",
       "      <td>0.749650</td>\n",
       "      <td>0.892657</td>\n",
       "      <td>0.780944</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sub0_Loc0  Sub0_Loc1  Sub0_Loc2  Sub1_Loc0  Sub1_Loc1  \\\n",
       "0          M0   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "1          M1   0.973077   0.780769   0.850000   0.976923   0.903846   \n",
       "2          M2   0.707692   0.415385   0.953846   0.969231   0.973077   \n",
       "3          M3   0.919231   0.519231   0.996154   1.000000   0.969231   \n",
       "4          M4   0.865385   0.815385   0.242308   1.000000   1.000000   \n",
       "5          M5   0.953846   0.588462   0.969231   1.000000   0.957692   \n",
       "6          M6   0.992308   0.615385   0.876923   0.826923   0.996154   \n",
       "7          M7   0.926923   0.696154   0.584615   0.969231   0.776923   \n",
       "8          M8   1.000000   0.946154   0.969231   0.823077   1.000000   \n",
       "9          M9   1.000000   0.888462   0.842308   0.950000   0.992308   \n",
       "10        M10   0.961538   0.950000   0.726923   0.603846   0.950000   \n",
       "11        M11   0.946154   0.600000   0.800000   0.919231   0.996154   \n",
       "12        M12   0.930769   0.769231   0.400000   0.796154   0.965385   \n",
       "13        M13   0.919231   0.607692   0.442308   0.784615   0.969231   \n",
       "14        M14   0.719231   0.584615   0.615385   0.738462   0.684615   \n",
       "15        M15   0.576923   0.488462   0.615385   0.819231   0.623077   \n",
       "16        M16   0.750000   0.957692   0.476923   0.976923   0.961538   \n",
       "17        M17   0.988462   0.888462   0.930769   0.950000   0.973077   \n",
       "18        M18   0.980769   0.896154   0.830769   0.907692   0.965385   \n",
       "19        M19   0.492308   0.600000   0.723077   0.996154   0.669231   \n",
       "20        M20   0.873077   0.842308   0.915385   0.757692   0.996154   \n",
       "21        M21   0.773077   0.715385   0.769231   0.838462   0.461538   \n",
       "22       Mean   0.875000   0.734790   0.751399   0.891084   0.899301   \n",
       "\n",
       "    Sub1_Loc2  Sub2_Loc0  Sub2_Loc1  Sub2_Loc2  Sub3_Loc0  Sub3_Loc1  \\\n",
       "0    1.000000   1.000000   0.957692   1.000000   1.000000   1.000000   \n",
       "1    1.000000   0.342308   0.657692   0.611538   0.803846   0.742308   \n",
       "2    0.857692   0.515385   1.000000   0.623077   0.892308   0.584615   \n",
       "3    0.992308   0.830769   0.865385   0.980769   0.865385   0.503846   \n",
       "4    0.900000   0.819231   0.561538   0.569231   0.830769   0.838462   \n",
       "5    0.711538   0.865385   0.980769   0.946154   0.980769   0.996154   \n",
       "6    0.776923   0.926923   0.869231   0.769231   0.942308   0.934615   \n",
       "7    0.565385   0.584615   0.973077   0.034615   0.934615   0.634615   \n",
       "8    0.996154   0.826923   0.715385   0.673077   0.773077   0.723077   \n",
       "9    0.996154   0.803846   0.200000   0.688462   0.888462   0.853846   \n",
       "10   0.988462   0.761538   0.761538   0.507692   0.734615   0.734615   \n",
       "11   0.950000   0.430769   0.792308   0.450000   0.788462   0.746154   \n",
       "12   0.961538   0.573077   0.338462   0.634615   0.696154   0.884615   \n",
       "13   0.950000   0.000000   0.007692   0.007692   0.834615   0.907692   \n",
       "14   0.915385   0.565385   0.496154   0.426923   0.861538   0.765385   \n",
       "15   0.919231   0.673077   0.242308   0.153846   0.480769   0.573077   \n",
       "16   0.976923   0.892308   0.961538   0.892308   0.919231   0.919231   \n",
       "17   0.815385   1.000000   0.938462   0.984615   0.953846   0.884615   \n",
       "18   0.919231   0.942308   0.950000   0.803846   0.938462   0.884615   \n",
       "19   0.907692   0.973077   0.950000   0.961538   0.984615   0.973077   \n",
       "20   0.965385   0.976923   0.742308   0.546154   0.861538   0.311538   \n",
       "21   0.884615   0.396154   0.373077   0.730769   0.880769   0.850000   \n",
       "22   0.906818   0.713636   0.697028   0.636189   0.856643   0.783916   \n",
       "\n",
       "    Sub3_Loc2  Sub4_Loc0  Sub4_Loc1  Sub4_Loc2  \n",
       "0    1.000000   1.000000   1.000000   1.000000  \n",
       "1    0.788462   0.961538   0.873077   0.569231  \n",
       "2    0.915385   0.915385   0.973077   0.550000  \n",
       "3    0.950000   0.946154   0.684615   0.800000  \n",
       "4    0.750000   0.853846   0.592308   0.473077  \n",
       "5    0.915385   0.976923   0.930769   0.703846  \n",
       "6    0.880769   0.961538   0.992308   0.761538  \n",
       "7    0.342308   0.915385   0.838462   0.350000  \n",
       "8    0.396154   0.861538   0.730769   0.511538  \n",
       "9    0.688462   0.757692   0.742308   0.646154  \n",
       "10   0.800000   0.865385   0.626923   0.742308  \n",
       "11   0.657692   0.834615   0.542308   0.642308  \n",
       "12   0.673077   0.692308   0.776923   0.596154  \n",
       "13   0.780769   0.815385   0.892308   0.457692  \n",
       "14   0.465385   0.907692   0.403846   0.446154  \n",
       "15   0.726923   0.696154   0.392308   0.234615  \n",
       "16   0.753846   0.957692   0.923077   0.669231  \n",
       "17   0.850000   0.973077   0.996154   0.696154  \n",
       "18   0.938462   0.976923   0.765385   0.915385  \n",
       "19   0.615385   0.957692   0.965385   0.580769  \n",
       "20   0.757692   0.915385   0.723077   0.730769  \n",
       "21   0.846154   0.896154   0.815385   0.469231  \n",
       "22   0.749650   0.892657   0.780944   0.615734  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_SCADANN, algo_name=algo_name)\n",
    "df = pd.read_csv(save_SCADANN+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Suppose there is a ndarray of NxM dataloaders, then N group of models will be trained, and each group will have M model. Each group is independent of the other, and each model within a group is dependent on its previous training weights.\n",
    "\n",
    "In general, overall accuracies of SCADANN are better than DANN, and DANN is better than TSD.\n",
    "Occasionally accuracies of SCADANN end up a little smaller than DANN, reasons may be lack of datasets put into training model (fixed) and non-optimal percentage_same_gesture_sable (fixed). Code should be reproducible if processed dataset sticks to the shape defined above.  \n",
    "\n",
    "The amount of increase in accuracies from DANN to SCADANN looks random. But if the base model is better at classifying one session, then its corresponding SCADANN is also better at classifying the same session. Given such result, to obtain the best performance from SCADANN, a good model trained with good data should be the starting point.\n",
    "\n",
    "* What to check if sth goes wrong:\n",
    "    * percentage_same_gesture_sable\n",
    "    * number of cycles or sessions\n",
    "    * shape of dataloaders (combination of train, test, valid should include all dataset)\n",
    "    * shape of procssed datasets\n",
    "    * directory paths of weights and results\n",
    "    * if weights are stored or loaded correclty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSD\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.698776</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.732343</td>\n",
       "      <td>0.672203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.770105</td>\n",
       "      <td>0.540909</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.567133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.698776      0.751923      0.598601      0.732343      0.672203\n",
       "Loc_2      0.650699      0.770105      0.540909      0.643706      0.567133"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>0.676573</td>\n",
       "      <td>0.764685</td>\n",
       "      <td>0.73986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.714161</td>\n",
       "      <td>0.873252</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.690385</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1      0.694755      0.870804      0.676573      0.764685       0.73986\n",
       "Loc_2      0.714161      0.873252      0.601923      0.690385      0.593706"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCADANN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_0</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.891084</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.856643</td>\n",
       "      <td>0.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.73479</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.783916</td>\n",
       "      <td>0.780944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.751399</td>\n",
       "      <td>0.906818</td>\n",
       "      <td>0.636189</td>\n",
       "      <td>0.74965</td>\n",
       "      <td>0.615734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_0         0.875      0.891084      0.713636      0.856643      0.892657\n",
       "Loc_1       0.73479      0.899301      0.697028      0.783916      0.780944\n",
       "Loc_2      0.751399      0.906818      0.636189       0.74965      0.615734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"TSD\")\n",
    "display(TSD_df)\n",
    "print(\"DANN\")\n",
    "display(DANN_df)\n",
    "print(\"SCADANN\")\n",
    "display(SCADANN_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "      <th>Participant_1</th>\n",
       "      <th>Participant_2</th>\n",
       "      <th>Participant_3</th>\n",
       "      <th>Participant_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loc_1</th>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.147378</td>\n",
       "      <td>0.098427</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.108741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loc_2</th>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.136713</td>\n",
       "      <td>0.09528</td>\n",
       "      <td>0.105944</td>\n",
       "      <td>0.048601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Participant_0 Participant_1 Participant_2 Participant_3 Participant_4\n",
       "Loc_1      0.036014      0.147378      0.098427      0.051573      0.108741\n",
       "Loc_2      0.100699      0.136713       0.09528      0.105944      0.048601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_df = SCADANN_df-TSD_df\n",
    "diff_df = diff_df.drop('Loc_0')\n",
    "display(diff_df)\n",
    "diff_df.to_csv(save_TSD+'/diff_results/across_loc_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSD</th>\n",
       "      <td>0.723695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.763275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCADANN</th>\n",
       "      <td>0.785653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Overall_Acc\n",
       "TSD         0.723695\n",
       "DANN        0.763275\n",
       "SCADANN     0.785653"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc_df = pd.DataFrame([TSD_acc_overall, DANN_acc_overall, SCADANN_acc_overall],\n",
    "                             index = [\"TSD\", \"DANN\", \"SCADANN\"],\n",
    "                             columns = [\"Overall_Acc\"])\n",
    "overall_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,20))\n",
    "acc_list = [TSD_df, DANN_df, SCADANN_df, overall_acc_df]\n",
    "title_list = [\"TSD\", \"DANN\", \"SCADANN\", \"Overall\"]\n",
    "for idx, ax in enumerate(axes.reshape(-1)): \n",
    "    acc_list[idx].transpose().plot.bar(ax = ax, rot=0)\n",
    "    ax.set_title(title_list[idx])\n",
    "    ax.set_ylim([0, 1.0])\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(str(np.round(p.get_height(),2)), (p.get_x()+p.get_width()/2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 8),textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking only at the average accuracy of individual participants among all sessions above, both overall and individual accuracies are increasing (the overall accuracy increases from 72% to 79%), so SCADANN is feasible in improving accuracy when trained across wearing locations. The overall acurracy for across location training is generally better than other cases. Though wearing location is to decrease the model performance, it has less effect than other controlling factor such as subjects and days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
