{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data\n",
    "\n",
    "### Training data includes the following gesture recordings from subject_1 at neutral wearing locations\n",
    "* rest\n",
    "* wrist flexion (WF)\n",
    "* forearm pronation and wrist extension (FP & WE)\n",
    "* radial deviation (RD)\n",
    "* ulnar deviation (UD)\n",
    "\n",
    "Check `train_for_ros_myo_one_subject.ipynb` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo\")\n",
    "from PrepareAndLoadData.process_data import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/laiy/gitrepos/msr_final/Wearable_Sensor_Long-term_sEMG_Dataset/data\"\n",
    "processed_data_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Processed_datasets_ros\"\n",
    "\n",
    "path_TSD =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_ros/TSD\"\n",
    "save_TSD = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_data_training(path=data_dir, store_path = processed_data_dir, num_participant=1, include_gestures = [1,2,10,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning examples  (1, 3, 40, 130, 252)\n",
      "traning labels  (1, 3, 40, 130)\n"
     ]
    }
   ],
   "source": [
    "# check stored pickle \n",
    "with open(processed_data_dir + \"/training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "print('traning examples ', np.shape(examples_datasets_train))\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "print('traning labels ', np.shape(labels_datasets_train))\n",
    "\n",
    "# 26 * 5 = 130 examples for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_cycles_total  40\n"
     ]
    }
   ],
   "source": [
    "num_kernels=[200, 200, 200]                        # model layer size \n",
    "number_of_cycles_total=np.shape(examples_datasets_train[0][0])[0]               # #session\n",
    "print(\"number_of_cycles_total \", number_of_cycles_total)\n",
    "number_of_classes=5\n",
    "batch_size=128          \n",
    "feature_vector_input_length=252                     # size of one example \n",
    "learning_rate=0.002515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TSD_DNN\n",
    "* The trained model is used for classifying right forearm gestures in the `myo_ros` project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 130, 252)\n",
      "   GET one training_index_examples  (40, 130, 252)  at  0\n",
      "   GOT one group XY  (5200, 252)    (5200,)\n",
      "       one group XY test  (0,)    (0,)\n",
      "       one group XY train (4680, 252)    (4680,)\n",
      "       one group XY valid (520, 252)    (520, 252)\n",
      "   GET one training_index_examples  (40, 130, 252)  at  1\n",
      "   GOT one group XY  (5200, 252)    (5200,)\n",
      "       one group XY test  (0,)    (0,)\n",
      "       one group XY train (4680, 252)    (4680,)\n",
      "       one group XY valid (520, 252)    (520, 252)\n",
      "   GET one training_index_examples  (40, 130, 252)  at  2\n",
      "   GOT one group XY  (5200, 252)    (5200,)\n",
      "       one group XY test  (0,)    (0,)\n",
      "       one group XY train (4680, 252)    (4680,)\n",
      "       one group XY valid (520, 252)    (520, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 0)\n",
      "START TRAINING\n",
      "Participant:  0\n",
      "Session:  0\n",
      "<generator object Module.parameters at 0x7efe449e3740>\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00185062 Acc: 0.93728299\n",
      "val Loss: 0.00003617 Acc: 0.99615385\n",
      "New best validation loss: 3.616625371460731e-05\n",
      "Epoch 1 of 500 took 0.397s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00025480 Acc: 0.99392361\n",
      "val Loss: 0.00000552 Acc: 1.0\n",
      "Epoch 2 of 500 took 0.392s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00008321 Acc: 0.99804688\n",
      "val Loss: 0.00000449 Acc: 1.0\n",
      "Epoch 3 of 500 took 0.418s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00014731 Acc: 0.99565972\n",
      "val Loss: 0.00000893 Acc: 0.99615385\n",
      "Epoch 4 of 500 took 0.388s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00018140 Acc: 0.99348958\n",
      "val Loss: 0.00008927 Acc: 0.98076923\n",
      "Epoch 5 of 500 took 0.330s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00009905 Acc: 0.99696181\n",
      "val Loss: 0.00000174 Acc: 1.0\n",
      "Epoch 6 of 500 took 0.376s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00007337 Acc: 0.99631076\n",
      "val Loss: 0.00002282 Acc: 0.99423077\n",
      "Epoch 7 of 500 took 0.498s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00009885 Acc: 0.99631076\n",
      "val Loss: 0.00000053 Acc: 1.0\n",
      "Epoch 8 of 500 took 0.496s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00006838 Acc: 0.99761285\n",
      "val Loss: 0.00000108 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.546s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00007340 Acc: 0.99696181\n",
      "val Loss: 0.00000388 Acc: 0.99807692\n",
      "Epoch 10 of 500 took 0.470s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00003230 Acc: 0.99891493\n",
      "val Loss: 0.00000236 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.561s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00005723 Acc: 0.99804688\n",
      "val Loss: 0.00000963 Acc: 0.99807692\n",
      "Epoch 12 of 500 took 0.684s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000036\n",
      "Session:  1\n",
      "<generator object Module.parameters at 0x7efe449e3890>\n",
      "=> loading checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_ros/TSD/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_ros/TSD/participant_0/best_state_0.pt' (epoch 1)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00049998 Acc: 0.98242188\n",
      "val Loss: 0.00002965 Acc: 0.99615385\n",
      "New best validation loss: 2.9649911448359488e-05\n",
      "Epoch 1 of 500 took 0.397s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00025406 Acc: 0.9906684\n",
      "val Loss: 0.00002249 Acc: 0.99615385\n",
      "Epoch 2 of 500 took 0.488s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00021283 Acc: 0.99023438\n",
      "val Loss: 0.00001461 Acc: 0.99807692\n",
      "Epoch 3 of 500 took 0.475s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00014008 Acc: 0.99457465\n",
      "val Loss: 0.00003536 Acc: 0.99615385\n",
      "Epoch 4 of 500 took 0.499s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00016927 Acc: 0.99283854\n",
      "val Loss: 0.00000436 Acc: 0.99807692\n",
      "Epoch 5 of 500 took 0.448s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00015994 Acc: 0.99414062\n",
      "val Loss: 0.00000945 Acc: 0.99807692\n",
      "Epoch 6 of 500 took 0.504s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00014888 Acc: 0.99435764\n",
      "val Loss: 0.00000690 Acc: 0.99807692\n",
      "Epoch 7 of 500 took 0.481s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00009891 Acc: 0.99544271\n",
      "val Loss: 0.00000630 Acc: 0.99807692\n",
      "Epoch 8 of 500 took 0.549s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00010442 Acc: 0.99631076\n",
      "val Loss: 0.00001584 Acc: 0.99807692\n",
      "Epoch 9 of 500 took 0.802s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00009150 Acc: 0.99652778\n",
      "val Loss: 0.00000734 Acc: 0.99807692\n",
      "Epoch 10 of 500 took 0.469s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00015576 Acc: 0.99414062\n",
      "val Loss: 0.00000693 Acc: 0.99807692\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 11 of 500 took 0.418s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00005165 Acc: 0.9984809\n",
      "val Loss: 0.00000178 Acc: 1.0\n",
      "Epoch 12 of 500 took 0.431s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000030\n",
      "Session:  2\n",
      "<generator object Module.parameters at 0x7efe449e3820>\n",
      "=> loading checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_ros/TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_ros/TSD/participant_0/best_state_1.pt' (epoch 1)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00070265 Acc: 0.97092014\n",
      "val Loss: 0.00006303 Acc: 0.99038462\n",
      "New best validation loss: 6.302625227432985e-05\n",
      "Epoch 1 of 500 took 0.412s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00047843 Acc: 0.97829861\n",
      "val Loss: 0.00009834 Acc: 0.97115385\n",
      "Epoch 2 of 500 took 0.445s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00036105 Acc: 0.98394097\n",
      "val Loss: 0.00004812 Acc: 0.99230769\n",
      "Epoch 3 of 500 took 0.424s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00031175 Acc: 0.98632812\n",
      "val Loss: 0.00001201 Acc: 1.0\n",
      "Epoch 4 of 500 took 0.435s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00030730 Acc: 0.98784722\n",
      "val Loss: 0.00001230 Acc: 1.0\n",
      "Epoch 5 of 500 took 0.428s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00020894 Acc: 0.99001736\n",
      "val Loss: 0.00002611 Acc: 0.99230769\n",
      "Epoch 6 of 500 took 0.429s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00015815 Acc: 0.99348958\n",
      "val Loss: 0.00001098 Acc: 0.99807692\n",
      "Epoch 7 of 500 took 0.429s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00019977 Acc: 0.99131944\n",
      "val Loss: 0.00000483 Acc: 1.0\n",
      "Epoch 8 of 500 took 0.420s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00024969 Acc: 0.98980035\n",
      "val Loss: 0.00000694 Acc: 1.0\n",
      "Epoch 9 of 500 took 0.421s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00015918 Acc: 0.99327257\n",
      "val Loss: 0.00000858 Acc: 1.0\n",
      "Epoch 10 of 500 took 0.471s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00020246 Acc: 0.99153646\n",
      "val Loss: 0.00000605 Acc: 1.0\n",
      "Epoch 11 of 500 took 0.454s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00022672 Acc: 0.98914931\n",
      "val Loss: 0.00010353 Acc: 0.97884615\n",
      "Epoch 12 of 500 took 0.431s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000063\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(examples_datasets_train, labels_datasets_train,\n",
    "                  num_kernels=num_kernels, path_weight_to_save_to=path_TSD,\n",
    "                  number_of_classes=number_of_classes, number_of_cycles_total=number_of_cycles_total,\n",
    "                  batch_size=batch_size,\n",
    "                  feature_vector_input_length=feature_vector_input_length,\n",
    "                  learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 130, 252)\n",
      "   GET one training_index_examples  (40, 130, 252)  at  0\n",
      "   GOT one group XY  (5200, 252)    (5200,)\n",
      "       one group XY test  (1300, 252)    (1300, 252)\n",
      "       one group XY train (4680, 252)    (4680,)\n",
      "       one group XY valid (520, 252)    (520, 252)\n",
      "   GET one training_index_examples  (40, 130, 252)  at  1\n",
      "   GOT one group XY  (5200, 252)    (5200,)\n",
      "       one group XY test  (1300, 252)    (1300, 252)\n",
      "       one group XY train (4680, 252)    (4680,)\n",
      "       one group XY valid (520, 252)    (520, 252)\n",
      "   GET one training_index_examples  (40, 130, 252)  at  2\n",
      "   GOT one group XY  (5200, 252)    (5200,)\n",
      "       one group XY test  (1300, 252)    (1300, 252)\n",
      "       one group XY train (4680, 252)    (4680,)\n",
      "       one group XY valid (520, 252)    (520, 252)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "0  SESSION   data =  1300\n",
      "Participant:  0  Accuracy:  0.9992307692307693\n",
      "1  SESSION   data =  1300\n",
      "Participant:  0  Accuracy:  0.9076923076923077\n",
      "2  SESSION   data =  1300\n",
      "Participant:  0  Accuracy:  0.9692307692307692\n",
      "ACCURACY PARTICIPANT  0 :  [0.9992307692307693, 0.9076923076923077, 0.9692307692307692]\n",
      "[array([0.99923077, 0.90769231, 0.96923077])]\n",
      "OVERALL ACCURACY: 0.9587179487179487\n"
     ]
    }
   ],
   "source": [
    "algo_name = \"standard_TSD\"\n",
    "test_TSD_DNN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=num_kernels, use_only_first_training=True,\n",
    "                                  path_weights=path_TSD,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  save_path = save_TSD, algo_name=algo_name,\n",
    "                                  number_of_cycles_total=number_of_cycles_total,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Session_0</th>\n",
       "      <td>0.999231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session_1</th>\n",
       "      <td>0.907692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session_2</th>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Participant_0\n",
       "Session_0      0.999231\n",
       "Session_1      0.907692\n",
       "Session_2      0.969231"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_TSD + '/predictions_' + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "TSD_acc = results[0]\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc.transpose(), \n",
    "                       index = [f'Session_{i}' for i in range(TSD_acc.shape[1])],\n",
    "                        columns = [f'Participant_{j}' for j in range(TSD_acc.shape[0])])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.utils import get_gesture_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground_truths  =  (1, 3)\n",
      "predictions =  (1, 3)\n",
      "accuracies_gestures =  (5, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sub0_Loc0</th>\n",
       "      <th>Sub0_Loc1</th>\n",
       "      <th>Sub0_Loc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.934615</td>\n",
       "      <td>0.888462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.999231</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.969231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  Sub0_Loc0  Sub0_Loc1  Sub0_Loc2\n",
       "0         M0   1.000000   1.000000   1.000000\n",
       "1         M1   1.000000   0.846154   1.000000\n",
       "2         M2   1.000000   1.000000   0.957692\n",
       "3         M3   1.000000   0.757692   1.000000\n",
       "4         M4   0.996154   0.934615   0.888462\n",
       "5       Mean   0.999231   0.907692   0.969231"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths = results[1]\n",
    "predictions = results[2]\n",
    "print(\"ground_truths  = \", np.shape(ground_truths))\n",
    "print(\"predictions = \", np.shape(predictions))\n",
    "m_name = \"Sub\"\n",
    "n_name = \"Loc\"\n",
    "df = get_gesture_accuracies(ground_truths, predictions, number_of_classes=number_of_classes, \n",
    "                            m_name=m_name, n_name=n_name, path=save_TSD, algo_name=algo_name)\n",
    "df = pd.read_csv(save_TSD+'/'+algo_name+'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Model\n",
    "Make sure the model can be saved and loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_example  (252,)\n",
      "test_label  4.0\n"
     ]
    }
   ],
   "source": [
    "test_example = examples_datasets_train[0][0][0][-1]\n",
    "test_label = labels_datasets_train[0][0][0][-1]\n",
    "\n",
    "print(\"test_example \", np.shape(test_example))\n",
    "print(\"test_label \", test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.TSD_neural_network import TSD_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_weights =\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_ros/TSD/participant_0/best_state_0.pt\"\n",
    "num_kernels=[200, 200, 200]                        # model layer size \n",
    "number_of_classes=5\n",
    "feature_vector_input_length=252                     # size of one example \n",
    "\n",
    "model = TSD_Network(number_of_class=number_of_classes, num_neurons=num_kernels,\n",
    "                            feature_vector_input_length=feature_vector_input_length)\n",
    "\n",
    "best_state = torch.load(path_weights)\n",
    "best_weights = best_state['state_dict']\n",
    "model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted =  4\n",
      "ground =  4.0\n"
     ]
    }
   ],
   "source": [
    "inputs  = torch.from_numpy(np.array([test_example], dtype=np.float32))\n",
    "model.eval()\n",
    "output = model(inputs)\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "print(\"predicted = \", predicted.numpy()[0])\n",
    "print(\"ground = \", test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
