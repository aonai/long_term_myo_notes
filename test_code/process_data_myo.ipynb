{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filename = D<#day>M<#motion/label>T<#trail>.csv\n",
    "* myo dataset\n",
    "    * total participants = 5\n",
    "    * total gestures = 22\n",
    "    * trails per parti = 4\n",
    "    * days per parti = 30\n",
    "    * total sessions = 3\n",
    "        * 10 days for each session\n",
    "    * each session = day\n",
    "   \n",
    "   \n",
    "* 3DC dataset\n",
    "    * total participants = 22\n",
    "    * total gestures = 11\n",
    "    * trails per parti = 4\n",
    "    * days (sessions) per parti = 4\n",
    "    * dataloaders per parti = 4 \n",
    "        * second cycle (max activation) is excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/laiy/gitrepos/msr_final/Wearable_Sensor_Long-term_sEMG_Dataset/data\"\n",
    "processed_data_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Processed_datasets\"\n",
    "code_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo\"\n",
    "save_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Results\"\n",
    "\n",
    "pos = ['N', 'I', 'O', 'N', 'I', 'I', 'O', 'O', 'N', 'N',      # 1-10th day \n",
    "      'O', 'N', 'N', 'O', 'O', 'I', 'I', 'I', 'N', 'O',       # 11-20th day\n",
    "      'O', 'I', 'O', 'I', 'I', 'N', 'N', 'I', 'N', 'O']       # 21-30th day\n",
    "\n",
    "pos_label = [1, 2, 3, 1, 2, 2, 3, 3, 1, 1,\n",
    "            3, 1, 1, 3, 3, 2, 2, 2, 1, 3,\n",
    "            3, 2, 3, 2, 2, 1, 1, 2, 1, 3] # N: 1, I: 2, O: 3\n",
    "\n",
    "day_num = 30\n",
    "sub_num = 5\n",
    "mov_num = 22\n",
    "fs = 200\n",
    "ch_num = 8\n",
    "trial_num = 4\n",
    "\n",
    "fs_pass = 15\n",
    "fil_order = 5\n",
    "\n",
    "win_size = 50            # 250ms window\n",
    "win_inc = 10             # 50ms overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 9, 10, 12, 13, 19, 26, 27, 29],\n",
       " [2, 5, 6, 16, 17, 18, 22, 24, 25, 28],\n",
       " [3, 7, 8, 11, 14, 15, 20, 21, 23, 30]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# days correspond to N, I, and O positions\n",
    "sessions_idx = [[],[],[]]\n",
    "for idx, pl in enumerate(pos_label):\n",
    "    sessions_idx[pl-1].append(idx+1)\n",
    "sessions_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTSDfeatures_for_one_representation(vector):\n",
    "    \"\"\"\n",
    "    % Implementation from Rami Khusaba\n",
    "    % Time-domain power spectral moments (TD-PSD)\n",
    "    % Using Fourier relations between time domina and frequency domain to\n",
    "    % extract power spectral moments dircetly from time domain.\n",
    "    %\n",
    "    % Modifications\n",
    "    % 17/11/2013  RK: Spectral moments first created.\n",
    "    % 02/03/2014  AT: I added 1 to the function name to differentiate it from other versions from Rami\n",
    "    % 01/02/2016  RK: Modifed this code intosomewhat deep structure\n",
    "    %\n",
    "    % References\n",
    "    % [1] A. Al-Timemy, R. N. Khushaba, G. Bugmann, and J. Escudero, \"Improving the Performance Against Force Variation of EMG Controlled Multifunctional Upper-Limb Prostheses for Transradial Amputees\",\n",
    "    %     IEEE Transactions on Neural Systems and Rehabilitation Engineering, DOI: 10.1109/TNSRE.2015.2445634, 2015.\n",
    "    % [2] R. N. Khushaba, Maen Takruri, Jaime Valls Miro, and Sarath Kodagoda, \"Towards limb position invariant myoelectric pattern recognition using time-dependent spectral features\",\n",
    "    %     Neural Networks, vol. 55, pp. 42-58, 2014.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the size of the input signal\n",
    "    samples, channels = vector.shape\n",
    "\n",
    "    if channels > samples:\n",
    "        vector = np.transpose(vector)\n",
    "        samples, channels = channels, samples\n",
    "\n",
    "    # Root squared zero order moment normalized\n",
    "    m0 = np.sqrt(np.nansum(vector ** 2, axis=0))[:, np.newaxis]\n",
    "    m0 = m0 ** .1 / .1\n",
    "\n",
    "    # Prepare derivatives for higher order moments\n",
    "    d1 = np.diff(np.concatenate([np.zeros((1, channels)), vector], axis=0), n=1, axis=0)\n",
    "    d2 = np.diff(np.concatenate([np.zeros((1, channels)), d1], axis=0), n=1, axis=0)\n",
    "\n",
    "    # Root squared 2nd and 4th order moments normalized\n",
    "    m2 = (np.sqrt(np.nansum(d1 ** 2, axis=0)) / (samples - 1))[:, np.newaxis]\n",
    "    m2 = m2 ** .1 / .1\n",
    "\n",
    "    m4 = (np.sqrt(np.nansum(d2 ** 2, axis=0)) / (samples - 1))[:, np.newaxis]\n",
    "    m4 = m4 ** .1 / .1\n",
    "\n",
    "    # Sparseness\n",
    "    sparsi = m0 / np.sqrt(np.abs(np.multiply((m0 - m2) ** 2, (m0 - m4) ** 2)))\n",
    "\n",
    "    # Irregularity Factor\n",
    "    IRF = m2 / np.sqrt(np.multiply(m0, m4))\n",
    "\n",
    "    # Coefficient of Variation\n",
    "    tmp = np.nanmean(vector, axis=0)\n",
    "    if 0 in tmp:   # avoid divison by zero case \n",
    "        tmp[tmp==0] = 1e-10\n",
    "    COV = (np.nanstd(vector, axis=0, ddof=1) / tmp)[:, np.newaxis]\n",
    "\n",
    "    # Teager-Kaiser energy operator\n",
    "    TEA = np.nansum(d1 ** 2 - np.multiply(vector[0:samples, :], d2), axis=0)[:, np.newaxis]\n",
    "\n",
    "    # All features together\n",
    "    STDD = np.nanstd(m0, axis=0, ddof=1)[:, np.newaxis]\n",
    "\n",
    "    if channels > 2:\n",
    "        Feat = np.concatenate((m0 / STDD, (m0 - m2) / STDD, (m0 - m4) / STDD, sparsi, IRF, COV, TEA), axis=0)\n",
    "    else:\n",
    "        Feat = np.concatenate((m0, m0 - m2, m0 - m4, sparsi, IRF, COV, TEA), axis=0)\n",
    "\n",
    "    Feat = np.log(np.abs(Feat)).flatten()\n",
    "\n",
    "    return Feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTSD(all_channels_data_in_window):\n",
    "    \"\"\"\n",
    "    This uses window emg directly instead of extracting a window then apply TSD like in Rami'code\n",
    "    \n",
    "        %Implementation from Rami Khusaba adapted to our code\n",
    "        % References\n",
    "        % [1] A. Al-Timemy, R. N. Khushaba, G. Bugmann, and J. Escudero, \"Improving the Performance Against Force Variation of EMG Controlled Multifunctional Upper-Limb Prostheses for Transradial Amputees\",\n",
    "        %     IEEE Transactions on Neural Systems and Rehabilitation Engineering, DOI: 10.1109/TNSRE.2015.2445634, 2015.\n",
    "        % [2] R. N. Khushaba, Maen Takruri, Jaime Valls Miro, and Sarath Kodagoda, \"Towards limb position invariant myoelectric pattern recognition using time-dependent spectral features\",\n",
    "        %     Neural Networks, vol. 55, pp. 42-58, 2014.\n",
    "    \"\"\"\n",
    "    # x should be a numpy array\n",
    "    all_channels_data_in_window = np.swapaxes(np.array(all_channels_data_in_window), 1, 0)\n",
    "\n",
    "    if len(all_channels_data_in_window.shape) == 1:\n",
    "        all_channels_data_in_window = all_channels_data_in_window[:, np.newaxis]\n",
    "\n",
    "    datasize = all_channels_data_in_window.shape[0]\n",
    "    Nsignals = all_channels_data_in_window.shape[1]\n",
    "\n",
    "    # prepare indices of each 2 channels combinations\n",
    "    # NCC = Number of channels to combine\n",
    "    NCC = 2\n",
    "    Indx = np.array(list(combinations(range(Nsignals), NCC)))   # (28,2)\n",
    "\n",
    "    # allocate memory\n",
    "    # define the number of features per channel\n",
    "    NFPC = 7\n",
    "\n",
    "    # Preallocate memory\n",
    "    feat = np.zeros((Indx.shape[0] * NFPC + Nsignals * NFPC))\n",
    "\n",
    "    # Step1.1: Extract between-channels features\n",
    "    ebp = getTSDfeatures_for_one_representation(\n",
    "        all_channels_data_in_window[:, Indx[:, 0]] - all_channels_data_in_window[:, Indx[:, 1]])\n",
    "    efp = getTSDfeatures_for_one_representation(\n",
    "        np.log(\n",
    "            (all_channels_data_in_window[:, Indx[:, 0]] - all_channels_data_in_window[:, Indx[:, 1]]) ** 2 + np.spacing(\n",
    "                1)) ** 2)\n",
    "    # Step 1.2: Correlation analysis\n",
    "    num = np.multiply(efp, ebp)\n",
    "    den = np.sqrt(np.multiply(efp, efp)) + np.sqrt(np.multiply(ebp, ebp))\n",
    "    feat[range(Indx.shape[0] * NFPC)] = num / den\n",
    "\n",
    "    # Step2.1: Extract within-channels features\n",
    "    ebp = getTSDfeatures_for_one_representation(all_channels_data_in_window)\n",
    "    efp = getTSDfeatures_for_one_representation(np.log((all_channels_data_in_window) ** 2 + np.spacing(1)) ** 2)\n",
    "    # Step2.2: Correlation analysis\n",
    "    num = np.multiply(efp, ebp)\n",
    "    den = np.sqrt(np.multiply(efp, efp)) + np.sqrt(np.multiply(ebp, ebp))\n",
    "    feat[np.max(range(Indx.shape[0] * NFPC)) + 1:] = num / den\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check TSD implementations\n",
      "[ 1.66371607  1.66384011  1.72873969  0.57375715  0.58066068  0.77698376\n",
      "  0.34551803  0.34280122  0.7670343   0.66016634  0.65935117  0.24134059\n",
      "  0.06078816  0.06078271  0.06325949  0.19869889  0.34002115  0.04613089\n",
      " -0.03433354  0.24671089  0.01165432  1.32489882  1.28015668  1.23306213\n",
      "  0.34843539  0.35125801  0.30172634  0.09836563  0.14334693  0.13194767\n",
      "  0.5315394   0.48664003  0.35045409  0.0659545   0.06957326  0.07320415\n",
      " -0.31086468 -0.07100652 -0.20960729 -0.06386305 -1.07034794 -0.00821557]\n",
      "[1.663716179, 1.663840215, 1.728739776, 0.573757313, 0.580660839, 0.776983895, 0.345518206, 0.342801404, 0.767034427, 0.660166337, 0.659351174, 0.241340596, 0.060788158, 0.060782713, 0.063259494, 0.198698886, 0.340021142, 0.046130887, -0.034333537, 0.246710895, 0.011654321, 1.324898831, 1.280156697, 1.233062152, 0.348435412, 0.351258045, 0.301726381, 0.09836566, 0.14334697, 0.13194771, 0.531539406, 0.48664003, 0.350454092, 0.065954505, 0.069573256, 0.073204152, -0.310864682, -0.07100652, -0.209607288, -0.063863048, -1.070347941, -0.008215568]\n",
      "Own implementation vs Rami Matlab:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Check TSD implementations\")\n",
    "tsd_data = np.array(\n",
    "    [[0.234631339, 0.569690978, 0.28497832, 0.767334908, 0.000929953, 0.955792684, 0.34489891, 0.901606785,\n",
    "      0.833662576, 0.293860399],\n",
    "     [0.022407932, 0.110714418, 0.173787089, 0.044756897, 0.608926394, 0.134628998, 0.373141251, 0.481913916,\n",
    "      0.360470935, 0.199844388],\n",
    "     [0.579233891, 0.596110557, 0.806037005, 0.889725032, 0.652525182, 0.193154786, 0.746598481, 0.627327263,\n",
    "      0.255035701, 0.200252276]])\n",
    "own_implementation = getTSD(tsd_data)\n",
    "matlab_result = [1.663716179, 1.663840215, 1.728739776, 0.573757313, 0.580660839, 0.776983895, 0.345518206,\n",
    "                 0.342801404, 0.767034427, 0.660166337, 0.659351174, 0.241340596, 0.060788158, 0.060782713,\n",
    "                 0.063259494, 0.198698886, 0.340021142, 0.046130887, -0.034333537, 0.246710895, 0.011654321,\n",
    "                 1.324898831, 1.280156697, 1.233062152, 0.348435412, 0.351258045, 0.301726381, 0.09836566,\n",
    "                 0.14334697, 0.13194771, 0.531539406, 0.48664003, 0.350454092, 0.065954505, 0.069573256,\n",
    "                 0.073204152, -0.310864682, -0.07100652, -0.209607288, -0.063863048, -1.070347941, -0.008215568]\n",
    "\n",
    "print(own_implementation)\n",
    "print(matlab_result)\n",
    "print(\"Own implementation vs Rami Matlab: \", np.allclose(own_implementation, matlab_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_examples(emg_examples, window_size=50, size_non_overlap=10):\n",
    "    ''' \n",
    "    emg_examples: list of emg signals, each row represent one recording of a 8 channel emg\n",
    "    feature_set_function\n",
    "    window_size: analysis window size\n",
    "    size_non_overlap: length of non-overlap portion between each analysis window\n",
    "    '''\n",
    "    formated_examples = []\n",
    "    example = []\n",
    "    for emg_vector in emg_examples:\n",
    "        if len(example) == 0:\n",
    "            example = emg_vector\n",
    "        else:\n",
    "            example = np.row_stack((example, emg_vector))\n",
    "        \n",
    "        # store one window_size of signal\n",
    "        if len(example) >= window_size:\n",
    "#             formated_examples.append(example.copy())\n",
    "            # print(\"   @ format one example \", np.shape(example.transpose()))\n",
    "            if not np.sum(example) == 0:   # avoid all zero signals\n",
    "                featured_example = getTSD(example.transpose())\n",
    "                formated_examples.append(np.array(featured_example).transpose().flatten())\n",
    "            else:\n",
    "                formated_examples.append(np.zeros((252)))\n",
    "            # print(\"   @ featured one example \",  np.shape(featured_example))\n",
    "           \n",
    "            # Remove part of the data of the example according to the size_non_overlap variable\n",
    "            example = example[size_non_overlap:]\n",
    "            \n",
    "    return formated_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_to_format_training_session(path_folder_examples, day_num,\n",
    "                                          number_of_cycles, number_of_gestures, window_size,\n",
    "                                          size_non_overlap):\n",
    "    \"\"\"\n",
    "    path_folder_examples: path to load training data\n",
    "    feature_set_function\n",
    "    number_of_cycles: number of trials recorded for each motion\n",
    "    number_of_gestures\n",
    "    window_size: analysis window size\n",
    "    size_non_overlap: length of non-overlap portion between each analysis window\n",
    "    \n",
    "    shape(formated_example) = (26, 50, 8)\n",
    "    \"\"\"\n",
    "    examples_training, labels_training = [], []\n",
    "    \n",
    "    for cycle in range(1, number_of_cycles+1):\n",
    "        examples, labels = [], []\n",
    "        for gesture_index in range(1, number_of_gestures+1):\n",
    "            read_file = path_folder_examples + \"/D\" + str(day_num) + \"M\" + str(gesture_index) + \"T\" + str(cycle) + \".csv\"\n",
    "#             print(\"      READ \", read_file)\n",
    "            examples_to_format = pd.read_csv(read_file, header=None).to_numpy()\n",
    "            # each file contains 15s (300 rows) of 8 channel signals \n",
    "#             print(\"            data = \", np.shape(examples_to_format))\n",
    "            \n",
    "            examples_formatted = format_examples(examples_to_format,\n",
    "                                     window_size=window_size,\n",
    "                                     size_non_overlap=size_non_overlap)\n",
    "#             print(\"            formated = \", np.shape(examples_formatted))\n",
    "\n",
    "            examples.extend(examples_formatted)\n",
    "            labels.extend(np.ones(len(examples_formatted)) * gesture_index)\n",
    "            \n",
    "#         print(\"   SHAPE SESSION \", cycle, \" EXAMPLES: \", np.shape(examples))\n",
    "        examples_training.append(examples)\n",
    "        labels_training.append(labels)\n",
    "#         print(\"   SHAPE ALL SESSION EXAMPLES: \", np.shape(examples_training))  \n",
    "\n",
    "    return examples_training, labels_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = data_dir\n",
    "store_path = processed_data_dir\n",
    "number_of_cycles = trial_num\n",
    "number_of_gestures = mov_num\n",
    "window_size = win_size\n",
    "size_non_overlap = win_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process data in days  [1, 4, 9, 10, 12, 13, 19, 26, 27, 29]\n",
      "@ traning sessions =  (1, 40, 572, 252)\n",
      "process data in days  [2, 5, 6, 16, 17, 18, 22, 24, 25, 28]\n",
      "@ traning sessions =  (2, 40, 572, 252)\n",
      "process data in days  [3, 7, 8, 11, 14, 15, 20, 21, 23, 30]\n",
      "@ traning sessions =  (3, 40, 572, 252)\n",
      "@ all traning sessions =  (1, 3, 40, 572, 252)\n",
      "process data in days  [1, 4, 9, 10, 12, 13, 19, 26, 27, 29]\n",
      "@ traning sessions =  (1, 40, 572, 252)\n",
      "process data in days  [2, 5, 6, 16, 17, 18, 22, 24, 25, 28]\n",
      "@ traning sessions =  (2, 40, 572, 252)\n",
      "process data in days  [3, 7, 8, 11, 14, 15, 20, 21, 23, 30]\n",
      "@ traning sessions =  (3, 40, 572, 252)\n",
      "@ all traning sessions =  (2, 3, 40, 572, 252)\n",
      "process data in days  [1, 4, 9, 10, 12, 13, 19, 26, 27, 29]\n",
      "@ traning sessions =  (1, 40, 572, 252)\n",
      "process data in days  [2, 5, 6, 16, 17, 18, 22, 24, 25, 28]\n",
      "@ traning sessions =  (2, 40, 572, 252)\n",
      "process data in days  [3, 7, 8, 11, 14, 15, 20, 21, 23, 30]\n",
      "@ traning sessions =  (3, 40, 572, 252)\n",
      "@ all traning sessions =  (3, 3, 40, 572, 252)\n"
     ]
    }
   ],
   "source": [
    "# load one participant for now\n",
    "examples_training_sessions_datasets = []\n",
    "labels_training_sessions_datasets = []\n",
    "\n",
    "for index_participant in range(1,4):\n",
    "    # load one participant data \n",
    "    folder_participant = \"sub\" + str(index_participant)\n",
    "    examples_participant_training_sessions, labels_participant_training_sessions = [], []\n",
    "    for days_of_current_session in sessions_idx:\n",
    "        print(\"process data in days \", days_of_current_session)\n",
    "        examples_per_session, labels_per_session = [], []\n",
    "        for day_num in days_of_current_session:\n",
    "            path_folder_examples = path + \"/\" + folder_participant + \"/day\" + str(day_num)\n",
    "#             print(\"current dir = \", day_num)\n",
    "            \n",
    "            examples_training, labels_training  = \\\n",
    "                read_files_to_format_training_session(path_folder_examples=path_folder_examples,\n",
    "                                                      day_num = day_num,\n",
    "                                                      number_of_cycles=number_of_cycles,\n",
    "                                                      number_of_gestures=number_of_gestures,\n",
    "                                                      window_size=window_size,\n",
    "                                                      size_non_overlap=size_non_overlap)\n",
    "            examples_per_session.extend(examples_training)\n",
    "            labels_per_session.extend(labels_training)\n",
    "        examples_participant_training_sessions.append(examples_per_session)\n",
    "        labels_participant_training_sessions.append(labels_per_session)\n",
    "        print(\"@ traning sessions = \", np.shape(examples_participant_training_sessions))\n",
    "        \n",
    "    examples_training_sessions_datasets.append(examples_participant_training_sessions)\n",
    "    labels_training_sessions_datasets.append(labels_participant_training_sessions)\n",
    "    print(\"@ all traning sessions = \", np.shape(examples_training_sessions_datasets))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning examples  (3, 40, 572, 252)\n",
      "all traning examples  (3, 3, 40, 572, 252)\n",
      "traning labels  (3, 40, 572)\n",
      "all traning labels  (3, 3, 40, 572)\n"
     ]
    }
   ],
   "source": [
    "# store processed data to dictionary\n",
    "\n",
    "# participants_num x sessions_num(3) x days_per_session(10)*trail_per_day(4) x #examples_window*#mov(26*22=572) x featured_window(252)\n",
    "print('traning examples ', np.shape(examples_participant_training_sessions))\n",
    "print('all traning examples ', np.shape(examples_training_sessions_datasets))\n",
    "\n",
    "# participants_num x sessions_num(3) x days_per_session(10)*trail_per_day(4) x #examples_window*#mov(26*22=572)\n",
    "print('traning labels ', np.shape(labels_participant_training_sessions))\n",
    "print('all traning labels ', np.shape(labels_training_sessions_datasets))\n",
    "\n",
    "dataset_dictionnary = {\"examples_training\": np.array(examples_training_sessions_datasets, dtype=object),\n",
    "                       \"labels_training\": np.array(labels_training_sessions_datasets, dtype=object)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store dictionary to pickle\n",
    "training_session_dataset_dictionnary = {}\n",
    "training_session_dataset_dictionnary[\"examples_training\"] = dataset_dictionnary[\"examples_training\"]\n",
    "training_session_dataset_dictionnary[\"labels_training\"] = dataset_dictionnary[\"labels_training\"]\n",
    "\n",
    "with open(store_path + \"raining_session.pickle\", 'wb') as f:\n",
    "    pickle.dump(training_session_dataset_dictionnary, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning examples  (3, 3, 40, 572, 252)\n",
      "traning labels  (3, 3, 40, 572)\n"
     ]
    }
   ],
   "source": [
    "# check stored pickle \n",
    "with open(store_path + \"raining_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "print('traning examples ', np.shape(examples_datasets_train))\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "print('traning labels ', np.shape(labels_datasets_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
