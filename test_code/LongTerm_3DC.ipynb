{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.insert(0,'../../LongTermEMG-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data\n",
    "* 20 participants total (exclude 10 and 11)\n",
    "* data from 3DC armband (10 channels with 1000 Hz)\n",
    "* 150 ms frames with overlap of 100 ms; band-pass filter between 20-495 Hz using fourth-order butterworth filter\n",
    "* dataset dict\n",
    "    * examples_training\n",
    "    * labels_training\n",
    "    * training_datetimes\n",
    "    * highest_activations\n",
    "    * examples_evaluation\n",
    "    * labels_evaluation\n",
    "    * evaluation_emg_timestamps\n",
    "    * angles_and_timestamps\n",
    "    * evaluation_datetimes\n",
    "* feature_set_function = feature_extraction.getTSD applied to each window \n",
    "    * exclude 0 sEMG recordings \n",
    "    * [1] A. Al-Timemy, R. N. Khushaba, G. Bugmann, and J. Escudero, \"Improving the Performance Against Force Variation of EMG Controlled Multifunctional Upper-Limb Prostheses for Transradial Amputees\", IEEE Transactions on Neural Systems and Rehabilitation Engineering, DOI: 10.1109/TNSRE.2015.2445634, 2015.\n",
    "    * [2] R. N. Khushaba, Maen Takruri, Jaime Valls Miro, and Sarath Kodagoda, \"Towards limb position invariant myoelectric pattern recognition using time-dependent spectral features\", Neural Networks, vol. 55, pp. 42-58, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm.prepare_dataset_utils import butter_bandpass_filter, \\\n",
    "    show_filtered_signal, load_timestamps_from_participant, get_angles_from_positions_3d_arm\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longterm_dataset_3DC.zip', 'longterm_dataset_3DC', 'README.md', 'LongTermClassificationMain', 'datasets', 'TransferLearning', '.idea', 'Weights_TSD']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/PrepareAndLoadDataLongTerm\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from handcrafted_features_prepare_from_from_raw_dataset import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_participant_training_1_to_skip = [\"Participant0/Training1\", \"Participant0/Evaluation2\", \"Participant0/Evaluation3\",\n",
    "                                       \"Participant2/Training1\", \"Participant2/Evaluation2\", \"Participant2/Evaluation3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_set_name = \"TSD_features_set\"\n",
    "# feature_set_function = feature_extraction.getTSD\n",
    "# read_data_training(path=\"../../datasets/longterm_dataset_3DC\", features_set_name=features_set_name, \\\n",
    "#                 feature_set_function=feature_set_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Temporal-Spatial Descriptors Deep Network (TSD_DNN)\n",
    "* input size = 128 x 3 x 1 = 384\n",
    "* 3 fully connected layers with 200 neurons \n",
    "    * batch normalization\n",
    "    * leaky ReLU (0.1)\n",
    "    * dropout (0.5)\n",
    "* mean cross entropy loss\n",
    "* optimization = ADAM (lr = 0.002515, beta = (0.5, 0.999))\n",
    "* lr_scheduler (1e-8)\n",
    "* dataloader needs\n",
    "    * examples_training\n",
    "    * labels_training\n",
    "   \n",
    "   \n",
    "### Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\n",
    "    * best_state_n.pt (n = # training session)\n",
    "        * epoch: #epochs\n",
    "        * model state_dict\n",
    "        * optimizer state_dict\n",
    "        * scheduler state_dict \n",
    "    * fine-tune from the previous training      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import train_Spectrogram_fine_tuning\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm. \\\n",
    "    load_dataset_spectrogram_in_dataloader import load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.utils_training_and_evaluation import create_confusion_matrix, \\\n",
    "    long_term_classification_graph, long_term_pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from train_tsd_dnn_standard import test_TSD_DNN_on_training_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "\n",
    "algo_name = \"11Gestures_standard_ConvNet_THREE_Cycles_TSD\"\n",
    "path_to_save_to = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "\n",
    "filter_size = [200, 200, 200]      \n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = None\n",
    "number_of_classes = 11                          \n",
    "learning_rate = 0.002515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2674, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2829, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2881, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2821, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2970, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2859, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2837, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2783, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2816, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2888, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2864, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2835, 385)\n",
      "Participant:  0\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01078506 Acc: 0.59921875\n",
      "val Loss: 0.00473772 Acc: 0.55704698\n",
      "New best validation loss: 0.004737716393182742\n",
      "Epoch 1 of 500 took 0.162s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00522106 Acc: 0.81484375\n",
      "val Loss: 0.00471500 Acc: 0.55033557\n",
      "New best validation loss: 0.004714995022588128\n",
      "Epoch 2 of 500 took 0.146s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00416198 Acc: 0.8453125\n",
      "val Loss: 0.00400784 Acc: 0.61744966\n",
      "New best validation loss: 0.004007844316879375\n",
      "Epoch 3 of 500 took 0.179s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00348485 Acc: 0.87148437\n",
      "val Loss: 0.00676295 Acc: 0.42281879\n",
      "Epoch 4 of 500 took 0.174s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00307632 Acc: 0.88554687\n",
      "val Loss: 0.00898366 Acc: 0.38926174\n",
      "Epoch 5 of 500 took 0.177s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00269824 Acc: 0.89414063\n",
      "val Loss: 0.01717294 Acc: 0.34228188\n",
      "Epoch 6 of 500 took 0.150s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00266772 Acc: 0.90703125\n",
      "val Loss: 0.00742899 Acc: 0.48993289\n",
      "Epoch 7 of 500 took 0.146s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00250256 Acc: 0.9078125\n",
      "val Loss: 0.00169821 Acc: 0.83557047\n",
      "New best validation loss: 0.0016982149357763713\n",
      "Epoch 8 of 500 took 0.138s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00237926 Acc: 0.90664062\n",
      "val Loss: 0.00195303 Acc: 0.78187919\n",
      "Epoch 9 of 500 took 0.141s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00219389 Acc: 0.91796875\n",
      "val Loss: 0.00267252 Acc: 0.7852349\n",
      "Epoch 10 of 500 took 0.135s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00197288 Acc: 0.91796875\n",
      "val Loss: 0.00649141 Acc: 0.62080537\n",
      "Epoch 11 of 500 took 0.141s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00219752 Acc: 0.91757813\n",
      "val Loss: 0.00139716 Acc: 0.87248322\n",
      "New best validation loss: 0.0013971620758107845\n",
      "Epoch 12 of 500 took 0.140s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00185842 Acc: 0.92304688\n",
      "val Loss: 0.00506645 Acc: 0.63087248\n",
      "Epoch 13 of 500 took 0.149s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00185123 Acc: 0.92773438\n",
      "val Loss: 0.00486095 Acc: 0.66442953\n",
      "Epoch 14 of 500 took 0.137s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00179670 Acc: 0.9265625\n",
      "val Loss: 0.01395356 Acc: 0.3590604\n",
      "Epoch 15 of 500 took 0.144s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00153678 Acc: 0.94140625\n",
      "val Loss: 0.00773399 Acc: 0.55033557\n",
      "Epoch 16 of 500 took 0.139s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00170495 Acc: 0.93359375\n",
      "val Loss: 0.01181150 Acc: 0.40604027\n",
      "Epoch 17 of 500 took 0.136s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00165472 Acc: 0.93867188\n",
      "val Loss: 0.00159672 Acc: 0.83892617\n",
      "Epoch    18: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 18 of 500 took 0.137s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00133228 Acc: 0.95429688\n",
      "val Loss: 0.00050231 Acc: 0.94630872\n",
      "New best validation loss: 0.0005023111432990772\n",
      "Epoch 19 of 500 took 0.160s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00124075 Acc: 0.95703125\n",
      "val Loss: 0.00060929 Acc: 0.94630872\n",
      "Epoch 20 of 500 took 0.134s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00114609 Acc: 0.96054688\n",
      "val Loss: 0.00081232 Acc: 0.9295302\n",
      "Epoch 21 of 500 took 0.140s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00113802 Acc: 0.95351562\n",
      "val Loss: 0.00064749 Acc: 0.94630872\n",
      "Epoch 22 of 500 took 0.135s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00108463 Acc: 0.95898438\n",
      "val Loss: 0.00058176 Acc: 0.93959732\n",
      "Epoch 23 of 500 took 0.145s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00112090 Acc: 0.9609375\n",
      "val Loss: 0.00039133 Acc: 0.96644295\n",
      "New best validation loss: 0.0003913283448091289\n",
      "Epoch 24 of 500 took 0.134s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00094436 Acc: 0.9640625\n",
      "val Loss: 0.00047555 Acc: 0.95973154\n",
      "Epoch 25 of 500 took 0.137s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00108957 Acc: 0.95976562\n",
      "val Loss: 0.00052084 Acc: 0.95973154\n",
      "Epoch 26 of 500 took 0.134s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00094187 Acc: 0.96601563\n",
      "val Loss: 0.00034917 Acc: 0.96979866\n",
      "New best validation loss: 0.00034917393486771806\n",
      "Epoch 27 of 500 took 0.138s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00102510 Acc: 0.96445313\n",
      "val Loss: 0.00088639 Acc: 0.89932886\n",
      "Epoch 28 of 500 took 0.132s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00101190 Acc: 0.959375\n",
      "val Loss: 0.00036770 Acc: 0.95973154\n",
      "Epoch 29 of 500 took 0.140s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00099083 Acc: 0.96210938\n",
      "val Loss: 0.00076489 Acc: 0.91946309\n",
      "Epoch 30 of 500 took 0.132s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00098549 Acc: 0.96328125\n",
      "val Loss: 0.00075221 Acc: 0.93288591\n",
      "Epoch 31 of 500 took 0.140s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00079820 Acc: 0.97226563\n",
      "val Loss: 0.00035784 Acc: 0.96979866\n",
      "Epoch 32 of 500 took 0.137s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00089220 Acc: 0.96679688\n",
      "val Loss: 0.00036961 Acc: 0.96308725\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 33 of 500 took 0.139s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00082088 Acc: 0.96796875\n",
      "val Loss: 0.00032114 Acc: 0.96979866\n",
      "New best validation loss: 0.0003211393002295654\n",
      "Epoch 34 of 500 took 0.133s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00072873 Acc: 0.97578125\n",
      "val Loss: 0.00032054 Acc: 0.97315436\n",
      "New best validation loss: 0.00032053722831226837\n",
      "Epoch 35 of 500 took 0.138s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00077671 Acc: 0.97460938\n",
      "val Loss: 0.00029179 Acc: 0.97651007\n",
      "New best validation loss: 0.00029179101322321285\n",
      "Epoch 36 of 500 took 0.139s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00085660 Acc: 0.96992188\n",
      "val Loss: 0.00032678 Acc: 0.96979866\n",
      "Epoch 37 of 500 took 0.169s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00075489 Acc: 0.971875\n",
      "val Loss: 0.00034011 Acc: 0.96979866\n",
      "Epoch 38 of 500 took 0.166s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00090992 Acc: 0.96601563\n",
      "val Loss: 0.00059578 Acc: 0.94295302\n",
      "Epoch 39 of 500 took 0.148s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00077704 Acc: 0.96953125\n",
      "val Loss: 0.00037122 Acc: 0.95637584\n",
      "Epoch 40 of 500 took 0.140s\n",
      "Epoch 40/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00077385 Acc: 0.97148437\n",
      "val Loss: 0.00031646 Acc: 0.96979866\n",
      "Epoch 41 of 500 took 0.142s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00079140 Acc: 0.97265625\n",
      "val Loss: 0.00036812 Acc: 0.96979866\n",
      "Epoch    42: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 42 of 500 took 0.133s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00077896 Acc: 0.97304687\n",
      "val Loss: 0.00028923 Acc: 0.97315436\n",
      "New best validation loss: 0.0002892273134433183\n",
      "Epoch 43 of 500 took 0.140s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00076286 Acc: 0.97382813\n",
      "val Loss: 0.00034561 Acc: 0.96979866\n",
      "Epoch 44 of 500 took 0.135s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00074569 Acc: 0.97226563\n",
      "val Loss: 0.00031003 Acc: 0.96979866\n",
      "Epoch 45 of 500 took 0.136s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00074433 Acc: 0.97539062\n",
      "val Loss: 0.00030430 Acc: 0.95973154\n",
      "Epoch 46 of 500 took 0.132s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00072665 Acc: 0.971875\n",
      "val Loss: 0.00028680 Acc: 0.96979866\n",
      "New best validation loss: 0.00028679842416872114\n",
      "Epoch 47 of 500 took 0.139s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00078612 Acc: 0.971875\n",
      "val Loss: 0.00031138 Acc: 0.97315436\n",
      "Epoch 48 of 500 took 0.135s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00077916 Acc: 0.9734375\n",
      "val Loss: 0.00030795 Acc: 0.95973154\n",
      "Epoch 49 of 500 took 0.142s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00066612 Acc: 0.9734375\n",
      "val Loss: 0.00032538 Acc: 0.96644295\n",
      "Epoch 50 of 500 took 0.133s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00074849 Acc: 0.97148437\n",
      "val Loss: 0.00029218 Acc: 0.96644295\n",
      "Epoch 51 of 500 took 0.168s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.00078546 Acc: 0.96875\n",
      "val Loss: 0.00033359 Acc: 0.97315436\n",
      "Epoch 52 of 500 took 0.173s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.00075357 Acc: 0.97578125\n",
      "val Loss: 0.00031178 Acc: 0.96644295\n",
      "Epoch    53: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 53 of 500 took 0.149s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00070886 Acc: 0.97421875\n",
      "val Loss: 0.00030989 Acc: 0.97986577\n",
      "Epoch 54 of 500 took 0.136s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.00077019 Acc: 0.97421875\n",
      "val Loss: 0.00029358 Acc: 0.97315436\n",
      "Epoch 55 of 500 took 0.136s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.00065245 Acc: 0.97695312\n",
      "val Loss: 0.00029453 Acc: 0.96979866\n",
      "Epoch 56 of 500 took 0.134s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.00075409 Acc: 0.97265625\n",
      "val Loss: 0.00032096 Acc: 0.96979866\n",
      "Epoch 57 of 500 took 0.141s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.00075099 Acc: 0.97070312\n",
      "val Loss: 0.00030648 Acc: 0.96979866\n",
      "Epoch 58 of 500 took 0.133s\n",
      "\n",
      "Training complete in 0m 8s\n",
      "Best val loss: 0.000287\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cc10>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00546762 Acc: 0.80255682\n",
      "val Loss: 0.00507528 Acc: 0.6\n",
      "New best validation loss: 0.005075277222527398\n",
      "Epoch 1 of 500 took 0.152s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00305401 Acc: 0.87784091\n",
      "val Loss: 0.01720725 Acc: 0.31111111\n",
      "Epoch 2 of 500 took 0.146s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00244835 Acc: 0.8984375\n",
      "val Loss: 0.00200149 Acc: 0.74285714\n",
      "New best validation loss: 0.00200149104708717\n",
      "Epoch 3 of 500 took 0.155s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00221601 Acc: 0.90696023\n",
      "val Loss: 0.00359733 Acc: 0.67936508\n",
      "Epoch 4 of 500 took 0.145s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00211801 Acc: 0.91370739\n",
      "val Loss: 0.00713442 Acc: 0.56507937\n",
      "Epoch 5 of 500 took 0.149s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00182369 Acc: 0.9243608\n",
      "val Loss: 0.00309756 Acc: 0.7047619\n",
      "Epoch 6 of 500 took 0.148s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00160996 Acc: 0.93536932\n",
      "val Loss: 0.00479970 Acc: 0.71111111\n",
      "Epoch 7 of 500 took 0.154s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00180275 Acc: 0.92329545\n",
      "val Loss: 0.00174137 Acc: 0.85714286\n",
      "New best validation loss: 0.0017413678623381115\n",
      "Epoch 8 of 500 took 0.159s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00161458 Acc: 0.93288352\n",
      "val Loss: 0.00239861 Acc: 0.73015873\n",
      "Epoch 9 of 500 took 0.155s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00144999 Acc: 0.94389205\n",
      "val Loss: 0.00813229 Acc: 0.41904762\n",
      "Epoch 10 of 500 took 0.146s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00156482 Acc: 0.93572443\n",
      "val Loss: 0.00165165 Acc: 0.81904762\n",
      "New best validation loss: 0.0016516473558213975\n",
      "Epoch 11 of 500 took 0.154s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00139980 Acc: 0.94176136\n",
      "val Loss: 0.00384797 Acc: 0.72380952\n",
      "Epoch 12 of 500 took 0.146s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00134874 Acc: 0.94389205\n",
      "val Loss: 0.00267309 Acc: 0.75555556\n",
      "Epoch 13 of 500 took 0.154s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00138629 Acc: 0.9428267\n",
      "val Loss: 0.01412067 Acc: 0.44444444\n",
      "Epoch 14 of 500 took 0.146s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00106857 Acc: 0.95632102\n",
      "val Loss: 0.00442108 Acc: 0.65396825\n",
      "Epoch 15 of 500 took 0.154s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00129045 Acc: 0.94886364\n",
      "val Loss: 0.00193345 Acc: 0.82539683\n",
      "Epoch 16 of 500 took 0.150s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00116615 Acc: 0.95099432\n",
      "val Loss: 0.01409900 Acc: 0.59047619\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 17 of 500 took 0.156s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00108113 Acc: 0.95596591\n",
      "val Loss: 0.00028761 Acc: 0.97460317\n",
      "New best validation loss: 0.00028761400589867245\n",
      "Epoch 18 of 500 took 0.149s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00088174 Acc: 0.96164773\n",
      "val Loss: 0.00065627 Acc: 0.92380952\n",
      "Epoch 19 of 500 took 0.158s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00077757 Acc: 0.96910511\n",
      "val Loss: 0.00034427 Acc: 0.96825397\n",
      "Epoch 20 of 500 took 0.146s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00083169 Acc: 0.96661932\n",
      "val Loss: 0.00032213 Acc: 0.96825397\n",
      "Epoch 21 of 500 took 0.157s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00073528 Acc: 0.9712358\n",
      "val Loss: 0.00019045 Acc: 0.97777778\n",
      "New best validation loss: 0.00019045107894473607\n",
      "Epoch 22 of 500 took 0.151s\n",
      "Epoch 22/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00076447 Acc: 0.97159091\n",
      "val Loss: 0.00021353 Acc: 0.97142857\n",
      "Epoch 23 of 500 took 0.154s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00075583 Acc: 0.97052557\n",
      "val Loss: 0.00077037 Acc: 0.92063492\n",
      "Epoch 24 of 500 took 0.155s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00075349 Acc: 0.97230114\n",
      "val Loss: 0.00031316 Acc: 0.97460317\n",
      "Epoch 25 of 500 took 0.166s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00069484 Acc: 0.96946023\n",
      "val Loss: 0.00027191 Acc: 0.97777778\n",
      "Epoch 26 of 500 took 0.187s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00076831 Acc: 0.96448864\n",
      "val Loss: 0.00081673 Acc: 0.90793651\n",
      "Epoch 27 of 500 took 0.183s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00071480 Acc: 0.97088068\n",
      "val Loss: 0.00022990 Acc: 0.97460317\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 28 of 500 took 0.182s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00069151 Acc: 0.96875\n",
      "val Loss: 0.00034092 Acc: 0.96507937\n",
      "Epoch 29 of 500 took 0.185s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00064852 Acc: 0.97585227\n",
      "val Loss: 0.00032440 Acc: 0.97142857\n",
      "Epoch 30 of 500 took 0.180s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00062366 Acc: 0.97088068\n",
      "val Loss: 0.00022183 Acc: 0.97460317\n",
      "Epoch 31 of 500 took 0.185s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00065574 Acc: 0.9712358\n",
      "val Loss: 0.00023895 Acc: 0.97777778\n",
      "Epoch 32 of 500 took 0.192s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00058947 Acc: 0.97585227\n",
      "val Loss: 0.00020370 Acc: 0.97777778\n",
      "Epoch 33 of 500 took 0.185s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000190\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_1.pt' (epoch 22)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00321052 Acc: 0.88174716\n",
      "val Loss: 0.00191688 Acc: 0.81931464\n",
      "New best validation loss: 0.0019168792483962584\n",
      "Epoch 1 of 500 took 0.189s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00165205 Acc: 0.93394886\n",
      "val Loss: 0.00071221 Acc: 0.92211838\n",
      "New best validation loss: 0.0007122090765248949\n",
      "Epoch 2 of 500 took 0.184s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00131654 Acc: 0.94921875\n",
      "val Loss: 0.00347061 Acc: 0.76012461\n",
      "Epoch 3 of 500 took 0.167s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00120331 Acc: 0.95170455\n",
      "val Loss: 0.00040180 Acc: 0.95950156\n",
      "New best validation loss: 0.0004017953746415373\n",
      "Epoch 4 of 500 took 0.148s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00102623 Acc: 0.95632102\n",
      "val Loss: 0.00107585 Acc: 0.894081\n",
      "Epoch 5 of 500 took 0.150s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00072909 Acc: 0.97017045\n",
      "val Loss: 0.00014262 Acc: 0.98442368\n",
      "New best validation loss: 0.0001426186656283441\n",
      "Epoch 6 of 500 took 0.147s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00080110 Acc: 0.96839489\n",
      "val Loss: 0.00053828 Acc: 0.9376947\n",
      "Epoch 7 of 500 took 0.154s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00072053 Acc: 0.97017045\n",
      "val Loss: 0.00081891 Acc: 0.92211838\n",
      "Epoch 8 of 500 took 0.146s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00072509 Acc: 0.97159091\n",
      "val Loss: 0.00031888 Acc: 0.95950156\n",
      "Epoch 9 of 500 took 0.149s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00063540 Acc: 0.97301136\n",
      "val Loss: 0.00097590 Acc: 0.90342679\n",
      "Epoch 10 of 500 took 0.149s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00071187 Acc: 0.97159091\n",
      "val Loss: 0.01134096 Acc: 0.50778816\n",
      "Epoch 11 of 500 took 0.152s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00070953 Acc: 0.96946023\n",
      "val Loss: 0.00531279 Acc: 0.65732087\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 12 of 500 took 0.147s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00063218 Acc: 0.97301136\n",
      "val Loss: 0.00018634 Acc: 0.97196262\n",
      "Epoch 13 of 500 took 0.153s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00048392 Acc: 0.97940341\n",
      "val Loss: 0.00013377 Acc: 0.97507788\n",
      "New best validation loss: 0.00013376543779982213\n",
      "Epoch 14 of 500 took 0.149s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00041353 Acc: 0.98401989\n",
      "val Loss: 0.00008742 Acc: 0.98753894\n",
      "New best validation loss: 8.741859056496546e-05\n",
      "Epoch 15 of 500 took 0.157s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00046363 Acc: 0.98153409\n",
      "val Loss: 0.00011669 Acc: 0.98130841\n",
      "Epoch 16 of 500 took 0.148s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00042749 Acc: 0.98366477\n",
      "val Loss: 0.00008601 Acc: 0.99376947\n",
      "New best validation loss: 8.601033218738818e-05\n",
      "Epoch 17 of 500 took 0.155s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00046761 Acc: 0.98579545\n",
      "val Loss: 0.00005503 Acc: 0.99376947\n",
      "New best validation loss: 5.503360332915345e-05\n",
      "Epoch 18 of 500 took 0.148s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00038096 Acc: 0.98401989\n",
      "val Loss: 0.00006343 Acc: 0.99376947\n",
      "Epoch 19 of 500 took 0.153s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00036003 Acc: 0.984375\n",
      "val Loss: 0.00004184 Acc: 0.99688474\n",
      "New best validation loss: 4.1836472315208934e-05\n",
      "Epoch 20 of 500 took 0.151s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00032150 Acc: 0.98615057\n",
      "val Loss: 0.00007805 Acc: 0.99065421\n",
      "Epoch 21 of 500 took 0.151s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00036396 Acc: 0.98508523\n",
      "val Loss: 0.00007277 Acc: 0.99065421\n",
      "Epoch 22 of 500 took 0.152s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00033107 Acc: 0.98579545\n",
      "val Loss: 0.00021773 Acc: 0.96884735\n",
      "Epoch 23 of 500 took 0.158s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00034902 Acc: 0.9868608\n",
      "val Loss: 0.00006490 Acc: 0.99376947\n",
      "Epoch 24 of 500 took 0.146s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00027333 Acc: 0.9897017\n",
      "val Loss: 0.00009039 Acc: 0.99065421\n",
      "Epoch 25 of 500 took 0.151s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00028391 Acc: 0.98615057\n",
      "val Loss: 0.00009749 Acc: 0.98753894\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 26 of 500 took 0.147s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00028396 Acc: 0.99041193\n",
      "val Loss: 0.00007339 Acc: 0.99376947\n",
      "Epoch 27 of 500 took 0.160s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00025542 Acc: 0.98792614\n",
      "val Loss: 0.00006209 Acc: 0.99376947\n",
      "Epoch 28 of 500 took 0.147s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00026307 Acc: 0.98757102\n",
      "val Loss: 0.00005428 Acc: 0.99688474\n",
      "Epoch 29 of 500 took 0.150s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00030195 Acc: 0.98792614\n",
      "val Loss: 0.00007084 Acc: 0.99376947\n",
      "Epoch 30 of 500 took 0.150s\n",
      "Epoch 30/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00019004 Acc: 0.99431818\n",
      "val Loss: 0.00004495 Acc: 0.99688474\n",
      "Epoch 31 of 500 took 0.154s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000042\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_2.pt' (epoch 20)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00269593 Acc: 0.91264205\n",
      "val Loss: 0.00436311 Acc: 0.73248408\n",
      "New best validation loss: 0.004363114666786923\n",
      "Epoch 1 of 500 took 0.148s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00154811 Acc: 0.94850852\n",
      "val Loss: 0.00543497 Acc: 0.65923567\n",
      "Epoch 2 of 500 took 0.154s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00123736 Acc: 0.95738636\n",
      "val Loss: 0.00094528 Acc: 0.89171975\n",
      "New best validation loss: 0.0009452783188242821\n",
      "Epoch 3 of 500 took 0.149s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00108158 Acc: 0.96271307\n",
      "val Loss: 0.00284769 Acc: 0.78980892\n",
      "Epoch 4 of 500 took 0.152s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00084285 Acc: 0.96590909\n",
      "val Loss: 0.00604295 Acc: 0.65605096\n",
      "Epoch 5 of 500 took 0.148s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00095533 Acc: 0.96306818\n",
      "val Loss: 0.00177450 Acc: 0.84076433\n",
      "Epoch 6 of 500 took 0.151s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00073133 Acc: 0.97372159\n",
      "val Loss: 0.00107066 Acc: 0.87579618\n",
      "Epoch 7 of 500 took 0.148s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00073173 Acc: 0.97301136\n",
      "val Loss: 0.00872155 Acc: 0.55414013\n",
      "Epoch 8 of 500 took 0.151s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00072191 Acc: 0.97336648\n",
      "val Loss: 0.00873833 Acc: 0.5955414\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 9 of 500 took 0.150s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00049612 Acc: 0.98153409\n",
      "val Loss: 0.00024203 Acc: 0.98407643\n",
      "New best validation loss: 0.000242026060060331\n",
      "Epoch 10 of 500 took 0.152s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00050390 Acc: 0.98117898\n",
      "val Loss: 0.00022355 Acc: 0.98407643\n",
      "New best validation loss: 0.00022355241665414943\n",
      "Epoch 11 of 500 took 0.149s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00046724 Acc: 0.98224432\n",
      "val Loss: 0.00030816 Acc: 0.98089172\n",
      "Epoch 12 of 500 took 0.158s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00043914 Acc: 0.98544034\n",
      "val Loss: 0.00021406 Acc: 0.99044586\n",
      "New best validation loss: 0.0002140640073521122\n",
      "Epoch 13 of 500 took 0.148s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00044148 Acc: 0.98544034\n",
      "val Loss: 0.00016963 Acc: 0.98407643\n",
      "New best validation loss: 0.000169625399029179\n",
      "Epoch 14 of 500 took 0.152s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00043356 Acc: 0.98473011\n",
      "val Loss: 0.00020966 Acc: 0.98407643\n",
      "Epoch 15 of 500 took 0.151s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00044069 Acc: 0.9818892\n",
      "val Loss: 0.00026327 Acc: 0.98407643\n",
      "Epoch 16 of 500 took 0.153s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00040222 Acc: 0.984375\n",
      "val Loss: 0.00033509 Acc: 0.97770701\n",
      "Epoch 17 of 500 took 0.153s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00037969 Acc: 0.98579545\n",
      "val Loss: 0.00017516 Acc: 0.98407643\n",
      "Epoch 18 of 500 took 0.153s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00045203 Acc: 0.98401989\n",
      "val Loss: 0.00020697 Acc: 0.98407643\n",
      "Epoch 19 of 500 took 0.152s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00035992 Acc: 0.98579545\n",
      "val Loss: 0.00019317 Acc: 0.98726115\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 20 of 500 took 0.153s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00042398 Acc: 0.98366477\n",
      "val Loss: 0.00019783 Acc: 0.98726115\n",
      "Epoch 21 of 500 took 0.146s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00034312 Acc: 0.9868608\n",
      "val Loss: 0.00015781 Acc: 0.99044586\n",
      "New best validation loss: 0.00015781157810217255\n",
      "Epoch 22 of 500 took 0.158s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00034407 Acc: 0.98828125\n",
      "val Loss: 0.00015855 Acc: 0.98726115\n",
      "Epoch 23 of 500 took 0.150s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00039724 Acc: 0.98330966\n",
      "val Loss: 0.00016656 Acc: 0.99044586\n",
      "Epoch 24 of 500 took 0.159s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00033607 Acc: 0.98650568\n",
      "val Loss: 0.00014942 Acc: 0.99044586\n",
      "New best validation loss: 0.00014941878379530208\n",
      "Epoch 25 of 500 took 0.152s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00032010 Acc: 0.99005682\n",
      "val Loss: 0.00018273 Acc: 0.98726115\n",
      "Epoch 26 of 500 took 0.152s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00031578 Acc: 0.98721591\n",
      "val Loss: 0.00015672 Acc: 0.99044586\n",
      "Epoch 27 of 500 took 0.149s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00040436 Acc: 0.98544034\n",
      "val Loss: 0.00022759 Acc: 0.97452229\n",
      "Epoch 28 of 500 took 0.153s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00038442 Acc: 0.9818892\n",
      "val Loss: 0.00018407 Acc: 0.98726115\n",
      "Epoch 29 of 500 took 0.149s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00031572 Acc: 0.98757102\n",
      "val Loss: 0.00015945 Acc: 0.99044586\n",
      "Epoch 30 of 500 took 0.151s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00034908 Acc: 0.98757102\n",
      "val Loss: 0.00020169 Acc: 0.98726115\n",
      "Epoch    31: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 31 of 500 took 0.150s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00026947 Acc: 0.9897017\n",
      "val Loss: 0.00016631 Acc: 0.98407643\n",
      "Epoch 32 of 500 took 0.154s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00029415 Acc: 0.98863636\n",
      "val Loss: 0.00016854 Acc: 0.99044586\n",
      "Epoch 33 of 500 took 0.146s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00031590 Acc: 0.98721591\n",
      "val Loss: 0.00014509 Acc: 0.99044586\n",
      "New best validation loss: 0.0001450856067952077\n",
      "Epoch 34 of 500 took 0.152s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00033348 Acc: 0.98863636\n",
      "val Loss: 0.00017127 Acc: 0.98407643\n",
      "Epoch 35 of 500 took 0.151s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00032235 Acc: 0.98934659\n",
      "val Loss: 0.00015614 Acc: 0.99044586\n",
      "Epoch 36 of 500 took 0.151s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00038120 Acc: 0.98508523\n",
      "val Loss: 0.00013785 Acc: 0.99044586\n",
      "New best validation loss: 0.00013785429631069207\n",
      "Epoch 37 of 500 took 0.148s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00028871 Acc: 0.99005682\n",
      "val Loss: 0.00015377 Acc: 0.99044586\n",
      "Epoch 38 of 500 took 0.152s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00033176 Acc: 0.98721591\n",
      "val Loss: 0.00016445 Acc: 0.99044586\n",
      "Epoch 39 of 500 took 0.148s\n",
      "Epoch 39/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00035666 Acc: 0.98863636\n",
      "val Loss: 0.00015461 Acc: 0.99363057\n",
      "Epoch 40 of 500 took 0.150s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00031496 Acc: 0.98792614\n",
      "val Loss: 0.00015923 Acc: 0.99044586\n",
      "Epoch 41 of 500 took 0.146s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00033672 Acc: 0.98863636\n",
      "val Loss: 0.00014366 Acc: 0.99363057\n",
      "Epoch 42 of 500 took 0.153s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00038555 Acc: 0.98508523\n",
      "val Loss: 0.00017334 Acc: 0.99044586\n",
      "Epoch    43: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 43 of 500 took 0.149s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00033694 Acc: 0.98650568\n",
      "val Loss: 0.00015853 Acc: 0.99044586\n",
      "Epoch 44 of 500 took 0.150s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00034509 Acc: 0.98721591\n",
      "val Loss: 0.00014921 Acc: 0.99044586\n",
      "Epoch 45 of 500 took 0.150s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00033977 Acc: 0.98757102\n",
      "val Loss: 0.00015393 Acc: 0.98726115\n",
      "Epoch 46 of 500 took 0.150s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00031838 Acc: 0.98899148\n",
      "val Loss: 0.00015295 Acc: 0.98726115\n",
      "Epoch 47 of 500 took 0.149s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00027204 Acc: 0.98934659\n",
      "val Loss: 0.00014871 Acc: 0.99044586\n",
      "Epoch 48 of 500 took 0.152s\n",
      "\n",
      "Training complete in 0m 7s\n",
      "Best val loss: 0.000138\n",
      "Participant:  1\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00950347 Acc: 0.64402174\n",
      "val Loss: 0.00342405 Acc: 0.61515152\n",
      "New best validation loss: 0.00342404842376709\n",
      "Epoch 1 of 500 took 0.157s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00380767 Acc: 0.86243207\n",
      "val Loss: 0.00456951 Acc: 0.46666667\n",
      "Epoch 2 of 500 took 0.163s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00271983 Acc: 0.90183424\n",
      "val Loss: 0.01801605 Acc: 0.32727273\n",
      "Epoch 3 of 500 took 0.157s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00219785 Acc: 0.91644022\n",
      "val Loss: 0.00291404 Acc: 0.66969697\n",
      "New best validation loss: 0.0029140403776457815\n",
      "Epoch 4 of 500 took 0.161s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00187141 Acc: 0.93036685\n",
      "val Loss: 0.00505963 Acc: 0.57878788\n",
      "Epoch 5 of 500 took 0.153s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00159438 Acc: 0.94293478\n",
      "val Loss: 0.00737631 Acc: 0.43030303\n",
      "Epoch 6 of 500 took 0.157s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00144727 Acc: 0.94497283\n",
      "val Loss: 0.00326360 Acc: 0.6969697\n",
      "Epoch 7 of 500 took 0.158s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00150688 Acc: 0.93987772\n",
      "val Loss: 0.01698319 Acc: 0.3\n",
      "Epoch 8 of 500 took 0.161s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00133553 Acc: 0.9517663\n",
      "val Loss: 0.00701936 Acc: 0.52727273\n",
      "Epoch 9 of 500 took 0.155s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00126204 Acc: 0.95923913\n",
      "val Loss: 0.01251473 Acc: 0.25757576\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 10 of 500 took 0.160s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00100628 Acc: 0.96433424\n",
      "val Loss: 0.00028896 Acc: 0.97272727\n",
      "New best validation loss: 0.0002889595248482444\n",
      "Epoch 11 of 500 took 0.157s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00086696 Acc: 0.96976902\n",
      "val Loss: 0.00025153 Acc: 0.97575758\n",
      "New best validation loss: 0.0002515269048286207\n",
      "Epoch 12 of 500 took 0.159s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00081806 Acc: 0.96807065\n",
      "val Loss: 0.00031911 Acc: 0.96969697\n",
      "Epoch 13 of 500 took 0.156s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00074620 Acc: 0.97282609\n",
      "val Loss: 0.00033673 Acc: 0.96363636\n",
      "Epoch 14 of 500 took 0.159s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00078408 Acc: 0.96875\n",
      "val Loss: 0.00028795 Acc: 0.97878788\n",
      "Epoch 15 of 500 took 0.155s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00070793 Acc: 0.97554348\n",
      "val Loss: 0.00037190 Acc: 0.95454545\n",
      "Epoch 16 of 500 took 0.160s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00064085 Acc: 0.97860054\n",
      "val Loss: 0.00026052 Acc: 0.97878788\n",
      "Epoch 17 of 500 took 0.153s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00063677 Acc: 0.97724185\n",
      "val Loss: 0.00026207 Acc: 0.96666667\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 18 of 500 took 0.160s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00070294 Acc: 0.97554348\n",
      "val Loss: 0.00025153 Acc: 0.97575758\n",
      "Epoch 19 of 500 took 0.156s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00061732 Acc: 0.9779212\n",
      "val Loss: 0.00026879 Acc: 0.96666667\n",
      "Epoch 20 of 500 took 0.158s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00054077 Acc: 0.97927989\n",
      "val Loss: 0.00022782 Acc: 0.97878788\n",
      "New best validation loss: 0.00022782249884171918\n",
      "Epoch 21 of 500 took 0.154s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00053168 Acc: 0.98063859\n",
      "val Loss: 0.00022889 Acc: 0.97878788\n",
      "Epoch 22 of 500 took 0.161s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00057267 Acc: 0.9779212\n",
      "val Loss: 0.00025099 Acc: 0.97575758\n",
      "Epoch 23 of 500 took 0.156s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00063657 Acc: 0.97961957\n",
      "val Loss: 0.00021681 Acc: 0.97575758\n",
      "New best validation loss: 0.0002168148530252052\n",
      "Epoch 24 of 500 took 0.158s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00057621 Acc: 0.97961957\n",
      "val Loss: 0.00022197 Acc: 0.97878788\n",
      "Epoch 25 of 500 took 0.153s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00055325 Acc: 0.98097826\n",
      "val Loss: 0.00026038 Acc: 0.97272727\n",
      "Epoch 26 of 500 took 0.163s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00059607 Acc: 0.97758152\n",
      "val Loss: 0.00035059 Acc: 0.96666667\n",
      "Epoch 27 of 500 took 0.152s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00053215 Acc: 0.98233696\n",
      "val Loss: 0.00024035 Acc: 0.96969697\n",
      "Epoch 28 of 500 took 0.156s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00063250 Acc: 0.97724185\n",
      "val Loss: 0.00021755 Acc: 0.97575758\n",
      "Epoch 29 of 500 took 0.156s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00054749 Acc: 0.97826087\n",
      "val Loss: 0.00023228 Acc: 0.96666667\n",
      "Epoch    30: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 30 of 500 took 0.159s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00054742 Acc: 0.97995924\n",
      "val Loss: 0.00026143 Acc: 0.97272727\n",
      "Epoch 31 of 500 took 0.153s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00055059 Acc: 0.9830163\n",
      "val Loss: 0.00019576 Acc: 0.98181818\n",
      "New best validation loss: 0.0001957591510180271\n",
      "Epoch 32 of 500 took 0.195s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00058385 Acc: 0.97894022\n",
      "val Loss: 0.00024904 Acc: 0.98181818\n",
      "Epoch 33 of 500 took 0.192s\n",
      "Epoch 33/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00048894 Acc: 0.9830163\n",
      "val Loss: 0.00024323 Acc: 0.97272727\n",
      "Epoch 34 of 500 took 0.193s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00044185 Acc: 0.984375\n",
      "val Loss: 0.00020751 Acc: 0.97272727\n",
      "Epoch 35 of 500 took 0.190s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00053275 Acc: 0.98233696\n",
      "val Loss: 0.00023237 Acc: 0.97878788\n",
      "Epoch 36 of 500 took 0.192s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00056065 Acc: 0.97961957\n",
      "val Loss: 0.00028533 Acc: 0.96969697\n",
      "Epoch 37 of 500 took 0.190s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00041830 Acc: 0.98675272\n",
      "val Loss: 0.00020909 Acc: 0.98484848\n",
      "Epoch    38: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 38 of 500 took 0.190s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00048711 Acc: 0.98539402\n",
      "val Loss: 0.00028684 Acc: 0.96969697\n",
      "Epoch 39 of 500 took 0.189s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00048252 Acc: 0.98403533\n",
      "val Loss: 0.00023906 Acc: 0.96969697\n",
      "Epoch 40 of 500 took 0.161s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00055164 Acc: 0.97995924\n",
      "val Loss: 0.00024905 Acc: 0.96363636\n",
      "Epoch 41 of 500 took 0.157s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00062227 Acc: 0.9765625\n",
      "val Loss: 0.00022215 Acc: 0.96969697\n",
      "Epoch 42 of 500 took 0.157s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00053491 Acc: 0.98063859\n",
      "val Loss: 0.00022461 Acc: 0.97272727\n",
      "Epoch 43 of 500 took 0.158s\n",
      "\n",
      "Training complete in 0m 7s\n",
      "Best val loss: 0.000196\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3e48cfb430>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00516881 Acc: 0.81605114\n",
      "val Loss: 0.00891880 Acc: 0.40566038\n",
      "New best validation loss: 0.008918795195765465\n",
      "Epoch 1 of 500 took 0.153s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00315357 Acc: 0.87606534\n",
      "val Loss: 0.00470249 Acc: 0.63522013\n",
      "New best validation loss: 0.004702493829547234\n",
      "Epoch 2 of 500 took 0.147s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00270066 Acc: 0.88991477\n",
      "val Loss: 0.00109677 Acc: 0.87735849\n",
      "New best validation loss: 0.0010967722291466576\n",
      "Epoch 3 of 500 took 0.155s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00240221 Acc: 0.9037642\n",
      "val Loss: 0.00588362 Acc: 0.59433962\n",
      "Epoch 4 of 500 took 0.149s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00203296 Acc: 0.91867898\n",
      "val Loss: 0.00654746 Acc: 0.52201258\n",
      "Epoch 5 of 500 took 0.151s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00199623 Acc: 0.92578125\n",
      "val Loss: 0.00647088 Acc: 0.50314465\n",
      "Epoch 6 of 500 took 0.147s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00179858 Acc: 0.92578125\n",
      "val Loss: 0.00296497 Acc: 0.7672956\n",
      "Epoch 7 of 500 took 0.158s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00171642 Acc: 0.92578125\n",
      "val Loss: 0.00811305 Acc: 0.46540881\n",
      "Epoch 8 of 500 took 0.150s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00181704 Acc: 0.92578125\n",
      "val Loss: 0.01462135 Acc: 0.39622642\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 9 of 500 took 0.152s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00160740 Acc: 0.93430398\n",
      "val Loss: 0.00033470 Acc: 0.96226415\n",
      "New best validation loss: 0.00033469580160746783\n",
      "Epoch 10 of 500 took 0.151s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00133088 Acc: 0.94921875\n",
      "val Loss: 0.00029454 Acc: 0.96855346\n",
      "New best validation loss: 0.0002945425609747569\n",
      "Epoch 11 of 500 took 0.153s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00127178 Acc: 0.94957386\n",
      "val Loss: 0.00057072 Acc: 0.9591195\n",
      "Epoch 12 of 500 took 0.150s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00118156 Acc: 0.95205966\n",
      "val Loss: 0.00050028 Acc: 0.94025157\n",
      "Epoch 13 of 500 took 0.155s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00119852 Acc: 0.95383523\n",
      "val Loss: 0.00036336 Acc: 0.95597484\n",
      "Epoch 14 of 500 took 0.147s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00107603 Acc: 0.95951705\n",
      "val Loss: 0.00039488 Acc: 0.95597484\n",
      "Epoch 15 of 500 took 0.150s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00114265 Acc: 0.95454545\n",
      "val Loss: 0.00024559 Acc: 0.97484277\n",
      "New best validation loss: 0.0002455874668352259\n",
      "Epoch 16 of 500 took 0.151s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00112622 Acc: 0.95738636\n",
      "val Loss: 0.00072610 Acc: 0.93396226\n",
      "Epoch 17 of 500 took 0.153s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00108141 Acc: 0.95916193\n",
      "val Loss: 0.00089856 Acc: 0.91194969\n",
      "Epoch 18 of 500 took 0.147s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00101031 Acc: 0.95774148\n",
      "val Loss: 0.00027904 Acc: 0.97484277\n",
      "Epoch 19 of 500 took 0.152s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00088904 Acc: 0.96448864\n",
      "val Loss: 0.00065797 Acc: 0.94025157\n",
      "Epoch 20 of 500 took 0.153s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00097185 Acc: 0.96022727\n",
      "val Loss: 0.00054457 Acc: 0.94339623\n",
      "Epoch 21 of 500 took 0.155s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00090645 Acc: 0.96555398\n",
      "val Loss: 0.00030278 Acc: 0.97169811\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 22 of 500 took 0.149s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00091064 Acc: 0.9634233\n",
      "val Loss: 0.00027807 Acc: 0.96855346\n",
      "Epoch 23 of 500 took 0.153s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00083850 Acc: 0.96555398\n",
      "val Loss: 0.00019007 Acc: 0.97484277\n",
      "New best validation loss: 0.0001900652013484787\n",
      "Epoch 24 of 500 took 0.151s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00090001 Acc: 0.96235795\n",
      "val Loss: 0.00021015 Acc: 0.97484277\n",
      "Epoch 25 of 500 took 0.151s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00090193 Acc: 0.9634233\n",
      "val Loss: 0.00024517 Acc: 0.97169811\n",
      "Epoch 26 of 500 took 0.146s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00084622 Acc: 0.96555398\n",
      "val Loss: 0.00019895 Acc: 0.97798742\n",
      "Epoch 27 of 500 took 0.151s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00088900 Acc: 0.96235795\n",
      "val Loss: 0.00020155 Acc: 0.97798742\n",
      "Epoch 28 of 500 took 0.154s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00082084 Acc: 0.97052557\n",
      "val Loss: 0.00019768 Acc: 0.97798742\n",
      "Epoch 29 of 500 took 0.151s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00088922 Acc: 0.96697443\n",
      "val Loss: 0.00023130 Acc: 0.97484277\n",
      "Epoch    30: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 30 of 500 took 0.153s\n",
      "Epoch 30/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00082405 Acc: 0.96875\n",
      "val Loss: 0.00022797 Acc: 0.97169811\n",
      "Epoch 31 of 500 took 0.150s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00073142 Acc: 0.96981534\n",
      "val Loss: 0.00025757 Acc: 0.97484277\n",
      "Epoch 32 of 500 took 0.149s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00082490 Acc: 0.96839489\n",
      "val Loss: 0.00022038 Acc: 0.97169811\n",
      "Epoch 33 of 500 took 0.152s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00077818 Acc: 0.96875\n",
      "val Loss: 0.00023240 Acc: 0.97169811\n",
      "Epoch 34 of 500 took 0.151s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00079547 Acc: 0.96768466\n",
      "val Loss: 0.00021556 Acc: 0.96855346\n",
      "Epoch 35 of 500 took 0.151s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000190\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_1.pt' (epoch 24)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00496762 Acc: 0.81534091\n",
      "val Loss: 0.00257865 Acc: 0.75632911\n",
      "New best validation loss: 0.00257864820806286\n",
      "Epoch 1 of 500 took 0.154s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00308921 Acc: 0.875\n",
      "val Loss: 0.00358695 Acc: 0.68037975\n",
      "Epoch 2 of 500 took 0.152s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00277955 Acc: 0.88139205\n",
      "val Loss: 0.01082602 Acc: 0.40189873\n",
      "Epoch 3 of 500 took 0.146s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00227832 Acc: 0.91193182\n",
      "val Loss: 0.00298965 Acc: 0.74367089\n",
      "Epoch 4 of 500 took 0.150s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00206732 Acc: 0.92045455\n",
      "val Loss: 0.00070452 Acc: 0.93987342\n",
      "New best validation loss: 0.0007045157253742218\n",
      "Epoch 5 of 500 took 0.154s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00208853 Acc: 0.91796875\n",
      "val Loss: 0.00255397 Acc: 0.76265823\n",
      "Epoch 6 of 500 took 0.150s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00192370 Acc: 0.92329545\n",
      "val Loss: 0.00471403 Acc: 0.53481013\n",
      "Epoch 7 of 500 took 0.146s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00167016 Acc: 0.93323864\n",
      "val Loss: 0.00124391 Acc: 0.86392405\n",
      "Epoch 8 of 500 took 0.152s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00158899 Acc: 0.94105114\n",
      "val Loss: 0.00744808 Acc: 0.48101266\n",
      "Epoch 9 of 500 took 0.149s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00157588 Acc: 0.93465909\n",
      "val Loss: 0.00160104 Acc: 0.84810127\n",
      "Epoch 10 of 500 took 0.151s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00154481 Acc: 0.9375\n",
      "val Loss: 0.00427663 Acc: 0.64240506\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 11 of 500 took 0.150s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00123908 Acc: 0.94992898\n",
      "val Loss: 0.00056444 Acc: 0.94303797\n",
      "New best validation loss: 0.0005644353790373741\n",
      "Epoch 12 of 500 took 0.152s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00111034 Acc: 0.95276989\n",
      "val Loss: 0.00036533 Acc: 0.96835443\n",
      "New best validation loss: 0.00036533386741257923\n",
      "Epoch 13 of 500 took 0.150s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00107040 Acc: 0.96022727\n",
      "val Loss: 0.00034531 Acc: 0.96202532\n",
      "New best validation loss: 0.0003453109743474405\n",
      "Epoch 14 of 500 took 0.152s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00107206 Acc: 0.95383523\n",
      "val Loss: 0.00057586 Acc: 0.94303797\n",
      "Epoch 15 of 500 took 0.152s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00097576 Acc: 0.96306818\n",
      "val Loss: 0.00049387 Acc: 0.9335443\n",
      "Epoch 16 of 500 took 0.151s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00093459 Acc: 0.96271307\n",
      "val Loss: 0.00063345 Acc: 0.9335443\n",
      "Epoch 17 of 500 took 0.150s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00093696 Acc: 0.96058239\n",
      "val Loss: 0.00042013 Acc: 0.95886076\n",
      "Epoch 18 of 500 took 0.154s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00082049 Acc: 0.96981534\n",
      "val Loss: 0.00034668 Acc: 0.95886076\n",
      "Epoch 19 of 500 took 0.151s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00081474 Acc: 0.96803977\n",
      "val Loss: 0.00035274 Acc: 0.96835443\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 20 of 500 took 0.151s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00079841 Acc: 0.97088068\n",
      "val Loss: 0.00031515 Acc: 0.96202532\n",
      "New best validation loss: 0.0003151546786480312\n",
      "Epoch 21 of 500 took 0.156s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00078532 Acc: 0.96981534\n",
      "val Loss: 0.00029967 Acc: 0.96518987\n",
      "New best validation loss: 0.00029967418765719934\n",
      "Epoch 22 of 500 took 0.152s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00080888 Acc: 0.96946023\n",
      "val Loss: 0.00029089 Acc: 0.96835443\n",
      "New best validation loss: 0.000290890825511534\n",
      "Epoch 23 of 500 took 0.148s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00073103 Acc: 0.97265625\n",
      "val Loss: 0.00032332 Acc: 0.96835443\n",
      "Epoch 24 of 500 took 0.152s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00080205 Acc: 0.96803977\n",
      "val Loss: 0.00033264 Acc: 0.96835443\n",
      "Epoch 25 of 500 took 0.154s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00078183 Acc: 0.96946023\n",
      "val Loss: 0.00036277 Acc: 0.95886076\n",
      "Epoch 26 of 500 took 0.155s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00075450 Acc: 0.96768466\n",
      "val Loss: 0.00033496 Acc: 0.95886076\n",
      "Epoch 27 of 500 took 0.147s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00074757 Acc: 0.96981534\n",
      "val Loss: 0.00031597 Acc: 0.96835443\n",
      "Epoch 28 of 500 took 0.154s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00071494 Acc: 0.97088068\n",
      "val Loss: 0.00033701 Acc: 0.96202532\n",
      "Epoch    29: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 29 of 500 took 0.147s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00076656 Acc: 0.96910511\n",
      "val Loss: 0.00032264 Acc: 0.95886076\n",
      "Epoch 30 of 500 took 0.151s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00063504 Acc: 0.97478693\n",
      "val Loss: 0.00033773 Acc: 0.96202532\n",
      "Epoch 31 of 500 took 0.151s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00075201 Acc: 0.96946023\n",
      "val Loss: 0.00031755 Acc: 0.95886076\n",
      "Epoch 32 of 500 took 0.159s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00078790 Acc: 0.97052557\n",
      "val Loss: 0.00032233 Acc: 0.95886076\n",
      "Epoch 33 of 500 took 0.153s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00071014 Acc: 0.97194602\n",
      "val Loss: 0.00031841 Acc: 0.95886076\n",
      "Epoch 34 of 500 took 0.175s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000291\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_2.pt' (epoch 23)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00389879 Acc: 0.86904762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.00281796 Acc: 0.73225806\n",
      "New best validation loss: 0.00281796109291815\n",
      "Epoch 1 of 500 took 0.177s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00254337 Acc: 0.90290179\n",
      "val Loss: 0.00370808 Acc: 0.68387097\n",
      "Epoch 2 of 500 took 0.178s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00219971 Acc: 0.91108631\n",
      "val Loss: 0.01018283 Acc: 0.56129032\n",
      "Epoch 3 of 500 took 0.177s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00199386 Acc: 0.92633929\n",
      "val Loss: 0.00386986 Acc: 0.70645161\n",
      "Epoch 4 of 500 took 0.176s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00182599 Acc: 0.93340774\n",
      "val Loss: 0.00082033 Acc: 0.91935484\n",
      "New best validation loss: 0.0008203323810331283\n",
      "Epoch 5 of 500 took 0.148s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00166491 Acc: 0.9375\n",
      "val Loss: 0.00266641 Acc: 0.76129032\n",
      "Epoch 6 of 500 took 0.142s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00166995 Acc: 0.93489583\n",
      "val Loss: 0.00749249 Acc: 0.52258065\n",
      "Epoch 7 of 500 took 0.146s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00149277 Acc: 0.94717262\n",
      "val Loss: 0.00464214 Acc: 0.61935484\n",
      "Epoch 8 of 500 took 0.141s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00158519 Acc: 0.93861607\n",
      "val Loss: 0.00391121 Acc: 0.67741935\n",
      "Epoch 9 of 500 took 0.144s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00126340 Acc: 0.94940476\n",
      "val Loss: 0.00086441 Acc: 0.91935484\n",
      "Epoch 10 of 500 took 0.142s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00135538 Acc: 0.94568452\n",
      "val Loss: 0.00415348 Acc: 0.67419355\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 11 of 500 took 0.146s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00119137 Acc: 0.95200893\n",
      "val Loss: 0.00049945 Acc: 0.9483871\n",
      "New best validation loss: 0.0004994487089495505\n",
      "Epoch 12 of 500 took 0.141s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00109330 Acc: 0.95647321\n",
      "val Loss: 0.00043623 Acc: 0.9483871\n",
      "New best validation loss: 0.00043622625450934134\n",
      "Epoch 13 of 500 took 0.146s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00105779 Acc: 0.96056548\n",
      "val Loss: 0.00052472 Acc: 0.9516129\n",
      "Epoch 14 of 500 took 0.143s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00100035 Acc: 0.95833333\n",
      "val Loss: 0.00053978 Acc: 0.9516129\n",
      "Epoch 15 of 500 took 0.143s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00096588 Acc: 0.96130952\n",
      "val Loss: 0.00040131 Acc: 0.96129032\n",
      "New best validation loss: 0.00040130778666465513\n",
      "Epoch 16 of 500 took 0.144s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00090843 Acc: 0.96614583\n",
      "val Loss: 0.00037718 Acc: 0.97096774\n",
      "New best validation loss: 0.0003771823500433276\n",
      "Epoch 17 of 500 took 0.145s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00090749 Acc: 0.96651786\n",
      "val Loss: 0.00056298 Acc: 0.93870968\n",
      "Epoch 18 of 500 took 0.150s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00086841 Acc: 0.9672619\n",
      "val Loss: 0.00049238 Acc: 0.9516129\n",
      "Epoch 19 of 500 took 0.145s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00085891 Acc: 0.96502976\n",
      "val Loss: 0.00042642 Acc: 0.95483871\n",
      "Epoch 20 of 500 took 0.143s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00080150 Acc: 0.9702381\n",
      "val Loss: 0.00062112 Acc: 0.93548387\n",
      "Epoch 21 of 500 took 0.143s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00081855 Acc: 0.96540179\n",
      "val Loss: 0.00035456 Acc: 0.96774194\n",
      "New best validation loss: 0.00035456272382890024\n",
      "Epoch 22 of 500 took 0.144s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00078245 Acc: 0.96986607\n",
      "val Loss: 0.00057318 Acc: 0.93870968\n",
      "Epoch 23 of 500 took 0.146s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00080259 Acc: 0.96651786\n",
      "val Loss: 0.00038743 Acc: 0.95806452\n",
      "Epoch 24 of 500 took 0.141s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00078749 Acc: 0.97172619\n",
      "val Loss: 0.00059077 Acc: 0.93225806\n",
      "Epoch 25 of 500 took 0.154s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00083898 Acc: 0.96986607\n",
      "val Loss: 0.00054184 Acc: 0.93870968\n",
      "Epoch 26 of 500 took 0.143s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00081565 Acc: 0.97284226\n",
      "val Loss: 0.00050401 Acc: 0.94193548\n",
      "Epoch 27 of 500 took 0.149s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00079334 Acc: 0.96800595\n",
      "val Loss: 0.00050956 Acc: 0.93870968\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 28 of 500 took 0.140s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00071519 Acc: 0.97284226\n",
      "val Loss: 0.00038008 Acc: 0.95806452\n",
      "Epoch 29 of 500 took 0.143s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00065147 Acc: 0.9765625\n",
      "val Loss: 0.00030808 Acc: 0.97419355\n",
      "New best validation loss: 0.0003080774218805375\n",
      "Epoch 30 of 500 took 0.146s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00066820 Acc: 0.97321429\n",
      "val Loss: 0.00039131 Acc: 0.96129032\n",
      "Epoch 31 of 500 took 0.178s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00062271 Acc: 0.9780506\n",
      "val Loss: 0.00051161 Acc: 0.9516129\n",
      "Epoch 32 of 500 took 0.173s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00060111 Acc: 0.97842262\n",
      "val Loss: 0.00034074 Acc: 0.96774194\n",
      "Epoch 33 of 500 took 0.178s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00064844 Acc: 0.97619048\n",
      "val Loss: 0.00035108 Acc: 0.96774194\n",
      "Epoch 34 of 500 took 0.175s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00062014 Acc: 0.9765625\n",
      "val Loss: 0.00032934 Acc: 0.97419355\n",
      "Epoch 35 of 500 took 0.148s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00067569 Acc: 0.97098214\n",
      "val Loss: 0.00031609 Acc: 0.97096774\n",
      "Epoch    36: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 36 of 500 took 0.144s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00064788 Acc: 0.97470238\n",
      "val Loss: 0.00031533 Acc: 0.97096774\n",
      "Epoch 37 of 500 took 0.144s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00062598 Acc: 0.97842262\n",
      "val Loss: 0.00032622 Acc: 0.97419355\n",
      "Epoch 38 of 500 took 0.146s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00064063 Acc: 0.97395833\n",
      "val Loss: 0.00031251 Acc: 0.97419355\n",
      "Epoch 39 of 500 took 0.144s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00064910 Acc: 0.9750744\n",
      "val Loss: 0.00036531 Acc: 0.96129032\n",
      "Epoch 40 of 500 took 0.143s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00063878 Acc: 0.97098214\n",
      "val Loss: 0.00037545 Acc: 0.96451613\n",
      "Epoch 41 of 500 took 0.144s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000308\n",
      "Participant:  2\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3e48cfb430>\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01137211 Acc: 0.52698864\n",
      "val Loss: 0.00811839 Acc: 0.31309904\n",
      "New best validation loss: 0.008118390275266604\n",
      "Epoch 1 of 500 took 0.151s\n",
      "Epoch 1/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00491746 Acc: 0.83025568\n",
      "val Loss: 0.01554208 Acc: 0.28753994\n",
      "Epoch 2 of 500 took 0.152s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00338912 Acc: 0.87357955\n",
      "val Loss: 0.03805309 Acc: 0.13099042\n",
      "Epoch 3 of 500 took 0.150s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00274252 Acc: 0.8959517\n",
      "val Loss: 0.01394975 Acc: 0.37060703\n",
      "Epoch 4 of 500 took 0.150s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00234983 Acc: 0.90767045\n",
      "val Loss: 0.02040028 Acc: 0.16932907\n",
      "Epoch 5 of 500 took 0.152s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00220033 Acc: 0.91441761\n",
      "val Loss: 0.04241798 Acc: 0.10223642\n",
      "Epoch 6 of 500 took 0.150s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00191349 Acc: 0.92826705\n",
      "val Loss: 0.00711506 Acc: 0.50479233\n",
      "New best validation loss: 0.007115058624706329\n",
      "Epoch 7 of 500 took 0.148s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00173198 Acc: 0.93856534\n",
      "val Loss: 0.01040616 Acc: 0.26837061\n",
      "Epoch 8 of 500 took 0.150s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00154937 Acc: 0.9375\n",
      "val Loss: 0.00873543 Acc: 0.47603834\n",
      "Epoch 9 of 500 took 0.152s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00141782 Acc: 0.9453125\n",
      "val Loss: 0.00427387 Acc: 0.63258786\n",
      "New best validation loss: 0.004273866312191509\n",
      "Epoch 10 of 500 took 0.158s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00133318 Acc: 0.95134943\n",
      "val Loss: 0.01308469 Acc: 0.45686901\n",
      "Epoch 11 of 500 took 0.147s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00141336 Acc: 0.94460227\n",
      "val Loss: 0.02846203 Acc: 0.23003195\n",
      "Epoch 12 of 500 took 0.155s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00122045 Acc: 0.953125\n",
      "val Loss: 0.00846976 Acc: 0.53354633\n",
      "Epoch 13 of 500 took 0.158s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00128662 Acc: 0.94708807\n",
      "val Loss: 0.01034724 Acc: 0.28115016\n",
      "Epoch 14 of 500 took 0.151s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00124422 Acc: 0.95170455\n",
      "val Loss: 0.01077686 Acc: 0.45367412\n",
      "Epoch 15 of 500 took 0.149s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00112856 Acc: 0.95809659\n",
      "val Loss: 0.01101035 Acc: 0.35782748\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 16 of 500 took 0.150s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00092302 Acc: 0.96484375\n",
      "val Loss: 0.00077729 Acc: 0.90734824\n",
      "New best validation loss: 0.0007772945557920315\n",
      "Epoch 17 of 500 took 0.159s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00072784 Acc: 0.97372159\n",
      "val Loss: 0.00023691 Acc: 0.97124601\n",
      "New best validation loss: 0.00023690525430459947\n",
      "Epoch 18 of 500 took 0.153s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00065481 Acc: 0.97336648\n",
      "val Loss: 0.00027394 Acc: 0.97763578\n",
      "Epoch 19 of 500 took 0.148s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00057640 Acc: 0.97727273\n",
      "val Loss: 0.00019702 Acc: 0.98722045\n",
      "New best validation loss: 0.00019701619070178024\n",
      "Epoch 20 of 500 took 0.154s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00057340 Acc: 0.98082386\n",
      "val Loss: 0.00044805 Acc: 0.95207668\n",
      "Epoch 21 of 500 took 0.159s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00054386 Acc: 0.97975852\n",
      "val Loss: 0.00032914 Acc: 0.96805112\n",
      "Epoch 22 of 500 took 0.152s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00058464 Acc: 0.9790483\n",
      "val Loss: 0.00024548 Acc: 0.98083067\n",
      "Epoch 23 of 500 took 0.151s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00045329 Acc: 0.98544034\n",
      "val Loss: 0.00018774 Acc: 0.98402556\n",
      "New best validation loss: 0.00018773745662107255\n",
      "Epoch 24 of 500 took 0.155s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00051346 Acc: 0.98366477\n",
      "val Loss: 0.00039970 Acc: 0.96166134\n",
      "Epoch 25 of 500 took 0.150s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00050648 Acc: 0.97798295\n",
      "val Loss: 0.00077835 Acc: 0.93610224\n",
      "Epoch 26 of 500 took 0.151s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00047228 Acc: 0.98117898\n",
      "val Loss: 0.00035150 Acc: 0.96805112\n",
      "Epoch 27 of 500 took 0.148s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00047455 Acc: 0.98224432\n",
      "val Loss: 0.00035018 Acc: 0.97763578\n",
      "Epoch 28 of 500 took 0.155s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00040927 Acc: 0.98615057\n",
      "val Loss: 0.00042239 Acc: 0.95207668\n",
      "Epoch 29 of 500 took 0.146s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00046539 Acc: 0.98295455\n",
      "val Loss: 0.00040556 Acc: 0.95207668\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 30 of 500 took 0.155s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00044605 Acc: 0.984375\n",
      "val Loss: 0.00020093 Acc: 0.97763578\n",
      "Epoch 31 of 500 took 0.146s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00041608 Acc: 0.98401989\n",
      "val Loss: 0.00019881 Acc: 0.98083067\n",
      "Epoch 32 of 500 took 0.156s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00042900 Acc: 0.98401989\n",
      "val Loss: 0.00032812 Acc: 0.98083067\n",
      "Epoch 33 of 500 took 0.146s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00038129 Acc: 0.98366477\n",
      "val Loss: 0.00019173 Acc: 0.98402556\n",
      "Epoch 34 of 500 took 0.149s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00035111 Acc: 0.98721591\n",
      "val Loss: 0.00021320 Acc: 0.98083067\n",
      "Epoch 35 of 500 took 0.149s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000188\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01227045 Acc: 0.60120739\n",
      "val Loss: 0.00887793 Acc: 0.3364486\n",
      "New best validation loss: 0.008877932468307353\n",
      "Epoch 1 of 500 took 0.155s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00449298 Acc: 0.80752841\n",
      "val Loss: 0.00536444 Acc: 0.53894081\n",
      "New best validation loss: 0.005364442911474875\n",
      "Epoch 2 of 500 took 0.153s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00312156 Acc: 0.87144886\n",
      "val Loss: 0.01339555 Acc: 0.25545171\n",
      "Epoch 3 of 500 took 0.154s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00260690 Acc: 0.88884943\n",
      "val Loss: 0.05031706 Acc: 0.10280374\n",
      "Epoch 4 of 500 took 0.146s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00222404 Acc: 0.90518466\n",
      "val Loss: 0.00624978 Acc: 0.44548287\n",
      "Epoch 5 of 500 took 0.153s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00195716 Acc: 0.91761364\n",
      "val Loss: 0.00298205 Acc: 0.63551402\n",
      "New best validation loss: 0.0029820452598025124\n",
      "Epoch 6 of 500 took 0.151s\n",
      "Epoch 6/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00191486 Acc: 0.92755682\n",
      "val Loss: 0.00825164 Acc: 0.51713396\n",
      "Epoch 7 of 500 took 0.151s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00168184 Acc: 0.93075284\n",
      "val Loss: 0.00312302 Acc: 0.68224299\n",
      "Epoch 8 of 500 took 0.157s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00165187 Acc: 0.93536932\n",
      "val Loss: 0.00439516 Acc: 0.63862928\n",
      "Epoch 9 of 500 took 0.154s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00130628 Acc: 0.95028409\n",
      "val Loss: 0.00308416 Acc: 0.70404984\n",
      "Epoch 10 of 500 took 0.150s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00121819 Acc: 0.95134943\n",
      "val Loss: 0.01367831 Acc: 0.33333333\n",
      "Epoch 11 of 500 took 0.154s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00118146 Acc: 0.95348011\n",
      "val Loss: 0.01132047 Acc: 0.24922118\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 12 of 500 took 0.147s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00086711 Acc: 0.96768466\n",
      "val Loss: 0.00097344 Acc: 0.90965732\n",
      "New best validation loss: 0.000973440962045735\n",
      "Epoch 13 of 500 took 0.155s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00091341 Acc: 0.96413352\n",
      "val Loss: 0.00048343 Acc: 0.96261682\n",
      "New best validation loss: 0.0004834266745041464\n",
      "Epoch 14 of 500 took 0.147s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00088533 Acc: 0.9662642\n",
      "val Loss: 0.00131938 Acc: 0.87538941\n",
      "Epoch 15 of 500 took 0.158s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00077339 Acc: 0.97017045\n",
      "val Loss: 0.00028686 Acc: 0.97507788\n",
      "New best validation loss: 0.0002868550124569474\n",
      "Epoch 16 of 500 took 0.150s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00073361 Acc: 0.97336648\n",
      "val Loss: 0.00047930 Acc: 0.96884735\n",
      "Epoch 17 of 500 took 0.153s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00063639 Acc: 0.97975852\n",
      "val Loss: 0.00051414 Acc: 0.96261682\n",
      "Epoch 18 of 500 took 0.148s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00070472 Acc: 0.97549716\n",
      "val Loss: 0.00102183 Acc: 0.91588785\n",
      "Epoch 19 of 500 took 0.152s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00069348 Acc: 0.97336648\n",
      "val Loss: 0.00060831 Acc: 0.9470405\n",
      "Epoch 20 of 500 took 0.149s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00068526 Acc: 0.9765625\n",
      "val Loss: 0.00085234 Acc: 0.91588785\n",
      "Epoch 21 of 500 took 0.153s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00064158 Acc: 0.9765625\n",
      "val Loss: 0.00095011 Acc: 0.93457944\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 22 of 500 took 0.153s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00066519 Acc: 0.97230114\n",
      "val Loss: 0.00026524 Acc: 0.97196262\n",
      "New best validation loss: 0.00026523878919744047\n",
      "Epoch 23 of 500 took 0.154s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00063374 Acc: 0.97975852\n",
      "val Loss: 0.00029630 Acc: 0.97196262\n",
      "Epoch 24 of 500 took 0.146s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00061507 Acc: 0.97869318\n",
      "val Loss: 0.00027343 Acc: 0.98130841\n",
      "Epoch 25 of 500 took 0.153s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00049197 Acc: 0.98153409\n",
      "val Loss: 0.00030191 Acc: 0.97507788\n",
      "Epoch 26 of 500 took 0.150s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00064727 Acc: 0.97798295\n",
      "val Loss: 0.00042435 Acc: 0.97507788\n",
      "Epoch 27 of 500 took 0.150s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00065972 Acc: 0.97585227\n",
      "val Loss: 0.00024255 Acc: 0.97819315\n",
      "New best validation loss: 0.00024254805759477466\n",
      "Epoch 28 of 500 took 0.151s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00055766 Acc: 0.98295455\n",
      "val Loss: 0.00031331 Acc: 0.97196262\n",
      "Epoch 29 of 500 took 0.155s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00055261 Acc: 0.98153409\n",
      "val Loss: 0.00038160 Acc: 0.97196262\n",
      "Epoch 30 of 500 took 0.184s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00059075 Acc: 0.9765625\n",
      "val Loss: 0.00027054 Acc: 0.97507788\n",
      "Epoch 31 of 500 took 0.155s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00061068 Acc: 0.97940341\n",
      "val Loss: 0.00028449 Acc: 0.97196262\n",
      "Epoch 32 of 500 took 0.146s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00062284 Acc: 0.9765625\n",
      "val Loss: 0.00026481 Acc: 0.97819315\n",
      "Epoch 33 of 500 took 0.154s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00055284 Acc: 0.9818892\n",
      "val Loss: 0.00036630 Acc: 0.97507788\n",
      "Epoch    34: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 34 of 500 took 0.146s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00056503 Acc: 0.97478693\n",
      "val Loss: 0.00025311 Acc: 0.97196262\n",
      "Epoch 35 of 500 took 0.152s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00058845 Acc: 0.97478693\n",
      "val Loss: 0.00041630 Acc: 0.97507788\n",
      "Epoch 36 of 500 took 0.151s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00056587 Acc: 0.97833807\n",
      "val Loss: 0.00042945 Acc: 0.97507788\n",
      "Epoch 37 of 500 took 0.157s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00058501 Acc: 0.97869318\n",
      "val Loss: 0.00037237 Acc: 0.97819315\n",
      "Epoch 38 of 500 took 0.147s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00047437 Acc: 0.98224432\n",
      "val Loss: 0.00035171 Acc: 0.97507788\n",
      "Epoch 39 of 500 took 0.153s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000243\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_1.pt' (epoch 28)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00517752 Acc: 0.81285511\n",
      "val Loss: 0.00264691 Acc: 0.73667712\n",
      "New best validation loss: 0.002646907183070168\n",
      "Epoch 1 of 500 took 0.149s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00202865 Acc: 0.91761364\n",
      "val Loss: 0.00616527 Acc: 0.60501567\n",
      "Epoch 2 of 500 took 0.182s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00151088 Acc: 0.93927557\n",
      "val Loss: 0.01722892 Acc: 0.43887147\n",
      "Epoch 3 of 500 took 0.149s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00125085 Acc: 0.94744318\n",
      "val Loss: 0.00396857 Acc: 0.69905956\n",
      "Epoch 4 of 500 took 0.153s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00123224 Acc: 0.95170455\n",
      "val Loss: 0.00515667 Acc: 0.65203762\n",
      "Epoch 5 of 500 took 0.155s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00119569 Acc: 0.94850852\n",
      "val Loss: 0.00460312 Acc: 0.64263323\n",
      "Epoch 6 of 500 took 0.157s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00093088 Acc: 0.96129261\n",
      "val Loss: 0.01265517 Acc: 0.49529781\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 7 of 500 took 0.157s\n",
      "Epoch 7/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00082550 Acc: 0.96448864\n",
      "val Loss: 0.00017385 Acc: 0.98119122\n",
      "New best validation loss: 0.00017384693119966871\n",
      "Epoch 8 of 500 took 0.171s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00070135 Acc: 0.9712358\n",
      "val Loss: 0.00039138 Acc: 0.94984326\n",
      "Epoch 9 of 500 took 0.193s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00073378 Acc: 0.97159091\n",
      "val Loss: 0.00016242 Acc: 0.98746082\n",
      "New best validation loss: 0.0001624219563313786\n",
      "Epoch 10 of 500 took 0.160s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00058259 Acc: 0.9765625\n",
      "val Loss: 0.00038460 Acc: 0.96238245\n",
      "Epoch 11 of 500 took 0.164s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00065974 Acc: 0.97301136\n",
      "val Loss: 0.00024851 Acc: 0.97805643\n",
      "Epoch 12 of 500 took 0.164s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00061466 Acc: 0.97514205\n",
      "val Loss: 0.00030326 Acc: 0.96865204\n",
      "Epoch 13 of 500 took 0.180s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00063229 Acc: 0.97549716\n",
      "val Loss: 0.00032986 Acc: 0.96551724\n",
      "Epoch 14 of 500 took 0.159s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00054199 Acc: 0.9790483\n",
      "val Loss: 0.00040627 Acc: 0.95924765\n",
      "Epoch 15 of 500 took 0.158s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00058910 Acc: 0.97514205\n",
      "val Loss: 0.00165218 Acc: 0.830721\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 16 of 500 took 0.167s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00053030 Acc: 0.98011364\n",
      "val Loss: 0.00025042 Acc: 0.96865204\n",
      "Epoch 17 of 500 took 0.153s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00054517 Acc: 0.97869318\n",
      "val Loss: 0.00018659 Acc: 0.98746082\n",
      "Epoch 18 of 500 took 0.150s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00040443 Acc: 0.984375\n",
      "val Loss: 0.00013858 Acc: 0.98746082\n",
      "New best validation loss: 0.00013858207200761872\n",
      "Epoch 19 of 500 took 0.193s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00042762 Acc: 0.98295455\n",
      "val Loss: 0.00012558 Acc: 0.98746082\n",
      "New best validation loss: 0.00012558272406225295\n",
      "Epoch 20 of 500 took 0.171s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00040000 Acc: 0.98295455\n",
      "val Loss: 0.00018468 Acc: 0.98746082\n",
      "Epoch 21 of 500 took 0.156s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00050794 Acc: 0.97975852\n",
      "val Loss: 0.00017149 Acc: 0.98432602\n",
      "Epoch 22 of 500 took 0.158s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00053694 Acc: 0.97869318\n",
      "val Loss: 0.00013756 Acc: 0.99059561\n",
      "Epoch 23 of 500 took 0.148s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00046501 Acc: 0.97940341\n",
      "val Loss: 0.00016700 Acc: 0.98432602\n",
      "Epoch 24 of 500 took 0.192s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00044631 Acc: 0.98259943\n",
      "val Loss: 0.00013035 Acc: 0.98746082\n",
      "Epoch 25 of 500 took 0.170s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00038980 Acc: 0.984375\n",
      "val Loss: 0.00014802 Acc: 0.98746082\n",
      "Epoch    26: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 26 of 500 took 0.156s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00044892 Acc: 0.98259943\n",
      "val Loss: 0.00013697 Acc: 0.98746082\n",
      "Epoch 27 of 500 took 0.154s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00044921 Acc: 0.98295455\n",
      "val Loss: 0.00015542 Acc: 0.98432602\n",
      "Epoch 28 of 500 took 0.181s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00044958 Acc: 0.98295455\n",
      "val Loss: 0.00015287 Acc: 0.98119122\n",
      "Epoch 29 of 500 took 0.167s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00045658 Acc: 0.98153409\n",
      "val Loss: 0.00019816 Acc: 0.98432602\n",
      "Epoch 30 of 500 took 0.177s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00042640 Acc: 0.98011364\n",
      "val Loss: 0.00014145 Acc: 0.98746082\n",
      "Epoch 31 of 500 took 0.158s\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val loss: 0.000126\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f3dd7c8cdd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_2.pt' (epoch 20)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00331424 Acc: 0.89701705\n",
      "val Loss: 0.00402218 Acc: 0.68253968\n",
      "New best validation loss: 0.004022182358635796\n",
      "Epoch 1 of 500 took 0.156s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00202478 Acc: 0.92933239\n",
      "val Loss: 0.01523902 Acc: 0.38095238\n",
      "Epoch 2 of 500 took 0.151s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00150912 Acc: 0.94034091\n",
      "val Loss: 0.01343406 Acc: 0.46984127\n",
      "Epoch 3 of 500 took 0.156s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00137978 Acc: 0.9477983\n",
      "val Loss: 0.00696124 Acc: 0.57460317\n",
      "Epoch 4 of 500 took 0.147s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00139406 Acc: 0.94886364\n",
      "val Loss: 0.00578857 Acc: 0.44761905\n",
      "Epoch 5 of 500 took 0.151s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00116361 Acc: 0.9584517\n",
      "val Loss: 0.00235413 Acc: 0.75555556\n",
      "New best validation loss: 0.0023541321830144006\n",
      "Epoch 6 of 500 took 0.173s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00113133 Acc: 0.9556108\n",
      "val Loss: 0.00456584 Acc: 0.64444444\n",
      "Epoch 7 of 500 took 0.176s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00101943 Acc: 0.95987216\n",
      "val Loss: 0.00199173 Acc: 0.85079365\n",
      "New best validation loss: 0.0019917279954940552\n",
      "Epoch 8 of 500 took 0.184s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00094092 Acc: 0.9634233\n",
      "val Loss: 0.00094400 Acc: 0.9015873\n",
      "New best validation loss: 0.0009440024693806966\n",
      "Epoch 9 of 500 took 0.156s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00090896 Acc: 0.96768466\n",
      "val Loss: 0.00358463 Acc: 0.65714286\n",
      "Epoch 10 of 500 took 0.180s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00087972 Acc: 0.96768466\n",
      "val Loss: 0.00943324 Acc: 0.48253968\n",
      "Epoch 11 of 500 took 0.156s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00098830 Acc: 0.96413352\n",
      "val Loss: 0.00750281 Acc: 0.54920635\n",
      "Epoch 12 of 500 took 0.165s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00076867 Acc: 0.97017045\n",
      "val Loss: 0.00202848 Acc: 0.78730159\n",
      "Epoch 13 of 500 took 0.160s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00085035 Acc: 0.96768466\n",
      "val Loss: 0.00110334 Acc: 0.86031746\n",
      "Epoch 14 of 500 took 0.177s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00074230 Acc: 0.96839489\n",
      "val Loss: 0.00912283 Acc: 0.56825397\n",
      "Epoch    15: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 15 of 500 took 0.170s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00062847 Acc: 0.97514205\n",
      "val Loss: 0.00025533 Acc: 0.97142857\n",
      "New best validation loss: 0.0002553278018557836\n",
      "Epoch 16 of 500 took 0.193s\n",
      "Epoch 16/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00051691 Acc: 0.98117898\n",
      "val Loss: 0.00017536 Acc: 0.98095238\n",
      "New best validation loss: 0.00017535509098143805\n",
      "Epoch 17 of 500 took 0.195s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00048709 Acc: 0.98366477\n",
      "val Loss: 0.00029362 Acc: 0.97777778\n",
      "Epoch 18 of 500 took 0.156s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00046967 Acc: 0.98330966\n",
      "val Loss: 0.00014481 Acc: 0.98412698\n",
      "New best validation loss: 0.00014481376560907514\n",
      "Epoch 19 of 500 took 0.154s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00040808 Acc: 0.98473011\n",
      "val Loss: 0.00020862 Acc: 0.98412698\n",
      "Epoch 20 of 500 took 0.169s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00041347 Acc: 0.98153409\n",
      "val Loss: 0.00039998 Acc: 0.96507937\n",
      "Epoch 21 of 500 took 0.160s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00044868 Acc: 0.98082386\n",
      "val Loss: 0.00019197 Acc: 0.98730159\n",
      "Epoch 22 of 500 took 0.182s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00041083 Acc: 0.98366477\n",
      "val Loss: 0.00012314 Acc: 0.99047619\n",
      "New best validation loss: 0.00012313552082531036\n",
      "Epoch 23 of 500 took 0.170s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00033842 Acc: 0.99005682\n",
      "val Loss: 0.00018432 Acc: 0.98730159\n",
      "Epoch 24 of 500 took 0.174s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00035112 Acc: 0.9868608\n",
      "val Loss: 0.00024370 Acc: 0.97142857\n",
      "Epoch 25 of 500 took 0.179s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00036071 Acc: 0.98544034\n",
      "val Loss: 0.00009119 Acc: 0.98412698\n",
      "New best validation loss: 9.11912393002283e-05\n",
      "Epoch 26 of 500 took 0.170s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00040833 Acc: 0.984375\n",
      "val Loss: 0.00014538 Acc: 0.98730159\n",
      "Epoch 27 of 500 took 0.157s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00037569 Acc: 0.98544034\n",
      "val Loss: 0.00017308 Acc: 0.97460317\n",
      "Epoch 28 of 500 took 0.157s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00040178 Acc: 0.984375\n",
      "val Loss: 0.00031037 Acc: 0.98095238\n",
      "Epoch 29 of 500 took 0.163s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00041951 Acc: 0.98366477\n",
      "val Loss: 0.00060004 Acc: 0.93650794\n",
      "Epoch 30 of 500 took 0.161s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00037157 Acc: 0.984375\n",
      "val Loss: 0.00012219 Acc: 0.99047619\n",
      "Epoch 31 of 500 took 0.159s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00029607 Acc: 0.98863636\n",
      "val Loss: 0.00019366 Acc: 0.98095238\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 32 of 500 took 0.152s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00029510 Acc: 0.9897017\n",
      "val Loss: 0.00010708 Acc: 0.98730159\n",
      "Epoch 33 of 500 took 0.167s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00034291 Acc: 0.9868608\n",
      "val Loss: 0.00015534 Acc: 0.98730159\n",
      "Epoch 34 of 500 took 0.153s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00029381 Acc: 0.98757102\n",
      "val Loss: 0.00011655 Acc: 0.98730159\n",
      "Epoch 35 of 500 took 0.194s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00031809 Acc: 0.98792614\n",
      "val Loss: 0.00012120 Acc: 0.98412698\n",
      "Epoch 36 of 500 took 0.195s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00026457 Acc: 0.99005682\n",
      "val Loss: 0.00010513 Acc: 0.99047619\n",
      "Epoch 37 of 500 took 0.190s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000091\n"
     ]
    }
   ],
   "source": [
    "train_Spectrogram_fine_tuning(examples_datasets_train, labels_datasets_train, filter_size=None,\n",
    "                              num_kernels=filter_size, number_of_cycle_for_first_training=4,\n",
    "                              number_of_cycles_rest_of_training=4, path_weight_to_save_to=path_to_save_to,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_classes,\n",
    "                              batch_size=128, spectrogram_model=False,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1854, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1899, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1938, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1780, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1981, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1809, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1928, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1902, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  0  Accuracy:  0.9970414201183432\n",
      "Participant:  0  Accuracy:  0.5889872173058014\n",
      "Participant:  0  Accuracy:  0.6760299625468165\n",
      "Participant:  0  Accuracy:  0.555767397521449\n",
      "ACCURACY PARTICIPANT:  [0.9970414201183432, 0.5889872173058014, 0.6760299625468165, 0.555767397521449]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  1  Accuracy:  0.9945553539019963\n",
      "Participant:  1  Accuracy:  0.6294896030245747\n",
      "Participant:  1  Accuracy:  0.738581146744412\n",
      "Participant:  1  Accuracy:  0.8821218074656189\n",
      "ACCURACY PARTICIPANT:  [0.9945553539019963, 0.6294896030245747, 0.738581146744412, 0.8821218074656189]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  2  Accuracy:  0.9960199004975124\n",
      "Participant:  2  Accuracy:  0.20915032679738563\n",
      "Participant:  2  Accuracy:  0.5874060150375939\n",
      "Participant:  2  Accuracy:  0.5787992495309568\n",
      "ACCURACY PARTICIPANT:  [0.9960199004975124, 0.20915032679738563, 0.5874060150375939, 0.5787992495309568]\n",
      "[0.99704142 0.58898722 0.67602996 0.5557674  0.99455535 0.6294896\n",
      " 0.73858115 0.88212181 0.9960199  0.20915033 0.58740602 0.57879925]\n",
      "[0.9970414201183432, 0.5889872173058014, 0.6760299625468165, 0.555767397521449, 0.9945553539019963, 0.6294896030245747, 0.738581146744412, 0.8821218074656189, 0.9960199004975124, 0.20915032679738563, 0.5874060150375939, 0.5787992495309568]\n",
      "OVERALL ACCURACY: 0.7028291167077052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "test_TSD_DNN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=filter_size, use_only_first_training=True,\n",
    "                                  path_weights=path_to_save_to,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  algo_name=algo_name, gestures_to_remove=gestures_to_remove,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.588987</td>\n",
       "      <td>0.676030</td>\n",
       "      <td>0.555767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_1</th>\n",
       "      <td>0.994555</td>\n",
       "      <td>0.629490</td>\n",
       "      <td>0.738581</td>\n",
       "      <td>0.882122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_2</th>\n",
       "      <td>0.996020</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.587406</td>\n",
       "      <td>0.578799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0   0.997041   0.588987   0.676030   0.555767\n",
       "Participant_1   0.994555   0.629490   0.738581   0.882122\n",
       "Participant_2   0.996020   0.209150   0.587406   0.578799"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "TSD_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    TSD_acc[i] = acc\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.savefig(\"/home/laiy/gitrepos/msr_final/code/test_code/img/3DC_TSD.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Domain Adverserial Neural Network (DANN)\n",
    "* 2 domians : source(0) and target(1) (output_domain includes 2 features)\n",
    "    * source / validation: labeled; first training\n",
    "    * target: unlabeled; others\n",
    "    * train using one source and one target\n",
    "* start training using TSD_DNN model params \n",
    "* DANN loss (domain_loss_weight=1e-1)\n",
    "    * loss_domain_source = crossEntropyLoss(pred_domain_source, label_source_domain)\n",
    "    * loss_main_source = (0.5 * loss_source_class + domain_loss_weight * loss_domain_source)\n",
    "    * loss_domain_target = 0.5 * (crossEntropyLoss(pred_domain_target, label_target_domain))\n",
    "    * loss_domain_target = 0.5 * domain_loss_weight * loss_domain_target\n",
    "    * loss_main = loss_main_source + loss_domain_target\n",
    "    * loss_domain = loss_domain_source + loss_domain_target\n",
    "   \n",
    "### Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD\n",
    "    * beat_state_n.pt (n = # training session)\n",
    "        * epoch: #epochs\n",
    "        * model state_dict\n",
    "        * optimizer state_dict\n",
    "        * scheduler state_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.TrainingsAndEvaluations.ForTrainingSessions.TSD_DNN.train_tsd_dnn_standard import \\\n",
    "    test_TSD_DNN_on_training_sessions\n",
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import train_DA_spectrograms\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm. \\\n",
    "    load_dataset_spectrogram_in_dataloader import load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.utils_training_and_evaluation import create_confusion_matrix, \\\n",
    "    long_term_classification_graph, long_term_pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from train_tsd_dnn_DA import test_network_DA_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [200, 200, 200]\n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = [5, 6, 9, 10]\n",
    "gestures_to_remove = None\n",
    "number_of_class = 11\n",
    "number_of_cycle_for_first_training = 4\n",
    "number_of_cycles_rest_of_training = 4\n",
    "learning_rate = 0.002515\n",
    "\n",
    "path_weights_fine_tuning = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "algo_name = \"DANN_THREE_CYCLES_11Gestures_TSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2674, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2829, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2881, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2821, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2970, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2859, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2837, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2783, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2816, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2888, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2864, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2835, 385)\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.969531, main loss classifier 0.169179, source classification loss 0.102475, loss domain distinction 1.047368, accuracy domain distinction 0.503125\n",
      "VALIDATION Loss: 0.17813204 Acc: 0.92281879\n",
      "New best validation loss:  0.1781320422887802\n",
      "Epoch 1 of 500 took 0.337s\n",
      "Accuracy source 0.973047, main loss classifier 0.161750, source classification loss 0.096788, loss domain distinction 0.989932, accuracy domain distinction 0.501563\n",
      "VALIDATION Loss: 0.16532521 Acc: 0.93288591\n",
      "New best validation loss:  0.16532520949840546\n",
      "Epoch 2 of 500 took 0.334s\n",
      "Accuracy source 0.971875, main loss classifier 0.157221, source classification loss 0.099201, loss domain distinction 0.918785, accuracy domain distinction 0.500977\n",
      "VALIDATION Loss: 0.32262576 Acc: 0.88255034\n",
      "Epoch 3 of 500 took 0.306s\n",
      "Accuracy source 0.970703, main loss classifier 0.153863, source classification loss 0.101036, loss domain distinction 0.865028, accuracy domain distinction 0.502148\n",
      "VALIDATION Loss: 0.28392455 Acc: 0.88590604\n",
      "Epoch 4 of 500 took 0.347s\n",
      "Accuracy source 0.970313, main loss classifier 0.145728, source classification loss 0.097099, loss domain distinction 0.788199, accuracy domain distinction 0.499805\n",
      "VALIDATION Loss: 0.16079253 Acc: 0.94295302\n",
      "New best validation loss:  0.1607925295829773\n",
      "Epoch 5 of 500 took 0.310s\n",
      "Accuracy source 0.968359, main loss classifier 0.148092, source classification loss 0.107705, loss domain distinction 0.745767, accuracy domain distinction 0.502148\n",
      "VALIDATION Loss: 0.34692079 Acc: 0.87919463\n",
      "Epoch    53: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.296s\n",
      "Accuracy source 0.972266, main loss classifier 0.140575, source classification loss 0.097122, loss domain distinction 0.717974, accuracy domain distinction 0.491016\n",
      "VALIDATION Loss: 0.12021227 Acc: 0.95302013\n",
      "New best validation loss:  0.12021227180957794\n",
      "Epoch 7 of 500 took 0.305s\n",
      "Accuracy source 0.968750, main loss classifier 0.144598, source classification loss 0.106036, loss domain distinction 0.711960, accuracy domain distinction 0.500391\n",
      "VALIDATION Loss: 0.34346443 Acc: 0.87583893\n",
      "Epoch 8 of 500 took 0.307s\n",
      "Accuracy source 0.966406, main loss classifier 0.146716, source classification loss 0.110307, loss domain distinction 0.704588, accuracy domain distinction 0.492383\n",
      "VALIDATION Loss: 0.26423383 Acc: 0.90268456\n",
      "Epoch 9 of 500 took 0.290s\n",
      "Accuracy source 0.970703, main loss classifier 0.140868, source classification loss 0.099674, loss domain distinction 0.697356, accuracy domain distinction 0.496875\n",
      "VALIDATION Loss: 0.40238708 Acc: 0.86577181\n",
      "Epoch 10 of 500 took 0.355s\n",
      "Accuracy source 0.972656, main loss classifier 0.140871, source classification loss 0.100239, loss domain distinction 0.690069, accuracy domain distinction 0.488281\n",
      "VALIDATION Loss: 0.30008951 Acc: 0.88590604\n",
      "Epoch 11 of 500 took 0.314s\n",
      "Accuracy source 0.968359, main loss classifier 0.141263, source classification loss 0.103175, loss domain distinction 0.680061, accuracy domain distinction 0.487109\n",
      "VALIDATION Loss: 0.25383028 Acc: 0.89932886\n",
      "Epoch    59: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.357s\n",
      "Accuracy source 0.971094, main loss classifier 0.144201, source classification loss 0.108450, loss domain distinction 0.678810, accuracy domain distinction 0.484766\n",
      "VALIDATION Loss: 0.22881885 Acc: 0.91610738\n",
      "Epoch 13 of 500 took 0.372s\n",
      "Accuracy source 0.972266, main loss classifier 0.140135, source classification loss 0.104377, loss domain distinction 0.654066, accuracy domain distinction 0.494727\n",
      "VALIDATION Loss: 0.18484916 Acc: 0.9261745\n",
      "Epoch 14 of 500 took 0.336s\n",
      "Accuracy source 0.967578, main loss classifier 0.142615, source classification loss 0.108848, loss domain distinction 0.661570, accuracy domain distinction 0.507422\n",
      "VALIDATION Loss: 0.13611934 Acc: 0.95637584\n",
      "Epoch 15 of 500 took 0.292s\n",
      "Accuracy source 0.967969, main loss classifier 0.141039, source classification loss 0.107836, loss domain distinction 0.650149, accuracy domain distinction 0.504492\n",
      "VALIDATION Loss: 0.27279094 Acc: 0.89597315\n",
      "Epoch 16 of 500 took 0.295s\n",
      "Accuracy source 0.974219, main loss classifier 0.134348, source classification loss 0.094161, loss domain distinction 0.651570, accuracy domain distinction 0.497461\n",
      "VALIDATION Loss: 0.18858369 Acc: 0.9261745\n",
      "Epoch 17 of 500 took 0.294s\n",
      "Accuracy source 0.967578, main loss classifier 0.140716, source classification loss 0.104501, loss domain distinction 0.662355, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 0.11668599 Acc: 0.95637584\n",
      "Epoch    65: reducing learning rate of group 0 to 1.6096e-07.\n",
      "New best validation loss:  0.11668599396944046\n",
      "Epoch 18 of 500 took 0.325s\n",
      "Accuracy source 0.966797, main loss classifier 0.140083, source classification loss 0.104485, loss domain distinction 0.655223, accuracy domain distinction 0.501172\n",
      "VALIDATION Loss: 0.15978663 Acc: 0.94630872\n",
      "Epoch 19 of 500 took 0.352s\n",
      "Accuracy source 0.971094, main loss classifier 0.136281, source classification loss 0.095104, loss domain distinction 0.665191, accuracy domain distinction 0.486719\n",
      "VALIDATION Loss: 0.19971466 Acc: 0.9295302\n",
      "Epoch 20 of 500 took 0.312s\n",
      "Accuracy source 0.972656, main loss classifier 0.134242, source classification loss 0.094629, loss domain distinction 0.646404, accuracy domain distinction 0.489844\n",
      "VALIDATION Loss: 0.16622339 Acc: 0.9295302\n",
      "Epoch 21 of 500 took 0.304s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.969141, main loss classifier 0.139213, source classification loss 0.104336, loss domain distinction 0.652068, accuracy domain distinction 0.503320\n",
      "VALIDATION Loss: 0.20247392 Acc: 0.92281879\n",
      "Epoch 22 of 500 took 0.304s\n",
      "Accuracy source 0.972656, main loss classifier 0.137415, source classification loss 0.101484, loss domain distinction 0.643768, accuracy domain distinction 0.502148\n",
      "VALIDATION Loss: 0.22646032 Acc: 0.92281879\n",
      "Epoch 23 of 500 took 0.294s\n",
      "Accuracy source 0.975781, main loss classifier 0.130587, source classification loss 0.087984, loss domain distinction 0.642837, accuracy domain distinction 0.505273\n",
      "VALIDATION Loss: 0.27631086 Acc: 0.89597315\n",
      "Epoch    71: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 24 of 500 took 0.298s\n",
      "Accuracy source 0.968359, main loss classifier 0.139767, source classification loss 0.104546, loss domain distinction 0.652416, accuracy domain distinction 0.488672\n",
      "VALIDATION Loss: 0.16983737 Acc: 0.93624161\n",
      "Epoch 25 of 500 took 0.339s\n",
      "Accuracy source 0.966797, main loss classifier 0.144840, source classification loss 0.111264, loss domain distinction 0.662494, accuracy domain distinction 0.483398\n",
      "VALIDATION Loss: 0.28763032 Acc: 0.88590604\n",
      "Epoch 26 of 500 took 0.335s\n",
      "Accuracy source 0.969922, main loss classifier 0.136320, source classification loss 0.099502, loss domain distinction 0.641147, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.20330843 Acc: 0.91946309\n",
      "Epoch 27 of 500 took 0.334s\n",
      "Accuracy source 0.972266, main loss classifier 0.136262, source classification loss 0.100711, loss domain distinction 0.637894, accuracy domain distinction 0.508594\n",
      "VALIDATION Loss: 0.25734302 Acc: 0.89597315\n",
      "Epoch 28 of 500 took 0.328s\n",
      "Accuracy source 0.966016, main loss classifier 0.142143, source classification loss 0.107651, loss domain distinction 0.658198, accuracy domain distinction 0.482031\n",
      "VALIDATION Loss: 0.32504791 Acc: 0.88926174\n",
      "Training complete in 0m 9s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.969531, main loss classifier 0.170183, source classification loss 0.104504, loss domain distinction 1.048983, accuracy domain distinction 0.510352\n",
      "VALIDATION Loss: 0.32229888 Acc: 0.89261745\n",
      "New best validation loss:  0.32229888439178467\n",
      "Epoch 1 of 500 took 0.419s\n",
      "Accuracy source 0.973437, main loss classifier 0.163190, source classification loss 0.100943, loss domain distinction 0.981487, accuracy domain distinction 0.503125\n",
      "VALIDATION Loss: 0.34773478 Acc: 0.88255034\n",
      "Epoch 2 of 500 took 0.380s\n",
      "Accuracy source 0.964453, main loss classifier 0.164403, source classification loss 0.112477, loss domain distinction 0.926852, accuracy domain distinction 0.500391\n",
      "VALIDATION Loss: 0.43612292 Acc: 0.83557047\n",
      "Epoch 3 of 500 took 0.371s\n",
      "Accuracy source 0.971094, main loss classifier 0.153319, source classification loss 0.099794, loss domain distinction 0.863331, accuracy domain distinction 0.493359\n",
      "VALIDATION Loss: 0.38831154 Acc: 0.86241611\n",
      "Epoch 4 of 500 took 0.356s\n",
      "Accuracy source 0.966797, main loss classifier 0.150973, source classification loss 0.110014, loss domain distinction 0.777379, accuracy domain distinction 0.502148\n",
      "VALIDATION Loss: 0.36288732 Acc: 0.86912752\n",
      "Epoch 5 of 500 took 0.332s\n",
      "Accuracy source 0.968750, main loss classifier 0.148022, source classification loss 0.105410, loss domain distinction 0.758315, accuracy domain distinction 0.488867\n",
      "VALIDATION Loss: 0.37088460 Acc: 0.87583893\n",
      "Epoch    53: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.303s\n",
      "Accuracy source 0.968750, main loss classifier 0.141823, source classification loss 0.100582, loss domain distinction 0.714108, accuracy domain distinction 0.499219\n",
      "VALIDATION Loss: 0.32027912 Acc: 0.89261745\n",
      "New best validation loss:  0.3202791213989258\n",
      "Epoch 7 of 500 took 0.359s\n",
      "Accuracy source 0.969141, main loss classifier 0.141579, source classification loss 0.099469, loss domain distinction 0.710160, accuracy domain distinction 0.500977\n",
      "VALIDATION Loss: 0.34122041 Acc: 0.88590604\n",
      "Epoch 8 of 500 took 0.360s\n",
      "Accuracy source 0.967187, main loss classifier 0.141727, source classification loss 0.101575, loss domain distinction 0.703293, accuracy domain distinction 0.499609\n",
      "VALIDATION Loss: 0.30422673 Acc: 0.89597315\n",
      "New best validation loss:  0.30422672629356384\n",
      "Epoch 9 of 500 took 0.293s\n",
      "Accuracy source 0.972656, main loss classifier 0.139576, source classification loss 0.097769, loss domain distinction 0.695900, accuracy domain distinction 0.491992\n",
      "VALIDATION Loss: 0.32348314 Acc: 0.90268456\n",
      "Epoch 10 of 500 took 0.287s\n",
      "Accuracy source 0.971875, main loss classifier 0.141206, source classification loss 0.103900, loss domain distinction 0.678776, accuracy domain distinction 0.498437\n",
      "VALIDATION Loss: 0.39690667 Acc: 0.87248322\n",
      "Epoch 11 of 500 took 0.315s\n",
      "Accuracy source 0.970313, main loss classifier 0.135749, source classification loss 0.094545, loss domain distinction 0.667692, accuracy domain distinction 0.497656\n",
      "VALIDATION Loss: 0.39927468 Acc: 0.86912752\n",
      "Epoch    59: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.321s\n",
      "Accuracy source 0.968359, main loss classifier 0.139925, source classification loss 0.105012, loss domain distinction 0.656404, accuracy domain distinction 0.508984\n",
      "VALIDATION Loss: 0.55205613 Acc: 0.82214765\n",
      "Epoch 13 of 500 took 0.329s\n",
      "Accuracy source 0.968750, main loss classifier 0.141418, source classification loss 0.105659, loss domain distinction 0.665624, accuracy domain distinction 0.490625\n",
      "VALIDATION Loss: 0.34354165 Acc: 0.88926174\n",
      "Epoch 14 of 500 took 0.306s\n",
      "Accuracy source 0.971094, main loss classifier 0.136957, source classification loss 0.096583, loss domain distinction 0.667228, accuracy domain distinction 0.500586\n",
      "VALIDATION Loss: 0.43859950 Acc: 0.8557047\n",
      "Epoch 15 of 500 took 0.306s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.969141, main loss classifier 0.141107, source classification loss 0.107331, loss domain distinction 0.653614, accuracy domain distinction 0.509180\n",
      "VALIDATION Loss: 0.33503160 Acc: 0.89261745\n",
      "Epoch 16 of 500 took 0.298s\n",
      "Accuracy source 0.969531, main loss classifier 0.139706, source classification loss 0.103662, loss domain distinction 0.658166, accuracy domain distinction 0.506836\n",
      "VALIDATION Loss: 0.42384365 Acc: 0.8557047\n",
      "Epoch 17 of 500 took 0.327s\n",
      "Accuracy source 0.967969, main loss classifier 0.144959, source classification loss 0.112413, loss domain distinction 0.662997, accuracy domain distinction 0.496484\n",
      "VALIDATION Loss: 0.38487995 Acc: 0.87583893\n",
      "Epoch    65: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.343s\n",
      "Accuracy source 0.969531, main loss classifier 0.139799, source classification loss 0.105095, loss domain distinction 0.654301, accuracy domain distinction 0.506055\n",
      "VALIDATION Loss: 0.36968577 Acc: 0.88590604\n",
      "Epoch 19 of 500 took 0.314s\n",
      "Accuracy source 0.973047, main loss classifier 0.138723, source classification loss 0.102530, loss domain distinction 0.649641, accuracy domain distinction 0.504883\n",
      "VALIDATION Loss: 0.36359334 Acc: 0.88590604\n",
      "Training complete in 0m 7s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.973047, main loss classifier 0.164881, source classification loss 0.094022, loss domain distinction 1.043629, accuracy domain distinction 0.489648\n",
      "VALIDATION Loss: 0.35221964 Acc: 0.88255034\n",
      "New best validation loss:  0.3522196412086487\n",
      "Epoch 1 of 500 took 0.339s\n",
      "Accuracy source 0.969141, main loss classifier 0.164298, source classification loss 0.100749, loss domain distinction 0.993292, accuracy domain distinction 0.497461\n",
      "VALIDATION Loss: 0.29249442 Acc: 0.89932886\n",
      "New best validation loss:  0.29249441623687744\n",
      "Epoch 2 of 500 took 0.394s\n",
      "Accuracy source 0.973437, main loss classifier 0.155809, source classification loss 0.095900, loss domain distinction 0.922009, accuracy domain distinction 0.500195\n",
      "VALIDATION Loss: 0.28059489 Acc: 0.89261745\n",
      "New best validation loss:  0.2805948853492737\n",
      "Epoch 3 of 500 took 0.372s\n",
      "Accuracy source 0.971094, main loss classifier 0.157348, source classification loss 0.108356, loss domain distinction 0.862319, accuracy domain distinction 0.488086\n",
      "VALIDATION Loss: 0.34707269 Acc: 0.87583893\n",
      "Epoch 4 of 500 took 0.355s\n",
      "Accuracy source 0.970703, main loss classifier 0.145947, source classification loss 0.095411, loss domain distinction 0.800097, accuracy domain distinction 0.496680\n",
      "VALIDATION Loss: 0.29614812 Acc: 0.88926174\n",
      "Epoch 5 of 500 took 0.300s\n",
      "Accuracy source 0.968750, main loss classifier 0.151531, source classification loss 0.116529, loss domain distinction 0.734445, accuracy domain distinction 0.509570\n",
      "VALIDATION Loss: 0.27257302 Acc: 0.91946309\n",
      "Epoch    53: reducing learning rate of group 0 to 4.0240e-06.\n",
      "New best validation loss:  0.2725730240345001\n",
      "Epoch 6 of 500 took 0.410s\n",
      "Accuracy source 0.968750, main loss classifier 0.145534, source classification loss 0.106008, loss domain distinction 0.718769, accuracy domain distinction 0.500391\n",
      "VALIDATION Loss: 0.32270068 Acc: 0.87248322\n",
      "Epoch 7 of 500 took 0.361s\n",
      "Accuracy source 0.973828, main loss classifier 0.142603, source classification loss 0.103126, loss domain distinction 0.703078, accuracy domain distinction 0.491992\n",
      "VALIDATION Loss: 0.33892930 Acc: 0.88590604\n",
      "Epoch 8 of 500 took 0.336s\n",
      "Accuracy source 0.964063, main loss classifier 0.145170, source classification loss 0.107601, loss domain distinction 0.705868, accuracy domain distinction 0.502539\n",
      "VALIDATION Loss: 0.47400409 Acc: 0.84228188\n",
      "Epoch 9 of 500 took 0.348s\n",
      "Accuracy source 0.974219, main loss classifier 0.138470, source classification loss 0.098323, loss domain distinction 0.674602, accuracy domain distinction 0.497266\n",
      "VALIDATION Loss: 0.32392493 Acc: 0.86912752\n",
      "Epoch 10 of 500 took 0.374s\n",
      "Accuracy source 0.971484, main loss classifier 0.142293, source classification loss 0.103741, loss domain distinction 0.687331, accuracy domain distinction 0.490430\n",
      "VALIDATION Loss: 0.29741406 Acc: 0.87583893\n",
      "Epoch 11 of 500 took 0.399s\n",
      "Accuracy source 0.969922, main loss classifier 0.138198, source classification loss 0.098849, loss domain distinction 0.669972, accuracy domain distinction 0.498828\n",
      "VALIDATION Loss: 0.25858366 Acc: 0.91275168\n",
      "Epoch    59: reducing learning rate of group 0 to 8.0480e-07.\n",
      "New best validation loss:  0.258583664894104\n",
      "Epoch 12 of 500 took 0.382s\n",
      "Accuracy source 0.972656, main loss classifier 0.138021, source classification loss 0.095993, loss domain distinction 0.678021, accuracy domain distinction 0.491602\n",
      "VALIDATION Loss: 0.22316845 Acc: 0.91946309\n",
      "New best validation loss:  0.22316844761371613\n",
      "Epoch 13 of 500 took 0.379s\n",
      "Accuracy source 0.971875, main loss classifier 0.143029, source classification loss 0.106916, loss domain distinction 0.673356, accuracy domain distinction 0.493555\n",
      "VALIDATION Loss: 0.31326032 Acc: 0.87919463\n",
      "Epoch 14 of 500 took 0.352s\n",
      "Accuracy source 0.972266, main loss classifier 0.139833, source classification loss 0.102989, loss domain distinction 0.657980, accuracy domain distinction 0.504687\n",
      "VALIDATION Loss: 0.33687329 Acc: 0.86912752\n",
      "Epoch 15 of 500 took 0.325s\n",
      "Accuracy source 0.967578, main loss classifier 0.142959, source classification loss 0.107863, loss domain distinction 0.665854, accuracy domain distinction 0.495508\n",
      "VALIDATION Loss: 0.42136663 Acc: 0.8590604\n",
      "Epoch 16 of 500 took 0.324s\n",
      "Accuracy source 0.970313, main loss classifier 0.139442, source classification loss 0.103215, loss domain distinction 0.660967, accuracy domain distinction 0.502930\n",
      "VALIDATION Loss: 0.28026181 Acc: 0.91610738\n",
      "Epoch 17 of 500 took 0.314s\n",
      "Accuracy source 0.969922, main loss classifier 0.142528, source classification loss 0.110056, loss domain distinction 0.654942, accuracy domain distinction 0.503906\n",
      "VALIDATION Loss: 0.30724633 Acc: 0.89597315\n",
      "Epoch    65: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.311s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.971875, main loss classifier 0.138471, source classification loss 0.104008, loss domain distinction 0.640716, accuracy domain distinction 0.501172\n",
      "VALIDATION Loss: 0.34384078 Acc: 0.88926174\n",
      "Epoch 19 of 500 took 0.314s\n",
      "Accuracy source 0.967187, main loss classifier 0.142113, source classification loss 0.109918, loss domain distinction 0.648226, accuracy domain distinction 0.500391\n",
      "VALIDATION Loss: 0.22708240 Acc: 0.91275168\n",
      "Epoch 20 of 500 took 0.303s\n",
      "Accuracy source 0.970703, main loss classifier 0.139316, source classification loss 0.102724, loss domain distinction 0.654367, accuracy domain distinction 0.503906\n",
      "VALIDATION Loss: 0.32220843 Acc: 0.88590604\n",
      "Epoch 21 of 500 took 0.334s\n",
      "Accuracy source 0.969922, main loss classifier 0.137974, source classification loss 0.099606, loss domain distinction 0.656373, accuracy domain distinction 0.504492\n",
      "VALIDATION Loss: 0.36247462 Acc: 0.87248322\n",
      "Epoch 22 of 500 took 0.344s\n",
      "Accuracy source 0.974219, main loss classifier 0.135178, source classification loss 0.094341, loss domain distinction 0.659261, accuracy domain distinction 0.499414\n",
      "VALIDATION Loss: 0.47087690 Acc: 0.85234899\n",
      "Epoch 23 of 500 took 0.324s\n",
      "Accuracy source 0.973437, main loss classifier 0.135601, source classification loss 0.095352, loss domain distinction 0.656923, accuracy domain distinction 0.498242\n",
      "VALIDATION Loss: 0.26099277 Acc: 0.89597315\n",
      "Epoch    71: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Training complete in 0m 8s\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.977628, main loss classifier 0.162259, source classification loss 0.077927, loss domain distinction 1.118851, accuracy domain distinction 0.507102\n",
      "VALIDATION Loss: 0.07241152 Acc: 0.96363636\n",
      "New best validation loss:  0.07241152226924896\n",
      "Epoch 1 of 500 took 0.368s\n",
      "Accuracy source 0.977273, main loss classifier 0.156732, source classification loss 0.080555, loss domain distinction 1.036587, accuracy domain distinction 0.508523\n",
      "VALIDATION Loss: 0.06485768 Acc: 0.96969697\n",
      "New best validation loss:  0.06485767662525177\n",
      "Epoch 2 of 500 took 0.351s\n",
      "Accuracy source 0.980824, main loss classifier 0.143075, source classification loss 0.068203, loss domain distinction 0.947301, accuracy domain distinction 0.507457\n",
      "VALIDATION Loss: 0.04206093 Acc: 0.98181818\n",
      "New best validation loss:  0.04206093028187752\n",
      "Epoch 3 of 500 took 0.368s\n",
      "Accuracy source 0.982244, main loss classifier 0.141907, source classification loss 0.074085, loss domain distinction 0.894245, accuracy domain distinction 0.501598\n",
      "VALIDATION Loss: 0.08131617 Acc: 0.96666667\n",
      "Epoch 4 of 500 took 0.375s\n",
      "Accuracy source 0.979759, main loss classifier 0.137324, source classification loss 0.079748, loss domain distinction 0.805411, accuracy domain distinction 0.511541\n",
      "VALIDATION Loss: 0.10248410 Acc: 0.95454545\n",
      "Epoch 5 of 500 took 0.399s\n",
      "Accuracy source 0.974432, main loss classifier 0.135798, source classification loss 0.084343, loss domain distinction 0.751839, accuracy domain distinction 0.507990\n",
      "VALIDATION Loss: 0.05468129 Acc: 0.96969697\n",
      "Epoch    38: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.428s\n",
      "Accuracy source 0.981179, main loss classifier 0.127137, source classification loss 0.070320, loss domain distinction 0.727793, accuracy domain distinction 0.500355\n",
      "VALIDATION Loss: 0.04826327 Acc: 0.97878788\n",
      "Epoch 7 of 500 took 0.346s\n",
      "Accuracy source 0.976207, main loss classifier 0.133489, source classification loss 0.086236, loss domain distinction 0.709646, accuracy domain distinction 0.509766\n",
      "VALIDATION Loss: 0.02997430 Acc: 0.98181818\n",
      "New best validation loss:  0.029974304139614105\n",
      "Epoch 8 of 500 took 0.336s\n",
      "Accuracy source 0.979403, main loss classifier 0.126165, source classification loss 0.073000, loss domain distinction 0.699934, accuracy domain distinction 0.503374\n",
      "VALIDATION Loss: 0.06913694 Acc: 0.96969697\n",
      "Epoch 9 of 500 took 0.355s\n",
      "Accuracy source 0.976562, main loss classifier 0.124024, source classification loss 0.073948, loss domain distinction 0.672619, accuracy domain distinction 0.512074\n",
      "VALIDATION Loss: 0.08574238 Acc: 0.96060606\n",
      "Epoch 10 of 500 took 0.342s\n",
      "Accuracy source 0.976562, main loss classifier 0.126020, source classification loss 0.076901, loss domain distinction 0.673492, accuracy domain distinction 0.506747\n",
      "VALIDATION Loss: 0.09215996 Acc: 0.95757576\n",
      "Epoch 11 of 500 took 0.352s\n",
      "Accuracy source 0.977273, main loss classifier 0.128025, source classification loss 0.081102, loss domain distinction 0.668503, accuracy domain distinction 0.502131\n",
      "VALIDATION Loss: 0.06948362 Acc: 0.96969697\n",
      "Epoch    44: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.370s\n",
      "Accuracy source 0.980469, main loss classifier 0.123279, source classification loss 0.073602, loss domain distinction 0.661118, accuracy domain distinction 0.502841\n",
      "VALIDATION Loss: 0.15628329 Acc: 0.94848485\n",
      "Epoch 13 of 500 took 0.368s\n",
      "Accuracy source 0.980469, main loss classifier 0.124098, source classification loss 0.074774, loss domain distinction 0.658397, accuracy domain distinction 0.502308\n",
      "VALIDATION Loss: 0.08230375 Acc: 0.96666667\n",
      "Epoch 14 of 500 took 0.338s\n",
      "Accuracy source 0.978693, main loss classifier 0.125234, source classification loss 0.078166, loss domain distinction 0.653102, accuracy domain distinction 0.509766\n",
      "VALIDATION Loss: 0.08841871 Acc: 0.96363636\n",
      "Epoch 15 of 500 took 0.326s\n",
      "Accuracy source 0.982244, main loss classifier 0.120583, source classification loss 0.068702, loss domain distinction 0.652820, accuracy domain distinction 0.509055\n",
      "VALIDATION Loss: 0.07505878 Acc: 0.97575758\n",
      "Epoch 16 of 500 took 0.315s\n",
      "Accuracy source 0.979403, main loss classifier 0.123585, source classification loss 0.076344, loss domain distinction 0.645852, accuracy domain distinction 0.511009\n",
      "VALIDATION Loss: 0.04094040 Acc: 0.98181818\n",
      "Epoch 17 of 500 took 0.315s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.975852, main loss classifier 0.126366, source classification loss 0.081287, loss domain distinction 0.646589, accuracy domain distinction 0.513139\n",
      "VALIDATION Loss: 0.06863474 Acc: 0.97575758\n",
      "Epoch    50: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.320s\n",
      "Accuracy source 0.976562, main loss classifier 0.127143, source classification loss 0.083834, loss domain distinction 0.640282, accuracy domain distinction 0.509233\n",
      "VALIDATION Loss: 0.06273346 Acc: 0.97878788\n",
      "Training complete in 0m 7s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.977273, main loss classifier 0.162208, source classification loss 0.079773, loss domain distinction 1.106627, accuracy domain distinction 0.506392\n",
      "VALIDATION Loss: 0.05982950 Acc: 0.97575758\n",
      "New best validation loss:  0.05982949957251549\n",
      "Epoch 1 of 500 took 0.315s\n",
      "Accuracy source 0.976562, main loss classifier 0.159073, source classification loss 0.085420, loss domain distinction 1.035000, accuracy domain distinction 0.498224\n",
      "VALIDATION Loss: 0.05657241 Acc: 0.98181818\n",
      "New best validation loss:  0.056572411209344864\n",
      "Epoch 2 of 500 took 0.320s\n",
      "Accuracy source 0.977628, main loss classifier 0.149362, source classification loss 0.079720, loss domain distinction 0.954126, accuracy domain distinction 0.512251\n",
      "VALIDATION Loss: 0.05450204 Acc: 0.98181818\n",
      "New best validation loss:  0.05450204387307167\n",
      "Epoch 3 of 500 took 0.318s\n",
      "Accuracy source 0.978338, main loss classifier 0.142600, source classification loss 0.077312, loss domain distinction 0.884034, accuracy domain distinction 0.507457\n",
      "VALIDATION Loss: 0.04057363 Acc: 0.98484848\n",
      "New best validation loss:  0.04057363420724869\n",
      "Epoch 4 of 500 took 0.316s\n",
      "Accuracy source 0.978693, main loss classifier 0.135520, source classification loss 0.073629, loss domain distinction 0.818966, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 0.11049258 Acc: 0.96666667\n",
      "Epoch 5 of 500 took 0.319s\n",
      "Accuracy source 0.982244, main loss classifier 0.130479, source classification loss 0.074209, loss domain distinction 0.752168, accuracy domain distinction 0.502663\n",
      "VALIDATION Loss: 0.03516325 Acc: 0.98787879\n",
      "Epoch    38: reducing learning rate of group 0 to 4.0240e-06.\n",
      "New best validation loss:  0.03516325354576111\n",
      "Epoch 6 of 500 took 0.322s\n",
      "Accuracy source 0.981179, main loss classifier 0.129348, source classification loss 0.075700, loss domain distinction 0.724496, accuracy domain distinction 0.507102\n",
      "VALIDATION Loss: 0.04750741 Acc: 0.98484848\n",
      "Epoch 7 of 500 took 0.315s\n",
      "Accuracy source 0.980114, main loss classifier 0.126613, source classification loss 0.073584, loss domain distinction 0.704009, accuracy domain distinction 0.512251\n",
      "VALIDATION Loss: 0.06185182 Acc: 0.97272727\n",
      "Epoch 8 of 500 took 0.317s\n",
      "Accuracy source 0.975852, main loss classifier 0.131694, source classification loss 0.085555, loss domain distinction 0.690157, accuracy domain distinction 0.508878\n",
      "VALIDATION Loss: 0.04417203 Acc: 0.98181818\n",
      "Epoch 9 of 500 took 0.320s\n",
      "Accuracy source 0.975497, main loss classifier 0.131151, source classification loss 0.084219, loss domain distinction 0.688233, accuracy domain distinction 0.497869\n",
      "VALIDATION Loss: 0.05022339 Acc: 0.98181818\n",
      "Epoch 10 of 500 took 0.316s\n",
      "Accuracy source 0.979048, main loss classifier 0.128420, source classification loss 0.078118, loss domain distinction 0.690205, accuracy domain distinction 0.495561\n",
      "VALIDATION Loss: 0.09919207 Acc: 0.96666667\n",
      "Epoch 11 of 500 took 0.315s\n",
      "Accuracy source 0.979403, main loss classifier 0.125903, source classification loss 0.077176, loss domain distinction 0.665909, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 0.05377126 Acc: 0.98181818\n",
      "Epoch    44: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.317s\n",
      "Accuracy source 0.983665, main loss classifier 0.118220, source classification loss 0.065830, loss domain distinction 0.645976, accuracy domain distinction 0.511719\n",
      "VALIDATION Loss: 0.06077736 Acc: 0.97272727\n",
      "Epoch 13 of 500 took 0.316s\n",
      "Accuracy source 0.977983, main loss classifier 0.126326, source classification loss 0.079832, loss domain distinction 0.654230, accuracy domain distinction 0.505149\n",
      "VALIDATION Loss: 0.06547419 Acc: 0.97575758\n",
      "Epoch 14 of 500 took 0.315s\n",
      "Accuracy source 0.980824, main loss classifier 0.120423, source classification loss 0.069614, loss domain distinction 0.649368, accuracy domain distinction 0.509055\n",
      "VALIDATION Loss: 0.05270948 Acc: 0.98181818\n",
      "Epoch 15 of 500 took 0.316s\n",
      "Accuracy source 0.978693, main loss classifier 0.123671, source classification loss 0.073241, loss domain distinction 0.659763, accuracy domain distinction 0.497337\n",
      "VALIDATION Loss: 0.04861804 Acc: 0.97878788\n",
      "Epoch 16 of 500 took 0.314s\n",
      "Accuracy source 0.973722, main loss classifier 0.128183, source classification loss 0.083625, loss domain distinction 0.652179, accuracy domain distinction 0.504972\n",
      "VALIDATION Loss: 0.04992944 Acc: 0.98181818\n",
      "Training complete in 0m 5s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.979167, main loss classifier 0.162088, source classification loss 0.077021, loss domain distinction 1.122644, accuracy domain distinction 0.505394\n",
      "VALIDATION Loss: 0.04970623 Acc: 0.98484848\n",
      "New best validation loss:  0.04970623180270195\n",
      "Epoch 1 of 500 took 0.304s\n",
      "Accuracy source 0.979911, main loss classifier 0.155087, source classification loss 0.075342, loss domain distinction 1.046892, accuracy domain distinction 0.498512\n",
      "VALIDATION Loss: 0.04345572 Acc: 0.98787879\n",
      "New best validation loss:  0.04345571994781494\n",
      "Epoch 2 of 500 took 0.305s\n",
      "Accuracy source 0.980655, main loss classifier 0.148402, source classification loss 0.073787, loss domain distinction 0.975607, accuracy domain distinction 0.495908\n",
      "VALIDATION Loss: 0.05536653 Acc: 0.98787879\n",
      "Epoch 3 of 500 took 0.300s\n",
      "Accuracy source 0.975818, main loss classifier 0.141881, source classification loss 0.072699, loss domain distinction 0.900758, accuracy domain distinction 0.494234\n",
      "VALIDATION Loss: 0.09094058 Acc: 0.96969697\n",
      "Epoch 4 of 500 took 0.307s\n",
      "Accuracy source 0.975818, main loss classifier 0.142113, source classification loss 0.084750, loss domain distinction 0.830257, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 0.05693052 Acc: 0.98484848\n",
      "Epoch 5 of 500 took 0.306s\n",
      "Accuracy source 0.979167, main loss classifier 0.134645, source classification loss 0.079152, loss domain distinction 0.772797, accuracy domain distinction 0.499256\n",
      "VALIDATION Loss: 0.08608675 Acc: 0.97272727\n",
      "Epoch    38: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.306s\n",
      "Accuracy source 0.978423, main loss classifier 0.129298, source classification loss 0.075712, loss domain distinction 0.725534, accuracy domain distinction 0.505394\n",
      "VALIDATION Loss: 0.07428386 Acc: 0.97272727\n",
      "Epoch 7 of 500 took 0.302s\n",
      "Accuracy source 0.976190, main loss classifier 0.130410, source classification loss 0.077732, loss domain distinction 0.723875, accuracy domain distinction 0.489955\n",
      "VALIDATION Loss: 0.04193806 Acc: 0.98787879\n",
      "New best validation loss:  0.04193805530667305\n",
      "Epoch 8 of 500 took 0.305s\n",
      "Accuracy source 0.975446, main loss classifier 0.131132, source classification loss 0.078680, loss domain distinction 0.724331, accuracy domain distinction 0.496466\n",
      "VALIDATION Loss: 0.04834833 Acc: 0.98787879\n",
      "Epoch 9 of 500 took 0.306s\n",
      "Accuracy source 0.979167, main loss classifier 0.130124, source classification loss 0.079793, loss domain distinction 0.704447, accuracy domain distinction 0.494606\n",
      "VALIDATION Loss: 0.05183196 Acc: 0.99090909\n",
      "Epoch 10 of 500 took 0.300s\n",
      "Accuracy source 0.978051, main loss classifier 0.127640, source classification loss 0.074969, loss domain distinction 0.699233, accuracy domain distinction 0.491629\n",
      "VALIDATION Loss: 0.08201286 Acc: 0.97878788\n",
      "Epoch 11 of 500 took 0.323s\n",
      "Accuracy source 0.978423, main loss classifier 0.128721, source classification loss 0.080153, loss domain distinction 0.684821, accuracy domain distinction 0.500186\n",
      "VALIDATION Loss: 0.06278227 Acc: 0.98484848\n",
      "Epoch    44: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.302s\n",
      "Accuracy source 0.975446, main loss classifier 0.124154, source classification loss 0.073708, loss domain distinction 0.671896, accuracy domain distinction 0.503720\n",
      "VALIDATION Loss: 0.07540185 Acc: 0.98181818\n",
      "Epoch 13 of 500 took 0.300s\n",
      "Accuracy source 0.980655, main loss classifier 0.125822, source classification loss 0.075286, loss domain distinction 0.679897, accuracy domain distinction 0.497024\n",
      "VALIDATION Loss: 0.06261097 Acc: 0.98484848\n",
      "Epoch 14 of 500 took 0.304s\n",
      "Accuracy source 0.983259, main loss classifier 0.118051, source classification loss 0.060965, loss domain distinction 0.671085, accuracy domain distinction 0.504836\n",
      "VALIDATION Loss: 0.05190589 Acc: 0.98787879\n",
      "Epoch 15 of 500 took 0.314s\n",
      "Accuracy source 0.978795, main loss classifier 0.122488, source classification loss 0.070757, loss domain distinction 0.664605, accuracy domain distinction 0.510417\n",
      "VALIDATION Loss: 0.03610348 Acc: 0.98787879\n",
      "New best validation loss:  0.03610347583889961\n",
      "Epoch 16 of 500 took 0.309s\n",
      "Accuracy source 0.979539, main loss classifier 0.124005, source classification loss 0.070932, loss domain distinction 0.678228, accuracy domain distinction 0.484933\n",
      "VALIDATION Loss: 0.03694092 Acc: 0.98484848\n",
      "Epoch 17 of 500 took 0.300s\n",
      "Accuracy source 0.977307, main loss classifier 0.126731, source classification loss 0.080758, loss domain distinction 0.654486, accuracy domain distinction 0.505394\n",
      "VALIDATION Loss: 0.06627586 Acc: 0.98181818\n",
      "Epoch    50: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.303s\n",
      "Accuracy source 0.981399, main loss classifier 0.123393, source classification loss 0.071983, loss domain distinction 0.666737, accuracy domain distinction 0.502604\n",
      "VALIDATION Loss: 0.06609384 Acc: 0.97878788\n",
      "Epoch 19 of 500 took 0.301s\n",
      "Accuracy source 0.979911, main loss classifier 0.124714, source classification loss 0.075259, loss domain distinction 0.661549, accuracy domain distinction 0.495164\n",
      "VALIDATION Loss: 0.04830746 Acc: 0.98181818\n",
      "Epoch 20 of 500 took 0.299s\n",
      "Accuracy source 0.982515, main loss classifier 0.124878, source classification loss 0.075533, loss domain distinction 0.661792, accuracy domain distinction 0.489583\n",
      "VALIDATION Loss: 0.04537826 Acc: 0.98787879\n",
      "Epoch 21 of 500 took 0.305s\n",
      "Accuracy source 0.973214, main loss classifier 0.131860, source classification loss 0.087327, loss domain distinction 0.674229, accuracy domain distinction 0.493676\n",
      "VALIDATION Loss: 0.06837311 Acc: 0.98181818\n",
      "Epoch 22 of 500 took 0.301s\n",
      "Accuracy source 0.982887, main loss classifier 0.120961, source classification loss 0.067735, loss domain distinction 0.664601, accuracy domain distinction 0.494792\n",
      "VALIDATION Loss: 0.07207882 Acc: 0.97878788\n",
      "Epoch 23 of 500 took 0.300s\n",
      "Accuracy source 0.976190, main loss classifier 0.132324, source classification loss 0.090178, loss domain distinction 0.663586, accuracy domain distinction 0.497768\n",
      "VALIDATION Loss: 0.07782476 Acc: 0.97575758\n",
      "Epoch    56: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 24 of 500 took 0.304s\n",
      "Accuracy source 0.979911, main loss classifier 0.125228, source classification loss 0.075169, loss domain distinction 0.666785, accuracy domain distinction 0.498884\n",
      "VALIDATION Loss: 0.04948249 Acc: 0.98787879\n",
      "Epoch 25 of 500 took 0.306s\n",
      "Accuracy source 0.977307, main loss classifier 0.125704, source classification loss 0.076989, loss domain distinction 0.660890, accuracy domain distinction 0.486979\n",
      "VALIDATION Loss: 0.04491507 Acc: 0.98787879\n",
      "Epoch 26 of 500 took 0.301s\n",
      "Accuracy source 0.978795, main loss classifier 0.126738, source classification loss 0.077880, loss domain distinction 0.671358, accuracy domain distinction 0.507626\n",
      "VALIDATION Loss: 0.04224749 Acc: 0.98484848\n",
      "Training complete in 0m 8s\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.979759, main loss classifier 0.106257, source classification loss 0.067337, loss domain distinction 0.272764, accuracy domain distinction 0.493253\n",
      "VALIDATION Loss: 2.98801517 Acc: 0.50798722\n",
      "New best validation loss:  2.9880151748657227\n",
      "Epoch 1 of 500 took 0.321s\n",
      "Accuracy source 0.984020, main loss classifier 0.106716, source classification loss 0.068240, loss domain distinction 0.195813, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 2.77549052 Acc: 0.54952077\n",
      "New best validation loss:  2.7754905223846436\n",
      "Epoch 2 of 500 took 0.340s\n",
      "Accuracy source 0.985795, main loss classifier 0.098878, source classification loss 0.053945, loss domain distinction 0.190154, accuracy domain distinction 0.499290\n",
      "VALIDATION Loss: 2.93719363 Acc: 0.55591054\n",
      "Epoch 3 of 500 took 0.350s\n",
      "Accuracy source 0.979048, main loss classifier 0.105448, source classification loss 0.069415, loss domain distinction 0.186744, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 3.14246702 Acc: 0.5686901\n",
      "Epoch 4 of 500 took 0.355s\n",
      "Accuracy source 0.981534, main loss classifier 0.102077, source classification loss 0.062697, loss domain distinction 0.188133, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 3.23084950 Acc: 0.51757188\n",
      "Epoch 5 of 500 took 0.351s\n",
      "Accuracy source 0.980824, main loss classifier 0.101837, source classification loss 0.062129, loss domain distinction 0.186823, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 3.20162654 Acc: 0.50159744\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 6 of 500 took 0.357s\n",
      "Accuracy source 0.985795, main loss classifier 0.097097, source classification loss 0.054316, loss domain distinction 0.184206, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 2.71982193 Acc: 0.57188498\n",
      "New best validation loss:  2.7198219299316406\n",
      "Epoch 7 of 500 took 0.363s\n",
      "Accuracy source 0.984020, main loss classifier 0.096342, source classification loss 0.053428, loss domain distinction 0.185727, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.43965816 Acc: 0.5942492\n",
      "New best validation loss:  2.4396581649780273\n",
      "Epoch 8 of 500 took 0.365s\n",
      "Accuracy source 0.982955, main loss classifier 0.097823, source classification loss 0.056465, loss domain distinction 0.185244, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.53579283 Acc: 0.55910543\n",
      "Epoch 9 of 500 took 0.361s\n",
      "Accuracy source 0.985795, main loss classifier 0.099480, source classification loss 0.059477, loss domain distinction 0.184257, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.93586922 Acc: 0.56230032\n",
      "Epoch 10 of 500 took 0.357s\n",
      "Accuracy source 0.986861, main loss classifier 0.094281, source classification loss 0.049055, loss domain distinction 0.186565, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.60820818 Acc: 0.5686901\n",
      "Epoch 11 of 500 took 0.363s\n",
      "Accuracy source 0.986506, main loss classifier 0.092686, source classification loss 0.047077, loss domain distinction 0.185312, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.33238530 Acc: 0.5942492\n",
      "Epoch    36: reducing learning rate of group 0 to 2.0120e-05.\n",
      "New best validation loss:  2.332385301589966\n",
      "Epoch 12 of 500 took 0.366s\n",
      "Accuracy source 0.985440, main loss classifier 0.095057, source classification loss 0.050903, loss domain distinction 0.187499, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.59812331 Acc: 0.58146965\n",
      "Epoch 13 of 500 took 0.423s\n",
      "Accuracy source 0.982955, main loss classifier 0.094864, source classification loss 0.050598, loss domain distinction 0.186164, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 2.94348955 Acc: 0.55591054\n",
      "Epoch 14 of 500 took 0.420s\n",
      "Accuracy source 0.986861, main loss classifier 0.093473, source classification loss 0.048280, loss domain distinction 0.184956, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.79209852 Acc: 0.5686901\n",
      "Epoch 15 of 500 took 0.439s\n",
      "Accuracy source 0.985440, main loss classifier 0.094760, source classification loss 0.050695, loss domain distinction 0.185567, accuracy domain distinction 0.500178\n",
      "VALIDATION Loss: 2.24055791 Acc: 0.61661342\n",
      "New best validation loss:  2.240557909011841\n",
      "Epoch 16 of 500 took 0.422s\n",
      "Accuracy source 0.984020, main loss classifier 0.098861, source classification loss 0.058994, loss domain distinction 0.183085, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.24707079 Acc: 0.61341853\n",
      "Epoch 17 of 500 took 0.429s\n",
      "Accuracy source 0.983310, main loss classifier 0.098579, source classification loss 0.058829, loss domain distinction 0.185228, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.59822106 Acc: 0.58466454\n",
      "Epoch    42: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 18 of 500 took 0.426s\n",
      "Accuracy source 0.990767, main loss classifier 0.094111, source classification loss 0.049184, loss domain distinction 0.185327, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 2.87116981 Acc: 0.56230032\n",
      "Epoch 19 of 500 took 0.439s\n",
      "Accuracy source 0.982955, main loss classifier 0.097649, source classification loss 0.057623, loss domain distinction 0.184659, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.59754205 Acc: 0.57827476\n",
      "Epoch 20 of 500 took 0.442s\n",
      "Accuracy source 0.985795, main loss classifier 0.094800, source classification loss 0.050715, loss domain distinction 0.184305, accuracy domain distinction 0.499645\n",
      "VALIDATION Loss: 2.40301752 Acc: 0.58466454\n",
      "Epoch 21 of 500 took 0.443s\n",
      "Accuracy source 0.990057, main loss classifier 0.089023, source classification loss 0.038972, loss domain distinction 0.187383, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 2.24234819 Acc: 0.61341853\n",
      "Epoch 22 of 500 took 0.424s\n",
      "Accuracy source 0.987216, main loss classifier 0.091308, source classification loss 0.044494, loss domain distinction 0.185513, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 2.46193552 Acc: 0.5942492\n",
      "Epoch 23 of 500 took 0.420s\n",
      "Accuracy source 0.987571, main loss classifier 0.096148, source classification loss 0.053979, loss domain distinction 0.182605, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.25723481 Acc: 0.5942492\n",
      "Epoch    48: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 24 of 500 took 0.421s\n",
      "Accuracy source 0.989347, main loss classifier 0.091772, source classification loss 0.046039, loss domain distinction 0.184058, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.67700934 Acc: 0.56230032\n",
      "Epoch 25 of 500 took 0.404s\n",
      "Accuracy source 0.985085, main loss classifier 0.094199, source classification loss 0.049629, loss domain distinction 0.185892, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.28152895 Acc: 0.58785942\n",
      "Epoch 26 of 500 took 0.406s\n",
      "Accuracy source 0.987926, main loss classifier 0.093887, source classification loss 0.050147, loss domain distinction 0.183788, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.45044804 Acc: 0.58785942\n",
      "Training complete in 0m 11s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.978693, main loss classifier 0.108701, source classification loss 0.070093, loss domain distinction 0.273780, accuracy domain distinction 0.491477\n",
      "VALIDATION Loss: 0.17341076 Acc: 0.9456869\n",
      "New best validation loss:  0.17341075837612152\n",
      "Epoch 1 of 500 took 0.361s\n",
      "Accuracy source 0.981534, main loss classifier 0.105488, source classification loss 0.065508, loss domain distinction 0.195572, accuracy domain distinction 0.499290\n",
      "VALIDATION Loss: 0.07976484 Acc: 0.97444089\n",
      "New best validation loss:  0.07976483553647995\n",
      "Epoch 2 of 500 took 0.383s\n",
      "Accuracy source 0.984375, main loss classifier 0.100113, source classification loss 0.057287, loss domain distinction 0.191037, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 0.23613723 Acc: 0.91054313\n",
      "Epoch 3 of 500 took 0.362s\n",
      "Accuracy source 0.979403, main loss classifier 0.108986, source classification loss 0.074569, loss domain distinction 0.188955, accuracy domain distinction 0.500178\n",
      "VALIDATION Loss: 0.18132323 Acc: 0.93290735\n",
      "Epoch 4 of 500 took 0.343s\n",
      "Accuracy source 0.982599, main loss classifier 0.099089, source classification loss 0.056981, loss domain distinction 0.184587, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.08653850 Acc: 0.96485623\n",
      "Epoch 5 of 500 took 0.369s\n",
      "Accuracy source 0.984020, main loss classifier 0.101833, source classification loss 0.063836, loss domain distinction 0.185244, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.47029069 Acc: 0.82747604\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 6 of 500 took 0.369s\n",
      "Accuracy source 0.984730, main loss classifier 0.097367, source classification loss 0.055427, loss domain distinction 0.186352, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.10438566 Acc: 0.95846645\n",
      "Epoch 7 of 500 took 0.342s\n",
      "Accuracy source 0.984730, main loss classifier 0.095822, source classification loss 0.052442, loss domain distinction 0.186143, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.16375938 Acc: 0.92651757\n",
      "Epoch 8 of 500 took 0.353s\n",
      "Accuracy source 0.984375, main loss classifier 0.095691, source classification loss 0.052677, loss domain distinction 0.185423, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.12188713 Acc: 0.94888179\n",
      "Epoch 9 of 500 took 0.348s\n",
      "Accuracy source 0.986861, main loss classifier 0.097064, source classification loss 0.054905, loss domain distinction 0.185157, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.14599746 Acc: 0.94888179\n",
      "Epoch 10 of 500 took 0.356s\n",
      "Accuracy source 0.983310, main loss classifier 0.103110, source classification loss 0.067424, loss domain distinction 0.185499, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.17381974 Acc: 0.93610224\n",
      "Epoch 11 of 500 took 0.341s\n",
      "Accuracy source 0.988991, main loss classifier 0.092564, source classification loss 0.046327, loss domain distinction 0.185578, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.08155000 Acc: 0.96166134\n",
      "Epoch    36: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 12 of 500 took 0.345s\n",
      "Accuracy source 0.986151, main loss classifier 0.094220, source classification loss 0.050658, loss domain distinction 0.182363, accuracy domain distinction 0.500178\n",
      "VALIDATION Loss: 0.09027653 Acc: 0.96485623\n",
      "Training complete in 0m 5s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.981179, main loss classifier 0.107356, source classification loss 0.069488, loss domain distinction 0.269633, accuracy domain distinction 0.497337\n",
      "VALIDATION Loss: 0.28050157 Acc: 0.88498403\n",
      "New best validation loss:  0.2805015742778778\n",
      "Epoch 1 of 500 took 0.431s\n",
      "Accuracy source 0.980824, main loss classifier 0.106209, source classification loss 0.068361, loss domain distinction 0.196425, accuracy domain distinction 0.498757\n",
      "VALIDATION Loss: 0.16563596 Acc: 0.93290735\n",
      "New best validation loss:  0.16563595831394196\n",
      "Epoch 2 of 500 took 0.391s\n",
      "Accuracy source 0.979403, main loss classifier 0.110000, source classification loss 0.076571, loss domain distinction 0.190116, accuracy domain distinction 0.499290\n",
      "VALIDATION Loss: 0.50975639 Acc: 0.83067093\n",
      "Epoch 3 of 500 took 0.391s\n",
      "Accuracy source 0.982244, main loss classifier 0.104997, source classification loss 0.067057, loss domain distinction 0.188727, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 1.89165699 Acc: 0.63897764\n",
      "Epoch 4 of 500 took 0.417s\n",
      "Accuracy source 0.980469, main loss classifier 0.104947, source classification loss 0.068043, loss domain distinction 0.189074, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.13964801 Acc: 0.95207668\n",
      "New best validation loss:  0.13964800536632538\n",
      "Epoch 5 of 500 took 0.439s\n",
      "Accuracy source 0.981534, main loss classifier 0.103216, source classification loss 0.064705, loss domain distinction 0.188824, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.38403532 Acc: 0.85942492\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 6 of 500 took 0.392s\n",
      "Accuracy source 0.977628, main loss classifier 0.107941, source classification loss 0.076114, loss domain distinction 0.188475, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 0.14041865 Acc: 0.96166134\n",
      "Epoch 7 of 500 took 0.381s\n",
      "Accuracy source 0.988281, main loss classifier 0.093868, source classification loss 0.046697, loss domain distinction 0.187850, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.27970281 Acc: 0.90415335\n",
      "Epoch 8 of 500 took 0.404s\n",
      "Accuracy source 0.983665, main loss classifier 0.098921, source classification loss 0.058385, loss domain distinction 0.185766, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 0.18178292 Acc: 0.94888179\n",
      "Epoch 9 of 500 took 0.446s\n",
      "Accuracy source 0.983665, main loss classifier 0.098945, source classification loss 0.057956, loss domain distinction 0.187871, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.19358847 Acc: 0.9456869\n",
      "Epoch 10 of 500 took 0.410s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.985440, main loss classifier 0.098145, source classification loss 0.057062, loss domain distinction 0.185794, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.19609575 Acc: 0.93290735\n",
      "Epoch 11 of 500 took 0.420s\n",
      "Accuracy source 0.985795, main loss classifier 0.097146, source classification loss 0.054114, loss domain distinction 0.187618, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.15331629 Acc: 0.94888179\n",
      "Epoch    36: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 12 of 500 took 0.405s\n",
      "Accuracy source 0.986861, main loss classifier 0.092451, source classification loss 0.047111, loss domain distinction 0.183759, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.20542796 Acc: 0.91373802\n",
      "Epoch 13 of 500 took 0.379s\n",
      "Accuracy source 0.987926, main loss classifier 0.095095, source classification loss 0.051744, loss domain distinction 0.184729, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.22987051 Acc: 0.92332268\n",
      "Epoch 14 of 500 took 0.405s\n",
      "Accuracy source 0.986151, main loss classifier 0.095844, source classification loss 0.052919, loss domain distinction 0.185454, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.20208515 Acc: 0.92651757\n",
      "Epoch 15 of 500 took 0.407s\n",
      "Accuracy source 0.985795, main loss classifier 0.093975, source classification loss 0.049407, loss domain distinction 0.183643, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.15115963 Acc: 0.95207668\n",
      "Training complete in 0m 7s\n"
     ]
    }
   ],
   "source": [
    "train_DA_spectrograms(examples_datasets_train, labels_datasets_train, filter_size=None,\n",
    "                      num_kernels=num_neurons, algo_name=algo_name,\n",
    "                      path_weights_fine_tuning=path_weights_fine_tuning,\n",
    "                      gestures_to_remove=gestures_to_remove, number_of_classes=number_of_class,\n",
    "                      number_of_cycle_for_first_training=number_of_cycle_for_first_training,\n",
    "                      number_of_cycles_rest_of_training=number_of_cycles_rest_of_training,\n",
    "                      batch_size=128, spectrogram_model=False,\n",
    "                      feature_vector_input_length=feature_vector_input_length,\n",
    "                      path_weights_to_save_to=\"Weights_TSD/weights_\", learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1854, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1899, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1938, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1780, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1981, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1809, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1928, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1902, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  0  Session ID:  0  Accuracy:  0.9970414201183432\n",
      "Participant ID:  0  Session ID:  1  Accuracy:  0.6106194690265486\n",
      "Participant ID:  0  Session ID:  2  Accuracy:  0.7762172284644194\n",
      "Participant ID:  0  Session ID:  3  Accuracy:  0.6396568160152526\n",
      "ACCURACY PARTICIPANT:  [0.9970414201183432, 0.6106194690265486, 0.7762172284644194, 0.6396568160152526]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  1  Session ID:  0  Accuracy:  0.9945553539019963\n",
      "Participant ID:  1  Session ID:  1  Accuracy:  0.6748582230623819\n",
      "Participant ID:  1  Session ID:  2  Accuracy:  0.7269193391642371\n",
      "Participant ID:  1  Session ID:  3  Accuracy:  0.8762278978388998\n",
      "ACCURACY PARTICIPANT:  [0.9945553539019963, 0.6748582230623819, 0.7269193391642371, 0.8762278978388998]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  2  Session ID:  0  Accuracy:  0.9960199004975124\n",
      "Participant ID:  2  Session ID:  1  Accuracy:  0.19234360410831\n",
      "Participant ID:  2  Session ID:  2  Accuracy:  0.8402255639097744\n",
      "Participant ID:  2  Session ID:  3  Accuracy:  0.8302063789868668\n",
      "ACCURACY PARTICIPANT:  [0.9960199004975124, 0.19234360410831, 0.8402255639097744, 0.8302063789868668]\n",
      "[0.99704142 0.61061947 0.77621723 0.63965682 0.99455535 0.67485822\n",
      " 0.72691934 0.8762279  0.9960199  0.1923436  0.84022556 0.83020638]\n",
      "[0.9970414201183432, 0.6106194690265486, 0.7762172284644194, 0.6396568160152526, 0.9945553539019963, 0.6748582230623819, 0.7269193391642371, 0.8762278978388998, 0.9960199004975124, 0.19234360410831, 0.8402255639097744, 0.8302063789868668]\n",
      "OVERALL ACCURACY: 0.762907599591212\n"
     ]
    }
   ],
   "source": [
    "np.warnings.filterwarnings('error', category=np.VisibleDeprecationWarning)   \n",
    "test_network_DA_algorithm(examples_datasets_train, labels_datasets_train,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              num_neurons=num_neurons, path_weights_DA='Weights_TSD/weights_' + algo_name,\n",
    "                              algo_name=algo_name,\n",
    "                              path_weights_normal=path_weights_fine_tuning,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_class,\n",
    "                              cycle_to_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.776217</td>\n",
       "      <td>0.639657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_1</th>\n",
       "      <td>0.994555</td>\n",
       "      <td>0.674858</td>\n",
       "      <td>0.726919</td>\n",
       "      <td>0.876228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_2</th>\n",
       "      <td>0.996020</td>\n",
       "      <td>0.192344</td>\n",
       "      <td>0.840226</td>\n",
       "      <td>0.830206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0   0.997041   0.610619   0.776217   0.639657\n",
       "Participant_1   0.994555   0.674858   0.726919   0.876228\n",
       "Participant_2   0.996020   0.192344   0.840226   0.830206"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "DANN_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    DANN_acc[i] = acc\n",
    "DANN_acc_overall = np.mean(DANN_acc)\n",
    "DANN_df = pd.DataFrame(DANN_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "DANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"DANN Accuracies\")\n",
    "plt.savefig(\"/home/laiy/gitrepos/msr_final/code/test_code/img/3DC_DANN.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCADANN\n",
    "* start training using TSD_DNN model params for the first training seesion, then using DANN model params \n",
    "* first traning = labeled, others = pseudo labels \n",
    "    * train using one lebaled and n psuedo labeled (n = #session)\n",
    "* use all training data at once\n",
    "* pseudo_labels_heuristic\n",
    "    * window_stable_mode_length = 30 (hold stable for 1.5s)\n",
    "    * percentage_same_gesture_now_stable = 65% (remove examples that are likely to generate false pseudo labels)\n",
    "    * maximum_length_instability_gesture_transition = 40\n",
    "    * maximum_length_instability_same_gesture = 40 (remove examples that are unstable for more than 2s)\n",
    "* SCADANN loss (domain_loss_weight=1e-1)\n",
    "    * loss_domain_source = ((1 - alpha) * crossEntropyLoss(pred_domain_source, label_source_domain))\n",
    "    * loss_main_source = (0.5 * loss_source_class + domain_loss_weight * loss_domain_source)\n",
    "    * loss_domain_target = 0.5 * (crossEntropyLoss(pred_domain_target, label_target_domain))\n",
    "    * loss_main_target = (0.5 * loss_target_class + domain_loss_weight * loss_domain_target)\n",
    "    * loss_main = loss_main_source + loss_main_target\n",
    "    * loss_domain = loss_domain_source + loss_domain_target\n",
    "\n",
    "   \n",
    "\n",
    "### Weights_TSD/weights_THREE_CYCLES_11Gestures_SCADANN\n",
    "* beat_state_n.pt (n = # training session)\n",
    "    * epoch: #epochs\n",
    "    * model state_dict\n",
    "    * optimizer state_dict\n",
    "    * scheduler state_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import load_checkpoint\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm.load_dataset_spectrogram_in_dataloader import \\\n",
    "    load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.self_learning.self_learning_utils import \\\n",
    "    generate_dataloaders_for_SCADANN\n",
    "from LongTermClassificationMain.Models.model_training_self_learning import SCADANN_BN_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from SCADANN_TSD_DNN_training_session import run_SCADANN_training_sessions, test_network_SLADANN\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [200, 200, 200]\n",
    "learning_rate = 0.002515\n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = None\n",
    "number_of_classes = 11\n",
    "percentage_same_gesture_stable = 0.65  # 0.65 for 11 gestures, 0.85 for 7 gestures\n",
    "path_weight_to_save_to = \"Weights_TSD/weights_THREE_CYCLES_11Gestures_SCADANN\"\n",
    "path_weights_start_with = \"Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD\"\n",
    "path_weights_Normal_training = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "algo_name = \"SCADANN_THREE_CYCLES_11Gestures_TSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2972, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3144, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3202, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3135, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (3300, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3177, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3153, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3093, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (3129, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3209, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3183, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3150, 385)\n",
      "participants_train =  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd61d9b30>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 18)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 18)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.5773195876288659   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.35051546391752575   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  72\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.8041237113402062   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.041237113402061855   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6914893617021277   AFTER:  1.0  len before:  94   len after:  94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  95   len after:  95\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.5344827586206896   AFTER:  1.0  len before:  58   len after:  31\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.5555555555555556  len before:  97   len after:  72\n",
      "BEFORE:  0.422680412371134   AFTER:  0.5416666666666666  len before:  97   len after:  72\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1188118811881188   AFTER:  0.0  len before:  101   len after:  101\n",
      "ACCURACY MODEL:  0.6288167938931297   Accuracy pseudo: 0.7611567297393788  len pseudo:  2801    len predictions 3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Accuracy total 0.836607, main loss classifier 0.768922, source accuracy 0.966518 source classification loss 0.108026, target accuracy 0.706696 target loss 1.202709 accuracy domain distinction 0.485268 loss domain distinction 1.135552,\n",
      "VALIDATION Loss: 0.86712713 Acc: 0.78431373\n",
      "New best validation loss:  0.8671271337403191\n",
      "Epoch 2 of 500 took 0.568s\n",
      "Accuracy total 0.837500, main loss classifier 0.788817, source accuracy 0.967411 source classification loss 0.123808, target accuracy 0.707589 target loss 1.228274 accuracy domain distinction 0.498437 loss domain distinction 1.127762,\n",
      "VALIDATION Loss: 1.11972878 Acc: 0.73083779\n",
      "Epoch 3 of 500 took 0.596s\n",
      "Accuracy total 0.837500, main loss classifier 0.742731, source accuracy 0.963393 source classification loss 0.120618, target accuracy 0.711607 target loss 1.138710 accuracy domain distinction 0.494420 loss domain distinction 1.130671,\n",
      "VALIDATION Loss: 0.96010715 Acc: 0.73796791\n",
      "Epoch 4 of 500 took 0.654s\n",
      "Accuracy total 0.832143, main loss classifier 0.769380, source accuracy 0.963839 source classification loss 0.113040, target accuracy 0.700446 target loss 1.199740 accuracy domain distinction 0.489063 loss domain distinction 1.129905,\n",
      "VALIDATION Loss: 0.91961478 Acc: 0.73262032\n",
      "Epoch 5 of 500 took 0.676s\n",
      "Accuracy total 0.833036, main loss classifier 0.755930, source accuracy 0.965625 source classification loss 0.107913, target accuracy 0.700446 target loss 1.179856 accuracy domain distinction 0.504464 loss domain distinction 1.120447,\n",
      "VALIDATION Loss: 0.77218553 Acc: 0.79679144\n",
      "New best validation loss:  0.772185527616077\n",
      "Epoch 6 of 500 took 0.642s\n",
      "Accuracy total 0.829688, main loss classifier 0.753963, source accuracy 0.962946 source classification loss 0.121114, target accuracy 0.696429 target loss 1.162215 accuracy domain distinction 0.494866 loss domain distinction 1.122987,\n",
      "VALIDATION Loss: 0.80153627 Acc: 0.79679144\n",
      "Epoch 7 of 500 took 0.597s\n",
      "Accuracy total 0.837054, main loss classifier 0.773634, source accuracy 0.961161 source classification loss 0.126225, target accuracy 0.712946 target loss 1.196376 accuracy domain distinction 0.488839 loss domain distinction 1.123334,\n",
      "VALIDATION Loss: 0.76255627 Acc: 0.82352941\n",
      "New best validation loss:  0.762556274731954\n",
      "Epoch 8 of 500 took 0.598s\n",
      "Accuracy total 0.828348, main loss classifier 0.789297, source accuracy 0.967411 source classification loss 0.117607, target accuracy 0.689286 target loss 1.235301 accuracy domain distinction 0.493304 loss domain distinction 1.128431,\n",
      "VALIDATION Loss: 0.99464878 Acc: 0.72905526\n",
      "Epoch 9 of 500 took 0.571s\n",
      "Accuracy total 0.833036, main loss classifier 0.758067, source accuracy 0.965179 source classification loss 0.115360, target accuracy 0.700893 target loss 1.178437 accuracy domain distinction 0.494196 loss domain distinction 1.111682,\n",
      "VALIDATION Loss: 1.07675939 Acc: 0.6916221\n",
      "Epoch 10 of 500 took 0.630s\n",
      "Accuracy total 0.846875, main loss classifier 0.746704, source accuracy 0.963393 source classification loss 0.131892, target accuracy 0.730357 target loss 1.137421 accuracy domain distinction 0.497321 loss domain distinction 1.120475,\n",
      "VALIDATION Loss: 0.81741899 Acc: 0.78253119\n",
      "Epoch 11 of 500 took 0.613s\n",
      "Accuracy total 0.828571, main loss classifier 0.762785, source accuracy 0.960714 source classification loss 0.120827, target accuracy 0.696429 target loss 1.179343 accuracy domain distinction 0.491741 loss domain distinction 1.127006,\n",
      "VALIDATION Loss: 0.81629884 Acc: 0.77183601\n",
      "Epoch 12 of 500 took 0.627s\n",
      "Accuracy total 0.835938, main loss classifier 0.736932, source accuracy 0.966071 source classification loss 0.110325, target accuracy 0.705804 target loss 1.137756 accuracy domain distinction 0.483036 loss domain distinction 1.128910,\n",
      "VALIDATION Loss: 0.94038529 Acc: 0.75579323\n",
      "Epoch 13 of 500 took 0.598s\n",
      "Accuracy total 0.835268, main loss classifier 0.749658, source accuracy 0.960714 source classification loss 0.125302, target accuracy 0.709821 target loss 1.150659 accuracy domain distinction 0.496652 loss domain distinction 1.116775,\n",
      "VALIDATION Loss: 0.88159544 Acc: 0.73796791\n",
      "Epoch    13: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 14 of 500 took 0.606s\n",
      "Accuracy total 0.834375, main loss classifier 0.771368, source accuracy 0.962946 source classification loss 0.122352, target accuracy 0.705804 target loss 1.196291 accuracy domain distinction 0.496205 loss domain distinction 1.120461,\n",
      "VALIDATION Loss: 0.90536310 Acc: 0.76470588\n",
      "Epoch 15 of 500 took 0.610s\n",
      "Accuracy total 0.840179, main loss classifier 0.747461, source accuracy 0.962946 source classification loss 0.121930, target accuracy 0.717411 target loss 1.147186 accuracy domain distinction 0.492411 loss domain distinction 1.129023,\n",
      "VALIDATION Loss: 0.72373630 Acc: 0.80748663\n",
      "New best validation loss:  0.7237363027201759\n",
      "Epoch 16 of 500 took 0.546s\n",
      "Accuracy total 0.842187, main loss classifier 0.762932, source accuracy 0.967411 source classification loss 0.115950, target accuracy 0.716964 target loss 1.184766 accuracy domain distinction 0.497098 loss domain distinction 1.125745,\n",
      "VALIDATION Loss: 0.74933187 Acc: 0.79500891\n",
      "Epoch 17 of 500 took 0.569s\n",
      "Accuracy total 0.838393, main loss classifier 0.742364, source accuracy 0.966964 source classification loss 0.106864, target accuracy 0.709821 target loss 1.153831 accuracy domain distinction 0.485491 loss domain distinction 1.120164,\n",
      "VALIDATION Loss: 0.92903085 Acc: 0.76292335\n",
      "Epoch 18 of 500 took 0.584s\n",
      "Accuracy total 0.842411, main loss classifier 0.740555, source accuracy 0.963393 source classification loss 0.118165, target accuracy 0.721429 target loss 1.137275 accuracy domain distinction 0.490848 loss domain distinction 1.128351,\n",
      "VALIDATION Loss: 1.04561062 Acc: 0.71836007\n",
      "Epoch 19 of 500 took 0.593s\n",
      "Accuracy total 0.836830, main loss classifier 0.765712, source accuracy 0.967411 source classification loss 0.114172, target accuracy 0.706250 target loss 1.192272 accuracy domain distinction 0.494420 loss domain distinction 1.124904,\n",
      "VALIDATION Loss: 0.85725462 Acc: 0.78431373\n",
      "Epoch 20 of 500 took 0.585s\n",
      "Accuracy total 0.841741, main loss classifier 0.739674, source accuracy 0.967411 source classification loss 0.107299, target accuracy 0.716071 target loss 1.150154 accuracy domain distinction 0.508929 loss domain distinction 1.109479,\n",
      "VALIDATION Loss: 1.01771209 Acc: 0.72905526\n",
      "Epoch 21 of 500 took 0.614s\n",
      "Accuracy total 0.830804, main loss classifier 0.766812, source accuracy 0.961607 source classification loss 0.119312, target accuracy 0.700000 target loss 1.190356 accuracy domain distinction 0.489063 loss domain distinction 1.119786,\n",
      "VALIDATION Loss: 0.77840156 Acc: 0.81283422\n",
      "Epoch    21: reducing learning rate of group 0 to 6.4384e-09.\n",
      "Epoch 22 of 500 took 0.617s\n",
      "Accuracy total 0.833929, main loss classifier 0.745435, source accuracy 0.958036 source classification loss 0.132043, target accuracy 0.709821 target loss 1.134070 accuracy domain distinction 0.497991 loss domain distinction 1.123789,\n",
      "VALIDATION Loss: 0.91935071 Acc: 0.76827094\n",
      "Epoch 23 of 500 took 0.621s\n",
      "Accuracy total 0.830804, main loss classifier 0.796145, source accuracy 0.963393 source classification loss 0.126251, target accuracy 0.698214 target loss 1.240462 accuracy domain distinction 0.483036 loss domain distinction 1.127890,\n",
      "VALIDATION Loss: 0.96604912 Acc: 0.72727273\n",
      "Epoch 24 of 500 took 0.549s\n",
      "Accuracy total 0.838170, main loss classifier 0.753661, source accuracy 0.971429 source classification loss 0.107256, target accuracy 0.704911 target loss 1.177694 accuracy domain distinction 0.497098 loss domain distinction 1.111861,\n",
      "VALIDATION Loss: 0.93367275 Acc: 0.76648841\n",
      "Epoch 25 of 500 took 0.573s\n",
      "Accuracy total 0.838839, main loss classifier 0.730258, source accuracy 0.967411 source classification loss 0.111820, target accuracy 0.710268 target loss 1.124438 accuracy domain distinction 0.494643 loss domain distinction 1.121286,\n",
      "VALIDATION Loss: 0.95606756 Acc: 0.72192513\n",
      "Epoch 26 of 500 took 0.534s\n",
      "Accuracy total 0.847991, main loss classifier 0.749228, source accuracy 0.969643 source classification loss 0.114889, target accuracy 0.726339 target loss 1.159955 accuracy domain distinction 0.504687 loss domain distinction 1.118059,\n",
      "VALIDATION Loss: 0.91182486 Acc: 0.7254902\n",
      "Epoch 27 of 500 took 0.624s\n",
      "Training complete in 0m 16s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd574fc10>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 9)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 18)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 9)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.5773195876288659   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.35051546391752575   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  72\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.8041237113402062   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.041237113402061855   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6914893617021277   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  95   len after:  95\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.5344827586206896   AFTER:  1.0  len before:  58   len after:  31\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.5555555555555556  len before:  97   len after:  72\n",
      "BEFORE:  0.422680412371134   AFTER:  0.5416666666666666  len before:  97   len after:  72\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1188118811881188   AFTER:  0.0  len before:  101   len after:  101\n",
      "ACCURACY MODEL:  0.6288167938931297   Accuracy pseudo: 0.7611567297393788  len pseudo:  2801    len predictions 3144\n",
      "HANDLING NEW SESSION  2\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.38144329896907214   AFTER:  1.0  len before:  97   len after:  32\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  64\n",
      "BEFORE:  0.14432989690721648   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7525773195876289   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4230769230769231   AFTER:  0.2980769230769231  len before:  104   len after:  104\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9148936170212766   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.7446808510638298   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4845360824742268   AFTER:  0.6288659793814433  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.783260462211118   Accuracy pseudo: 0.8455906821963395  len pseudo:  3005    len predictions 3202\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.825169, main loss classifier 0.756903, source accuracy 0.813345 source classification loss 0.684057, target accuracy 0.836993 target loss 0.602658 accuracy domain distinction 0.499578 loss domain distinction 1.135447,\n",
      "VALIDATION Loss: 0.60343366 Acc: 0.83860233\n",
      "New best validation loss:  0.6034336626529694\n",
      "Epoch 2 of 500 took 0.723s\n",
      "Accuracy total 0.844806, main loss classifier 0.670911, source accuracy 0.835304 source classification loss 0.591451, target accuracy 0.854307 target loss 0.524656 accuracy domain distinction 0.497889 loss domain distinction 1.128572,\n",
      "VALIDATION Loss: 0.39227833 Acc: 0.90016639\n",
      "New best validation loss:  0.39227832704782484\n",
      "Epoch 3 of 500 took 0.731s\n",
      "Accuracy total 0.852618, main loss classifier 0.666223, source accuracy 0.834459 source classification loss 0.620833, target accuracy 0.870777 target loss 0.487542 accuracy domain distinction 0.509924 loss domain distinction 1.120361,\n",
      "VALIDATION Loss: 0.43553712 Acc: 0.88019967\n",
      "Epoch 4 of 500 took 0.726s\n",
      "Accuracy total 0.852407, main loss classifier 0.622133, source accuracy 0.850084 source classification loss 0.546060, target accuracy 0.854730 target loss 0.472788 accuracy domain distinction 0.489654 loss domain distinction 1.127093,\n",
      "VALIDATION Loss: 0.34506124 Acc: 0.90682196\n",
      "New best validation loss:  0.3450612351298332\n",
      "Epoch 5 of 500 took 0.725s\n",
      "Accuracy total 0.845861, main loss classifier 0.687920, source accuracy 0.837838 source classification loss 0.611738, target accuracy 0.853885 target loss 0.540282 accuracy domain distinction 0.490287 loss domain distinction 1.119100,\n",
      "VALIDATION Loss: 0.46778435 Acc: 0.88519135\n",
      "Epoch 6 of 500 took 0.798s\n",
      "Accuracy total 0.866132, main loss classifier 0.603951, source accuracy 0.860642 source classification loss 0.495213, target accuracy 0.871622 target loss 0.489632 accuracy domain distinction 0.495355 loss domain distinction 1.115279,\n",
      "VALIDATION Loss: 0.37599349 Acc: 0.8968386\n",
      "Epoch 7 of 500 took 0.792s\n",
      "Accuracy total 0.850929, main loss classifier 0.654648, source accuracy 0.847551 source classification loss 0.570283, target accuracy 0.854307 target loss 0.514006 accuracy domain distinction 0.493877 loss domain distinction 1.125037,\n",
      "VALIDATION Loss: 0.41086912 Acc: 0.89517471\n",
      "Epoch 8 of 500 took 0.734s\n",
      "Accuracy total 0.857897, main loss classifier 0.627650, source accuracy 0.855574 source classification loss 0.514868, target accuracy 0.860220 target loss 0.517807 accuracy domain distinction 0.492821 loss domain distinction 1.113132,\n",
      "VALIDATION Loss: 0.37492522 Acc: 0.90183028\n",
      "Epoch 9 of 500 took 0.672s\n",
      "Accuracy total 0.857897, main loss classifier 0.613696, source accuracy 0.851774 source classification loss 0.526855, target accuracy 0.864020 target loss 0.480708 accuracy domain distinction 0.499155 loss domain distinction 1.099141,\n",
      "VALIDATION Loss: 0.43449432 Acc: 0.88851913\n",
      "Epoch 10 of 500 took 0.681s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.864654, main loss classifier 0.591506, source accuracy 0.856419 source classification loss 0.503661, target accuracy 0.872889 target loss 0.461465 accuracy domain distinction 0.509291 loss domain distinction 1.089425,\n",
      "VALIDATION Loss: 0.39564482 Acc: 0.90016639\n",
      "Epoch    10: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 11 of 500 took 0.650s\n",
      "Accuracy total 0.861698, main loss classifier 0.607588, source accuracy 0.850507 source classification loss 0.541351, target accuracy 0.872889 target loss 0.457540 accuracy domain distinction 0.509713 loss domain distinction 1.081426,\n",
      "VALIDATION Loss: 0.40233786 Acc: 0.89184692\n",
      "Epoch 12 of 500 took 0.649s\n",
      "Accuracy total 0.855152, main loss classifier 0.643461, source accuracy 0.843328 source classification loss 0.586801, target accuracy 0.866976 target loss 0.476460 accuracy domain distinction 0.490921 loss domain distinction 1.118304,\n",
      "VALIDATION Loss: 0.37360395 Acc: 0.89517471\n",
      "Epoch 13 of 500 took 0.639s\n",
      "Accuracy total 0.858742, main loss classifier 0.608606, source accuracy 0.845861 source classification loss 0.545784, target accuracy 0.871622 target loss 0.452371 accuracy domain distinction 0.499578 loss domain distinction 1.095282,\n",
      "VALIDATION Loss: 0.43159842 Acc: 0.89351082\n",
      "Epoch 14 of 500 took 0.662s\n",
      "Accuracy total 0.866132, main loss classifier 0.598917, source accuracy 0.854307 source classification loss 0.521767, target accuracy 0.877956 target loss 0.458316 accuracy domain distinction 0.492399 loss domain distinction 1.088754,\n",
      "VALIDATION Loss: 0.36526980 Acc: 0.8985025\n",
      "Epoch 15 of 500 took 0.745s\n",
      "Accuracy total 0.860008, main loss classifier 0.603206, source accuracy 0.857686 source classification loss 0.512506, target accuracy 0.862331 target loss 0.477321 accuracy domain distinction 0.517103 loss domain distinction 1.082923,\n",
      "VALIDATION Loss: 0.40281296 Acc: 0.90682196\n",
      "Epoch 16 of 500 took 0.658s\n",
      "Training complete in 0m 11s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd5c11b30>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt' (epoch 13)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 47)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 18)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 9)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt' (epoch 13)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.5773195876288659   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.35051546391752575   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  72\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.8041237113402062   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.041237113402061855   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6914893617021277   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  95   len after:  95\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.5344827586206896   AFTER:  1.0  len before:  58   len after:  31\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.5555555555555556  len before:  97   len after:  72\n",
      "BEFORE:  0.422680412371134   AFTER:  0.5416666666666666  len before:  97   len after:  72\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  0.1188118811881188   AFTER:  0.0  len before:  101   len after:  101\n",
      "ACCURACY MODEL:  0.6288167938931297   Accuracy pseudo: 0.7611567297393788  len pseudo:  2801    len predictions 3144\n",
      "HANDLING NEW SESSION  2\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.38144329896907214   AFTER:  1.0  len before:  97   len after:  32\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  64\n",
      "BEFORE:  0.14432989690721648   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7525773195876289   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4230769230769231   AFTER:  0.2980769230769231  len before:  104   len after:  104\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9148936170212766   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.7446808510638298   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4845360824742268   AFTER:  0.6288659793814433  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.783260462211118   Accuracy pseudo: 0.8455906821963395  len pseudo:  3005    len predictions 3202\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  77\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9318181818181818   AFTER:  1.0  len before:  44   len after:  44\n",
      "BEFORE:  0.8041237113402062   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  1\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.0  len before:  97   len after:  57\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8811881188118812   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8723404255319149   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8942307692307693   AFTER:  1.0  len before:  104   len after:  104\n",
      "BEFORE:  0.5567010309278351   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "BEFORE:  0.36082474226804123   AFTER:  0.4852941176470588  len before:  97   len after:  68\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.31958762886597936   AFTER:  0.0  len before:  97   len after:  52\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6268656716417911   AFTER:  1.0  len before:  67   len after:  67\n",
      "BEFORE:  0.42574257425742573   AFTER:  0.32673267326732675  len before:  101   len after:  101\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  47\n",
      "BEFORE:  0.2268041237113402   AFTER:  0.16494845360824742  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.0297029702970297   AFTER:  0.0  len before:  101   len after:  101\n",
      "ACCURACY MODEL:  0.7358851674641148   Accuracy pseudo: 0.8327439886845828  len pseudo:  2828    len predictions 3135\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.811161, main loss classifier 0.842284, source accuracy 0.820089 source classification loss 0.707552, target accuracy 0.802232 target loss 0.749581 accuracy domain distinction 0.490179 loss domain distinction 1.137173,\n",
      "VALIDATION Loss: 0.49819616 Acc: 0.86749117\n",
      "New best validation loss:  0.49819615814420914\n",
      "Epoch 2 of 500 took 0.630s\n",
      "Accuracy total 0.814955, main loss classifier 0.822433, source accuracy 0.825000 source classification loss 0.646680, target accuracy 0.804911 target loss 0.773443 accuracy domain distinction 0.501786 loss domain distinction 1.123719,\n",
      "VALIDATION Loss: 0.47544358 Acc: 0.86749117\n",
      "New best validation loss:  0.47544357511732316\n",
      "Epoch 3 of 500 took 0.612s\n",
      "Accuracy total 0.813839, main loss classifier 0.820713, source accuracy 0.819196 source classification loss 0.695554, target accuracy 0.808482 target loss 0.718827 accuracy domain distinction 0.494420 loss domain distinction 1.135218,\n",
      "VALIDATION Loss: 0.43404423 Acc: 0.88162544\n",
      "New best validation loss:  0.4340442319711049\n",
      "Epoch 4 of 500 took 0.629s\n",
      "Accuracy total 0.816071, main loss classifier 0.813260, source accuracy 0.823661 source classification loss 0.647896, target accuracy 0.808482 target loss 0.752875 accuracy domain distinction 0.495312 loss domain distinction 1.128748,\n",
      "VALIDATION Loss: 0.41490258 Acc: 0.88162544\n",
      "New best validation loss:  0.41490257945325637\n",
      "Epoch 5 of 500 took 0.678s\n",
      "Accuracy total 0.812500, main loss classifier 0.821231, source accuracy 0.824554 source classification loss 0.646355, target accuracy 0.800446 target loss 0.769502 accuracy domain distinction 0.495089 loss domain distinction 1.133026,\n",
      "VALIDATION Loss: 0.44928910 Acc: 0.86925795\n",
      "Epoch 6 of 500 took 0.643s\n",
      "Accuracy total 0.818527, main loss classifier 0.779392, source accuracy 0.823214 source classification loss 0.629751, target accuracy 0.813839 target loss 0.702082 accuracy domain distinction 0.498661 loss domain distinction 1.134756,\n",
      "VALIDATION Loss: 0.46254328 Acc: 0.87632509\n",
      "Epoch 7 of 500 took 0.599s\n",
      "Accuracy total 0.816295, main loss classifier 0.841194, source accuracy 0.818304 source classification loss 0.749682, target accuracy 0.814286 target loss 0.708643 accuracy domain distinction 0.502902 loss domain distinction 1.120320,\n",
      "VALIDATION Loss: 0.45597886 Acc: 0.88869258\n",
      "Epoch 8 of 500 took 0.598s\n",
      "Accuracy total 0.810045, main loss classifier 0.839342, source accuracy 0.815179 source classification loss 0.662175, target accuracy 0.804911 target loss 0.793184 accuracy domain distinction 0.507143 loss domain distinction 1.116626,\n",
      "VALIDATION Loss: 0.47090554 Acc: 0.85865724\n",
      "Epoch 9 of 500 took 0.658s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.817857, main loss classifier 0.824465, source accuracy 0.835714 source classification loss 0.629226, target accuracy 0.800000 target loss 0.796839 accuracy domain distinction 0.500670 loss domain distinction 1.114331,\n",
      "VALIDATION Loss: 0.46177110 Acc: 0.85689046\n",
      "Epoch 10 of 500 took 0.555s\n",
      "Accuracy total 0.819420, main loss classifier 0.792281, source accuracy 0.839286 source classification loss 0.604950, target accuracy 0.799554 target loss 0.752930 accuracy domain distinction 0.497098 loss domain distinction 1.133409,\n",
      "VALIDATION Loss: 0.48125322 Acc: 0.86219081\n",
      "Epoch    10: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 11 of 500 took 0.538s\n",
      "Accuracy total 0.814286, main loss classifier 0.820669, source accuracy 0.824107 source classification loss 0.663516, target accuracy 0.804464 target loss 0.752209 accuracy domain distinction 0.501786 loss domain distinction 1.128060,\n",
      "VALIDATION Loss: 0.41442364 Acc: 0.89575972\n",
      "New best validation loss:  0.4144236428870095\n",
      "Epoch 12 of 500 took 0.580s\n",
      "Accuracy total 0.819643, main loss classifier 0.780811, source accuracy 0.827232 source classification loss 0.618301, target accuracy 0.812054 target loss 0.715895 accuracy domain distinction 0.487723 loss domain distinction 1.137131,\n",
      "VALIDATION Loss: 0.39409355 Acc: 0.90106007\n",
      "New best validation loss:  0.3940935466024611\n",
      "Epoch 13 of 500 took 0.632s\n",
      "Accuracy total 0.825000, main loss classifier 0.771819, source accuracy 0.837500 source classification loss 0.596808, target accuracy 0.812500 target loss 0.722200 accuracy domain distinction 0.494196 loss domain distinction 1.123147,\n",
      "VALIDATION Loss: 0.38380764 Acc: 0.89399293\n",
      "New best validation loss:  0.38380763596958584\n",
      "Epoch 14 of 500 took 0.560s\n",
      "Accuracy total 0.822768, main loss classifier 0.784099, source accuracy 0.826339 source classification loss 0.636539, target accuracy 0.819196 target loss 0.707670 accuracy domain distinction 0.480134 loss domain distinction 1.119943,\n",
      "VALIDATION Loss: 0.41357335 Acc: 0.87985866\n",
      "Epoch 15 of 500 took 0.560s\n",
      "Accuracy total 0.816518, main loss classifier 0.797140, source accuracy 0.816964 source classification loss 0.670844, target accuracy 0.816071 target loss 0.701176 accuracy domain distinction 0.503571 loss domain distinction 1.111307,\n",
      "VALIDATION Loss: 0.45163259 Acc: 0.87985866\n",
      "Epoch 16 of 500 took 0.614s\n",
      "Accuracy total 0.820536, main loss classifier 0.799263, source accuracy 0.828125 source classification loss 0.626956, target accuracy 0.812946 target loss 0.746952 accuracy domain distinction 0.495982 loss domain distinction 1.123094,\n",
      "VALIDATION Loss: 0.42056376 Acc: 0.88339223\n",
      "Epoch 17 of 500 took 0.535s\n",
      "Accuracy total 0.826339, main loss classifier 0.787008, source accuracy 0.829464 source classification loss 0.649768, target accuracy 0.823214 target loss 0.701323 accuracy domain distinction 0.495312 loss domain distinction 1.114622,\n",
      "VALIDATION Loss: 0.46821765 Acc: 0.88339223\n",
      "Epoch 18 of 500 took 0.538s\n",
      "Accuracy total 0.823438, main loss classifier 0.802093, source accuracy 0.830357 source classification loss 0.667136, target accuracy 0.816518 target loss 0.715347 accuracy domain distinction 0.502232 loss domain distinction 1.108517,\n",
      "VALIDATION Loss: 0.52519377 Acc: 0.83745583\n",
      "Epoch 19 of 500 took 0.577s\n",
      "Accuracy total 0.819866, main loss classifier 0.800232, source accuracy 0.831250 source classification loss 0.611312, target accuracy 0.808482 target loss 0.765202 accuracy domain distinction 0.500893 loss domain distinction 1.119749,\n",
      "VALIDATION Loss: 0.42521126 Acc: 0.89222615\n",
      "Epoch    19: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 20 of 500 took 0.526s\n",
      "Accuracy total 0.824554, main loss classifier 0.770175, source accuracy 0.842411 source classification loss 0.582697, target accuracy 0.806696 target loss 0.734297 accuracy domain distinction 0.499777 loss domain distinction 1.116782,\n",
      "VALIDATION Loss: 0.44548762 Acc: 0.87279152\n",
      "Epoch 21 of 500 took 0.540s\n",
      "Accuracy total 0.824554, main loss classifier 0.784074, source accuracy 0.838839 source classification loss 0.621931, target accuracy 0.810268 target loss 0.721448 accuracy domain distinction 0.495089 loss domain distinction 1.123848,\n",
      "VALIDATION Loss: 0.41381752 Acc: 0.8975265\n",
      "Epoch 22 of 500 took 0.520s\n",
      "Accuracy total 0.825000, main loss classifier 0.784631, source accuracy 0.829018 source classification loss 0.623087, target accuracy 0.820982 target loss 0.718315 accuracy domain distinction 0.504018 loss domain distinction 1.139304,\n",
      "VALIDATION Loss: 0.47132544 Acc: 0.8869258\n",
      "Epoch 23 of 500 took 0.531s\n",
      "Accuracy total 0.819196, main loss classifier 0.801959, source accuracy 0.818750 source classification loss 0.649235, target accuracy 0.819643 target loss 0.729275 accuracy domain distinction 0.500670 loss domain distinction 1.127044,\n",
      "VALIDATION Loss: 0.46474880 Acc: 0.86572438\n",
      "Epoch 24 of 500 took 0.577s\n",
      "Accuracy total 0.824777, main loss classifier 0.781055, source accuracy 0.837946 source classification loss 0.587870, target accuracy 0.811607 target loss 0.750086 accuracy domain distinction 0.499554 loss domain distinction 1.120773,\n",
      "VALIDATION Loss: 0.40706626 Acc: 0.88869258\n",
      "Epoch 25 of 500 took 0.580s\n",
      "Training complete in 0m 14s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dcf92a0b0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 8)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 8)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.7340425531914894   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  69\n",
      "BEFORE:  0.22340425531914893   AFTER:  0.0  len before:  94   len after:  43\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.3711340206185567  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7978723404255319   AFTER:  1.0  len before:  94   len after:  66\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9591836734693877   AFTER:  1.0  len before:  98   len after:  98\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9813084112149533   AFTER:  1.0  len before:  107   len after:  107\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.5319148936170213   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.32989690721649484  len before:  97   len after:  97\n",
      "BEFORE:  0.39361702127659576   AFTER:  0.20212765957446807  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  1\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.6741573033707865   AFTER:  1.0  len before:  89   len after:  45\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8723404255319149   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.24742268041237114   AFTER:  0.0  len before:  97   len after:  31\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  52\n",
      "BEFORE:  0.3617021276595745   AFTER:  0.3723404255319149  len before:  94   len after:  94\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  69\n",
      "ACCURACY MODEL:  0.6927919420837267   Accuracy pseudo: 0.8480631816472358  len pseudo:  2659    len predictions 3177\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.871686, main loss classifier 0.643039, source accuracy 0.975379 source classification loss 0.091460, target accuracy 0.767992 target loss 0.969956 accuracy domain distinction 0.505208 loss domain distinction 1.123311,\n",
      "VALIDATION Loss: 0.64166330 Acc: 0.80075188\n",
      "New best validation loss:  0.6416632963551415\n",
      "Epoch 2 of 500 took 0.621s\n",
      "Accuracy total 0.876184, main loss classifier 0.613347, source accuracy 0.970170 source classification loss 0.088271, target accuracy 0.782197 target loss 0.915497 accuracy domain distinction 0.500237 loss domain distinction 1.114630,\n",
      "VALIDATION Loss: 0.65527135 Acc: 0.84210526\n",
      "Epoch 3 of 500 took 0.591s\n",
      "Accuracy total 0.872633, main loss classifier 0.603585, source accuracy 0.980114 source classification loss 0.077091, target accuracy 0.765152 target loss 0.910410 accuracy domain distinction 0.508049 loss domain distinction 1.098347,\n",
      "VALIDATION Loss: 0.56806919 Acc: 0.84022556\n",
      "New best validation loss:  0.568069189786911\n",
      "Epoch 4 of 500 took 0.701s\n",
      "Accuracy total 0.880445, main loss classifier 0.572507, source accuracy 0.971591 source classification loss 0.085767, target accuracy 0.789299 target loss 0.839254 accuracy domain distinction 0.497633 loss domain distinction 1.099965,\n",
      "VALIDATION Loss: 0.70243890 Acc: 0.81203008\n",
      "Epoch 5 of 500 took 0.703s\n",
      "Accuracy total 0.879972, main loss classifier 0.566788, source accuracy 0.972538 source classification loss 0.090977, target accuracy 0.787405 target loss 0.826251 accuracy domain distinction 0.499053 loss domain distinction 1.081736,\n",
      "VALIDATION Loss: 0.74116200 Acc: 0.80075188\n",
      "Epoch 6 of 500 took 0.680s\n",
      "Accuracy total 0.887311, main loss classifier 0.543072, source accuracy 0.973485 source classification loss 0.092007, target accuracy 0.801136 target loss 0.779524 accuracy domain distinction 0.508759 loss domain distinction 1.073063,\n",
      "VALIDATION Loss: 0.61084186 Acc: 0.81578947\n",
      "Epoch 7 of 500 took 0.616s\n",
      "Accuracy total 0.890862, main loss classifier 0.549683, source accuracy 0.975379 source classification loss 0.096949, target accuracy 0.806345 target loss 0.784964 accuracy domain distinction 0.501657 loss domain distinction 1.087269,\n",
      "VALIDATION Loss: 0.61186269 Acc: 0.83646617\n",
      "Epoch 8 of 500 took 0.603s\n",
      "Accuracy total 0.883996, main loss classifier 0.582095, source accuracy 0.973011 source classification loss 0.097118, target accuracy 0.794981 target loss 0.848326 accuracy domain distinction 0.494318 loss domain distinction 1.093724,\n",
      "VALIDATION Loss: 0.54959994 Acc: 0.85714286\n",
      "New best validation loss:  0.5495999422338274\n",
      "Epoch 9 of 500 took 0.590s\n",
      "Accuracy total 0.889915, main loss classifier 0.533765, source accuracy 0.972538 source classification loss 0.091612, target accuracy 0.807292 target loss 0.760703 accuracy domain distinction 0.509233 loss domain distinction 1.076077,\n",
      "VALIDATION Loss: 0.43597169 Acc: 0.87593985\n",
      "New best validation loss:  0.4359716859956582\n",
      "Epoch 10 of 500 took 0.650s\n",
      "Accuracy total 0.887547, main loss classifier 0.528143, source accuracy 0.974432 source classification loss 0.090058, target accuracy 0.800663 target loss 0.753876 accuracy domain distinction 0.504735 loss domain distinction 1.061756,\n",
      "VALIDATION Loss: 0.52804572 Acc: 0.84962406\n",
      "Epoch 11 of 500 took 0.580s\n",
      "Accuracy total 0.889441, main loss classifier 0.537718, source accuracy 0.973011 source classification loss 0.085497, target accuracy 0.805871 target loss 0.776888 accuracy domain distinction 0.502367 loss domain distinction 1.065252,\n",
      "VALIDATION Loss: 0.52471008 Acc: 0.84962406\n",
      "Epoch 12 of 500 took 0.575s\n",
      "Accuracy total 0.887074, main loss classifier 0.546849, source accuracy 0.974905 source classification loss 0.092279, target accuracy 0.799242 target loss 0.787327 accuracy domain distinction 0.493845 loss domain distinction 1.070463,\n",
      "VALIDATION Loss: 0.68943652 Acc: 0.80263158\n",
      "Epoch 13 of 500 took 0.505s\n",
      "Accuracy total 0.890625, main loss classifier 0.540118, source accuracy 0.973011 source classification loss 0.091885, target accuracy 0.808239 target loss 0.776490 accuracy domain distinction 0.500710 loss domain distinction 1.059304,\n",
      "VALIDATION Loss: 0.55303677 Acc: 0.84586466\n",
      "Epoch 14 of 500 took 0.559s\n",
      "Accuracy total 0.888968, main loss classifier 0.542155, source accuracy 0.976326 source classification loss 0.091842, target accuracy 0.801610 target loss 0.779396 accuracy domain distinction 0.497396 loss domain distinction 1.065359,\n",
      "VALIDATION Loss: 0.46775175 Acc: 0.87969925\n",
      "Epoch 15 of 500 took 0.526s\n",
      "Accuracy total 0.891098, main loss classifier 0.517749, source accuracy 0.964962 source classification loss 0.102371, target accuracy 0.817235 target loss 0.720028 accuracy domain distinction 0.497159 loss domain distinction 1.065493,\n",
      "VALIDATION Loss: 0.46899747 Acc: 0.86090226\n",
      "Epoch    15: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 16 of 500 took 0.469s\n",
      "Accuracy total 0.890152, main loss classifier 0.518193, source accuracy 0.973958 source classification loss 0.089013, target accuracy 0.806345 target loss 0.731314 accuracy domain distinction 0.491241 loss domain distinction 1.080296,\n",
      "VALIDATION Loss: 0.57313753 Acc: 0.82706767\n",
      "Epoch 17 of 500 took 0.496s\n",
      "Accuracy total 0.893939, main loss classifier 0.512815, source accuracy 0.974432 source classification loss 0.084217, target accuracy 0.813447 target loss 0.728688 accuracy domain distinction 0.497633 loss domain distinction 1.063626,\n",
      "VALIDATION Loss: 0.50198931 Acc: 0.85902256\n",
      "Epoch 18 of 500 took 0.478s\n",
      "Accuracy total 0.900568, main loss classifier 0.496262, source accuracy 0.973485 source classification loss 0.091353, target accuracy 0.827652 target loss 0.688770 accuracy domain distinction 0.502131 loss domain distinction 1.062002,\n",
      "VALIDATION Loss: 0.53997559 Acc: 0.86278195\n",
      "Epoch 19 of 500 took 0.507s\n",
      "Accuracy total 0.890862, main loss classifier 0.531064, source accuracy 0.975852 source classification loss 0.094509, target accuracy 0.805871 target loss 0.756164 accuracy domain distinction 0.503788 loss domain distinction 1.057272,\n",
      "VALIDATION Loss: 0.51856813 Acc: 0.87781955\n",
      "Epoch 20 of 500 took 0.464s\n",
      "Accuracy total 0.889441, main loss classifier 0.536359, source accuracy 0.977746 source classification loss 0.084246, target accuracy 0.801136 target loss 0.774789 accuracy domain distinction 0.490767 loss domain distinction 1.068413,\n",
      "VALIDATION Loss: 0.57807701 Acc: 0.85902256\n",
      "Epoch 21 of 500 took 0.467s\n",
      "Training complete in 0m 11s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd5c11190>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt' (epoch 6)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 8)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt' (epoch 6)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.7340425531914894   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  69\n",
      "BEFORE:  0.22340425531914893   AFTER:  0.0  len before:  94   len after:  43\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.3711340206185567  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7978723404255319   AFTER:  1.0  len before:  94   len after:  66\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9591836734693877   AFTER:  1.0  len before:  98   len after:  98\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9813084112149533   AFTER:  1.0  len before:  107   len after:  107\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.5319148936170213   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.32989690721649484  len before:  97   len after:  97\n",
      "BEFORE:  0.39361702127659576   AFTER:  0.20212765957446807  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  1\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.6741573033707865   AFTER:  1.0  len before:  89   len after:  45\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8723404255319149   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.24742268041237114   AFTER:  0.0  len before:  97   len after:  31\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  52\n",
      "BEFORE:  0.3617021276595745   AFTER:  0.3723404255319149  len before:  94   len after:  94\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  69\n",
      "ACCURACY MODEL:  0.6927919420837267   Accuracy pseudo: 0.8480631816472358  len pseudo:  2659    len predictions 3177\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.5277777777777778  len before:  97   len after:  72\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.4639175257731959   AFTER:  0.8461538461538461  len before:  97   len after:  13\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4742268041237113   AFTER:  0.14814814814814814  len before:  97   len after:  54\n",
      "BEFORE:  0.9081632653061225   AFTER:  1.0  len before:  98   len after:  71\n",
      "BEFORE:  0.41237113402061853   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.17777777777777778   AFTER:  0.0  len before:  90   len after:  90\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.981651376146789   AFTER:  1.0  len before:  109   len after:  109\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.967032967032967   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.7916666666666666   AFTER:  1.0  len before:  96   len after:  75\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  65\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7659574468085106   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  71   len after:  71\n",
      "BEFORE:  0.36082474226804123   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.8888888888888888   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.30927835051546393  len before:  97   len after:  97\n",
      "BEFORE:  0.041237113402061855   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "ACCURACY MODEL:  0.7779892166190929   Accuracy pseudo: 0.8461811722912966  len pseudo:  2815    len predictions 3153\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.847768, main loss classifier 0.726657, source accuracy 0.872768 source classification loss 0.457421, target accuracy 0.822768 target loss 0.771780 accuracy domain distinction 0.493080 loss domain distinction 1.120571,\n",
      "VALIDATION Loss: 0.37445143 Acc: 0.90053286\n",
      "New best validation loss:  0.37445143196317887\n",
      "Epoch 2 of 500 took 0.599s\n",
      "Accuracy total 0.849777, main loss classifier 0.721547, source accuracy 0.870536 source classification loss 0.474635, target accuracy 0.829018 target loss 0.744697 accuracy domain distinction 0.493304 loss domain distinction 1.118808,\n",
      "VALIDATION Loss: 0.36945877 Acc: 0.90586146\n",
      "New best validation loss:  0.3694587681028578\n",
      "Epoch 3 of 500 took 0.635s\n",
      "Accuracy total 0.854911, main loss classifier 0.705053, source accuracy 0.881696 source classification loss 0.470523, target accuracy 0.828125 target loss 0.717100 accuracy domain distinction 0.501786 loss domain distinction 1.112412,\n",
      "VALIDATION Loss: 0.36185986 Acc: 0.90763766\n",
      "New best validation loss:  0.36185986465877956\n",
      "Epoch 4 of 500 took 0.494s\n",
      "Accuracy total 0.859152, main loss classifier 0.678382, source accuracy 0.886607 source classification loss 0.425542, target accuracy 0.831696 target loss 0.709244 accuracy domain distinction 0.501339 loss domain distinction 1.109886,\n",
      "VALIDATION Loss: 0.40781625 Acc: 0.87921847\n",
      "Epoch 5 of 500 took 0.484s\n",
      "Accuracy total 0.862277, main loss classifier 0.654566, source accuracy 0.892857 source classification loss 0.399668, target accuracy 0.831696 target loss 0.689661 accuracy domain distinction 0.495982 loss domain distinction 1.099014,\n",
      "VALIDATION Loss: 0.40481572 Acc: 0.88987567\n",
      "Epoch 6 of 500 took 0.473s\n",
      "Accuracy total 0.854464, main loss classifier 0.687313, source accuracy 0.885268 source classification loss 0.449571, target accuracy 0.823661 target loss 0.706610 accuracy domain distinction 0.498884 loss domain distinction 1.092225,\n",
      "VALIDATION Loss: 0.38481800 Acc: 0.90230906\n",
      "Epoch 7 of 500 took 0.481s\n",
      "Accuracy total 0.858036, main loss classifier 0.649752, source accuracy 0.890625 source classification loss 0.400511, target accuracy 0.825446 target loss 0.685132 accuracy domain distinction 0.506250 loss domain distinction 1.069306,\n",
      "VALIDATION Loss: 0.46558079 Acc: 0.87566607\n",
      "Epoch 8 of 500 took 0.527s\n",
      "Accuracy total 0.863839, main loss classifier 0.637858, source accuracy 0.892857 source classification loss 0.385440, target accuracy 0.834821 target loss 0.673319 accuracy domain distinction 0.494866 loss domain distinction 1.084783,\n",
      "VALIDATION Loss: 0.32507342 Acc: 0.91296625\n",
      "New best validation loss:  0.3250734243128035\n",
      "Epoch 9 of 500 took 0.588s\n",
      "Accuracy total 0.859375, main loss classifier 0.654119, source accuracy 0.875446 source classification loss 0.439506, target accuracy 0.843304 target loss 0.652904 accuracy domain distinction 0.501563 loss domain distinction 1.079137,\n",
      "VALIDATION Loss: 0.41286817 Acc: 0.88277087\n",
      "Epoch 10 of 500 took 0.502s\n",
      "Accuracy total 0.858482, main loss classifier 0.661121, source accuracy 0.883929 source classification loss 0.426299, target accuracy 0.833036 target loss 0.680673 accuracy domain distinction 0.493973 loss domain distinction 1.076342,\n",
      "VALIDATION Loss: 0.38043759 Acc: 0.89520426\n",
      "Epoch 11 of 500 took 0.602s\n",
      "Accuracy total 0.866964, main loss classifier 0.626511, source accuracy 0.894196 source classification loss 0.371011, target accuracy 0.839732 target loss 0.668059 accuracy domain distinction 0.502902 loss domain distinction 1.069759,\n",
      "VALIDATION Loss: 0.33544957 Acc: 0.90230906\n",
      "Epoch 12 of 500 took 0.527s\n",
      "Accuracy total 0.861607, main loss classifier 0.655631, source accuracy 0.882143 source classification loss 0.431537, target accuracy 0.841071 target loss 0.664165 accuracy domain distinction 0.503348 loss domain distinction 1.077798,\n",
      "VALIDATION Loss: 0.32349224 Acc: 0.90408526\n",
      "New best validation loss:  0.32349223560757107\n",
      "Epoch 13 of 500 took 0.473s\n",
      "Accuracy total 0.865402, main loss classifier 0.633402, source accuracy 0.897321 source classification loss 0.382004, target accuracy 0.833482 target loss 0.671405 accuracy domain distinction 0.503125 loss domain distinction 1.066978,\n",
      "VALIDATION Loss: 0.34339898 Acc: 0.90408526\n",
      "Epoch 14 of 500 took 0.472s\n",
      "Accuracy total 0.858259, main loss classifier 0.677890, source accuracy 0.879018 source classification loss 0.463261, target accuracy 0.837500 target loss 0.678306 accuracy domain distinction 0.499107 loss domain distinction 1.071063,\n",
      "VALIDATION Loss: 0.34443419 Acc: 0.89342806\n",
      "Epoch 15 of 500 took 0.484s\n",
      "Accuracy total 0.865848, main loss classifier 0.633960, source accuracy 0.887946 source classification loss 0.409701, target accuracy 0.843750 target loss 0.645693 accuracy domain distinction 0.497098 loss domain distinction 1.062636,\n",
      "VALIDATION Loss: 0.31087260 Acc: 0.90230906\n",
      "New best validation loss:  0.3108725978268517\n",
      "Epoch 16 of 500 took 0.476s\n",
      "Accuracy total 0.862946, main loss classifier 0.640727, source accuracy 0.891071 source classification loss 0.416040, target accuracy 0.834821 target loss 0.651020 accuracy domain distinction 0.493973 loss domain distinction 1.071966,\n",
      "VALIDATION Loss: 0.36178620 Acc: 0.89165187\n",
      "Epoch 17 of 500 took 0.477s\n",
      "Accuracy total 0.864286, main loss classifier 0.636480, source accuracy 0.891071 source classification loss 0.389976, target accuracy 0.837500 target loss 0.672203 accuracy domain distinction 0.502455 loss domain distinction 1.053910,\n",
      "VALIDATION Loss: 0.38984022 Acc: 0.89698046\n",
      "Epoch 18 of 500 took 0.470s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.862723, main loss classifier 0.620558, source accuracy 0.879911 source classification loss 0.404550, target accuracy 0.845536 target loss 0.624689 accuracy domain distinction 0.500446 loss domain distinction 1.059388,\n",
      "VALIDATION Loss: 0.32995538 Acc: 0.90053286\n",
      "Epoch 19 of 500 took 0.474s\n",
      "Accuracy total 0.871652, main loss classifier 0.600882, source accuracy 0.897321 source classification loss 0.361265, target accuracy 0.845982 target loss 0.628283 accuracy domain distinction 0.496205 loss domain distinction 1.061078,\n",
      "VALIDATION Loss: 0.30226802 Acc: 0.90941385\n",
      "New best validation loss:  0.30226801832516986\n",
      "Epoch 20 of 500 took 0.474s\n",
      "Accuracy total 0.865402, main loss classifier 0.632988, source accuracy 0.890179 source classification loss 0.391170, target accuracy 0.840625 target loss 0.664916 accuracy domain distinction 0.509152 loss domain distinction 1.049449,\n",
      "VALIDATION Loss: 0.37034417 Acc: 0.88454707\n",
      "Epoch 21 of 500 took 0.472s\n",
      "Accuracy total 0.868080, main loss classifier 0.616381, source accuracy 0.900893 source classification loss 0.386646, target accuracy 0.835268 target loss 0.631176 accuracy domain distinction 0.490179 loss domain distinction 1.074700,\n",
      "VALIDATION Loss: 0.37250503 Acc: 0.90230906\n",
      "Epoch 22 of 500 took 0.472s\n",
      "Accuracy total 0.870982, main loss classifier 0.588493, source accuracy 0.896875 source classification loss 0.340977, target accuracy 0.845089 target loss 0.623812 accuracy domain distinction 0.502232 loss domain distinction 1.060978,\n",
      "VALIDATION Loss: 0.35025831 Acc: 0.90408526\n",
      "Epoch 23 of 500 took 0.475s\n",
      "Accuracy total 0.867188, main loss classifier 0.617680, source accuracy 0.895536 source classification loss 0.367369, target accuracy 0.838839 target loss 0.654157 accuracy domain distinction 0.494866 loss domain distinction 1.069171,\n",
      "VALIDATION Loss: 0.30265740 Acc: 0.91829485\n",
      "Epoch 24 of 500 took 0.470s\n",
      "Accuracy total 0.874554, main loss classifier 0.592446, source accuracy 0.895982 source classification loss 0.366156, target accuracy 0.853125 target loss 0.605969 accuracy domain distinction 0.501563 loss domain distinction 1.063834,\n",
      "VALIDATION Loss: 0.40393168 Acc: 0.88632327\n",
      "Epoch 25 of 500 took 0.503s\n",
      "Accuracy total 0.866964, main loss classifier 0.615039, source accuracy 0.894196 source classification loss 0.379164, target accuracy 0.839732 target loss 0.639413 accuracy domain distinction 0.497991 loss domain distinction 1.057510,\n",
      "VALIDATION Loss: 0.30323564 Acc: 0.90941385\n",
      "Epoch    25: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 26 of 500 took 0.472s\n",
      "Accuracy total 0.868080, main loss classifier 0.591158, source accuracy 0.893304 source classification loss 0.365077, target accuracy 0.842857 target loss 0.606367 accuracy domain distinction 0.501339 loss domain distinction 1.054358,\n",
      "VALIDATION Loss: 0.40919622 Acc: 0.88809947\n",
      "Epoch 27 of 500 took 0.478s\n",
      "Accuracy total 0.873884, main loss classifier 0.607203, source accuracy 0.901786 source classification loss 0.375861, target accuracy 0.845982 target loss 0.628651 accuracy domain distinction 0.500670 loss domain distinction 1.049470,\n",
      "VALIDATION Loss: 0.28782562 Acc: 0.91829485\n",
      "New best validation loss:  0.28782561586962807\n",
      "Epoch 28 of 500 took 0.483s\n",
      "Accuracy total 0.860491, main loss classifier 0.626538, source accuracy 0.878571 source classification loss 0.434684, target accuracy 0.842411 target loss 0.607088 accuracy domain distinction 0.501563 loss domain distinction 1.056525,\n",
      "VALIDATION Loss: 0.35642859 Acc: 0.89520426\n",
      "Epoch 29 of 500 took 0.474s\n",
      "Accuracy total 0.868973, main loss classifier 0.598662, source accuracy 0.887500 source classification loss 0.386103, target accuracy 0.850446 target loss 0.599636 accuracy domain distinction 0.491964 loss domain distinction 1.057918,\n",
      "VALIDATION Loss: 0.35616449 Acc: 0.88987567\n",
      "Epoch 30 of 500 took 0.471s\n",
      "Accuracy total 0.869196, main loss classifier 0.596348, source accuracy 0.897768 source classification loss 0.383444, target accuracy 0.840625 target loss 0.598573 accuracy domain distinction 0.506920 loss domain distinction 1.053398,\n",
      "VALIDATION Loss: 0.35345940 Acc: 0.90408526\n",
      "Epoch 31 of 500 took 0.469s\n",
      "Accuracy total 0.866071, main loss classifier 0.609256, source accuracy 0.897321 source classification loss 0.374779, target accuracy 0.834821 target loss 0.633626 accuracy domain distinction 0.498661 loss domain distinction 1.050531,\n",
      "VALIDATION Loss: 0.29420473 Acc: 0.91474245\n",
      "Epoch 32 of 500 took 0.472s\n",
      "Accuracy total 0.866295, main loss classifier 0.630277, source accuracy 0.890179 source classification loss 0.408748, target accuracy 0.842411 target loss 0.638858 accuracy domain distinction 0.495982 loss domain distinction 1.064744,\n",
      "VALIDATION Loss: 0.31928946 Acc: 0.90230906\n",
      "Epoch 33 of 500 took 0.470s\n",
      "Accuracy total 0.872321, main loss classifier 0.591442, source accuracy 0.895536 source classification loss 0.376557, target accuracy 0.849107 target loss 0.594566 accuracy domain distinction 0.493527 loss domain distinction 1.058799,\n",
      "VALIDATION Loss: 0.34092595 Acc: 0.90230906\n",
      "Epoch    33: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 34 of 500 took 0.477s\n",
      "Accuracy total 0.866518, main loss classifier 0.603548, source accuracy 0.888839 source classification loss 0.377618, target accuracy 0.844196 target loss 0.617086 accuracy domain distinction 0.499554 loss domain distinction 1.061959,\n",
      "VALIDATION Loss: 0.37247941 Acc: 0.91296625\n",
      "Epoch 35 of 500 took 0.472s\n",
      "Accuracy total 0.866741, main loss classifier 0.594826, source accuracy 0.883482 source classification loss 0.367322, target accuracy 0.850000 target loss 0.610358 accuracy domain distinction 0.496429 loss domain distinction 1.059863,\n",
      "VALIDATION Loss: 0.33042045 Acc: 0.90408526\n",
      "Epoch 36 of 500 took 0.479s\n",
      "Accuracy total 0.865402, main loss classifier 0.619207, source accuracy 0.887500 source classification loss 0.373730, target accuracy 0.843304 target loss 0.651468 accuracy domain distinction 0.499107 loss domain distinction 1.066083,\n",
      "VALIDATION Loss: 0.48216304 Acc: 0.88809947\n",
      "Epoch 37 of 500 took 0.469s\n",
      "Accuracy total 0.865179, main loss classifier 0.630266, source accuracy 0.887946 source classification loss 0.404176, target accuracy 0.842411 target loss 0.642442 accuracy domain distinction 0.495312 loss domain distinction 1.069565,\n",
      "VALIDATION Loss: 0.29338957 Acc: 0.91651865\n",
      "Epoch 38 of 500 took 0.483s\n",
      "Accuracy total 0.874330, main loss classifier 0.584197, source accuracy 0.893750 source classification loss 0.345351, target accuracy 0.854911 target loss 0.608408 accuracy domain distinction 0.492188 loss domain distinction 1.073173,\n",
      "VALIDATION Loss: 0.30993808 Acc: 0.91474245\n",
      "Epoch 39 of 500 took 0.500s\n",
      "Training complete in 0m 19s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd574feb0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt' (epoch 16)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 32)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 8)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt' (epoch 6)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt' (epoch 16)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.7340425531914894   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  69\n",
      "BEFORE:  0.22340425531914893   AFTER:  0.0  len before:  94   len after:  43\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.3711340206185567  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7978723404255319   AFTER:  1.0  len before:  94   len after:  66\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9591836734693877   AFTER:  1.0  len before:  98   len after:  98\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9813084112149533   AFTER:  1.0  len before:  107   len after:  107\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.5319148936170213   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.32989690721649484  len before:  97   len after:  97\n",
      "BEFORE:  0.39361702127659576   AFTER:  0.20212765957446807  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  1\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.6741573033707865   AFTER:  1.0  len before:  89   len after:  45\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8723404255319149   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.24742268041237114   AFTER:  0.0  len before:  97   len after:  31\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  52\n",
      "BEFORE:  0.3617021276595745   AFTER:  0.3723404255319149  len before:  94   len after:  94\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  69\n",
      "ACCURACY MODEL:  0.6927919420837267   Accuracy pseudo: 0.8480631816472358  len pseudo:  2659    len predictions 3177\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.5277777777777778  len before:  97   len after:  72\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.4639175257731959   AFTER:  0.8461538461538461  len before:  97   len after:  13\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4742268041237113   AFTER:  0.14814814814814814  len before:  97   len after:  54\n",
      "BEFORE:  0.9081632653061225   AFTER:  1.0  len before:  98   len after:  71\n",
      "BEFORE:  0.41237113402061853   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.17777777777777778   AFTER:  0.0  len before:  90   len after:  90\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.981651376146789   AFTER:  1.0  len before:  109   len after:  109\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.967032967032967   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.7916666666666666   AFTER:  1.0  len before:  96   len after:  75\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  65\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7659574468085106   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  71   len after:  71\n",
      "BEFORE:  0.36082474226804123   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.8888888888888888   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.44329896907216493   AFTER:  0.30927835051546393  len before:  97   len after:  97\n",
      "BEFORE:  0.041237113402061855   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "ACCURACY MODEL:  0.7779892166190929   Accuracy pseudo: 0.8461811722912966  len pseudo:  2815    len predictions 3153\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.14432989690721648   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.922077922077922   AFTER:  1.0  len before:  77   len after:  49\n",
      "BEFORE:  0.9583333333333334   AFTER:  1.0  len before:  96   len after:  96\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7666666666666667   AFTER:  1.0  len before:  90   len after:  61\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8888888888888888   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.6914893617021277   AFTER:  0.6808510638297872  len before:  94   len after:  94\n",
      "BEFORE:  0.9574468085106383   AFTER:  1.0  len before:  94   len after:  73\n",
      "BEFORE:  0.8735632183908046   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.978021978021978   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.3402061855670103  len before:  97   len after:  97\n",
      "BEFORE:  0.4329896907216495   AFTER:  0.30927835051546393  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6703296703296703   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9702970297029703   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  67\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9   AFTER:  1.0  len before:  80   len after:  80\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3333333333333333   AFTER:  0.44776119402985076  len before:  87   len after:  67\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.7142857142857143   AFTER:  1.0  len before:  84   len after:  84\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.8354348528936307   Accuracy pseudo: 0.8995231607629428  len pseudo:  2936    len predictions 3093\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.853733, main loss classifier 0.701394, source accuracy 0.853299 source classification loss 0.573824, target accuracy 0.854167 target loss 0.607718 accuracy domain distinction 0.499783 loss domain distinction 1.106237,\n",
      "VALIDATION Loss: 0.45424442 Acc: 0.90306122\n",
      "New best validation loss:  0.4542444184422493\n",
      "Epoch 2 of 500 took 0.484s\n",
      "Accuracy total 0.853516, main loss classifier 0.680694, source accuracy 0.842448 source classification loss 0.581119, target accuracy 0.864583 target loss 0.558822 accuracy domain distinction 0.499132 loss domain distinction 1.107239,\n",
      "VALIDATION Loss: 0.56920524 Acc: 0.88095238\n",
      "Epoch 3 of 500 took 0.488s\n",
      "Accuracy total 0.861545, main loss classifier 0.662311, source accuracy 0.858941 source classification loss 0.530108, target accuracy 0.864149 target loss 0.573472 accuracy domain distinction 0.500651 loss domain distinction 1.105216,\n",
      "VALIDATION Loss: 0.46028150 Acc: 0.89285714\n",
      "Epoch 4 of 500 took 0.484s\n",
      "Accuracy total 0.857205, main loss classifier 0.696893, source accuracy 0.861111 source classification loss 0.530640, target accuracy 0.853299 target loss 0.646335 accuracy domain distinction 0.502387 loss domain distinction 1.084052,\n",
      "VALIDATION Loss: 0.41920070 Acc: 0.90646259\n",
      "New best validation loss:  0.4192007005913183\n",
      "Epoch 5 of 500 took 0.488s\n",
      "Accuracy total 0.856554, main loss classifier 0.700307, source accuracy 0.859375 source classification loss 0.569378, target accuracy 0.853733 target loss 0.609603 accuracy domain distinction 0.498047 loss domain distinction 1.108162,\n",
      "VALIDATION Loss: 0.51555688 Acc: 0.90136054\n",
      "Epoch 6 of 500 took 0.488s\n",
      "Accuracy total 0.861979, main loss classifier 0.660122, source accuracy 0.864149 source classification loss 0.517379, target accuracy 0.859809 target loss 0.584562 accuracy domain distinction 0.498481 loss domain distinction 1.091512,\n",
      "VALIDATION Loss: 0.43182670 Acc: 0.90646259\n",
      "Epoch 7 of 500 took 0.496s\n",
      "Accuracy total 0.865451, main loss classifier 0.656963, source accuracy 0.862413 source classification loss 0.532167, target accuracy 0.868490 target loss 0.563978 accuracy domain distinction 0.504991 loss domain distinction 1.088900,\n",
      "VALIDATION Loss: 0.49072770 Acc: 0.90306122\n",
      "Epoch 8 of 500 took 0.485s\n",
      "Accuracy total 0.864366, main loss classifier 0.662273, source accuracy 0.865017 source classification loss 0.542970, target accuracy 0.863715 target loss 0.562736 accuracy domain distinction 0.500868 loss domain distinction 1.094203,\n",
      "VALIDATION Loss: 0.60293559 Acc: 0.89965986\n",
      "Epoch 9 of 500 took 0.493s\n",
      "Accuracy total 0.857422, main loss classifier 0.664162, source accuracy 0.856771 source classification loss 0.552977, target accuracy 0.858073 target loss 0.555656 accuracy domain distinction 0.493707 loss domain distinction 1.098456,\n",
      "VALIDATION Loss: 0.46588636 Acc: 0.90816327\n",
      "Epoch 10 of 500 took 0.483s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.865017, main loss classifier 0.648527, source accuracy 0.867188 source classification loss 0.499595, target accuracy 0.862847 target loss 0.577387 accuracy domain distinction 0.500868 loss domain distinction 1.100357,\n",
      "VALIDATION Loss: 0.46016553 Acc: 0.88435374\n",
      "Epoch    10: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 11 of 500 took 0.489s\n",
      "Accuracy total 0.862847, main loss classifier 0.651229, source accuracy 0.865451 source classification loss 0.512167, target accuracy 0.860243 target loss 0.570525 accuracy domain distinction 0.495660 loss domain distinction 1.098829,\n",
      "VALIDATION Loss: 0.52445634 Acc: 0.9047619\n",
      "Epoch 12 of 500 took 0.488s\n",
      "Accuracy total 0.858941, main loss classifier 0.652234, source accuracy 0.857205 source classification loss 0.529516, target accuracy 0.860677 target loss 0.555869 accuracy domain distinction 0.500651 loss domain distinction 1.095419,\n",
      "VALIDATION Loss: 0.39223663 Acc: 0.92176871\n",
      "New best validation loss:  0.39223663192242386\n",
      "Epoch 13 of 500 took 0.487s\n",
      "Accuracy total 0.862847, main loss classifier 0.652983, source accuracy 0.863715 source classification loss 0.515888, target accuracy 0.861979 target loss 0.570476 accuracy domain distinction 0.495660 loss domain distinction 1.098015,\n",
      "VALIDATION Loss: 0.40577393 Acc: 0.91496599\n",
      "Epoch 14 of 500 took 0.484s\n",
      "Accuracy total 0.867405, main loss classifier 0.655278, source accuracy 0.875000 source classification loss 0.498346, target accuracy 0.859809 target loss 0.592437 accuracy domain distinction 0.503255 loss domain distinction 1.098865,\n",
      "VALIDATION Loss: 0.39457526 Acc: 0.91666667\n",
      "Epoch 15 of 500 took 0.484s\n",
      "Accuracy total 0.856554, main loss classifier 0.669996, source accuracy 0.850260 source classification loss 0.571296, target accuracy 0.862847 target loss 0.550110 accuracy domain distinction 0.491753 loss domain distinction 1.092933,\n",
      "VALIDATION Loss: 0.43199283 Acc: 0.92176871\n",
      "Epoch 16 of 500 took 0.486s\n",
      "Accuracy total 0.865234, main loss classifier 0.656772, source accuracy 0.871094 source classification loss 0.521876, target accuracy 0.859375 target loss 0.572932 accuracy domain distinction 0.498698 loss domain distinction 1.093684,\n",
      "VALIDATION Loss: 0.43686668 Acc: 0.90306122\n",
      "Epoch 17 of 500 took 0.493s\n",
      "Accuracy total 0.865017, main loss classifier 0.665478, source accuracy 0.865885 source classification loss 0.515037, target accuracy 0.864149 target loss 0.595889 accuracy domain distinction 0.496745 loss domain distinction 1.100146,\n",
      "VALIDATION Loss: 0.44887493 Acc: 0.88945578\n",
      "Epoch 18 of 500 took 0.486s\n",
      "Accuracy total 0.858073, main loss classifier 0.665163, source accuracy 0.853733 source classification loss 0.541081, target accuracy 0.862413 target loss 0.568026 accuracy domain distinction 0.480903 loss domain distinction 1.106095,\n",
      "VALIDATION Loss: 0.41849271 Acc: 0.91666667\n",
      "Epoch    18: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 19 of 500 took 0.489s\n",
      "Accuracy total 0.874132, main loss classifier 0.657639, source accuracy 0.866319 source classification loss 0.559378, target accuracy 0.881944 target loss 0.539242 accuracy domain distinction 0.501519 loss domain distinction 1.083286,\n",
      "VALIDATION Loss: 0.40143549 Acc: 0.91836735\n",
      "Epoch 20 of 500 took 0.492s\n",
      "Accuracy total 0.868490, main loss classifier 0.648416, source accuracy 0.876736 source classification loss 0.468094, target accuracy 0.860243 target loss 0.610898 accuracy domain distinction 0.504774 loss domain distinction 1.089204,\n",
      "VALIDATION Loss: 0.46410967 Acc: 0.90986395\n",
      "Epoch 21 of 500 took 0.488s\n",
      "Accuracy total 0.869575, main loss classifier 0.658851, source accuracy 0.864583 source classification loss 0.545845, target accuracy 0.874566 target loss 0.549727 accuracy domain distinction 0.490451 loss domain distinction 1.110650,\n",
      "VALIDATION Loss: 0.57341900 Acc: 0.88945578\n",
      "Epoch 22 of 500 took 0.488s\n",
      "Accuracy total 0.867405, main loss classifier 0.634616, source accuracy 0.863281 source classification loss 0.515492, target accuracy 0.871528 target loss 0.535465 accuracy domain distinction 0.495009 loss domain distinction 1.091378,\n",
      "VALIDATION Loss: 0.55695525 Acc: 0.90986395\n",
      "Epoch 23 of 500 took 0.556s\n",
      "Accuracy total 0.866970, main loss classifier 0.646400, source accuracy 0.868924 source classification loss 0.522596, target accuracy 0.865017 target loss 0.554640 accuracy domain distinction 0.511719 loss domain distinction 1.077823,\n",
      "VALIDATION Loss: 0.42097578 Acc: 0.91496599\n",
      "Epoch 24 of 500 took 0.489s\n",
      "Training complete in 0m 11s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd574feb0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 16)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 16)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  30\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  101\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  61\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  33\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  51\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.05154639175257732   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.4225352112676056  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6185567010309279   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.31958762886597936  len before:  97   len after:  97\n",
      "BEFORE:  0.8247422680412371   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  64\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  0.7525773195876289   AFTER:  0.5733333333333334  len before:  97   len after:  75\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0594059405940594   AFTER:  0.0  len before:  101   len after:  31\n",
      "ACCURACY MODEL:  0.213773761296354   Accuracy pseudo: 0.25667090216010163  len pseudo:  2361    len predictions 3209\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.800108, main loss classifier 0.987748, source accuracy 0.979526 source classification loss 0.071321, target accuracy 0.620690 target loss 1.658067 accuracy domain distinction 0.500000 loss domain distinction 1.230534,\n",
      "VALIDATION Loss: 0.96597153 Acc: 0.7589852\n",
      "New best validation loss:  0.9659715294837952\n",
      "Epoch 2 of 500 took 0.398s\n",
      "Accuracy total 0.826778, main loss classifier 0.848037, source accuracy 0.977909 source classification loss 0.069592, target accuracy 0.675647 target loss 1.390346 accuracy domain distinction 0.500000 loss domain distinction 1.180672,\n",
      "VALIDATION Loss: 0.86513039 Acc: 0.78435518\n",
      "New best validation loss:  0.8651303872466087\n",
      "Epoch 3 of 500 took 0.393s\n",
      "Accuracy total 0.834860, main loss classifier 0.800447, source accuracy 0.982220 source classification loss 0.063914, target accuracy 0.687500 target loss 1.307655 accuracy domain distinction 0.500000 loss domain distinction 1.146620,\n",
      "VALIDATION Loss: 0.81164995 Acc: 0.76109937\n",
      "New best validation loss:  0.8116499483585358\n",
      "Epoch 4 of 500 took 0.400s\n",
      "Accuracy total 0.842672, main loss classifier 0.746542, source accuracy 0.977371 source classification loss 0.065558, target accuracy 0.707974 target loss 1.200007 accuracy domain distinction 0.500000 loss domain distinction 1.137596,\n",
      "VALIDATION Loss: 0.80934665 Acc: 0.7653277\n",
      "New best validation loss:  0.8093466479331255\n",
      "Epoch 5 of 500 took 0.397s\n",
      "Accuracy total 0.846713, main loss classifier 0.706203, source accuracy 0.978448 source classification loss 0.066904, target accuracy 0.714978 target loss 1.123324 accuracy domain distinction 0.500269 loss domain distinction 1.110892,\n",
      "VALIDATION Loss: 0.74169037 Acc: 0.78435518\n",
      "New best validation loss:  0.7416903711855412\n",
      "Epoch 6 of 500 took 0.389s\n",
      "Accuracy total 0.857489, main loss classifier 0.653228, source accuracy 0.974138 source classification loss 0.087054, target accuracy 0.740841 target loss 0.997934 accuracy domain distinction 0.500269 loss domain distinction 1.107341,\n",
      "VALIDATION Loss: 0.72454559 Acc: 0.8012685\n",
      "New best validation loss:  0.7245455905795097\n",
      "Epoch 7 of 500 took 0.399s\n",
      "Accuracy total 0.844289, main loss classifier 0.712034, source accuracy 0.969828 source classification loss 0.093265, target accuracy 0.718750 target loss 1.114108 accuracy domain distinction 0.498922 loss domain distinction 1.083474,\n",
      "VALIDATION Loss: 0.71767521 Acc: 0.78858351\n",
      "New best validation loss:  0.7176752127707005\n",
      "Epoch 8 of 500 took 0.398s\n",
      "Accuracy total 0.846983, main loss classifier 0.714593, source accuracy 0.968211 source classification loss 0.108549, target accuracy 0.725754 target loss 1.102529 accuracy domain distinction 0.500000 loss domain distinction 1.090538,\n",
      "VALIDATION Loss: 0.75929676 Acc: 0.79069767\n",
      "Epoch 9 of 500 took 0.394s\n",
      "Accuracy total 0.858297, main loss classifier 0.632193, source accuracy 0.973599 source classification loss 0.087593, target accuracy 0.742996 target loss 0.959768 accuracy domain distinction 0.500000 loss domain distinction 1.085122,\n",
      "VALIDATION Loss: 0.72165717 Acc: 0.78224101\n",
      "Epoch 10 of 500 took 0.395s\n",
      "Accuracy total 0.861530, main loss classifier 0.663106, source accuracy 0.976293 source classification loss 0.079864, target accuracy 0.746767 target loss 1.031571 accuracy domain distinction 0.499731 loss domain distinction 1.073887,\n",
      "VALIDATION Loss: 0.59616647 Acc: 0.83298097\n",
      "New best validation loss:  0.5961664654314518\n",
      "Epoch 11 of 500 took 0.393s\n",
      "Accuracy total 0.865302, main loss classifier 0.638266, source accuracy 0.977371 source classification loss 0.082390, target accuracy 0.753233 target loss 0.979371 accuracy domain distinction 0.499192 loss domain distinction 1.073850,\n",
      "VALIDATION Loss: 0.63283984 Acc: 0.82241015\n",
      "Epoch 12 of 500 took 0.452s\n",
      "Accuracy total 0.866379, main loss classifier 0.627542, source accuracy 0.972522 source classification loss 0.087739, target accuracy 0.760237 target loss 0.953138 accuracy domain distinction 0.499192 loss domain distinction 1.071037,\n",
      "VALIDATION Loss: 0.60471408 Acc: 0.8372093\n",
      "Epoch 13 of 500 took 0.477s\n",
      "Accuracy total 0.862877, main loss classifier 0.627516, source accuracy 0.977371 source classification loss 0.074002, target accuracy 0.748384 target loss 0.967270 accuracy domain distinction 0.499731 loss domain distinction 1.068805,\n",
      "VALIDATION Loss: 0.67923616 Acc: 0.82663848\n",
      "Epoch 14 of 500 took 0.401s\n",
      "Accuracy total 0.862069, main loss classifier 0.603302, source accuracy 0.976293 source classification loss 0.076104, target accuracy 0.747845 target loss 0.918512 accuracy domain distinction 0.500539 loss domain distinction 1.059946,\n",
      "VALIDATION Loss: 0.59652450 Acc: 0.83509514\n",
      "Epoch 15 of 500 took 0.412s\n",
      "Accuracy total 0.862069, main loss classifier 0.588531, source accuracy 0.970905 source classification loss 0.087376, target accuracy 0.753233 target loss 0.877854 accuracy domain distinction 0.499461 loss domain distinction 1.059159,\n",
      "VALIDATION Loss: 0.54144483 Acc: 0.84143763\n",
      "New best validation loss:  0.541444830596447\n",
      "Epoch 16 of 500 took 0.431s\n",
      "Accuracy total 0.858836, main loss classifier 0.633349, source accuracy 0.970905 source classification loss 0.086370, target accuracy 0.746767 target loss 0.969569 accuracy domain distinction 0.500539 loss domain distinction 1.053802,\n",
      "VALIDATION Loss: 0.54719779 Acc: 0.84143763\n",
      "Epoch 17 of 500 took 0.465s\n",
      "Accuracy total 0.865302, main loss classifier 0.585717, source accuracy 0.969828 source classification loss 0.091718, target accuracy 0.760776 target loss 0.866335 accuracy domain distinction 0.499731 loss domain distinction 1.066911,\n",
      "VALIDATION Loss: 0.65074274 Acc: 0.78646934\n",
      "Epoch 18 of 500 took 0.468s\n",
      "Accuracy total 0.873653, main loss classifier 0.589212, source accuracy 0.981681 source classification loss 0.066438, target accuracy 0.765625 target loss 0.899555 accuracy domain distinction 0.499192 loss domain distinction 1.062155,\n",
      "VALIDATION Loss: 0.50139481 Acc: 0.85623679\n",
      "New best validation loss:  0.5013948120176792\n",
      "Epoch 19 of 500 took 0.463s\n",
      "Accuracy total 0.872575, main loss classifier 0.596613, source accuracy 0.971983 source classification loss 0.094714, target accuracy 0.773168 target loss 0.886340 accuracy domain distinction 0.499731 loss domain distinction 1.060862,\n",
      "VALIDATION Loss: 0.55748967 Acc: 0.83086681\n",
      "Epoch 20 of 500 took 0.405s\n",
      "Accuracy total 0.875000, main loss classifier 0.571152, source accuracy 0.974138 source classification loss 0.086450, target accuracy 0.775862 target loss 0.844298 accuracy domain distinction 0.500269 loss domain distinction 1.057782,\n",
      "VALIDATION Loss: 0.87428258 Acc: 0.78224101\n",
      "Epoch 21 of 500 took 0.394s\n",
      "Accuracy total 0.873384, main loss classifier 0.579578, source accuracy 0.981681 source classification loss 0.068919, target accuracy 0.765086 target loss 0.879506 accuracy domain distinction 0.500269 loss domain distinction 1.053653,\n",
      "VALIDATION Loss: 0.51813512 Acc: 0.84989429\n",
      "Epoch 22 of 500 took 0.448s\n",
      "Accuracy total 0.876078, main loss classifier 0.560222, source accuracy 0.975216 source classification loss 0.087638, target accuracy 0.776940 target loss 0.820534 accuracy domain distinction 0.500269 loss domain distinction 1.061360,\n",
      "VALIDATION Loss: 0.62187639 Acc: 0.81818182\n",
      "Epoch 23 of 500 took 0.415s\n",
      "Accuracy total 0.878772, main loss classifier 0.571130, source accuracy 0.978987 source classification loss 0.068248, target accuracy 0.778556 target loss 0.860843 accuracy domain distinction 0.499461 loss domain distinction 1.065842,\n",
      "VALIDATION Loss: 0.50883660 Acc: 0.85412262\n",
      "Epoch 24 of 500 took 0.429s\n",
      "Accuracy total 0.876078, main loss classifier 0.537750, source accuracy 0.977371 source classification loss 0.075854, target accuracy 0.774784 target loss 0.789476 accuracy domain distinction 0.500000 loss domain distinction 1.050851,\n",
      "VALIDATION Loss: 0.58636956 Acc: 0.81395349\n",
      "Epoch    24: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 25 of 500 took 0.417s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.881466, main loss classifier 0.535339, source accuracy 0.975754 source classification loss 0.078146, target accuracy 0.787177 target loss 0.780749 accuracy domain distinction 0.500539 loss domain distinction 1.058923,\n",
      "VALIDATION Loss: 0.50389491 Acc: 0.86046512\n",
      "Epoch 26 of 500 took 0.429s\n",
      "Accuracy total 0.881735, main loss classifier 0.516838, source accuracy 0.982220 source classification loss 0.063399, target accuracy 0.781250 target loss 0.760041 accuracy domain distinction 0.500269 loss domain distinction 1.051181,\n",
      "VALIDATION Loss: 0.49842641 Acc: 0.86257928\n",
      "New best validation loss:  0.4984264075756073\n",
      "Epoch 27 of 500 took 0.457s\n",
      "Accuracy total 0.868804, main loss classifier 0.581507, source accuracy 0.966056 source classification loss 0.097124, target accuracy 0.771552 target loss 0.853377 accuracy domain distinction 0.500539 loss domain distinction 1.062568,\n",
      "VALIDATION Loss: 0.58588985 Acc: 0.80549683\n",
      "Epoch 28 of 500 took 0.505s\n",
      "Accuracy total 0.874192, main loss classifier 0.557219, source accuracy 0.973060 source classification loss 0.091606, target accuracy 0.775323 target loss 0.811856 accuracy domain distinction 0.499461 loss domain distinction 1.054884,\n",
      "VALIDATION Loss: 0.54556767 Acc: 0.85835095\n",
      "Epoch 29 of 500 took 0.483s\n",
      "Accuracy total 0.877694, main loss classifier 0.553172, source accuracy 0.980065 source classification loss 0.074186, target accuracy 0.775323 target loss 0.820780 accuracy domain distinction 0.500000 loss domain distinction 1.056891,\n",
      "VALIDATION Loss: 0.55673075 Acc: 0.85200846\n",
      "Epoch 30 of 500 took 0.453s\n",
      "Accuracy total 0.877963, main loss classifier 0.539956, source accuracy 0.975216 source classification loss 0.083342, target accuracy 0.780711 target loss 0.786413 accuracy domain distinction 0.500269 loss domain distinction 1.050783,\n",
      "VALIDATION Loss: 0.47592029 Acc: 0.85200846\n",
      "New best validation loss:  0.47592029348015785\n",
      "Epoch 31 of 500 took 0.465s\n",
      "Accuracy total 0.879310, main loss classifier 0.541043, source accuracy 0.975754 source classification loss 0.083747, target accuracy 0.782866 target loss 0.787114 accuracy domain distinction 0.499731 loss domain distinction 1.056120,\n",
      "VALIDATION Loss: 0.52858324 Acc: 0.87526427\n",
      "Epoch 32 of 500 took 0.474s\n",
      "Accuracy total 0.875539, main loss classifier 0.568014, source accuracy 0.972522 source classification loss 0.091250, target accuracy 0.778556 target loss 0.834058 accuracy domain distinction 0.499731 loss domain distinction 1.053603,\n",
      "VALIDATION Loss: 0.76098493 Acc: 0.78224101\n",
      "Epoch 33 of 500 took 0.435s\n",
      "Accuracy total 0.879310, main loss classifier 0.554374, source accuracy 0.970905 source classification loss 0.091648, target accuracy 0.787716 target loss 0.805319 accuracy domain distinction 0.500000 loss domain distinction 1.058904,\n",
      "VALIDATION Loss: 0.50794601 Acc: 0.86469345\n",
      "Epoch 34 of 500 took 0.469s\n",
      "Accuracy total 0.870959, main loss classifier 0.556834, source accuracy 0.975754 source classification loss 0.080960, target accuracy 0.766164 target loss 0.820721 accuracy domain distinction 0.499461 loss domain distinction 1.059933,\n",
      "VALIDATION Loss: 0.55516029 Acc: 0.82875264\n",
      "Epoch 35 of 500 took 0.489s\n",
      "Accuracy total 0.881735, main loss classifier 0.547248, source accuracy 0.977909 source classification loss 0.077259, target accuracy 0.785560 target loss 0.807184 accuracy domain distinction 0.500269 loss domain distinction 1.050259,\n",
      "VALIDATION Loss: 0.79066962 Acc: 0.77378436\n",
      "Epoch 36 of 500 took 0.494s\n",
      "Accuracy total 0.880388, main loss classifier 0.530888, source accuracy 0.978987 source classification loss 0.085526, target accuracy 0.781789 target loss 0.764987 accuracy domain distinction 0.500269 loss domain distinction 1.056318,\n",
      "VALIDATION Loss: 0.50703593 Acc: 0.83509514\n",
      "Epoch    36: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 37 of 500 took 0.444s\n",
      "Accuracy total 0.879310, main loss classifier 0.535389, source accuracy 0.977909 source classification loss 0.081545, target accuracy 0.780711 target loss 0.780005 accuracy domain distinction 0.500000 loss domain distinction 1.046136,\n",
      "VALIDATION Loss: 0.53897073 Acc: 0.87526427\n",
      "Epoch 38 of 500 took 0.452s\n",
      "Accuracy total 0.875539, main loss classifier 0.532806, source accuracy 0.977909 source classification loss 0.072205, target accuracy 0.773168 target loss 0.782481 accuracy domain distinction 0.499461 loss domain distinction 1.054627,\n",
      "VALIDATION Loss: 0.52894579 Acc: 0.84778013\n",
      "Epoch 39 of 500 took 0.479s\n",
      "Accuracy total 0.876347, main loss classifier 0.563834, source accuracy 0.970366 source classification loss 0.092302, target accuracy 0.782328 target loss 0.822995 accuracy domain distinction 0.500000 loss domain distinction 1.061857,\n",
      "VALIDATION Loss: 0.51161503 Acc: 0.86046512\n",
      "Epoch 40 of 500 took 0.509s\n",
      "Accuracy total 0.866918, main loss classifier 0.573453, source accuracy 0.975754 source classification loss 0.089947, target accuracy 0.758082 target loss 0.847211 accuracy domain distinction 0.500000 loss domain distinction 1.048737,\n",
      "VALIDATION Loss: 0.49722452 Acc: 0.84778013\n",
      "Epoch 41 of 500 took 0.516s\n",
      "Accuracy total 0.873114, main loss classifier 0.550272, source accuracy 0.969828 source classification loss 0.106447, target accuracy 0.776401 target loss 0.782790 accuracy domain distinction 0.500539 loss domain distinction 1.056536,\n",
      "VALIDATION Loss: 0.48315471 Acc: 0.84566596\n",
      "Epoch 42 of 500 took 0.482s\n",
      "Training complete in 0m 18s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd574feb0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 16)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt' (epoch 2)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  30\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  101\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  61\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  33\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  51\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.05154639175257732   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.4225352112676056  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6185567010309279   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.31958762886597936  len before:  97   len after:  97\n",
      "BEFORE:  0.8247422680412371   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  64\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  45\n",
      "BEFORE:  0.7525773195876289   AFTER:  0.5733333333333334  len before:  97   len after:  75\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0594059405940594   AFTER:  0.0  len before:  101   len after:  31\n",
      "ACCURACY MODEL:  0.213773761296354   Accuracy pseudo: 0.25667090216010163  len pseudo:  2361    len predictions 3209\n",
      "HANDLING NEW SESSION  2\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5567010309278351   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.851063829787234   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5463917525773195   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9574468085106383   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.851063829787234   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  0.43478260869565216  len before:  97   len after:  69\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7216494845360825   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9354838709677419   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  72\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.422680412371134   AFTER:  1.0  len before:  97   len after:  37\n",
      "ACCURACY MODEL:  0.8693056864593152   Accuracy pseudo: 0.9871116986120291  len pseudo:  3026    len predictions 3183\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.829814, main loss classifier 0.723071, source accuracy 0.805743 source classification loss 0.700283, target accuracy 0.853885 target loss 0.521915 accuracy domain distinction 0.500211 loss domain distinction 1.119727,\n",
      "VALIDATION Loss: 0.87086027 Acc: 0.7359736\n",
      "New best validation loss:  0.8708602666854859\n",
      "Epoch 2 of 500 took 0.582s\n",
      "Accuracy total 0.858742, main loss classifier 0.570685, source accuracy 0.844595 source classification loss 0.521005, target accuracy 0.872889 target loss 0.403032 accuracy domain distinction 0.498944 loss domain distinction 1.086661,\n",
      "VALIDATION Loss: 0.31252352 Acc: 0.89273927\n",
      "New best validation loss:  0.31252351999282835\n",
      "Epoch 3 of 500 took 0.565s\n",
      "Accuracy total 0.880912, main loss classifier 0.488245, source accuracy 0.864865 source classification loss 0.431819, target accuracy 0.896959 target loss 0.329391 accuracy domain distinction 0.500633 loss domain distinction 1.076402,\n",
      "VALIDATION Loss: 1.55464190 Acc: 0.58415842\n",
      "Epoch 4 of 500 took 0.595s\n",
      "Accuracy total 0.887880, main loss classifier 0.453083, source accuracy 0.879645 source classification loss 0.381087, target accuracy 0.896115 target loss 0.312216 accuracy domain distinction 0.500000 loss domain distinction 1.064314,\n",
      "VALIDATION Loss: 0.67674745 Acc: 0.76567657\n",
      "Epoch 5 of 500 took 0.654s\n",
      "Accuracy total 0.894637, main loss classifier 0.451788, source accuracy 0.886402 source classification loss 0.371824, target accuracy 0.902872 target loss 0.320434 accuracy domain distinction 0.500000 loss domain distinction 1.056589,\n",
      "VALIDATION Loss: 1.10455171 Acc: 0.69966997\n",
      "Epoch 6 of 500 took 0.603s\n",
      "Accuracy total 0.898438, main loss classifier 0.432261, source accuracy 0.888936 source classification loss 0.357657, target accuracy 0.907939 target loss 0.296308 accuracy domain distinction 0.500000 loss domain distinction 1.052787,\n",
      "VALIDATION Loss: 0.53578222 Acc: 0.8349835\n",
      "Epoch 7 of 500 took 0.511s\n",
      "Accuracy total 0.901605, main loss classifier 0.422959, source accuracy 0.879223 source classification loss 0.368913, target accuracy 0.923986 target loss 0.266029 accuracy domain distinction 0.500000 loss domain distinction 1.054880,\n",
      "VALIDATION Loss: 0.61734325 Acc: 0.82013201\n",
      "Epoch 8 of 500 took 0.556s\n",
      "Accuracy total 0.904772, main loss classifier 0.408385, source accuracy 0.899493 source classification loss 0.322875, target accuracy 0.910051 target loss 0.283374 accuracy domain distinction 0.500000 loss domain distinction 1.052603,\n",
      "VALIDATION Loss: 0.75685354 Acc: 0.82013201\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 9 of 500 took 0.500s\n",
      "Accuracy total 0.903505, main loss classifier 0.397053, source accuracy 0.887669 source classification loss 0.329840, target accuracy 0.919341 target loss 0.255642 accuracy domain distinction 0.500000 loss domain distinction 1.043121,\n",
      "VALIDATION Loss: 0.21966302 Acc: 0.92244224\n",
      "New best validation loss:  0.21966302171349525\n",
      "Epoch 10 of 500 took 0.519s\n",
      "Accuracy total 0.919764, main loss classifier 0.362515, source accuracy 0.915963 source classification loss 0.270980, target accuracy 0.923564 target loss 0.246277 accuracy domain distinction 0.500000 loss domain distinction 1.038863,\n",
      "VALIDATION Loss: 0.13722584 Acc: 0.95379538\n",
      "New best validation loss:  0.13722583800554275\n",
      "Epoch 11 of 500 took 0.542s\n",
      "Accuracy total 0.919764, main loss classifier 0.358166, source accuracy 0.915963 source classification loss 0.273081, target accuracy 0.923564 target loss 0.235962 accuracy domain distinction 0.500000 loss domain distinction 1.036447,\n",
      "VALIDATION Loss: 0.12096681 Acc: 0.96534653\n",
      "New best validation loss:  0.1209668129682541\n",
      "Epoch 12 of 500 took 0.549s\n",
      "Accuracy total 0.924620, main loss classifier 0.352686, source accuracy 0.920608 source classification loss 0.263647, target accuracy 0.928632 target loss 0.233194 accuracy domain distinction 0.500000 loss domain distinction 1.042653,\n",
      "VALIDATION Loss: 0.09899112 Acc: 0.96864686\n",
      "New best validation loss:  0.09899112172424793\n",
      "Epoch 13 of 500 took 0.560s\n",
      "Accuracy total 0.918919, main loss classifier 0.356085, source accuracy 0.908784 source classification loss 0.286500, target accuracy 0.929054 target loss 0.217896 accuracy domain distinction 0.500000 loss domain distinction 1.038867,\n",
      "VALIDATION Loss: 0.14111054 Acc: 0.95544554\n",
      "Epoch 14 of 500 took 0.522s\n",
      "Accuracy total 0.931377, main loss classifier 0.336677, source accuracy 0.918497 source classification loss 0.267990, target accuracy 0.944257 target loss 0.197754 accuracy domain distinction 0.500000 loss domain distinction 1.038051,\n",
      "VALIDATION Loss: 0.12858965 Acc: 0.95709571\n",
      "Epoch 15 of 500 took 0.505s\n",
      "Accuracy total 0.926731, main loss classifier 0.343245, source accuracy 0.916807 source classification loss 0.272132, target accuracy 0.936655 target loss 0.206992 accuracy domain distinction 0.500000 loss domain distinction 1.036828,\n",
      "VALIDATION Loss: 0.15717237 Acc: 0.95049505\n",
      "Epoch 16 of 500 took 0.555s\n",
      "Accuracy total 0.923564, main loss classifier 0.338182, source accuracy 0.915118 source classification loss 0.267953, target accuracy 0.932010 target loss 0.200931 accuracy domain distinction 0.500000 loss domain distinction 1.037399,\n",
      "VALIDATION Loss: 0.12536019 Acc: 0.95874587\n",
      "Epoch 17 of 500 took 0.544s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.922297, main loss classifier 0.342564, source accuracy 0.911318 source classification loss 0.269100, target accuracy 0.933277 target loss 0.209391 accuracy domain distinction 0.500000 loss domain distinction 1.033179,\n",
      "VALIDATION Loss: 0.11294012 Acc: 0.95709571\n",
      "Epoch 18 of 500 took 0.525s\n",
      "Accuracy total 0.926731, main loss classifier 0.339640, source accuracy 0.919341 source classification loss 0.255836, target accuracy 0.934122 target loss 0.216138 accuracy domain distinction 0.500000 loss domain distinction 1.036534,\n",
      "VALIDATION Loss: 0.09483541 Acc: 0.9620462\n",
      "New best validation loss:  0.09483541250228882\n",
      "Epoch 19 of 500 took 0.577s\n",
      "Accuracy total 0.935389, main loss classifier 0.329372, source accuracy 0.926520 source classification loss 0.245480, target accuracy 0.944257 target loss 0.205858 accuracy domain distinction 0.500000 loss domain distinction 1.037026,\n",
      "VALIDATION Loss: 0.08566367 Acc: 0.97359736\n",
      "New best validation loss:  0.08566367216408252\n",
      "Epoch 20 of 500 took 0.518s\n",
      "Accuracy total 0.936867, main loss classifier 0.313675, source accuracy 0.931588 source classification loss 0.235636, target accuracy 0.942145 target loss 0.184541 accuracy domain distinction 0.500000 loss domain distinction 1.035868,\n",
      "VALIDATION Loss: 0.12709800 Acc: 0.96039604\n",
      "Epoch 21 of 500 took 0.500s\n",
      "Accuracy total 0.928632, main loss classifier 0.323769, source accuracy 0.921453 source classification loss 0.239393, target accuracy 0.935811 target loss 0.201122 accuracy domain distinction 0.500000 loss domain distinction 1.035121,\n",
      "VALIDATION Loss: 0.10903404 Acc: 0.97029703\n",
      "Epoch 22 of 500 took 0.497s\n",
      "Accuracy total 0.923775, main loss classifier 0.341743, source accuracy 0.918074 source classification loss 0.259723, target accuracy 0.929476 target loss 0.216563 accuracy domain distinction 0.500000 loss domain distinction 1.035997,\n",
      "VALIDATION Loss: 0.12380296 Acc: 0.96039604\n",
      "Epoch 23 of 500 took 0.497s\n",
      "Accuracy total 0.927365, main loss classifier 0.328669, source accuracy 0.920608 source classification loss 0.248926, target accuracy 0.934122 target loss 0.200744 accuracy domain distinction 0.500000 loss domain distinction 1.038339,\n",
      "VALIDATION Loss: 0.13135744 Acc: 0.95544554\n",
      "Epoch 24 of 500 took 0.501s\n",
      "Accuracy total 0.932432, main loss classifier 0.315172, source accuracy 0.924831 source classification loss 0.239064, target accuracy 0.940034 target loss 0.183943 accuracy domain distinction 0.500000 loss domain distinction 1.036686,\n",
      "VALIDATION Loss: 0.13051529 Acc: 0.96369637\n",
      "Epoch 25 of 500 took 0.512s\n",
      "Accuracy total 0.926520, main loss classifier 0.320864, source accuracy 0.918919 source classification loss 0.241384, target accuracy 0.934122 target loss 0.192825 accuracy domain distinction 0.500000 loss domain distinction 1.037599,\n",
      "VALIDATION Loss: 0.14019811 Acc: 0.95379538\n",
      "Epoch    25: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 26 of 500 took 0.517s\n",
      "Accuracy total 0.931166, main loss classifier 0.328745, source accuracy 0.918919 source classification loss 0.258469, target accuracy 0.943412 target loss 0.192127 accuracy domain distinction 0.500000 loss domain distinction 1.034465,\n",
      "VALIDATION Loss: 0.10251292 Acc: 0.97029703\n",
      "Epoch 27 of 500 took 0.542s\n",
      "Accuracy total 0.938767, main loss classifier 0.301052, source accuracy 0.933277 source classification loss 0.218184, target accuracy 0.944257 target loss 0.177826 accuracy domain distinction 0.500000 loss domain distinction 1.030472,\n",
      "VALIDATION Loss: 0.08995683 Acc: 0.97194719\n",
      "Epoch 28 of 500 took 0.639s\n",
      "Accuracy total 0.935811, main loss classifier 0.306148, source accuracy 0.921453 source classification loss 0.240708, target accuracy 0.950169 target loss 0.165035 accuracy domain distinction 0.500000 loss domain distinction 1.032766,\n",
      "VALIDATION Loss: 0.08928584 Acc: 0.9669967\n",
      "Epoch 29 of 500 took 0.577s\n",
      "Accuracy total 0.926943, main loss classifier 0.324823, source accuracy 0.915541 source classification loss 0.252526, target accuracy 0.938345 target loss 0.190018 accuracy domain distinction 0.500000 loss domain distinction 1.035514,\n",
      "VALIDATION Loss: 0.09642474 Acc: 0.96534653\n",
      "Epoch 30 of 500 took 0.537s\n",
      "Accuracy total 0.938767, main loss classifier 0.299051, source accuracy 0.930743 source classification loss 0.220361, target accuracy 0.946791 target loss 0.170865 accuracy domain distinction 0.500000 loss domain distinction 1.034377,\n",
      "VALIDATION Loss: 0.09717518 Acc: 0.97029703\n",
      "Epoch 31 of 500 took 0.524s\n",
      "Training complete in 0m 16s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f3dd574fc10>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt' (epoch 5)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 24)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 16)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt' (epoch 5)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  30\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  101\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  61\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  33\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  51\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.05154639175257732   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.4225352112676056  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6185567010309279   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.31958762886597936  len before:  97   len after:  97\n",
      "BEFORE:  0.8247422680412371   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  64\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  45\n",
      "BEFORE:  0.7525773195876289   AFTER:  0.5733333333333334  len before:  97   len after:  75\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0594059405940594   AFTER:  0.0  len before:  101   len after:  31\n",
      "ACCURACY MODEL:  0.213773761296354   Accuracy pseudo: 0.25667090216010163  len pseudo:  2361    len predictions 3209\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5567010309278351   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.851063829787234   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5463917525773195   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9574468085106383   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.851063829787234   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  0.43478260869565216  len before:  97   len after:  69\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7216494845360825   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9354838709677419   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  72\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.422680412371134   AFTER:  1.0  len before:  97   len after:  37\n",
      "ACCURACY MODEL:  0.8693056864593152   Accuracy pseudo: 0.9871116986120291  len pseudo:  3026    len predictions 3183\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6777777777777778   AFTER:  1.0  len before:  90   len after:  23\n",
      "BEFORE:  0.6597938144329897   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7216494845360825   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.4845360824742268   AFTER:  0.8857142857142857  len before:  97   len after:  35\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.5876288659793815   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6067415730337079   AFTER:  0.5384615384615384  len before:  89   len after:  65\n",
      "BEFORE:  0.7954545454545454   AFTER:  1.0  len before:  88   len after:  88\n",
      "BEFORE:  0.3711340206185567   AFTER:  0.484375  len before:  97   len after:  64\n",
      "BEFORE:  0.8850574712643678   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.7446808510638298   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8247422680412371   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8041237113402062   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6391752577319587   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5773195876288659   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.875   AFTER:  1.0  len before:  96   len after:  96\n",
      "ACCURACY MODEL:  0.799047619047619   Accuracy pseudo: 0.9210618232623122  len pseudo:  2863    len predictions 3150\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.793304, main loss classifier 0.858828, source accuracy 0.787054 source classification loss 0.777156, target accuracy 0.799554 target loss 0.718857 accuracy domain distinction 0.500893 loss domain distinction 1.108213,\n",
      "VALIDATION Loss: 1.04433882 Acc: 0.69284468\n",
      "New best validation loss:  1.0443388223648071\n",
      "Epoch 2 of 500 took 0.602s\n",
      "Accuracy total 0.829241, main loss classifier 0.654516, source accuracy 0.822321 source classification loss 0.571347, target accuracy 0.836161 target loss 0.520922 accuracy domain distinction 0.499777 loss domain distinction 1.083817,\n",
      "VALIDATION Loss: 0.72646620 Acc: 0.7434555\n",
      "New best validation loss:  0.726466202073627\n",
      "Epoch 3 of 500 took 0.569s\n",
      "Accuracy total 0.843750, main loss classifier 0.591302, source accuracy 0.844196 source classification loss 0.486529, target accuracy 0.843304 target loss 0.482748 accuracy domain distinction 0.499777 loss domain distinction 1.066638,\n",
      "VALIDATION Loss: 0.88108945 Acc: 0.73472949\n",
      "Epoch 4 of 500 took 0.494s\n",
      "Accuracy total 0.863616, main loss classifier 0.561240, source accuracy 0.859821 source classification loss 0.461116, target accuracy 0.867411 target loss 0.448264 accuracy domain distinction 0.500000 loss domain distinction 1.065501,\n",
      "VALIDATION Loss: 0.59960485 Acc: 0.81151832\n",
      "New best validation loss:  0.5996048483583662\n",
      "Epoch 5 of 500 took 0.574s\n",
      "Accuracy total 0.877232, main loss classifier 0.500598, source accuracy 0.875000 source classification loss 0.404645, target accuracy 0.879464 target loss 0.384954 accuracy domain distinction 0.500000 loss domain distinction 1.057985,\n",
      "VALIDATION Loss: 0.34352526 Acc: 0.87958115\n",
      "New best validation loss:  0.3435252573755052\n",
      "Epoch 6 of 500 took 0.501s\n",
      "Accuracy total 0.876786, main loss classifier 0.498703, source accuracy 0.875893 source classification loss 0.385650, target accuracy 0.877679 target loss 0.401459 accuracy domain distinction 0.500000 loss domain distinction 1.051480,\n",
      "VALIDATION Loss: 0.28756415 Acc: 0.90575916\n",
      "New best validation loss:  0.28756414850552875\n",
      "Epoch 7 of 500 took 0.513s\n",
      "Accuracy total 0.875223, main loss classifier 0.507010, source accuracy 0.873214 source classification loss 0.419533, target accuracy 0.877232 target loss 0.383875 accuracy domain distinction 0.500000 loss domain distinction 1.053056,\n",
      "VALIDATION Loss: 1.09685804 Acc: 0.67713787\n",
      "Epoch 8 of 500 took 0.521s\n",
      "Accuracy total 0.878125, main loss classifier 0.494820, source accuracy 0.880357 source classification loss 0.392437, target accuracy 0.875893 target loss 0.387452 accuracy domain distinction 0.500000 loss domain distinction 1.048753,\n",
      "VALIDATION Loss: 0.55510986 Acc: 0.80104712\n",
      "Epoch 9 of 500 took 0.485s\n",
      "Accuracy total 0.886607, main loss classifier 0.475093, source accuracy 0.885268 source classification loss 0.378129, target accuracy 0.887946 target loss 0.361855 accuracy domain distinction 0.500000 loss domain distinction 1.051003,\n",
      "VALIDATION Loss: 0.44770796 Acc: 0.82547993\n",
      "Epoch 10 of 500 took 0.479s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.890402, main loss classifier 0.466325, source accuracy 0.892411 source classification loss 0.367020, target accuracy 0.888393 target loss 0.356928 accuracy domain distinction 0.500000 loss domain distinction 1.043503,\n",
      "VALIDATION Loss: 0.40424802 Acc: 0.86561955\n",
      "Epoch 11 of 500 took 0.491s\n",
      "Accuracy total 0.892857, main loss classifier 0.449472, source accuracy 0.897768 source classification loss 0.341032, target accuracy 0.887946 target loss 0.348079 accuracy domain distinction 0.500000 loss domain distinction 1.049170,\n",
      "VALIDATION Loss: 0.32379214 Acc: 0.88830716\n",
      "Epoch 12 of 500 took 0.476s\n",
      "Accuracy total 0.894643, main loss classifier 0.443374, source accuracy 0.892411 source classification loss 0.360388, target accuracy 0.896875 target loss 0.317987 accuracy domain distinction 0.500000 loss domain distinction 1.041862,\n",
      "VALIDATION Loss: 0.70836873 Acc: 0.79406632\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 13 of 500 took 0.471s\n",
      "Accuracy total 0.897768, main loss classifier 0.419612, source accuracy 0.900446 source classification loss 0.320165, target accuracy 0.895089 target loss 0.312688 accuracy domain distinction 0.500000 loss domain distinction 1.031855,\n",
      "VALIDATION Loss: 0.24460049 Acc: 0.91623037\n",
      "New best validation loss:  0.24460048807991874\n",
      "Epoch 14 of 500 took 0.501s\n",
      "Accuracy total 0.900893, main loss classifier 0.404446, source accuracy 0.904018 source classification loss 0.312027, target accuracy 0.897768 target loss 0.289336 accuracy domain distinction 0.500000 loss domain distinction 1.037645,\n",
      "VALIDATION Loss: 0.21360773 Acc: 0.92670157\n",
      "New best validation loss:  0.21360772599776587\n",
      "Epoch 15 of 500 took 0.506s\n",
      "Accuracy total 0.906696, main loss classifier 0.406839, source accuracy 0.908036 source classification loss 0.306725, target accuracy 0.905357 target loss 0.300443 accuracy domain distinction 0.500000 loss domain distinction 1.032555,\n",
      "VALIDATION Loss: 0.23080476 Acc: 0.91448517\n",
      "Epoch 16 of 500 took 0.558s\n",
      "Accuracy total 0.908036, main loss classifier 0.398761, source accuracy 0.912054 source classification loss 0.289005, target accuracy 0.904018 target loss 0.301902 accuracy domain distinction 0.500000 loss domain distinction 1.033073,\n",
      "VALIDATION Loss: 0.26366722 Acc: 0.92146597\n",
      "Epoch 17 of 500 took 0.528s\n",
      "Accuracy total 0.910045, main loss classifier 0.388152, source accuracy 0.910714 source classification loss 0.290639, target accuracy 0.909375 target loss 0.278318 accuracy domain distinction 0.500000 loss domain distinction 1.036739,\n",
      "VALIDATION Loss: 0.25512199 Acc: 0.91623037\n",
      "Epoch 18 of 500 took 0.488s\n",
      "Accuracy total 0.915402, main loss classifier 0.380387, source accuracy 0.918750 source classification loss 0.277706, target accuracy 0.912054 target loss 0.276612 accuracy domain distinction 0.500000 loss domain distinction 1.032280,\n",
      "VALIDATION Loss: 0.19840089 Acc: 0.93193717\n",
      "New best validation loss:  0.19840089480082193\n",
      "Epoch 19 of 500 took 0.494s\n",
      "Accuracy total 0.911161, main loss classifier 0.383630, source accuracy 0.915179 source classification loss 0.263636, target accuracy 0.907143 target loss 0.296935 accuracy domain distinction 0.500000 loss domain distinction 1.033446,\n",
      "VALIDATION Loss: 0.19187514 Acc: 0.93368237\n",
      "New best validation loss:  0.1918751448392868\n",
      "Epoch 20 of 500 took 0.491s\n",
      "Accuracy total 0.908482, main loss classifier 0.382644, source accuracy 0.916518 source classification loss 0.262552, target accuracy 0.900446 target loss 0.295329 accuracy domain distinction 0.500000 loss domain distinction 1.037040,\n",
      "VALIDATION Loss: 0.20063630 Acc: 0.93193717\n",
      "Epoch 21 of 500 took 0.497s\n",
      "Accuracy total 0.910045, main loss classifier 0.378474, source accuracy 0.911607 source classification loss 0.284244, target accuracy 0.908482 target loss 0.266028 accuracy domain distinction 0.500000 loss domain distinction 1.033377,\n",
      "VALIDATION Loss: 0.25639631 Acc: 0.91448517\n",
      "Epoch 22 of 500 took 0.542s\n",
      "Accuracy total 0.912277, main loss classifier 0.378773, source accuracy 0.914286 source classification loss 0.280738, target accuracy 0.910268 target loss 0.270433 accuracy domain distinction 0.500000 loss domain distinction 1.031872,\n",
      "VALIDATION Loss: 0.24301595 Acc: 0.91972077\n",
      "Epoch 23 of 500 took 0.599s\n",
      "Accuracy total 0.910491, main loss classifier 0.379894, source accuracy 0.908482 source classification loss 0.290756, target accuracy 0.912500 target loss 0.262023 accuracy domain distinction 0.500000 loss domain distinction 1.035045,\n",
      "VALIDATION Loss: 0.27418247 Acc: 0.90750436\n",
      "Epoch 24 of 500 took 0.498s\n",
      "Accuracy total 0.908929, main loss classifier 0.374799, source accuracy 0.907589 source classification loss 0.271215, target accuracy 0.910268 target loss 0.271962 accuracy domain distinction 0.500000 loss domain distinction 1.032108,\n",
      "VALIDATION Loss: 0.20575393 Acc: 0.93368237\n",
      "Epoch 25 of 500 took 0.536s\n",
      "Accuracy total 0.911161, main loss classifier 0.371902, source accuracy 0.915179 source classification loss 0.265087, target accuracy 0.907143 target loss 0.270934 accuracy domain distinction 0.500000 loss domain distinction 1.038913,\n",
      "VALIDATION Loss: 0.20687903 Acc: 0.93019197\n",
      "Epoch    25: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 26 of 500 took 0.483s\n",
      "Accuracy total 0.916964, main loss classifier 0.367120, source accuracy 0.921429 source classification loss 0.261961, target accuracy 0.912500 target loss 0.266280 accuracy domain distinction 0.500000 loss domain distinction 1.029996,\n",
      "VALIDATION Loss: 0.20672161 Acc: 0.92670157\n",
      "Epoch 27 of 500 took 0.480s\n",
      "Accuracy total 0.919420, main loss classifier 0.357634, source accuracy 0.929464 source classification loss 0.245990, target accuracy 0.909375 target loss 0.262429 accuracy domain distinction 0.500000 loss domain distinction 1.034252,\n",
      "VALIDATION Loss: 0.19308081 Acc: 0.93542757\n",
      "Epoch 28 of 500 took 0.567s\n",
      "Accuracy total 0.918973, main loss classifier 0.354726, source accuracy 0.920982 source classification loss 0.252226, target accuracy 0.916964 target loss 0.250712 accuracy domain distinction 0.500000 loss domain distinction 1.032573,\n",
      "VALIDATION Loss: 0.21630259 Acc: 0.92321117\n",
      "Epoch 29 of 500 took 0.547s\n",
      "Accuracy total 0.910937, main loss classifier 0.378906, source accuracy 0.915625 source classification loss 0.265492, target accuracy 0.906250 target loss 0.286107 accuracy domain distinction 0.500000 loss domain distinction 1.031060,\n",
      "VALIDATION Loss: 0.20130603 Acc: 0.92495637\n",
      "Epoch 30 of 500 took 0.606s\n",
      "Accuracy total 0.923661, main loss classifier 0.360968, source accuracy 0.928125 source classification loss 0.255173, target accuracy 0.919196 target loss 0.260603 accuracy domain distinction 0.500000 loss domain distinction 1.030808,\n",
      "VALIDATION Loss: 0.23935196 Acc: 0.92321117\n",
      "Epoch 31 of 500 took 0.575s\n",
      "Training complete in 0m 16s\n",
      "['participant_1', 'participant_2', 'participant_0']\n"
     ]
    }
   ],
   "source": [
    "run_SCADANN_training_sessions(examples_datasets=examples_datasets_train, labels_datasets=labels_datasets_train,\n",
    "                              num_neurons=num_neurons, feature_vector_input_length=feature_vector_input_length,\n",
    "                              path_weights_to_save_to=path_weight_to_save_to,\n",
    "                              path_weights_Adversarial_training=path_weights_start_with,\n",
    "                              path_weights_Normal_training=path_weights_Normal_training,\n",
    "                              number_of_cycle_for_first_training=4, number_of_cycles_rest_of_training=4,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_classes,\n",
    "                              learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1854, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1899, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1938, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1780, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1981, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1809, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1928, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1902, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  0  Accuracy:  0.9970414201183432\n",
      "Participant:  0  Accuracy:  0.5752212389380531\n",
      "Participant:  0  Accuracy:  0.7930711610486891\n",
      "Participant:  0  Accuracy:  0.6263107721639657\n",
      "ACCURACY PARTICIPANT:  [0.9970414201183432, 0.5752212389380531, 0.7930711610486891, 0.6263107721639657]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  1  Accuracy:  0.9945553539019963\n",
      "Participant:  1  Accuracy:  0.6899810964083176\n",
      "Participant:  1  Accuracy:  0.7240038872691934\n",
      "Participant:  1  Accuracy:  0.888015717092338\n",
      "ACCURACY PARTICIPANT:  [0.9945553539019963, 0.6899810964083176, 0.7240038872691934, 0.888015717092338]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  2  Accuracy:  0.9960199004975124\n",
      "Participant:  2  Accuracy:  0.15219421101774042\n",
      "Participant:  2  Accuracy:  0.9473684210526315\n",
      "Participant:  2  Accuracy:  0.9587242026266416\n",
      "ACCURACY PARTICIPANT:  [0.9960199004975124, 0.15219421101774042, 0.9473684210526315, 0.9587242026266416]\n",
      "[0.997 0.575 0.793 0.626 0.995 0.69  0.724 0.888 0.996 0.152 0.947 0.959]\n",
      "[0.9970414201183432, 0.5752212389380531, 0.7930711610486891, 0.6263107721639657, 0.9945553539019963, 0.6899810964083176, 0.7240038872691934, 0.888015717092338, 0.9960199004975124, 0.15219421101774042, 0.9473684210526315, 0.9587242026266416]\n",
      "OVERALL ACCURACY: 0.7785422818446186\n"
     ]
    }
   ],
   "source": [
    "path_weights_normal_training = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "test_network_SLADANN(examples_datasets_train=examples_datasets_train, labels_datasets_train=labels_datasets_train,\n",
    "                     num_neurons=num_neurons, feature_vector_input_length=feature_vector_input_length,\n",
    "                     path_weights_ASR=path_weight_to_save_to, path_weights_normal=path_weights_normal_training,\n",
    "                     algo_name=algo_name, cycle_test=3, gestures_to_remove=gestures_to_remove,\n",
    "                     number_of_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>0.997041</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.793071</td>\n",
       "      <td>0.626311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_1</th>\n",
       "      <td>0.994555</td>\n",
       "      <td>0.689981</td>\n",
       "      <td>0.724004</td>\n",
       "      <td>0.888016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_2</th>\n",
       "      <td>0.996020</td>\n",
       "      <td>0.152194</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.958724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0   0.997041   0.575221   0.793071   0.626311\n",
       "Participant_1   0.994555   0.689981   0.724004   0.888016\n",
       "Participant_2   0.996020   0.152194   0.947368   0.958724"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "SCADANN_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    SCADANN_acc[i] = acc\n",
    "SCADANN_acc_overall = np.mean(SCADANN_acc)\n",
    "SCADANN_df = pd.DataFrame(SCADANN_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "SCADANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SCADANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"SCADANN Accuracies\")\n",
    "plt.savefig(\"/home/laiy/gitrepos/msr_final/code/test_code/img/3DC_SCADANN.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSD</th>\n",
       "      <td>0.702829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.762908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCADANN</th>\n",
       "      <td>0.778542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Overall_Acc\n",
       "TSD         0.702829\n",
       "DANN        0.762908\n",
       "SCADANN     0.778542"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc_df = pd.DataFrame([TSD_acc_overall, DANN_acc_overall, SCADANN_acc_overall],\n",
    "                             index = [\"TSD\", \"DANN\", \"SCADANN\"],\n",
    "                             columns = [\"Overall_Acc\"])\n",
    "overall_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,20))\n",
    "acc_list = [TSD_df, DANN_df, SCADANN_df, overall_acc_df]\n",
    "title_list = [\"TSD\", \"DANN\", \"SCADANN\", \"Overall\"]\n",
    "for idx, ax in enumerate(axes.reshape(-1)): \n",
    "    acc_list[idx].transpose().plot.bar(ax = ax, rot=0)\n",
    "    ax.set_title(title_list[idx])\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(str(np.round(p.get_height(),2)), (p.get_x()+p.get_width()/2., p.get_height()),\n",
    "                    ha='center', va='center', xytext=(0, 8),textcoords='offset points')\n",
    "fig.savefig(\"/home/laiy/gitrepos/msr_final/code/test_code/img/3DC_results.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for 2_only dataset:   \n",
    "* result from STD -> DANN -> SCADANN  \n",
    "    * 10.0 -> 17.9 -> 16.0\n",
    "    * 17.2 -> 17.9 -> 16.9\n",
    "    * 14.3 -> 16.5 -> 14.6\n",
    "    * 12.7 -> 19.0 -> 16.4\n",
    "* maybe this is just a bad data  \n",
    "* percentage_same_gesture_stable=0.65\n",
    "    * maybe too many unstable examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
