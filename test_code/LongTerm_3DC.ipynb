{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.insert(0,'../../LongTermEMG-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data\n",
    "* 20 participants total (exclude 10 and 11)\n",
    "* data from 3DC armband (10 channels with 1000 Hz)\n",
    "* 150 ms frames with overlap of 100 ms; band-pass filter between 20-495 Hz using fourth-order butterworth filter\n",
    "* dataset dict\n",
    "    * examples_training\n",
    "    * labels_training\n",
    "    * training_datetimes\n",
    "    * highest_activations\n",
    "    * examples_evaluation\n",
    "    * labels_evaluation\n",
    "    * evaluation_emg_timestamps\n",
    "    * angles_and_timestamps\n",
    "    * evaluation_datetimes\n",
    "* feature_set_function = feature_extraction.getTSD applied to each window \n",
    "    * exclude 0 sEMG recordings \n",
    "    * [1] A. Al-Timemy, R. N. Khushaba, G. Bugmann, and J. Escudero, \"Improving the Performance Against Force Variation of EMG Controlled Multifunctional Upper-Limb Prostheses for Transradial Amputees\", IEEE Transactions on Neural Systems and Rehabilitation Engineering, DOI: 10.1109/TNSRE.2015.2445634, 2015.\n",
    "    * [2] R. N. Khushaba, Maen Takruri, Jaime Valls Miro, and Sarath Kodagoda, \"Towards limb position invariant myoelectric pattern recognition using time-dependent spectral features\", Neural Networks, vol. 55, pp. 42-58, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm.prepare_dataset_utils import butter_bandpass_filter, \\\n",
    "    show_filtered_signal, load_timestamps_from_participant, get_angles_from_positions_3d_arm\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longterm_dataset_3DC.zip', 'longterm_dataset_3DC', 'README.md', 'LongTermClassificationMain', 'datasets', 'TransferLearning', '.idea', 'Weights_TSD']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/PrepareAndLoadDataLongTerm\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from handcrafted_features_prepare_from_from_raw_dataset import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_participant_training_1_to_skip = [\"Participant0/Training1\", \"Participant0/Evaluation2\", \"Participant0/Evaluation3\",\n",
    "                                       \"Participant2/Training1\", \"Participant2/Evaluation2\", \"Participant2/Evaluation3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_set_name = \"TSD_features_set\"\n",
    "# feature_set_function = feature_extraction.getTSD\n",
    "# read_data_training(path=\"../../datasets/longterm_dataset_3DC\", features_set_name=features_set_name, \\\n",
    "#                 feature_set_function=feature_set_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Temporal-Spatial Descriptors Deep Network (TSD_DNN)\n",
    "* input size = 128 x 3 x 1 = 384\n",
    "* 3 fully connected layers with 200 neurons \n",
    "    * batch normalization\n",
    "    * leaky ReLU (0.1)\n",
    "    * dropout (0.5)\n",
    "* mean cross entropy loss\n",
    "* optimization = ADAM (lr = 0.002515, beta = (0.5, 0.999))\n",
    "* lr_scheduler (1e-8)\n",
    "* dataloader needs\n",
    "    * examples_training\n",
    "    * labels_training\n",
    "   \n",
    "   \n",
    "### Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\n",
    "    * best_state_n.pt (n = # training session)\n",
    "        * epoch: #epochs\n",
    "        * model state_dict\n",
    "        * optimizer state_dict\n",
    "        * scheduler state_dict \n",
    "    * fine-tune from the previous training      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import train_Spectrogram_fine_tuning\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm. \\\n",
    "    load_dataset_spectrogram_in_dataloader import load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.utils_training_and_evaluation import create_confusion_matrix, \\\n",
    "    long_term_classification_graph, long_term_pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from train_tsd_dnn_standard import test_TSD_DNN_on_training_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "\n",
    "algo_name = \"11Gestures_standard_ConvNet_THREE_Cycles_TSD\"\n",
    "path_to_save_to = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "\n",
    "filter_size = [200, 200, 200]      \n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = None\n",
    "number_of_classes = 11                          \n",
    "learning_rate = 0.002515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2816, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2835, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2864, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2888, 385)\n",
      "Participant:  0\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f577ef01eb0>\n",
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.01102007 Acc: 0.54332386\n",
      "val Loss: 0.00946779 Acc: 0.23642173\n",
      "New best validation loss: 0.009467786874253148\n",
      "Epoch 1 of 500 took 0.213s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00474644 Acc: 0.82528409\n",
      "val Loss: 0.00789105 Acc: 0.37699681\n",
      "New best validation loss: 0.007891046353422415\n",
      "Epoch 2 of 500 took 0.210s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00355613 Acc: 0.86044034\n",
      "val Loss: 0.00701236 Acc: 0.40894569\n",
      "New best validation loss: 0.007012360393048856\n",
      "Epoch 3 of 500 took 0.195s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00257248 Acc: 0.9037642\n",
      "val Loss: 0.06854719 Acc: 0.10223642\n",
      "Epoch 4 of 500 took 0.214s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00233468 Acc: 0.90980114\n",
      "val Loss: 0.00667140 Acc: 0.4313099\n",
      "New best validation loss: 0.006671398973312622\n",
      "Epoch 5 of 500 took 0.275s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00199999 Acc: 0.92151989\n",
      "val Loss: 0.00844331 Acc: 0.40255591\n",
      "Epoch 6 of 500 took 0.259s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00184634 Acc: 0.92578125\n",
      "val Loss: 0.01594259 Acc: 0.24600639\n",
      "Epoch 7 of 500 took 0.259s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00163241 Acc: 0.93465909\n",
      "val Loss: 0.02193665 Acc: 0.31309904\n",
      "Epoch 8 of 500 took 0.201s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00172166 Acc: 0.92933239\n",
      "val Loss: 0.03059966 Acc: 0.092651757\n",
      "Epoch 9 of 500 took 0.189s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00149050 Acc: 0.93963068\n",
      "val Loss: 0.00715550 Acc: 0.46645367\n",
      "Epoch 10 of 500 took 0.205s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00150332 Acc: 0.94460227\n",
      "val Loss: 0.02108460 Acc: 0.28115016\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 11 of 500 took 0.214s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00104166 Acc: 0.9634233\n",
      "val Loss: 0.00028945 Acc: 0.96485623\n",
      "New best validation loss: 0.0002894526758133032\n",
      "Epoch 12 of 500 took 0.195s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00093203 Acc: 0.96803977\n",
      "val Loss: 0.00108970 Acc: 0.90415335\n",
      "Epoch 13 of 500 took 0.197s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00086998 Acc: 0.96768466\n",
      "val Loss: 0.00052804 Acc: 0.92651757\n",
      "Epoch 14 of 500 took 0.199s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00069295 Acc: 0.9740767\n",
      "val Loss: 0.00024538 Acc: 0.97763578\n",
      "New best validation loss: 0.0002453806110845206\n",
      "Epoch 15 of 500 took 0.216s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00073496 Acc: 0.97336648\n",
      "val Loss: 0.00047638 Acc: 0.95527157\n",
      "Epoch 16 of 500 took 0.212s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00072272 Acc: 0.97336648\n",
      "val Loss: 0.00023094 Acc: 0.98402556\n",
      "New best validation loss: 0.0002309357681975197\n",
      "Epoch 17 of 500 took 0.193s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00066529 Acc: 0.97691761\n",
      "val Loss: 0.00144879 Acc: 0.87859425\n",
      "Epoch 18 of 500 took 0.209s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00063111 Acc: 0.97514205\n",
      "val Loss: 0.00031942 Acc: 0.96166134\n",
      "Epoch 19 of 500 took 0.210s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00059661 Acc: 0.97727273\n",
      "val Loss: 0.00043050 Acc: 0.9456869\n",
      "Epoch 20 of 500 took 0.209s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00058233 Acc: 0.97940341\n",
      "val Loss: 0.00035703 Acc: 0.96805112\n",
      "Epoch 21 of 500 took 0.233s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00054878 Acc: 0.97940341\n",
      "val Loss: 0.00110409 Acc: 0.89776358\n",
      "Epoch 22 of 500 took 0.251s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00058474 Acc: 0.97549716\n",
      "val Loss: 0.00036974 Acc: 0.97444089\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 23 of 500 took 0.254s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00057046 Acc: 0.9790483\n",
      "val Loss: 0.00020332 Acc: 0.98402556\n",
      "New best validation loss: 0.00020331929857357622\n",
      "Epoch 24 of 500 took 0.234s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00055029 Acc: 0.9790483\n",
      "val Loss: 0.00021498 Acc: 0.97444089\n",
      "Epoch 25 of 500 took 0.222s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00051476 Acc: 0.98259943\n",
      "val Loss: 0.00017401 Acc: 0.98722045\n",
      "New best validation loss: 0.00017401327292759197\n",
      "Epoch 26 of 500 took 0.192s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00046142 Acc: 0.98046875\n",
      "val Loss: 0.00016337 Acc: 0.99361022\n",
      "New best validation loss: 0.00016336614331498314\n",
      "Epoch 27 of 500 took 0.228s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00049642 Acc: 0.98117898\n",
      "val Loss: 0.00018481 Acc: 0.98722045\n",
      "Epoch 28 of 500 took 0.202s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00050302 Acc: 0.98259943\n",
      "val Loss: 0.00017602 Acc: 0.98402556\n",
      "Epoch 29 of 500 took 0.188s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00055396 Acc: 0.98224432\n",
      "val Loss: 0.00016297 Acc: 0.99041534\n",
      "New best validation loss: 0.00016296602571353364\n",
      "Epoch 30 of 500 took 0.197s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00049243 Acc: 0.9818892\n",
      "val Loss: 0.00019767 Acc: 0.98083067\n",
      "Epoch 31 of 500 took 0.185s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00046436 Acc: 0.984375\n",
      "val Loss: 0.00023317 Acc: 0.98083067\n",
      "Epoch 32 of 500 took 0.196s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00054182 Acc: 0.97940341\n",
      "val Loss: 0.00023040 Acc: 0.98083067\n",
      "Epoch 33 of 500 took 0.220s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00047845 Acc: 0.98117898\n",
      "val Loss: 0.00016452 Acc: 0.99041534\n",
      "Epoch 34 of 500 took 0.204s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00048546 Acc: 0.9818892\n",
      "val Loss: 0.00015152 Acc: 0.99361022\n",
      "New best validation loss: 0.00015152368349389145\n",
      "Epoch 35 of 500 took 0.219s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00054603 Acc: 0.97833807\n",
      "val Loss: 0.00020346 Acc: 0.98722045\n",
      "Epoch 36 of 500 took 0.199s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00044167 Acc: 0.984375\n",
      "val Loss: 0.00017632 Acc: 0.99041534\n",
      "Epoch 37 of 500 took 0.210s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00047848 Acc: 0.98295455\n",
      "val Loss: 0.00017941 Acc: 0.99361022\n",
      "Epoch 38 of 500 took 0.202s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00042734 Acc: 0.984375\n",
      "val Loss: 0.00021403 Acc: 0.98402556\n",
      "Epoch 39 of 500 took 0.209s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00042106 Acc: 0.9868608\n",
      "val Loss: 0.00014861 Acc: 0.99361022\n",
      "New best validation loss: 0.0001486132796199177\n",
      "Epoch 40 of 500 took 0.221s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00046167 Acc: 0.98544034\n",
      "val Loss: 0.00062680 Acc: 0.93290735\n",
      "Epoch 41 of 500 took 0.199s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00050841 Acc: 0.98259943\n",
      "val Loss: 0.00024294 Acc: 0.98402556\n",
      "Epoch 42 of 500 took 0.208s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00044981 Acc: 0.98259943\n",
      "val Loss: 0.00022716 Acc: 0.99041534\n",
      "Epoch 43 of 500 took 0.197s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00042632 Acc: 0.984375\n",
      "val Loss: 0.00017507 Acc: 0.98722045\n",
      "Epoch 44 of 500 took 0.209s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00039136 Acc: 0.98721591\n",
      "val Loss: 0.00019615 Acc: 0.99041534\n",
      "Epoch 45 of 500 took 0.214s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00041640 Acc: 0.98473011\n",
      "val Loss: 0.00026777 Acc: 0.96485623\n",
      "Epoch    46: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 46 of 500 took 0.240s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00041037 Acc: 0.98401989\n",
      "val Loss: 0.00020752 Acc: 0.97763578\n",
      "Epoch 47 of 500 took 0.245s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00041774 Acc: 0.98401989\n",
      "val Loss: 0.00021116 Acc: 0.98722045\n",
      "Epoch 48 of 500 took 0.258s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00037658 Acc: 0.98650568\n",
      "val Loss: 0.00019954 Acc: 0.98402556\n",
      "Epoch 49 of 500 took 0.212s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00041226 Acc: 0.98650568\n",
      "val Loss: 0.00019754 Acc: 0.98722045\n",
      "Epoch 50 of 500 took 0.336s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00041732 Acc: 0.98544034\n",
      "val Loss: 0.00017341 Acc: 0.99041534\n",
      "Epoch 51 of 500 took 0.252s\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val loss: 0.000149\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f577ef01dd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00378108 Acc: 0.8647017\n",
      "val Loss: 0.01610005 Acc: 0.26666667\n",
      "New best validation loss: 0.016100049397302054\n",
      "Epoch 1 of 500 took 0.243s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00217426 Acc: 0.91619318\n",
      "val Loss: 0.00386366 Acc: 0.62857143\n",
      "New best validation loss: 0.0038636563316224114\n",
      "Epoch 2 of 500 took 0.233s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00188226 Acc: 0.92791193\n",
      "val Loss: 0.01223792 Acc: 0.44444444\n",
      "Epoch 3 of 500 took 0.234s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00166716 Acc: 0.93536932\n",
      "val Loss: 0.00515250 Acc: 0.58730159\n",
      "Epoch 4 of 500 took 0.202s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00143027 Acc: 0.94708807\n",
      "val Loss: 0.01428993 Acc: 0.41587302\n",
      "Epoch 5 of 500 took 0.188s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00126341 Acc: 0.95134943\n",
      "val Loss: 0.05196617 Acc: 0.17142857\n",
      "Epoch 6 of 500 took 0.188s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00125123 Acc: 0.9506392\n",
      "val Loss: 0.00572349 Acc: 0.63492063\n",
      "Epoch 7 of 500 took 0.194s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00121473 Acc: 0.95738636\n",
      "val Loss: 0.00385884 Acc: 0.72698413\n",
      "New best validation loss: 0.0038588398978823706\n",
      "Epoch 8 of 500 took 0.247s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00098337 Acc: 0.95951705\n",
      "val Loss: 0.01971029 Acc: 0.37142857\n",
      "Epoch 9 of 500 took 0.315s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00114724 Acc: 0.95028409\n",
      "val Loss: 0.00205647 Acc: 0.79047619\n",
      "New best validation loss: 0.0020564743450709752\n",
      "Epoch 10 of 500 took 0.273s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00113428 Acc: 0.95490057\n",
      "val Loss: 0.01826856 Acc: 0.3047619\n",
      "Epoch 11 of 500 took 0.249s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00104400 Acc: 0.95987216\n",
      "val Loss: 0.01944475 Acc: 0.33015873\n",
      "Epoch 12 of 500 took 0.241s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00090200 Acc: 0.9634233\n",
      "val Loss: 0.00516175 Acc: 0.63809524\n",
      "Epoch 13 of 500 took 0.267s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00088910 Acc: 0.96732955\n",
      "val Loss: 0.00085735 Acc: 0.91428571\n",
      "New best validation loss: 0.0008573452631632487\n",
      "Epoch 14 of 500 took 0.265s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00076819 Acc: 0.96981534\n",
      "val Loss: 0.00445059 Acc: 0.58412698\n",
      "Epoch 15 of 500 took 0.262s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00072374 Acc: 0.96946023\n",
      "val Loss: 0.00154462 Acc: 0.85079365\n",
      "Epoch 16 of 500 took 0.207s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00081909 Acc: 0.96946023\n",
      "val Loss: 0.01294393 Acc: 0.43809524\n",
      "Epoch 17 of 500 took 0.189s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00078009 Acc: 0.97017045\n",
      "val Loss: 0.03554868 Acc: 0.26031746\n",
      "Epoch 18 of 500 took 0.199s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00088988 Acc: 0.9609375\n",
      "val Loss: 0.00355979 Acc: 0.6952381\n",
      "Epoch 19 of 500 took 0.192s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00077828 Acc: 0.97372159\n",
      "val Loss: 0.00314764 Acc: 0.71746032\n",
      "Epoch    20: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 20 of 500 took 0.201s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00062206 Acc: 0.97585227\n",
      "val Loss: 0.00018366 Acc: 0.98412698\n",
      "New best validation loss: 0.00018366358819462005\n",
      "Epoch 21 of 500 took 0.258s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00052526 Acc: 0.97975852\n",
      "val Loss: 0.00018798 Acc: 0.97777778\n",
      "Epoch 22 of 500 took 0.228s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00050123 Acc: 0.98046875\n",
      "val Loss: 0.00014274 Acc: 0.99047619\n",
      "New best validation loss: 0.00014273754897571746\n",
      "Epoch 23 of 500 took 0.244s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00044439 Acc: 0.98366477\n",
      "val Loss: 0.00028684 Acc: 0.97460317\n",
      "Epoch 24 of 500 took 0.245s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00037731 Acc: 0.98508523\n",
      "val Loss: 0.00021988 Acc: 0.98412698\n",
      "Epoch 25 of 500 took 0.231s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00041940 Acc: 0.98401989\n",
      "val Loss: 0.00023840 Acc: 0.98412698\n",
      "Epoch 26 of 500 took 0.218s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00037148 Acc: 0.98899148\n",
      "val Loss: 0.00012469 Acc: 0.98412698\n",
      "New best validation loss: 0.00012468875400603764\n",
      "Epoch 27 of 500 took 0.232s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00035208 Acc: 0.98544034\n",
      "val Loss: 0.00021809 Acc: 0.98095238\n",
      "Epoch 28 of 500 took 0.244s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00030876 Acc: 0.9897017\n",
      "val Loss: 0.00023909 Acc: 0.98095238\n",
      "Epoch 29 of 500 took 0.243s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00035063 Acc: 0.98650568\n",
      "val Loss: 0.00022261 Acc: 0.97777778\n",
      "Epoch 30 of 500 took 0.187s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00029482 Acc: 0.98934659\n",
      "val Loss: 0.00031742 Acc: 0.97777778\n",
      "Epoch 31 of 500 took 0.191s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00033165 Acc: 0.9868608\n",
      "val Loss: 0.00019399 Acc: 0.98412698\n",
      "Epoch 32 of 500 took 0.192s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00028923 Acc: 0.98828125\n",
      "val Loss: 0.00021001 Acc: 0.98412698\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 33 of 500 took 0.198s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00031818 Acc: 0.98792614\n",
      "val Loss: 0.00024918 Acc: 0.97460317\n",
      "Epoch 34 of 500 took 0.202s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00025853 Acc: 0.99325284\n",
      "val Loss: 0.00020972 Acc: 0.98730159\n",
      "Epoch 35 of 500 took 0.195s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00028920 Acc: 0.9897017\n",
      "val Loss: 0.00019512 Acc: 0.98095238\n",
      "Epoch 36 of 500 took 0.192s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00031768 Acc: 0.98792614\n",
      "val Loss: 0.00018687 Acc: 0.98730159\n",
      "Epoch 37 of 500 took 0.197s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00030458 Acc: 0.9868608\n",
      "val Loss: 0.00018506 Acc: 0.99047619\n",
      "Epoch 38 of 500 took 0.191s\n",
      "\n",
      "Training complete in 0m 8s\n",
      "Best val loss: 0.000125\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f577ef01d60>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_1.pt' (epoch 27)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00233245 Acc: 0.92009943\n",
      "val Loss: 0.00764962 Acc: 0.59247649\n",
      "New best validation loss: 0.007649624982971383\n",
      "Epoch 1 of 500 took 0.191s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00142756 Acc: 0.9428267\n",
      "val Loss: 0.00216975 Acc: 0.79310345\n",
      "New best validation loss: 0.002169751822014214\n",
      "Epoch 2 of 500 took 0.192s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00136045 Acc: 0.94460227\n",
      "val Loss: 0.00788555 Acc: 0.62382445\n",
      "Epoch 3 of 500 took 0.188s\n",
      "Epoch 3/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00099864 Acc: 0.9634233\n",
      "val Loss: 0.00205173 Acc: 0.78996865\n",
      "New best validation loss: 0.0020517278988159563\n",
      "Epoch 4 of 500 took 0.190s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00096266 Acc: 0.96519886\n",
      "val Loss: 0.00031202 Acc: 0.97492163\n",
      "New best validation loss: 0.0003120150171850916\n",
      "Epoch 5 of 500 took 0.189s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00085422 Acc: 0.96732955\n",
      "val Loss: 0.00384555 Acc: 0.63636364\n",
      "Epoch 6 of 500 took 0.192s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00091099 Acc: 0.96271307\n",
      "val Loss: 0.01510661 Acc: 0.44827586\n",
      "Epoch 7 of 500 took 0.188s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00090286 Acc: 0.96058239\n",
      "val Loss: 0.01222827 Acc: 0.51410658\n",
      "Epoch 8 of 500 took 0.190s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00079467 Acc: 0.9662642\n",
      "val Loss: 0.00102827 Acc: 0.87774295\n",
      "Epoch 9 of 500 took 0.235s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00075570 Acc: 0.96946023\n",
      "val Loss: 0.00329184 Acc: 0.72100313\n",
      "Epoch 10 of 500 took 0.224s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00071766 Acc: 0.96981534\n",
      "val Loss: 0.00692972 Acc: 0.62695925\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 11 of 500 took 0.214s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00055970 Acc: 0.97585227\n",
      "val Loss: 0.00040388 Acc: 0.95924765\n",
      "Epoch 12 of 500 took 0.236s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00049350 Acc: 0.98153409\n",
      "val Loss: 0.00018446 Acc: 0.98119122\n",
      "New best validation loss: 0.00018446099561957355\n",
      "Epoch 13 of 500 took 0.252s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00047368 Acc: 0.97975852\n",
      "val Loss: 0.00013240 Acc: 0.98746082\n",
      "New best validation loss: 0.00013239556765855292\n",
      "Epoch 14 of 500 took 0.210s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00040195 Acc: 0.98366477\n",
      "val Loss: 0.00014860 Acc: 0.98119122\n",
      "Epoch 15 of 500 took 0.202s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00042162 Acc: 0.98330966\n",
      "val Loss: 0.00014864 Acc: 0.98432602\n",
      "Epoch 16 of 500 took 0.194s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00034122 Acc: 0.98650568\n",
      "val Loss: 0.00012945 Acc: 0.98746082\n",
      "New best validation loss: 0.00012945430499259207\n",
      "Epoch 17 of 500 took 0.199s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00039672 Acc: 0.97975852\n",
      "val Loss: 0.00018826 Acc: 0.98119122\n",
      "Epoch 18 of 500 took 0.189s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00033871 Acc: 0.98721591\n",
      "val Loss: 0.00020705 Acc: 0.98119122\n",
      "Epoch 19 of 500 took 0.216s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00037086 Acc: 0.984375\n",
      "val Loss: 0.00015368 Acc: 0.98746082\n",
      "Epoch 20 of 500 took 0.210s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00034986 Acc: 0.98401989\n",
      "val Loss: 0.00026200 Acc: 0.96551724\n",
      "Epoch 21 of 500 took 0.234s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00032638 Acc: 0.98401989\n",
      "val Loss: 0.00042991 Acc: 0.94984326\n",
      "Epoch 22 of 500 took 0.222s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00036414 Acc: 0.98473011\n",
      "val Loss: 0.00018158 Acc: 0.97805643\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 23 of 500 took 0.208s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00029409 Acc: 0.98721591\n",
      "val Loss: 0.00016613 Acc: 0.98746082\n",
      "Epoch 24 of 500 took 0.194s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00031451 Acc: 0.98721591\n",
      "val Loss: 0.00015154 Acc: 0.98432602\n",
      "Epoch 25 of 500 took 0.200s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00027907 Acc: 0.98721591\n",
      "val Loss: 0.00010505 Acc: 0.99059561\n",
      "New best validation loss: 0.00010504941441422345\n",
      "Epoch 26 of 500 took 0.200s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00024146 Acc: 0.99005682\n",
      "val Loss: 0.00010263 Acc: 0.99373041\n",
      "New best validation loss: 0.00010263372130902209\n",
      "Epoch 27 of 500 took 0.192s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00026944 Acc: 0.9897017\n",
      "val Loss: 0.00010689 Acc: 0.99373041\n",
      "Epoch 28 of 500 took 0.224s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00023706 Acc: 0.99041193\n",
      "val Loss: 0.00015598 Acc: 0.99059561\n",
      "Epoch 29 of 500 took 0.315s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00028087 Acc: 0.98721591\n",
      "val Loss: 0.00016314 Acc: 0.99059561\n",
      "Epoch 30 of 500 took 0.203s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00030548 Acc: 0.98863636\n",
      "val Loss: 0.00018836 Acc: 0.98432602\n",
      "Epoch 31 of 500 took 0.208s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00027202 Acc: 0.98899148\n",
      "val Loss: 0.00014898 Acc: 0.99059561\n",
      "Epoch 32 of 500 took 0.215s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00028939 Acc: 0.98757102\n",
      "val Loss: 0.00012788 Acc: 0.99059561\n",
      "Epoch    33: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 33 of 500 took 0.225s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00025693 Acc: 0.99005682\n",
      "val Loss: 0.00011985 Acc: 0.99059561\n",
      "Epoch 34 of 500 took 0.226s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00027428 Acc: 0.98934659\n",
      "val Loss: 0.00013249 Acc: 0.99059561\n",
      "Epoch 35 of 500 took 0.232s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00025586 Acc: 0.9897017\n",
      "val Loss: 0.00013454 Acc: 0.99059561\n",
      "Epoch 36 of 500 took 0.217s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00021986 Acc: 0.99112216\n",
      "val Loss: 0.00012389 Acc: 0.99059561\n",
      "Epoch 37 of 500 took 0.218s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00026060 Acc: 0.98899148\n",
      "val Loss: 0.00013801 Acc: 0.98746082\n",
      "Epoch 38 of 500 took 0.234s\n",
      "\n",
      "Training complete in 0m 8s\n",
      "Best val loss: 0.000103\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f577ef01d60>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_2.pt' (epoch 27)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01520558 Acc: 0.62144886\n",
      "val Loss: 0.00549228 Acc: 0.58255452\n",
      "New best validation loss: 0.005492280205462209\n",
      "Epoch 1 of 500 took 0.221s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00492725 Acc: 0.81321023\n",
      "val Loss: 0.00413668 Acc: 0.58878505\n",
      "New best validation loss: 0.004136679328490641\n",
      "Epoch 2 of 500 took 0.209s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00352439 Acc: 0.85830966\n",
      "val Loss: 0.00100930 Acc: 0.90031153\n",
      "New best validation loss: 0.0010092972409316684\n",
      "Epoch 3 of 500 took 0.205s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00286261 Acc: 0.88671875\n",
      "val Loss: 0.00401011 Acc: 0.59501558\n",
      "Epoch 4 of 500 took 0.200s\n",
      "Epoch 4/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00257720 Acc: 0.89985795\n",
      "val Loss: 0.00121934 Acc: 0.84735202\n",
      "Epoch 5 of 500 took 0.246s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00204891 Acc: 0.91725852\n",
      "val Loss: 0.00651926 Acc: 0.50778816\n",
      "Epoch 6 of 500 took 0.220s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00200989 Acc: 0.92080966\n",
      "val Loss: 0.00137153 Acc: 0.84735202\n",
      "Epoch 7 of 500 took 0.199s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00173273 Acc: 0.93323864\n",
      "val Loss: 0.00643391 Acc: 0.59190031\n",
      "Epoch 8 of 500 took 0.195s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00165140 Acc: 0.93288352\n",
      "val Loss: 0.00741499 Acc: 0.53894081\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 9 of 500 took 0.208s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00142855 Acc: 0.94637784\n",
      "val Loss: 0.00036469 Acc: 0.95015576\n",
      "New best validation loss: 0.0003646880248996699\n",
      "Epoch 10 of 500 took 0.192s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00132522 Acc: 0.9506392\n",
      "val Loss: 0.00050798 Acc: 0.9376947\n",
      "Epoch 11 of 500 took 0.204s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00122412 Acc: 0.9506392\n",
      "val Loss: 0.00031715 Acc: 0.97819315\n",
      "New best validation loss: 0.0003171463111107966\n",
      "Epoch 12 of 500 took 0.203s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00117029 Acc: 0.95028409\n",
      "val Loss: 0.00031750 Acc: 0.96884735\n",
      "Epoch 13 of 500 took 0.230s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00114276 Acc: 0.95951705\n",
      "val Loss: 0.00034925 Acc: 0.96573209\n",
      "Epoch 14 of 500 took 0.191s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00109921 Acc: 0.95703125\n",
      "val Loss: 0.00051706 Acc: 0.94080997\n",
      "Epoch 15 of 500 took 0.197s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00103739 Acc: 0.96235795\n",
      "val Loss: 0.00027837 Acc: 0.96573209\n",
      "New best validation loss: 0.0002783700081046868\n",
      "Epoch 16 of 500 took 0.192s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00097577 Acc: 0.96448864\n",
      "val Loss: 0.00064139 Acc: 0.91277259\n",
      "Epoch 17 of 500 took 0.231s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00096303 Acc: 0.96129261\n",
      "val Loss: 0.00064789 Acc: 0.91900312\n",
      "Epoch 18 of 500 took 0.197s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00089494 Acc: 0.96661932\n",
      "val Loss: 0.00031761 Acc: 0.96261682\n",
      "Epoch 19 of 500 took 0.193s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00093969 Acc: 0.9634233\n",
      "val Loss: 0.00037141 Acc: 0.96261682\n",
      "Epoch 20 of 500 took 0.244s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00095192 Acc: 0.96235795\n",
      "val Loss: 0.00035120 Acc: 0.95638629\n",
      "Epoch 21 of 500 took 0.222s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00098235 Acc: 0.95987216\n",
      "val Loss: 0.00042828 Acc: 0.93146417\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 22 of 500 took 0.191s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00086701 Acc: 0.96377841\n",
      "val Loss: 0.00024213 Acc: 0.97507788\n",
      "New best validation loss: 0.00024212518492220346\n",
      "Epoch 23 of 500 took 0.219s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00081217 Acc: 0.96519886\n",
      "val Loss: 0.00031980 Acc: 0.96884735\n",
      "Epoch 24 of 500 took 0.231s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00090887 Acc: 0.96484375\n",
      "val Loss: 0.00017986 Acc: 0.98130841\n",
      "New best validation loss: 0.0001798569227676154\n",
      "Epoch 25 of 500 took 0.193s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00085004 Acc: 0.9662642\n",
      "val Loss: 0.00019789 Acc: 0.97507788\n",
      "Epoch 26 of 500 took 0.210s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00084426 Acc: 0.96875\n",
      "val Loss: 0.00018024 Acc: 0.98442368\n",
      "Epoch 27 of 500 took 0.246s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00079787 Acc: 0.96839489\n",
      "val Loss: 0.00018827 Acc: 0.97819315\n",
      "Epoch 28 of 500 took 0.222s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00087867 Acc: 0.96661932\n",
      "val Loss: 0.00028023 Acc: 0.96261682\n",
      "Epoch 29 of 500 took 0.191s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00074967 Acc: 0.97194602\n",
      "val Loss: 0.00023451 Acc: 0.96884735\n",
      "Epoch 30 of 500 took 0.196s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00082283 Acc: 0.96910511\n",
      "val Loss: 0.00023911 Acc: 0.97507788\n",
      "Epoch    31: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 31 of 500 took 0.226s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00079219 Acc: 0.97265625\n",
      "val Loss: 0.00017177 Acc: 0.98130841\n",
      "New best validation loss: 0.00017177175463545732\n",
      "Epoch 32 of 500 took 0.229s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00088530 Acc: 0.96661932\n",
      "val Loss: 0.00023179 Acc: 0.96573209\n",
      "Epoch 33 of 500 took 0.209s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00088332 Acc: 0.96661932\n",
      "val Loss: 0.00023460 Acc: 0.97196262\n",
      "Epoch 34 of 500 took 0.198s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00072066 Acc: 0.97301136\n",
      "val Loss: 0.00020468 Acc: 0.97819315\n",
      "Epoch 35 of 500 took 0.194s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00077475 Acc: 0.96981534\n",
      "val Loss: 0.00017191 Acc: 0.98130841\n",
      "Epoch 36 of 500 took 0.220s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00074127 Acc: 0.97514205\n",
      "val Loss: 0.00013568 Acc: 0.98130841\n",
      "New best validation loss: 0.00013568057356593764\n",
      "Epoch 37 of 500 took 0.217s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00086389 Acc: 0.96164773\n",
      "val Loss: 0.00014712 Acc: 0.98130841\n",
      "Epoch 38 of 500 took 0.202s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00071329 Acc: 0.97443182\n",
      "val Loss: 0.00018228 Acc: 0.98130841\n",
      "Epoch 39 of 500 took 0.193s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00077460 Acc: 0.96661932\n",
      "val Loss: 0.00018190 Acc: 0.98442368\n",
      "Epoch 40 of 500 took 0.195s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00076059 Acc: 0.97088068\n",
      "val Loss: 0.00019080 Acc: 0.98130841\n",
      "Epoch 41 of 500 took 0.191s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00077363 Acc: 0.96910511\n",
      "val Loss: 0.00018117 Acc: 0.98130841\n",
      "Epoch 42 of 500 took 0.200s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00077085 Acc: 0.97088068\n",
      "val Loss: 0.00024190 Acc: 0.96573209\n",
      "Epoch    43: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 43 of 500 took 0.214s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00077853 Acc: 0.97372159\n",
      "val Loss: 0.00017025 Acc: 0.98130841\n",
      "Epoch 44 of 500 took 0.218s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00082900 Acc: 0.96875\n",
      "val Loss: 0.00017191 Acc: 0.98442368\n",
      "Epoch 45 of 500 took 0.211s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00069955 Acc: 0.9712358\n",
      "val Loss: 0.00018890 Acc: 0.97196262\n",
      "Epoch 46 of 500 took 0.245s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00070539 Acc: 0.97372159\n",
      "val Loss: 0.00017976 Acc: 0.98130841\n",
      "Epoch 47 of 500 took 0.210s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00081250 Acc: 0.96875\n",
      "val Loss: 0.00016504 Acc: 0.97507788\n",
      "Epoch 48 of 500 took 0.193s\n",
      "\n",
      "Training complete in 0m 10s\n",
      "Best val loss: 0.000136\n"
     ]
    }
   ],
   "source": [
    "train_Spectrogram_fine_tuning(examples_datasets_train, labels_datasets_train, filter_size=None,\n",
    "                              num_kernels=filter_size, number_of_cycle_for_first_training=4,\n",
    "                              number_of_cycles_rest_of_training=4, path_weight_to_save_to=path_to_save_to,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_classes,\n",
    "                              batch_size=128, spectrogram_model=False,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1902, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1928, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  0  Accuracy:  1.0\n",
      "Participant:  0  Accuracy:  0.5534709193245778\n",
      "Participant:  0  Accuracy:  0.6231203007518797\n",
      "Participant:  0  Accuracy:  0.12698412698412698\n",
      "ACCURACY PARTICIPANT:  [1.0, 0.5534709193245778, 0.6231203007518797, 0.12698412698412698]\n",
      "[1.         0.55347092 0.6231203  0.12698413]\n",
      "[1.0, 0.5534709193245778, 0.6231203007518797, 0.12698412698412698]\n",
      "OVERALL ACCURACY: 0.5758938367651462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "test_TSD_DNN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=filter_size, use_only_first_training=True,\n",
    "                                  path_weights=path_to_save_to,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  algo_name=algo_name, gestures_to_remove=gestures_to_remove,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553471</td>\n",
       "      <td>0.62312</td>\n",
       "      <td>0.126984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0        1.0   0.553471    0.62312   0.126984"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "TSD_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    TSD_acc[i] = acc\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Domain Adverserial Neural Network (DANN)\n",
    "* 2 domians : source(0) and target(1) (output_domain includes 2 features)\n",
    "    * source / validation: labeled; first training\n",
    "    * target: unlabeled; others\n",
    "    * train using one source and one target\n",
    "* start training using TSD_DNN model params \n",
    "* DANN loss (domain_loss_weight=1e-1)\n",
    "    * loss_domain_source = crossEntropyLoss(pred_domain_source, label_source_domain)\n",
    "    * loss_main_source = (0.5 * loss_source_class + domain_loss_weight * loss_domain_source)\n",
    "    * loss_domain_target = 0.5 * (crossEntropyLoss(pred_domain_target, label_target_domain))\n",
    "    * loss_domain_target = 0.5 * domain_loss_weight * loss_domain_target\n",
    "    * loss_main = loss_main_source + loss_domain_target\n",
    "    * loss_domain = loss_domain_source + loss_domain_target\n",
    "   \n",
    "### Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD\n",
    "    * beat_state_n.pt (n = # training session)\n",
    "        * epoch: #epochs\n",
    "        * model state_dict\n",
    "        * optimizer state_dict\n",
    "        * scheduler state_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.TrainingsAndEvaluations.ForTrainingSessions.TSD_DNN.train_tsd_dnn_standard import \\\n",
    "    test_TSD_DNN_on_training_sessions\n",
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import train_DA_spectrograms\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm. \\\n",
    "    load_dataset_spectrogram_in_dataloader import load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.utils_training_and_evaluation import create_confusion_matrix, \\\n",
    "    long_term_classification_graph, long_term_pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from train_tsd_dnn_DA import test_network_DA_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [200, 200, 200]\n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = [5, 6, 9, 10]\n",
    "gestures_to_remove = None\n",
    "number_of_class = 11\n",
    "number_of_cycle_for_first_training = 4\n",
    "number_of_cycles_rest_of_training = 4\n",
    "learning_rate = 0.002515\n",
    "\n",
    "path_weights_fine_tuning = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "algo_name = \"DANN_THREE_CYCLES_11Gestures_TSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2816, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2835, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2864, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2888, 385)\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.980114, main loss classifier 0.122786, source classification loss 0.064545, loss domain distinction 0.649101, accuracy domain distinction 0.509411\n",
      "VALIDATION Loss: 0.18664561 Acc: 0.93610224\n",
      "New best validation loss:  0.18664561212062836\n",
      "Epoch 1 of 500 took 0.554s\n",
      "Accuracy source 0.985795, main loss classifier 0.106923, source classification loss 0.053308, loss domain distinction 0.467732, accuracy domain distinction 0.496626\n",
      "VALIDATION Loss: 0.17620555 Acc: 0.94888179\n",
      "New best validation loss:  0.17620554566383362\n",
      "Epoch 2 of 500 took 0.459s\n",
      "Accuracy source 0.984020, main loss classifier 0.103389, source classification loss 0.054271, loss domain distinction 0.362303, accuracy domain distinction 0.493075\n",
      "VALIDATION Loss: 0.31597662 Acc: 0.89456869\n",
      "Epoch 3 of 500 took 0.479s\n",
      "Accuracy source 0.984375, main loss classifier 0.103649, source classification loss 0.058511, loss domain distinction 0.302477, accuracy domain distinction 0.490589\n",
      "VALIDATION Loss: 0.24536805 Acc: 0.91373802\n",
      "Epoch 4 of 500 took 0.422s\n",
      "Accuracy source 0.985085, main loss classifier 0.102371, source classification loss 0.057126, loss domain distinction 0.261849, accuracy domain distinction 0.493963\n",
      "VALIDATION Loss: 0.31601694 Acc: 0.89456869\n",
      "Epoch 5 of 500 took 0.431s\n",
      "Accuracy source 0.982955, main loss classifier 0.105098, source classification loss 0.062511, loss domain distinction 0.237530, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 0.25028208 Acc: 0.92332268\n",
      "Epoch    46: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 6 of 500 took 0.428s\n",
      "Accuracy source 0.987926, main loss classifier 0.097387, source classification loss 0.048463, loss domain distinction 0.227015, accuracy domain distinction 0.495206\n",
      "VALIDATION Loss: 0.23170836 Acc: 0.92332268\n",
      "Epoch 7 of 500 took 0.461s\n",
      "Accuracy source 0.986506, main loss classifier 0.100935, source classification loss 0.054283, loss domain distinction 0.227240, accuracy domain distinction 0.493430\n",
      "VALIDATION Loss: 0.20717263 Acc: 0.93610224\n",
      "Epoch 8 of 500 took 0.461s\n",
      "Accuracy source 0.987571, main loss classifier 0.096842, source classification loss 0.046575, loss domain distinction 0.221439, accuracy domain distinction 0.496271\n",
      "VALIDATION Loss: 0.24313527 Acc: 0.92971246\n",
      "Epoch 9 of 500 took 0.496s\n",
      "Accuracy source 0.989347, main loss classifier 0.095744, source classification loss 0.045643, loss domain distinction 0.223104, accuracy domain distinction 0.495206\n",
      "VALIDATION Loss: 0.28286171 Acc: 0.91373802\n",
      "Epoch 10 of 500 took 0.468s\n",
      "Accuracy source 0.982599, main loss classifier 0.099884, source classification loss 0.053156, loss domain distinction 0.217988, accuracy domain distinction 0.496449\n",
      "VALIDATION Loss: 0.20058320 Acc: 0.93929712\n",
      "Epoch 11 of 500 took 0.441s\n",
      "Accuracy source 0.983665, main loss classifier 0.102363, source classification loss 0.058027, loss domain distinction 0.212382, accuracy domain distinction 0.496626\n",
      "VALIDATION Loss: 0.41631365 Acc: 0.85942492\n",
      "Epoch    52: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 12 of 500 took 0.466s\n",
      "Accuracy source 0.984020, main loss classifier 0.101082, source classification loss 0.055546, loss domain distinction 0.213532, accuracy domain distinction 0.498047\n",
      "VALIDATION Loss: 0.26638746 Acc: 0.91373802\n",
      "Training complete in 0m 6s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.984375, main loss classifier 0.120771, source classification loss 0.060026, loss domain distinction 0.653925, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 0.30377841 Acc: 0.8913738\n",
      "New best validation loss:  0.30377840995788574\n",
      "Epoch 1 of 500 took 0.486s\n",
      "Accuracy source 0.983665, main loss classifier 0.108261, source classification loss 0.054762, loss domain distinction 0.471054, accuracy domain distinction 0.489702\n",
      "VALIDATION Loss: 0.22052653 Acc: 0.93290735\n",
      "New best validation loss:  0.2205265313386917\n",
      "Epoch 2 of 500 took 0.425s\n",
      "Accuracy source 0.983310, main loss classifier 0.103891, source classification loss 0.055297, loss domain distinction 0.366693, accuracy domain distinction 0.493608\n",
      "VALIDATION Loss: 0.25127441 Acc: 0.91373802\n",
      "Epoch 3 of 500 took 0.430s\n",
      "Accuracy source 0.985440, main loss classifier 0.101039, source classification loss 0.052777, loss domain distinction 0.302303, accuracy domain distinction 0.494673\n",
      "VALIDATION Loss: 0.17399973 Acc: 0.94888179\n",
      "New best validation loss:  0.17399972677230835\n",
      "Epoch 4 of 500 took 0.419s\n",
      "Accuracy source 0.982244, main loss classifier 0.102990, source classification loss 0.058898, loss domain distinction 0.258014, accuracy domain distinction 0.494141\n",
      "VALIDATION Loss: 0.13177608 Acc: 0.96166134\n",
      "New best validation loss:  0.13177607953548431\n",
      "Epoch 5 of 500 took 0.426s\n",
      "Accuracy source 0.983310, main loss classifier 0.101679, source classification loss 0.055958, loss domain distinction 0.238908, accuracy domain distinction 0.498047\n",
      "VALIDATION Loss: 0.18365441 Acc: 0.94249201\n",
      "Epoch    46: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 6 of 500 took 0.490s\n",
      "Accuracy source 0.988636, main loss classifier 0.096791, source classification loss 0.046673, loss domain distinction 0.227505, accuracy domain distinction 0.497514\n",
      "VALIDATION Loss: 0.26205504 Acc: 0.9201278\n",
      "Epoch 7 of 500 took 0.581s\n",
      "Accuracy source 0.986861, main loss classifier 0.098898, source classification loss 0.050958, loss domain distinction 0.225444, accuracy domain distinction 0.493963\n",
      "VALIDATION Loss: 0.23811199 Acc: 0.9201278\n",
      "Epoch 8 of 500 took 0.568s\n",
      "Accuracy source 0.987571, main loss classifier 0.098084, source classification loss 0.048829, loss domain distinction 0.221806, accuracy domain distinction 0.497159\n",
      "VALIDATION Loss: 0.23302843 Acc: 0.92332268\n",
      "Epoch 9 of 500 took 1.037s\n",
      "Accuracy source 0.984730, main loss classifier 0.098327, source classification loss 0.050975, loss domain distinction 0.215114, accuracy domain distinction 0.497869\n",
      "VALIDATION Loss: 0.20182148 Acc: 0.94249201\n",
      "Epoch 10 of 500 took 0.771s\n",
      "Accuracy source 0.987571, main loss classifier 0.096206, source classification loss 0.045624, loss domain distinction 0.215722, accuracy domain distinction 0.498402\n",
      "VALIDATION Loss: 0.20761849 Acc: 0.93290735\n",
      "Epoch 11 of 500 took 0.523s\n",
      "Accuracy source 0.985440, main loss classifier 0.097660, source classification loss 0.049767, loss domain distinction 0.208874, accuracy domain distinction 0.500888\n",
      "VALIDATION Loss: 0.25006595 Acc: 0.92332268\n",
      "Epoch    52: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 12 of 500 took 0.516s\n",
      "Accuracy source 0.979759, main loss classifier 0.102993, source classification loss 0.060577, loss domain distinction 0.210754, accuracy domain distinction 0.499467\n",
      "VALIDATION Loss: 0.27499673 Acc: 0.9201278\n",
      "Epoch 13 of 500 took 0.508s\n",
      "Accuracy source 0.986861, main loss classifier 0.098024, source classification loss 0.050170, loss domain distinction 0.210110, accuracy domain distinction 0.498402\n",
      "VALIDATION Loss: 0.20124017 Acc: 0.9456869\n",
      "Epoch 14 of 500 took 0.426s\n",
      "Accuracy source 0.980469, main loss classifier 0.105267, source classification loss 0.064168, loss domain distinction 0.213192, accuracy domain distinction 0.498757\n",
      "VALIDATION Loss: 0.15652132 Acc: 0.95207668\n",
      "Epoch 15 of 500 took 0.428s\n",
      "Accuracy source 0.987216, main loss classifier 0.099206, source classification loss 0.052569, loss domain distinction 0.209030, accuracy domain distinction 0.500533\n",
      "VALIDATION Loss: 0.21921654 Acc: 0.92971246\n",
      "Training complete in 0m 8s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.981889, main loss classifier 0.122399, source classification loss 0.064333, loss domain distinction 0.651821, accuracy domain distinction 0.499645\n",
      "VALIDATION Loss: 3.04311466 Acc: 0.52396166\n",
      "New best validation loss:  3.04311466217041\n",
      "Epoch 1 of 500 took 0.522s\n",
      "Accuracy source 0.981889, main loss classifier 0.109937, source classification loss 0.060501, loss domain distinction 0.465061, accuracy domain distinction 0.482777\n",
      "VALIDATION Loss: 2.75684834 Acc: 0.55271565\n",
      "New best validation loss:  2.7568483352661133\n",
      "Epoch 2 of 500 took 0.539s\n",
      "Accuracy source 0.983665, main loss classifier 0.105362, source classification loss 0.058815, loss domain distinction 0.366539, accuracy domain distinction 0.483132\n",
      "VALIDATION Loss: 2.74442387 Acc: 0.55271565\n",
      "New best validation loss:  2.7444238662719727\n",
      "Epoch 3 of 500 took 0.544s\n",
      "Accuracy source 0.986506, main loss classifier 0.100053, source classification loss 0.051117, loss domain distinction 0.300737, accuracy domain distinction 0.479403\n",
      "VALIDATION Loss: 2.65849638 Acc: 0.56549521\n",
      "New best validation loss:  2.658496379852295\n",
      "Epoch 4 of 500 took 0.556s\n",
      "Accuracy source 0.987216, main loss classifier 0.099895, source classification loss 0.052314, loss domain distinction 0.261929, accuracy domain distinction 0.485440\n",
      "VALIDATION Loss: 3.29605293 Acc: 0.51757188\n",
      "Epoch 5 of 500 took 0.593s\n",
      "Accuracy source 0.981534, main loss classifier 0.106308, source classification loss 0.065244, loss domain distinction 0.241076, accuracy domain distinction 0.487393\n",
      "VALIDATION Loss: 2.44282579 Acc: 0.56549521\n",
      "Epoch    46: reducing learning rate of group 0 to 2.0120e-05.\n",
      "New best validation loss:  2.4428257942199707\n",
      "Epoch 6 of 500 took 0.878s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.985440, main loss classifier 0.099132, source classification loss 0.049485, loss domain distinction 0.232702, accuracy domain distinction 0.488459\n",
      "VALIDATION Loss: 2.64014244 Acc: 0.57188498\n",
      "Epoch 7 of 500 took 0.671s\n",
      "Accuracy source 0.985440, main loss classifier 0.101740, source classification loss 0.055618, loss domain distinction 0.226259, accuracy domain distinction 0.490589\n",
      "VALIDATION Loss: 3.46765566 Acc: 0.51757188\n",
      "Epoch 8 of 500 took 0.599s\n",
      "Accuracy source 0.982955, main loss classifier 0.102261, source classification loss 0.057143, loss domain distinction 0.218917, accuracy domain distinction 0.495206\n",
      "VALIDATION Loss: 2.64769125 Acc: 0.55910543\n",
      "Epoch 9 of 500 took 0.450s\n",
      "Accuracy source 0.985795, main loss classifier 0.099729, source classification loss 0.053336, loss domain distinction 0.216214, accuracy domain distinction 0.495561\n",
      "VALIDATION Loss: 2.76676226 Acc: 0.54952077\n",
      "Epoch 10 of 500 took 0.418s\n",
      "Accuracy source 0.984020, main loss classifier 0.099183, source classification loss 0.052424, loss domain distinction 0.215075, accuracy domain distinction 0.494496\n",
      "VALIDATION Loss: 2.43703604 Acc: 0.58146965\n",
      "New best validation loss:  2.4370360374450684\n",
      "Epoch 11 of 500 took 0.413s\n",
      "Accuracy source 0.986861, main loss classifier 0.097818, source classification loss 0.047209, loss domain distinction 0.216706, accuracy domain distinction 0.495206\n",
      "VALIDATION Loss: 2.63465881 Acc: 0.55910543\n",
      "Epoch    52: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 12 of 500 took 0.422s\n",
      "Accuracy source 0.983665, main loss classifier 0.101736, source classification loss 0.057157, loss domain distinction 0.209490, accuracy domain distinction 0.495028\n",
      "VALIDATION Loss: 2.61549735 Acc: 0.5686901\n",
      "Epoch 13 of 500 took 0.436s\n",
      "Accuracy source 0.987926, main loss classifier 0.098596, source classification loss 0.049994, loss domain distinction 0.214394, accuracy domain distinction 0.493786\n",
      "VALIDATION Loss: 2.60689521 Acc: 0.55591054\n",
      "Epoch 14 of 500 took 0.510s\n",
      "Accuracy source 0.985440, main loss classifier 0.098975, source classification loss 0.051140, loss domain distinction 0.210954, accuracy domain distinction 0.494141\n",
      "VALIDATION Loss: 2.95008874 Acc: 0.53354633\n",
      "Epoch 15 of 500 took 0.468s\n",
      "Accuracy source 0.989347, main loss classifier 0.096407, source classification loss 0.046398, loss domain distinction 0.209733, accuracy domain distinction 0.495206\n",
      "VALIDATION Loss: 2.92856359 Acc: 0.52715655\n",
      "Epoch 16 of 500 took 0.430s\n",
      "Accuracy source 0.984730, main loss classifier 0.101302, source classification loss 0.054825, loss domain distinction 0.212615, accuracy domain distinction 0.493075\n",
      "VALIDATION Loss: 2.78505087 Acc: 0.56549521\n",
      "Epoch 17 of 500 took 0.579s\n",
      "Accuracy source 0.984020, main loss classifier 0.100441, source classification loss 0.054178, loss domain distinction 0.210072, accuracy domain distinction 0.496271\n",
      "VALIDATION Loss: 3.03776526 Acc: 0.54313099\n",
      "Epoch    58: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 18 of 500 took 0.464s\n",
      "Accuracy source 0.990057, main loss classifier 0.096598, source classification loss 0.046634, loss domain distinction 0.210504, accuracy domain distinction 0.494318\n",
      "VALIDATION Loss: 2.79538345 Acc: 0.56230032\n",
      "Epoch 19 of 500 took 0.504s\n",
      "Accuracy source 0.985440, main loss classifier 0.098336, source classification loss 0.050675, loss domain distinction 0.209301, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 3.42587948 Acc: 0.52076677\n",
      "Epoch 20 of 500 took 0.436s\n",
      "Accuracy source 0.981889, main loss classifier 0.102805, source classification loss 0.059691, loss domain distinction 0.209277, accuracy domain distinction 0.494496\n",
      "VALIDATION Loss: 3.15251017 Acc: 0.53035144\n",
      "Epoch 21 of 500 took 0.472s\n",
      "Accuracy source 0.984730, main loss classifier 0.100377, source classification loss 0.054740, loss domain distinction 0.206232, accuracy domain distinction 0.496982\n",
      "VALIDATION Loss: 2.62998104 Acc: 0.55591054\n",
      "Training complete in 0m 11s\n"
     ]
    }
   ],
   "source": [
    "train_DA_spectrograms(examples_datasets_train, labels_datasets_train, filter_size=None,\n",
    "                      num_kernels=num_neurons, algo_name=algo_name,\n",
    "                      path_weights_fine_tuning=path_weights_fine_tuning,\n",
    "                      gestures_to_remove=gestures_to_remove, number_of_classes=number_of_class,\n",
    "                      number_of_cycle_for_first_training=number_of_cycle_for_first_training,\n",
    "                      number_of_cycles_rest_of_training=number_of_cycles_rest_of_training,\n",
    "                      batch_size=128, spectrogram_model=False,\n",
    "                      feature_vector_input_length=feature_vector_input_length,\n",
    "                      path_weights_to_save_to=\"Weights_TSD/weights_\", learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1902, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1928, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  0  Session ID:  0  Accuracy:  1.0\n",
      "Participant ID:  0  Session ID:  1  Accuracy:  0.7795497185741088\n",
      "Participant ID:  0  Session ID:  2  Accuracy:  0.8618421052631579\n",
      "Participant ID:  0  Session ID:  3  Accuracy:  0.19047619047619047\n",
      "ACCURACY PARTICIPANT:  [1.0, 0.7795497185741088, 0.8618421052631579, 0.19047619047619047]\n",
      "[1.         0.77954972 0.86184211 0.19047619]\n",
      "[1.0, 0.7795497185741088, 0.8618421052631579, 0.19047619047619047]\n",
      "OVERALL ACCURACY: 0.7079670035783643\n"
     ]
    }
   ],
   "source": [
    "np.warnings.filterwarnings('error', category=np.VisibleDeprecationWarning)   \n",
    "test_network_DA_algorithm(examples_datasets_train, labels_datasets_train,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              num_neurons=num_neurons, path_weights_DA='Weights_TSD/weights_' + algo_name,\n",
    "                              algo_name=algo_name,\n",
    "                              path_weights_normal=path_weights_fine_tuning,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_class,\n",
    "                              cycle_to_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.77955</td>\n",
       "      <td>0.861842</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0        1.0    0.77955   0.861842   0.190476"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "DANN_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    DANN_acc[i] = acc\n",
    "DANN_acc_overall = np.mean(DANN_acc)\n",
    "DANN_df = pd.DataFrame(DANN_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "DANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"DANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCADANN\n",
    "* start training using TSD_DNN model params for the first training seesion, then using DANN model params \n",
    "* first traning = labeled, others = pseudo labels \n",
    "    * train using one lebaled and n psuedo labeled (n = #session)\n",
    "* use all training data at once\n",
    "* pseudo_labels_heuristic\n",
    "    * window_stable_mode_length = 30 (hold stable for 1.5s)\n",
    "    * percentage_same_gesture_now_stable = 65% (remove examples that are likely to generate false pseudo labels)\n",
    "    * maximum_length_instability_gesture_transition = 40\n",
    "    * maximum_length_instability_same_gesture = 40 (remove examples that are unstable for more than 2s)\n",
    "* SCADANN loss (domain_loss_weight=1e-1)\n",
    "    * loss_domain_source = ((1 - alpha) * crossEntropyLoss(pred_domain_source, label_source_domain))\n",
    "    * loss_main_source = (0.5 * loss_source_class + domain_loss_weight * loss_domain_source)\n",
    "    * loss_domain_target = 0.5 * (crossEntropyLoss(pred_domain_target, label_target_domain))\n",
    "    * loss_main_target = (0.5 * loss_target_class + domain_loss_weight * loss_domain_target)\n",
    "    * loss_main = loss_main_source + loss_main_target\n",
    "    * loss_domain = loss_domain_source + loss_domain_target\n",
    "\n",
    "   \n",
    "\n",
    "### Weights_TSD/weights_THREE_CYCLES_11Gestures_SCADANN\n",
    "* beat_state_n.pt (n = # training session)\n",
    "    * epoch: #epochs\n",
    "    * model state_dict\n",
    "    * optimizer state_dict\n",
    "    * scheduler state_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import load_checkpoint\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm.load_dataset_spectrogram_in_dataloader import \\\n",
    "    load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.self_learning.self_learning_utils import \\\n",
    "    generate_dataloaders_for_SCADANN\n",
    "from LongTermClassificationMain.Models.model_training_self_learning import SCADANN_BN_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from SCADANN_TSD_DNN_training_session import run_SCADANN_training_sessions, test_network_SLADANN\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [200, 200, 200]\n",
    "learning_rate = 0.002515\n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = None\n",
    "number_of_classes = 11\n",
    "percentage_same_gesture_stable = 0.65  # 0.65 for 11 gestures, 0.85 for 7 gestures\n",
    "path_weight_to_save_to = \"Weights_TSD/weights_THREE_CYCLES_11Gestures_SCADANN\"\n",
    "path_weights_start_with = \"Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD\"\n",
    "path_weights_Normal_training = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "algo_name = \"SCADANN_THREE_CYCLES_11Gestures_TSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (3129, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3150, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3183, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3209, 385)\n",
      "participants_train =  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f577d5813c0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 2)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  0.6888888888888889   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4948453608247423   AFTER:  1.0  len before:  97   len after:  40\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9888888888888889   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.7216494845360825   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.898876404494382   AFTER:  1.0  len before:  89   len after:  89\n",
      "BEFORE:  0.8181818181818182   AFTER:  1.0  len before:  88   len after:  88\n",
      "BEFORE:  0.6082474226804123   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8735632183908046   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.7340425531914894   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.17525773195876287   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6907216494845361   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.21649484536082475   AFTER:  0.04054054054054054  len before:  97   len after:  74\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5520833333333334   AFTER:  1.0  len before:  96   len after:  72\n",
      "ACCURACY MODEL:  0.8034920634920635   Accuracy pseudo: 0.9521563342318059  len pseudo:  2968    len predictions 3150\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.899704, main loss classifier 0.472300, source accuracy 0.970439 source classification loss 0.081142, target accuracy 0.828970 target loss 0.627177 accuracy domain distinction 0.491343 loss domain distinction 1.181401,\n",
      "VALIDATION Loss: 0.66029191 Acc: 0.81313131\n",
      "New best validation loss:  0.6602919071912765\n",
      "Epoch 2 of 500 took 0.789s\n",
      "Accuracy total 0.916385, main loss classifier 0.400567, source accuracy 0.972128 source classification loss 0.087906, target accuracy 0.860642 target loss 0.483285 accuracy domain distinction 0.490498 loss domain distinction 1.149722,\n",
      "VALIDATION Loss: 0.32318812 Acc: 0.90909091\n",
      "New best validation loss:  0.323188117146492\n",
      "Epoch 3 of 500 took 0.885s\n",
      "Accuracy total 0.925253, main loss classifier 0.392625, source accuracy 0.971284 source classification loss 0.090581, target accuracy 0.879223 target loss 0.467344 accuracy domain distinction 0.491554 loss domain distinction 1.136619,\n",
      "VALIDATION Loss: 0.22981162 Acc: 0.92760943\n",
      "New best validation loss:  0.22981162257492543\n",
      "Epoch 4 of 500 took 0.938s\n",
      "Accuracy total 0.925887, main loss classifier 0.367665, source accuracy 0.969595 source classification loss 0.095308, target accuracy 0.882179 target loss 0.419631 accuracy domain distinction 0.501267 loss domain distinction 1.101953,\n",
      "VALIDATION Loss: 0.29748657 Acc: 0.92255892\n",
      "Epoch 5 of 500 took 0.892s\n",
      "Accuracy total 0.929265, main loss classifier 0.346808, source accuracy 0.977196 source classification loss 0.083226, target accuracy 0.881334 target loss 0.391719 accuracy domain distinction 0.500422 loss domain distinction 1.093354,\n",
      "VALIDATION Loss: 0.22466087 Acc: 0.93771044\n",
      "New best validation loss:  0.22466086633503438\n",
      "Epoch 6 of 500 took 1.114s\n",
      "Accuracy total 0.936444, main loss classifier 0.338896, source accuracy 0.976351 source classification loss 0.088273, target accuracy 0.896537 target loss 0.371490 accuracy domain distinction 0.499578 loss domain distinction 1.090147,\n",
      "VALIDATION Loss: 0.26732181 Acc: 0.92255892\n",
      "Epoch 7 of 500 took 0.899s\n",
      "Accuracy total 0.938133, main loss classifier 0.328243, source accuracy 0.976774 source classification loss 0.082556, target accuracy 0.899493 target loss 0.355701 accuracy domain distinction 0.498522 loss domain distinction 1.091153,\n",
      "VALIDATION Loss: 0.22077216 Acc: 0.93939394\n",
      "New best validation loss:  0.22077216245234013\n",
      "Epoch 8 of 500 took 0.719s\n",
      "Accuracy total 0.930321, main loss classifier 0.343616, source accuracy 0.970439 source classification loss 0.097502, target accuracy 0.890203 target loss 0.372719 accuracy domain distinction 0.499367 loss domain distinction 1.085053,\n",
      "VALIDATION Loss: 0.18691830 Acc: 0.94781145\n",
      "New best validation loss:  0.18691830039024354\n",
      "Epoch 9 of 500 took 0.764s\n",
      "Accuracy total 0.926520, main loss classifier 0.341368, source accuracy 0.970439 source classification loss 0.091556, target accuracy 0.882601 target loss 0.377027 accuracy domain distinction 0.499578 loss domain distinction 1.070763,\n",
      "VALIDATION Loss: 0.19800641 Acc: 0.93939394\n",
      "Epoch 10 of 500 took 0.847s\n",
      "Accuracy total 0.933910, main loss classifier 0.331523, source accuracy 0.971284 source classification loss 0.101952, target accuracy 0.896537 target loss 0.345311 accuracy domain distinction 0.500211 loss domain distinction 1.078907,\n",
      "VALIDATION Loss: 0.19391023 Acc: 0.94612795\n",
      "Epoch 11 of 500 took 0.739s\n",
      "Accuracy total 0.948057, main loss classifier 0.294921, source accuracy 0.980574 source classification loss 0.070605, target accuracy 0.915541 target loss 0.303318 accuracy domain distinction 0.498522 loss domain distinction 1.079596,\n",
      "VALIDATION Loss: 0.21167298 Acc: 0.93939394\n",
      "Epoch 12 of 500 took 0.671s\n",
      "Accuracy total 0.937922, main loss classifier 0.316685, source accuracy 0.970439 source classification loss 0.097751, target accuracy 0.905405 target loss 0.320717 accuracy domain distinction 0.498311 loss domain distinction 1.074507,\n",
      "VALIDATION Loss: 0.16487827 Acc: 0.95286195\n",
      "New best validation loss:  0.1648782655596733\n",
      "Epoch 13 of 500 took 0.698s\n",
      "Accuracy total 0.942356, main loss classifier 0.302111, source accuracy 0.975084 source classification loss 0.082928, target accuracy 0.909628 target loss 0.306232 accuracy domain distinction 0.500000 loss domain distinction 1.075309,\n",
      "VALIDATION Loss: 0.17572986 Acc: 0.94949495\n",
      "Epoch 14 of 500 took 0.990s\n",
      "Accuracy total 0.942356, main loss classifier 0.293844, source accuracy 0.973818 source classification loss 0.093675, target accuracy 0.910895 target loss 0.280767 accuracy domain distinction 0.498944 loss domain distinction 1.066237,\n",
      "VALIDATION Loss: 0.17949027 Acc: 0.95959596\n",
      "Epoch 15 of 500 took 0.908s\n",
      "Accuracy total 0.941723, main loss classifier 0.306822, source accuracy 0.975929 source classification loss 0.082980, target accuracy 0.907517 target loss 0.317184 accuracy domain distinction 0.500422 loss domain distinction 1.067402,\n",
      "VALIDATION Loss: 0.28470556 Acc: 0.91582492\n",
      "Epoch 16 of 500 took 0.673s\n",
      "Accuracy total 0.941934, main loss classifier 0.283851, source accuracy 0.975929 source classification loss 0.084370, target accuracy 0.907939 target loss 0.271008 accuracy domain distinction 0.499578 loss domain distinction 1.061621,\n",
      "VALIDATION Loss: 0.25057995 Acc: 0.92592593\n",
      "Epoch 17 of 500 took 0.678s\n",
      "Accuracy total 0.946368, main loss classifier 0.280069, source accuracy 0.982686 source classification loss 0.066338, target accuracy 0.910051 target loss 0.280876 accuracy domain distinction 0.499789 loss domain distinction 1.064618,\n",
      "VALIDATION Loss: 0.14508344 Acc: 0.95622896\n",
      "New best validation loss:  0.14508344009518623\n",
      "Epoch 18 of 500 took 0.719s\n",
      "Accuracy total 0.952703, main loss classifier 0.275823, source accuracy 0.977196 source classification loss 0.087411, target accuracy 0.928209 target loss 0.251718 accuracy domain distinction 0.498733 loss domain distinction 1.062590,\n",
      "VALIDATION Loss: 0.14474012 Acc: 0.95286195\n",
      "New best validation loss:  0.1447401169454679\n",
      "Epoch 19 of 500 took 0.706s\n",
      "Accuracy total 0.948902, main loss classifier 0.274148, source accuracy 0.978041 source classification loss 0.074734, target accuracy 0.919764 target loss 0.261262 accuracy domain distinction 0.499578 loss domain distinction 1.061502,\n",
      "VALIDATION Loss: 0.20380185 Acc: 0.93602694\n",
      "Epoch 20 of 500 took 0.667s\n",
      "Accuracy total 0.948902, main loss classifier 0.285625, source accuracy 0.978041 source classification loss 0.077966, target accuracy 0.919764 target loss 0.281218 accuracy domain distinction 0.500211 loss domain distinction 1.060330,\n",
      "VALIDATION Loss: 0.24524235 Acc: 0.94276094\n",
      "Epoch 21 of 500 took 0.680s\n",
      "Accuracy total 0.952492, main loss classifier 0.269781, source accuracy 0.976774 source classification loss 0.081346, target accuracy 0.928209 target loss 0.246457 accuracy domain distinction 0.500422 loss domain distinction 1.058794,\n",
      "VALIDATION Loss: 0.12710687 Acc: 0.95117845\n",
      "New best validation loss:  0.1271068733651191\n",
      "Epoch 22 of 500 took 0.677s\n",
      "Accuracy total 0.946791, main loss classifier 0.275877, source accuracy 0.974662 source classification loss 0.086132, target accuracy 0.918919 target loss 0.254433 accuracy domain distinction 0.500211 loss domain distinction 1.055942,\n",
      "VALIDATION Loss: 0.32347008 Acc: 0.90572391\n",
      "Epoch 23 of 500 took 0.692s\n",
      "Accuracy total 0.946157, main loss classifier 0.279341, source accuracy 0.971284 source classification loss 0.095936, target accuracy 0.921030 target loss 0.252070 accuracy domain distinction 0.499789 loss domain distinction 1.053379,\n",
      "VALIDATION Loss: 0.18963160 Acc: 0.94444444\n",
      "Epoch 24 of 500 took 0.695s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.952492, main loss classifier 0.263632, source accuracy 0.977196 source classification loss 0.078843, target accuracy 0.927787 target loss 0.239389 accuracy domain distinction 0.500633 loss domain distinction 1.045166,\n",
      "VALIDATION Loss: 0.16493253 Acc: 0.94781145\n",
      "Epoch 25 of 500 took 0.733s\n",
      "Accuracy total 0.952703, main loss classifier 0.268594, source accuracy 0.978041 source classification loss 0.074694, target accuracy 0.927365 target loss 0.252279 accuracy domain distinction 0.499789 loss domain distinction 1.051072,\n",
      "VALIDATION Loss: 0.14554142 Acc: 0.94781145\n",
      "Epoch 26 of 500 took 0.655s\n",
      "Accuracy total 0.949958, main loss classifier 0.259254, source accuracy 0.978885 source classification loss 0.074205, target accuracy 0.921030 target loss 0.233960 accuracy domain distinction 0.500211 loss domain distinction 1.051716,\n",
      "VALIDATION Loss: 0.15920632 Acc: 0.95117845\n",
      "Epoch 27 of 500 took 0.665s\n",
      "Accuracy total 0.953970, main loss classifier 0.258511, source accuracy 0.974662 source classification loss 0.085458, target accuracy 0.933277 target loss 0.221992 accuracy domain distinction 0.500000 loss domain distinction 1.047857,\n",
      "VALIDATION Loss: 0.22998786 Acc: 0.93434343\n",
      "Epoch    27: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 28 of 500 took 0.651s\n",
      "Accuracy total 0.953970, main loss classifier 0.254611, source accuracy 0.978463 source classification loss 0.072371, target accuracy 0.929476 target loss 0.227753 accuracy domain distinction 0.500211 loss domain distinction 1.045490,\n",
      "VALIDATION Loss: 0.12704873 Acc: 0.96296296\n",
      "New best validation loss:  0.12704873085021973\n",
      "Epoch 29 of 500 took 0.655s\n",
      "Accuracy total 0.954392, main loss classifier 0.258528, source accuracy 0.976774 source classification loss 0.079577, target accuracy 0.932010 target loss 0.228274 accuracy domain distinction 0.500211 loss domain distinction 1.046027,\n",
      "VALIDATION Loss: 0.15269996 Acc: 0.95622896\n",
      "Epoch 30 of 500 took 0.811s\n",
      "Accuracy total 0.954181, main loss classifier 0.247602, source accuracy 0.978463 source classification loss 0.070122, target accuracy 0.929899 target loss 0.215307 accuracy domain distinction 0.500000 loss domain distinction 1.048871,\n",
      "VALIDATION Loss: 0.15644360 Acc: 0.95117845\n",
      "Epoch 31 of 500 took 0.975s\n",
      "Accuracy total 0.955659, main loss classifier 0.255002, source accuracy 0.976774 source classification loss 0.074674, target accuracy 0.934544 target loss 0.225600 accuracy domain distinction 0.500000 loss domain distinction 1.048648,\n",
      "VALIDATION Loss: 0.13292509 Acc: 0.95791246\n",
      "Epoch 32 of 500 took 0.672s\n",
      "Accuracy total 0.956292, main loss classifier 0.247702, source accuracy 0.976774 source classification loss 0.078137, target accuracy 0.935811 target loss 0.208528 accuracy domain distinction 0.500422 loss domain distinction 1.043693,\n",
      "VALIDATION Loss: 0.16098215 Acc: 0.95117845\n",
      "Epoch 33 of 500 took 0.664s\n",
      "Accuracy total 0.956081, main loss classifier 0.250765, source accuracy 0.977196 source classification loss 0.077157, target accuracy 0.934966 target loss 0.215725 accuracy domain distinction 0.499578 loss domain distinction 1.043237,\n",
      "VALIDATION Loss: 0.11285274 Acc: 0.96296296\n",
      "New best validation loss:  0.11285273786634206\n",
      "Epoch 34 of 500 took 0.656s\n",
      "Accuracy total 0.954814, main loss classifier 0.256354, source accuracy 0.980574 source classification loss 0.071915, target accuracy 0.929054 target loss 0.230971 accuracy domain distinction 0.500000 loss domain distinction 1.049111,\n",
      "VALIDATION Loss: 0.20707390 Acc: 0.94444444\n",
      "Epoch 35 of 500 took 0.682s\n",
      "Accuracy total 0.959882, main loss classifier 0.235373, source accuracy 0.979730 source classification loss 0.064621, target accuracy 0.940034 target loss 0.197114 accuracy domain distinction 0.500000 loss domain distinction 1.045056,\n",
      "VALIDATION Loss: 0.12843874 Acc: 0.95791246\n",
      "Epoch 36 of 500 took 0.987s\n",
      "Accuracy total 0.957348, main loss classifier 0.246664, source accuracy 0.979730 source classification loss 0.068881, target accuracy 0.934966 target loss 0.215412 accuracy domain distinction 0.499789 loss domain distinction 1.045173,\n",
      "VALIDATION Loss: 0.17788834 Acc: 0.95622896\n",
      "Epoch 37 of 500 took 0.900s\n",
      "Accuracy total 0.956292, main loss classifier 0.245371, source accuracy 0.981419 source classification loss 0.061242, target accuracy 0.931166 target loss 0.220332 accuracy domain distinction 0.500000 loss domain distinction 1.045840,\n",
      "VALIDATION Loss: 0.19012050 Acc: 0.94781145\n",
      "Epoch 38 of 500 took 0.745s\n",
      "Accuracy total 0.956926, main loss classifier 0.249450, source accuracy 0.982264 source classification loss 0.062272, target accuracy 0.931588 target loss 0.228379 accuracy domain distinction 0.500000 loss domain distinction 1.041241,\n",
      "VALIDATION Loss: 0.19947483 Acc: 0.94949495\n",
      "Epoch 39 of 500 took 0.695s\n",
      "Accuracy total 0.960515, main loss classifier 0.238691, source accuracy 0.981419 source classification loss 0.063678, target accuracy 0.939611 target loss 0.203380 accuracy domain distinction 0.499789 loss domain distinction 1.051619,\n",
      "VALIDATION Loss: 0.19598593 Acc: 0.93771044\n",
      "Epoch    39: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 40 of 500 took 0.653s\n",
      "Accuracy total 0.958404, main loss classifier 0.243553, source accuracy 0.983530 source classification loss 0.066196, target accuracy 0.933277 target loss 0.211683 accuracy domain distinction 0.500422 loss domain distinction 1.046132,\n",
      "VALIDATION Loss: 0.15973553 Acc: 0.95959596\n",
      "Epoch 41 of 500 took 0.673s\n",
      "Accuracy total 0.960726, main loss classifier 0.237798, source accuracy 0.980997 source classification loss 0.065682, target accuracy 0.940456 target loss 0.200487 accuracy domain distinction 0.500000 loss domain distinction 1.047132,\n",
      "VALIDATION Loss: 0.15514352 Acc: 0.95286195\n",
      "Epoch 42 of 500 took 0.645s\n",
      "Accuracy total 0.956926, main loss classifier 0.243416, source accuracy 0.979307 source classification loss 0.069518, target accuracy 0.934544 target loss 0.208284 accuracy domain distinction 0.500000 loss domain distinction 1.045148,\n",
      "VALIDATION Loss: 0.18204440 Acc: 0.94781145\n",
      "Epoch 43 of 500 took 0.669s\n",
      "Accuracy total 0.960304, main loss classifier 0.237799, source accuracy 0.985642 source classification loss 0.057977, target accuracy 0.934966 target loss 0.208755 accuracy domain distinction 0.500000 loss domain distinction 1.044330,\n",
      "VALIDATION Loss: 0.14775915 Acc: 0.95622896\n",
      "Epoch 44 of 500 took 0.715s\n",
      "Accuracy total 0.955659, main loss classifier 0.251372, source accuracy 0.978885 source classification loss 0.072260, target accuracy 0.932432 target loss 0.221080 accuracy domain distinction 0.500211 loss domain distinction 1.047021,\n",
      "VALIDATION Loss: 0.13552588 Acc: 0.96464646\n",
      "Epoch 45 of 500 took 0.715s\n",
      "Training complete in 0m 33s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f577d5813c0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 5)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 5)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  0.6888888888888889   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4948453608247423   AFTER:  1.0  len before:  97   len after:  40\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9888888888888889   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.7216494845360825   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.898876404494382   AFTER:  1.0  len before:  89   len after:  89\n",
      "BEFORE:  0.8181818181818182   AFTER:  1.0  len before:  88   len after:  88\n",
      "BEFORE:  0.6082474226804123   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8735632183908046   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.7340425531914894   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.17525773195876287   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6907216494845361   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.21649484536082475   AFTER:  0.04054054054054054  len before:  97   len after:  74\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5520833333333334   AFTER:  1.0  len before:  96   len after:  72\n",
      "ACCURACY MODEL:  0.8034920634920635   Accuracy pseudo: 0.9521563342318059  len pseudo:  2968    len predictions 3150\n",
      "HANDLING NEW SESSION  2\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5979381443298969   AFTER:  1.0  len before:  97   len after:  45\n",
      "BEFORE:  0.23711340206185566   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7553191489361702   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8350515463917526   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8191489361702128   AFTER:  1.0  len before:  94   len after:  68\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6185567010309279   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6914893617021277   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6185567010309279   AFTER:  1.0  len before:  97   len after:  71\n",
      "ACCURACY MODEL:  0.8586239396795476   Accuracy pseudo: 0.989093387866394  len pseudo:  2934    len predictions 3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Accuracy total 0.877821, main loss classifier 0.564166, source accuracy 0.886285 source classification loss 0.421422, target accuracy 0.869358 target loss 0.461008 accuracy domain distinction 0.496094 loss domain distinction 1.229514,\n",
      "VALIDATION Loss: 0.19306063 Acc: 0.9318569\n",
      "New best validation loss:  0.19306062683463096\n",
      "Epoch 2 of 500 took 0.635s\n",
      "Accuracy total 0.891059, main loss classifier 0.481872, source accuracy 0.900174 source classification loss 0.347020, target accuracy 0.881944 target loss 0.385178 accuracy domain distinction 0.494575 loss domain distinction 1.157732,\n",
      "VALIDATION Loss: 0.15311742 Acc: 0.94889267\n",
      "New best validation loss:  0.15311742201447487\n",
      "Epoch 3 of 500 took 0.630s\n",
      "Accuracy total 0.909288, main loss classifier 0.431671, source accuracy 0.912326 source classification loss 0.306245, target accuracy 0.906250 target loss 0.332864 accuracy domain distinction 0.500434 loss domain distinction 1.121166,\n",
      "VALIDATION Loss: 0.36549686 Acc: 0.87052811\n",
      "Epoch 4 of 500 took 0.627s\n",
      "Accuracy total 0.913411, main loss classifier 0.407023, source accuracy 0.926215 source classification loss 0.266367, target accuracy 0.900608 target loss 0.325597 accuracy domain distinction 0.498915 loss domain distinction 1.110414,\n",
      "VALIDATION Loss: 0.29721470 Acc: 0.92333901\n",
      "Epoch 5 of 500 took 0.637s\n",
      "Accuracy total 0.916233, main loss classifier 0.396643, source accuracy 0.920139 source classification loss 0.280040, target accuracy 0.912326 target loss 0.294516 accuracy domain distinction 0.500000 loss domain distinction 1.093645,\n",
      "VALIDATION Loss: 0.17819305 Acc: 0.9318569\n",
      "Epoch 6 of 500 took 0.633s\n",
      "Accuracy total 0.915365, main loss classifier 0.375827, source accuracy 0.925347 source classification loss 0.230336, target accuracy 0.905382 target loss 0.303534 accuracy domain distinction 0.499132 loss domain distinction 1.088918,\n",
      "VALIDATION Loss: 0.15068676 Acc: 0.9471891\n",
      "New best validation loss:  0.15068675577640533\n",
      "Epoch 7 of 500 took 0.629s\n",
      "Accuracy total 0.917535, main loss classifier 0.382480, source accuracy 0.922743 source classification loss 0.267197, target accuracy 0.912326 target loss 0.278091 accuracy domain distinction 0.500651 loss domain distinction 1.098356,\n",
      "VALIDATION Loss: 0.11135971 Acc: 0.96252129\n",
      "New best validation loss:  0.11135971434414386\n",
      "Epoch 8 of 500 took 0.637s\n",
      "Accuracy total 0.920790, main loss classifier 0.374840, source accuracy 0.927951 source classification loss 0.263213, target accuracy 0.913628 target loss 0.268530 accuracy domain distinction 0.500000 loss domain distinction 1.089681,\n",
      "VALIDATION Loss: 0.16685259 Acc: 0.93015332\n",
      "Epoch 9 of 500 took 0.628s\n",
      "Accuracy total 0.925564, main loss classifier 0.345538, source accuracy 0.934028 source classification loss 0.222797, target accuracy 0.917101 target loss 0.253500 accuracy domain distinction 0.501953 loss domain distinction 1.073893,\n",
      "VALIDATION Loss: 0.10464251 Acc: 0.95400341\n",
      "New best validation loss:  0.10464251295197755\n",
      "Epoch 10 of 500 took 0.626s\n",
      "Accuracy total 0.926432, main loss classifier 0.354610, source accuracy 0.926215 source classification loss 0.256053, target accuracy 0.926649 target loss 0.237730 accuracy domain distinction 0.499132 loss domain distinction 1.077187,\n",
      "VALIDATION Loss: 0.12183974 Acc: 0.96081772\n",
      "Epoch 11 of 500 took 0.624s\n",
      "Accuracy total 0.926215, main loss classifier 0.350722, source accuracy 0.931424 source classification loss 0.234429, target accuracy 0.921007 target loss 0.252836 accuracy domain distinction 0.499349 loss domain distinction 1.070899,\n",
      "VALIDATION Loss: 0.10217750 Acc: 0.96763203\n",
      "New best validation loss:  0.10217750016599894\n",
      "Epoch 12 of 500 took 0.627s\n",
      "Accuracy total 0.929253, main loss classifier 0.343022, source accuracy 0.929253 source classification loss 0.236379, target accuracy 0.929253 target loss 0.235377 accuracy domain distinction 0.498698 loss domain distinction 1.071442,\n",
      "VALIDATION Loss: 0.37757464 Acc: 0.86541738\n",
      "Epoch 13 of 500 took 0.628s\n",
      "Accuracy total 0.930773, main loss classifier 0.330481, source accuracy 0.937066 source classification loss 0.222116, target accuracy 0.924479 target loss 0.225967 accuracy domain distinction 0.498264 loss domain distinction 1.064397,\n",
      "VALIDATION Loss: 0.08613457 Acc: 0.96763203\n",
      "New best validation loss:  0.08613456767052412\n",
      "Epoch 14 of 500 took 0.659s\n",
      "Accuracy total 0.935113, main loss classifier 0.321893, source accuracy 0.934462 source classification loss 0.219518, target accuracy 0.935764 target loss 0.210493 accuracy domain distinction 0.500217 loss domain distinction 1.068875,\n",
      "VALIDATION Loss: 0.11186528 Acc: 0.95741056\n",
      "Epoch 15 of 500 took 0.682s\n",
      "Accuracy total 0.930773, main loss classifier 0.335023, source accuracy 0.928819 source classification loss 0.238875, target accuracy 0.932726 target loss 0.217811 accuracy domain distinction 0.500651 loss domain distinction 1.066806,\n",
      "VALIDATION Loss: 0.14630464 Acc: 0.94037479\n",
      "Epoch 16 of 500 took 0.701s\n",
      "Accuracy total 0.931424, main loss classifier 0.319919, source accuracy 0.935764 source classification loss 0.204130, target accuracy 0.927083 target loss 0.222512 accuracy domain distinction 0.500217 loss domain distinction 1.065978,\n",
      "VALIDATION Loss: 0.11697851 Acc: 0.95400341\n",
      "Epoch 17 of 500 took 0.704s\n",
      "Accuracy total 0.929036, main loss classifier 0.317968, source accuracy 0.930990 source classification loss 0.211578, target accuracy 0.927083 target loss 0.211405 accuracy domain distinction 0.499783 loss domain distinction 1.064759,\n",
      "VALIDATION Loss: 0.21049988 Acc: 0.95059625\n",
      "Epoch 18 of 500 took 0.649s\n",
      "Accuracy total 0.931641, main loss classifier 0.323955, source accuracy 0.933160 source classification loss 0.218853, target accuracy 0.930122 target loss 0.215965 accuracy domain distinction 0.498698 loss domain distinction 1.065462,\n",
      "VALIDATION Loss: 0.17426982 Acc: 0.9318569\n",
      "Epoch 19 of 500 took 0.630s\n",
      "Accuracy total 0.938368, main loss classifier 0.307533, source accuracy 0.945747 source classification loss 0.198243, target accuracy 0.930990 target loss 0.204617 accuracy domain distinction 0.500434 loss domain distinction 1.061031,\n",
      "VALIDATION Loss: 0.25850737 Acc: 0.92163543\n",
      "Epoch    19: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 20 of 500 took 0.628s\n",
      "Accuracy total 0.943793, main loss classifier 0.300503, source accuracy 0.949653 source classification loss 0.184186, target accuracy 0.937934 target loss 0.205446 accuracy domain distinction 0.500217 loss domain distinction 1.056874,\n",
      "VALIDATION Loss: 0.11248372 Acc: 0.96081772\n",
      "Epoch 21 of 500 took 0.641s\n",
      "Accuracy total 0.937283, main loss classifier 0.311841, source accuracy 0.937066 source classification loss 0.208897, target accuracy 0.937500 target loss 0.204930 accuracy domain distinction 0.500434 loss domain distinction 1.049273,\n",
      "VALIDATION Loss: 0.11107201 Acc: 0.96252129\n",
      "Epoch 22 of 500 took 0.650s\n",
      "Accuracy total 0.942491, main loss classifier 0.288268, source accuracy 0.945312 source classification loss 0.183000, target accuracy 0.939670 target loss 0.181949 accuracy domain distinction 0.499566 loss domain distinction 1.057937,\n",
      "VALIDATION Loss: 0.11355294 Acc: 0.96592845\n",
      "Epoch 23 of 500 took 0.632s\n",
      "Accuracy total 0.941406, main loss classifier 0.298520, source accuracy 0.940538 source classification loss 0.196722, target accuracy 0.942274 target loss 0.190430 accuracy domain distinction 0.499566 loss domain distinction 1.049441,\n",
      "VALIDATION Loss: 0.09273747 Acc: 0.96422487\n",
      "Epoch 24 of 500 took 0.656s\n",
      "Accuracy total 0.938368, main loss classifier 0.309831, source accuracy 0.942708 source classification loss 0.204275, target accuracy 0.934028 target loss 0.205858 accuracy domain distinction 0.499349 loss domain distinction 1.047640,\n",
      "VALIDATION Loss: 0.15360438 Acc: 0.95400341\n",
      "Epoch 25 of 500 took 0.637s\n",
      "Training complete in 0m 15s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f5771de0820>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt' (epoch 11)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 40)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 5)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt' (epoch 11)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  0.6888888888888889   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4948453608247423   AFTER:  1.0  len before:  97   len after:  40\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9888888888888889   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.7216494845360825   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.898876404494382   AFTER:  1.0  len before:  89   len after:  89\n",
      "BEFORE:  0.8181818181818182   AFTER:  1.0  len before:  88   len after:  88\n",
      "BEFORE:  0.6082474226804123   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8735632183908046   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.7340425531914894   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.17525773195876287   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6907216494845361   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.21649484536082475   AFTER:  0.04054054054054054  len before:  97   len after:  74\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5520833333333334   AFTER:  1.0  len before:  96   len after:  72\n",
      "ACCURACY MODEL:  0.8034920634920635   Accuracy pseudo: 0.9521563342318059  len pseudo:  2968    len predictions 3150\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5979381443298969   AFTER:  1.0  len before:  97   len after:  45\n",
      "BEFORE:  0.23711340206185566   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7553191489361702   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8350515463917526   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8191489361702128   AFTER:  1.0  len before:  94   len after:  68\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6185567010309279   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6914893617021277   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6185567010309279   AFTER:  1.0  len before:  97   len after:  71\n",
      "ACCURACY MODEL:  0.8586239396795476   Accuracy pseudo: 0.989093387866394  len pseudo:  2934    len predictions 3183\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  54\n",
      "BEFORE:  0.12371134020618557   AFTER:  0.0  len before:  97   len after:  42\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  70\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.061855670103092786   AFTER:  0.0  len before:  97   len after:  68\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.17525773195876287   AFTER:  0.0  len before:  97   len after:  30\n",
      "BEFORE:  0.32989690721649484   AFTER:  0.43478260869565216  len before:  97   len after:  69\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  36\n",
      "BEFORE:  0.41237113402061853   AFTER:  0.6701030927835051  len before:  97   len after:  97\n",
      "BEFORE:  0.13402061855670103   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.05154639175257732   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.25773195876288657   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.6804123711340206   AFTER:  0.5733333333333334  len before:  97   len after:  75\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.07216494845360824   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0297029702970297   AFTER:  0.0  len before:  101   len after:  1\n",
      "ACCURACY MODEL:  0.213773761296354   Accuracy pseudo: 0.23823910228744066  len pseudo:  2317    len predictions 3209\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.715960, main loss classifier 1.237211, source accuracy 0.832589 source classification loss 0.609576, target accuracy 0.599330 target loss 1.606303 accuracy domain distinction 0.494420 loss domain distinction 1.292709,\n",
      "VALIDATION Loss: 1.19433960 Acc: 0.68318966\n",
      "New best validation loss:  1.1943396031856537\n",
      "Epoch 2 of 500 took 0.497s\n",
      "Accuracy total 0.753069, main loss classifier 1.104366, source accuracy 0.853237 source classification loss 0.536080, target accuracy 0.652902 target loss 1.420331 accuracy domain distinction 0.498047 loss domain distinction 1.261607,\n",
      "VALIDATION Loss: 1.16468670 Acc: 0.69612069\n",
      "New best validation loss:  1.1646867021918297\n",
      "Epoch 3 of 500 took 0.484s\n",
      "Accuracy total 0.765067, main loss classifier 1.010251, source accuracy 0.867746 source classification loss 0.442825, target accuracy 0.662388 target loss 1.329710 accuracy domain distinction 0.496652 loss domain distinction 1.239833,\n",
      "VALIDATION Loss: 0.98252404 Acc: 0.73491379\n",
      "New best validation loss:  0.9825240354984999\n",
      "Epoch 4 of 500 took 0.490s\n",
      "Accuracy total 0.769531, main loss classifier 1.014580, source accuracy 0.861607 source classification loss 0.485976, target accuracy 0.677455 target loss 1.298176 accuracy domain distinction 0.494141 loss domain distinction 1.225045,\n",
      "VALIDATION Loss: 1.05302504 Acc: 0.70905172\n",
      "Epoch 5 of 500 took 0.487s\n",
      "Accuracy total 0.778181, main loss classifier 0.925089, source accuracy 0.873326 source classification loss 0.418452, target accuracy 0.683036 target loss 1.190755 accuracy domain distinction 0.495815 loss domain distinction 1.204851,\n",
      "VALIDATION Loss: 0.88480467 Acc: 0.75646552\n",
      "New best validation loss:  0.8848046660423279\n",
      "Epoch 6 of 500 took 0.509s\n",
      "Accuracy total 0.772879, main loss classifier 0.955100, source accuracy 0.858817 source classification loss 0.468474, target accuracy 0.686942 target loss 1.204867 accuracy domain distinction 0.496931 loss domain distinction 1.184291,\n",
      "VALIDATION Loss: 1.00239967 Acc: 0.72198276\n",
      "Epoch 7 of 500 took 0.579s\n",
      "Accuracy total 0.783761, main loss classifier 0.940996, source accuracy 0.869978 source classification loss 0.447606, target accuracy 0.697545 target loss 1.200213 accuracy domain distinction 0.498605 loss domain distinction 1.170866,\n",
      "VALIDATION Loss: 0.88862373 Acc: 0.76724138\n",
      "Epoch 8 of 500 took 0.492s\n",
      "Accuracy total 0.792969, main loss classifier 0.882472, source accuracy 0.869420 source classification loss 0.408116, target accuracy 0.716518 target loss 1.123418 accuracy domain distinction 0.498326 loss domain distinction 1.167052,\n",
      "VALIDATION Loss: 0.78462069 Acc: 0.78663793\n",
      "New best validation loss:  0.7846206873655319\n",
      "Epoch 9 of 500 took 0.491s\n",
      "Accuracy total 0.793806, main loss classifier 0.903119, source accuracy 0.877790 source classification loss 0.456934, target accuracy 0.709821 target loss 1.117565 accuracy domain distinction 0.496652 loss domain distinction 1.158697,\n",
      "VALIDATION Loss: 0.83298770 Acc: 0.74137931\n",
      "Epoch 10 of 500 took 0.548s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.791853, main loss classifier 0.868067, source accuracy 0.877790 source classification loss 0.448067, target accuracy 0.705915 target loss 1.059247 accuracy domain distinction 0.494141 loss domain distinction 1.144099,\n",
      "VALIDATION Loss: 0.77908929 Acc: 0.75646552\n",
      "New best validation loss:  0.7790892943739891\n",
      "Epoch 11 of 500 took 0.523s\n",
      "Accuracy total 0.800781, main loss classifier 0.861652, source accuracy 0.879464 source classification loss 0.426907, target accuracy 0.722098 target loss 1.066853 accuracy domain distinction 0.497489 loss domain distinction 1.147723,\n",
      "VALIDATION Loss: 0.76153905 Acc: 0.77155172\n",
      "New best validation loss:  0.7615390494465828\n",
      "Epoch 12 of 500 took 0.577s\n",
      "Accuracy total 0.801618, main loss classifier 0.851810, source accuracy 0.883371 source classification loss 0.409146, target accuracy 0.719866 target loss 1.066704 accuracy domain distinction 0.497210 loss domain distinction 1.138846,\n",
      "VALIDATION Loss: 0.90338019 Acc: 0.76724138\n",
      "Epoch 13 of 500 took 0.511s\n",
      "Accuracy total 0.792969, main loss classifier 0.876298, source accuracy 0.880022 source classification loss 0.416995, target accuracy 0.705915 target loss 1.109381 accuracy domain distinction 0.495536 loss domain distinction 1.131098,\n",
      "VALIDATION Loss: 1.02695017 Acc: 0.73491379\n",
      "Epoch 14 of 500 took 0.522s\n",
      "Accuracy total 0.812221, main loss classifier 0.793613, source accuracy 0.896763 source classification loss 0.351810, target accuracy 0.727679 target loss 1.008778 accuracy domain distinction 0.493304 loss domain distinction 1.133185,\n",
      "VALIDATION Loss: 0.81966243 Acc: 0.77155172\n",
      "Epoch 15 of 500 took 0.523s\n",
      "Accuracy total 0.804967, main loss classifier 0.812392, source accuracy 0.893415 source classification loss 0.355589, target accuracy 0.716518 target loss 1.046394 accuracy domain distinction 0.497489 loss domain distinction 1.114013,\n",
      "VALIDATION Loss: 0.84011088 Acc: 0.75646552\n",
      "Epoch 16 of 500 took 0.498s\n",
      "Accuracy total 0.811384, main loss classifier 0.822910, source accuracy 0.881138 source classification loss 0.419946, target accuracy 0.741629 target loss 1.002083 accuracy domain distinction 0.498884 loss domain distinction 1.118957,\n",
      "VALIDATION Loss: 0.90617619 Acc: 0.77155172\n",
      "Epoch 17 of 500 took 0.483s\n",
      "Accuracy total 0.807757, main loss classifier 0.814753, source accuracy 0.881696 source classification loss 0.393784, target accuracy 0.733817 target loss 1.011461 accuracy domain distinction 0.497489 loss domain distinction 1.121310,\n",
      "VALIDATION Loss: 0.94623467 Acc: 0.72198276\n",
      "Epoch    17: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 18 of 500 took 0.496s\n",
      "Accuracy total 0.812779, main loss classifier 0.794579, source accuracy 0.895089 source classification loss 0.397821, target accuracy 0.730469 target loss 0.966851 accuracy domain distinction 0.498605 loss domain distinction 1.122436,\n",
      "VALIDATION Loss: 0.81564935 Acc: 0.79094828\n",
      "Epoch 19 of 500 took 0.496s\n",
      "Accuracy total 0.807478, main loss classifier 0.800534, source accuracy 0.886719 source classification loss 0.390406, target accuracy 0.728237 target loss 0.986981 accuracy domain distinction 0.499721 loss domain distinction 1.118402,\n",
      "VALIDATION Loss: 0.70819129 Acc: 0.83405172\n",
      "New best validation loss:  0.7081912904977798\n",
      "Epoch 20 of 500 took 0.522s\n",
      "Accuracy total 0.810547, main loss classifier 0.777754, source accuracy 0.888393 source classification loss 0.410247, target accuracy 0.732701 target loss 0.922513 accuracy domain distinction 0.498884 loss domain distinction 1.113739,\n",
      "VALIDATION Loss: 0.72300246 Acc: 0.75862069\n",
      "Epoch 21 of 500 took 0.764s\n",
      "Accuracy total 0.805525, main loss classifier 0.814365, source accuracy 0.875000 source classification loss 0.445101, target accuracy 0.736049 target loss 0.957866 accuracy domain distinction 0.497210 loss domain distinction 1.128816,\n",
      "VALIDATION Loss: 0.72438548 Acc: 0.81896552\n",
      "Epoch 22 of 500 took 0.807s\n",
      "Accuracy total 0.806362, main loss classifier 0.808089, source accuracy 0.882254 source classification loss 0.406470, target accuracy 0.730469 target loss 0.986252 accuracy domain distinction 0.498326 loss domain distinction 1.117283,\n",
      "VALIDATION Loss: 0.82642483 Acc: 0.75862069\n",
      "Epoch 23 of 500 took 0.723s\n",
      "Accuracy total 0.803571, main loss classifier 0.821723, source accuracy 0.885603 source classification loss 0.409924, target accuracy 0.721540 target loss 1.012101 accuracy domain distinction 0.498326 loss domain distinction 1.107101,\n",
      "VALIDATION Loss: 0.75942310 Acc: 0.80387931\n",
      "Epoch 24 of 500 took 0.762s\n",
      "Accuracy total 0.801897, main loss classifier 0.818064, source accuracy 0.887835 source classification loss 0.398645, target accuracy 0.715960 target loss 1.015448 accuracy domain distinction 0.497768 loss domain distinction 1.110176,\n",
      "VALIDATION Loss: 0.87277840 Acc: 0.77155172\n",
      "Epoch 25 of 500 took 0.726s\n",
      "Accuracy total 0.809989, main loss classifier 0.795549, source accuracy 0.893415 source classification loss 0.380050, target accuracy 0.726562 target loss 0.987798 accuracy domain distinction 0.500558 loss domain distinction 1.116249,\n",
      "VALIDATION Loss: 1.11388585 Acc: 0.70474138\n",
      "Epoch    25: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 26 of 500 took 0.590s\n",
      "Accuracy total 0.805525, main loss classifier 0.781785, source accuracy 0.885045 source classification loss 0.392393, target accuracy 0.726004 target loss 0.948486 accuracy domain distinction 0.499721 loss domain distinction 1.113454,\n",
      "VALIDATION Loss: 0.73313268 Acc: 0.77801724\n",
      "Epoch 27 of 500 took 0.504s\n",
      "Accuracy total 0.813616, main loss classifier 0.805830, source accuracy 0.892857 source classification loss 0.401015, target accuracy 0.734375 target loss 0.989611 accuracy domain distinction 0.500558 loss domain distinction 1.105174,\n",
      "VALIDATION Loss: 0.68625107 Acc: 0.79956897\n",
      "New best validation loss:  0.6862510740756989\n",
      "Epoch 28 of 500 took 0.567s\n",
      "Accuracy total 0.808036, main loss classifier 0.784879, source accuracy 0.878906 source classification loss 0.388371, target accuracy 0.737165 target loss 0.958254 accuracy domain distinction 0.501116 loss domain distinction 1.115668,\n",
      "VALIDATION Loss: 0.97465664 Acc: 0.70905172\n",
      "Epoch 29 of 500 took 0.506s\n",
      "Accuracy total 0.811384, main loss classifier 0.788582, source accuracy 0.887277 source classification loss 0.381551, target accuracy 0.735491 target loss 0.971771 accuracy domain distinction 0.496931 loss domain distinction 1.119208,\n",
      "VALIDATION Loss: 0.86464738 Acc: 0.76077586\n",
      "Epoch 30 of 500 took 0.495s\n",
      "Accuracy total 0.809431, main loss classifier 0.779024, source accuracy 0.886719 source classification loss 0.424487, target accuracy 0.732143 target loss 0.911041 accuracy domain distinction 0.499442 loss domain distinction 1.112605,\n",
      "VALIDATION Loss: 0.73318773 Acc: 0.79525862\n",
      "Epoch 31 of 500 took 0.556s\n",
      "Accuracy total 0.812779, main loss classifier 0.775861, source accuracy 0.882254 source classification loss 0.394316, target accuracy 0.743304 target loss 0.935789 accuracy domain distinction 0.499163 loss domain distinction 1.108085,\n",
      "VALIDATION Loss: 0.69473530 Acc: 0.78232759\n",
      "Epoch 32 of 500 took 0.528s\n",
      "Accuracy total 0.799944, main loss classifier 0.839906, source accuracy 0.880580 source classification loss 0.433257, target accuracy 0.719308 target loss 1.025347 accuracy domain distinction 0.498605 loss domain distinction 1.106039,\n",
      "VALIDATION Loss: 0.85589470 Acc: 0.76508621\n",
      "Epoch 33 of 500 took 0.662s\n",
      "Accuracy total 0.820033, main loss classifier 0.771288, source accuracy 0.893415 source classification loss 0.378898, target accuracy 0.746652 target loss 0.943674 accuracy domain distinction 0.500558 loss domain distinction 1.100023,\n",
      "VALIDATION Loss: 0.70103764 Acc: 0.82327586\n",
      "Epoch    33: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 34 of 500 took 0.633s\n",
      "Accuracy total 0.815569, main loss classifier 0.766673, source accuracy 0.888951 source classification loss 0.391639, target accuracy 0.742188 target loss 0.918661 accuracy domain distinction 0.500279 loss domain distinction 1.115223,\n",
      "VALIDATION Loss: 0.72042569 Acc: 0.78663793\n",
      "Epoch 35 of 500 took 0.597s\n",
      "Accuracy total 0.797712, main loss classifier 0.848212, source accuracy 0.871652 source classification loss 0.431226, target accuracy 0.723772 target loss 1.043455 accuracy domain distinction 0.497768 loss domain distinction 1.108713,\n",
      "VALIDATION Loss: 0.83448229 Acc: 0.79956897\n",
      "Epoch 36 of 500 took 0.634s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.816127, main loss classifier 0.778852, source accuracy 0.890067 source classification loss 0.386054, target accuracy 0.742188 target loss 0.948935 accuracy domain distinction 0.497768 loss domain distinction 1.113572,\n",
      "VALIDATION Loss: 0.87083895 Acc: 0.74784483\n",
      "Epoch 37 of 500 took 0.642s\n",
      "Accuracy total 0.805246, main loss classifier 0.839343, source accuracy 0.882254 source classification loss 0.456307, target accuracy 0.728237 target loss 1.000353 accuracy domain distinction 0.496652 loss domain distinction 1.110124,\n",
      "VALIDATION Loss: 0.75519289 Acc: 0.81681034\n",
      "Epoch 38 of 500 took 0.624s\n",
      "Accuracy total 0.810268, main loss classifier 0.781016, source accuracy 0.890625 source classification loss 0.385105, target accuracy 0.729911 target loss 0.956714 accuracy domain distinction 0.498884 loss domain distinction 1.101059,\n",
      "VALIDATION Loss: 0.76555854 Acc: 0.84051724\n",
      "Epoch 39 of 500 took 0.580s\n",
      "Training complete in 0m 22s\n",
      "['participant_1', 'participant_2', 'participant_0']\n"
     ]
    }
   ],
   "source": [
    "run_SCADANN_training_sessions(examples_datasets=examples_datasets_train, labels_datasets=labels_datasets_train,\n",
    "                              num_neurons=num_neurons, feature_vector_input_length=feature_vector_input_length,\n",
    "                              path_weights_to_save_to=path_weight_to_save_to,\n",
    "                              path_weights_Adversarial_training=path_weights_start_with,\n",
    "                              path_weights_Normal_training=path_weights_Normal_training,\n",
    "                              number_of_cycle_for_first_training=4, number_of_cycles_rest_of_training=4,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_classes,\n",
    "                              learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1902, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1928, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  0  Accuracy:  1.0\n",
      "Participant:  0  Accuracy:  0.8874296435272045\n",
      "Participant:  0  Accuracy:  0.9605263157894737\n",
      "Participant:  0  Accuracy:  0.16433239962651727\n",
      "ACCURACY PARTICIPANT:  [1.0, 0.8874296435272045, 0.9605263157894737, 0.16433239962651727]\n",
      "[1.    0.887 0.961 0.164]\n",
      "[1.0, 0.8874296435272045, 0.9605263157894737, 0.16433239962651727]\n",
      "OVERALL ACCURACY: 0.7530720897357989\n"
     ]
    }
   ],
   "source": [
    "path_weights_normal_training = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "test_network_SLADANN(examples_datasets_train=examples_datasets_train, labels_datasets_train=labels_datasets_train,\n",
    "                     num_neurons=num_neurons, feature_vector_input_length=feature_vector_input_length,\n",
    "                     path_weights_ASR=path_weight_to_save_to, path_weights_normal=path_weights_normal_training,\n",
    "                     algo_name=algo_name, cycle_test=3, gestures_to_remove=gestures_to_remove,\n",
    "                     number_of_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.88743</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.164332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0        1.0    0.88743   0.960526   0.164332"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "SCADANN_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    SCADANN_acc[i] = acc\n",
    "SCADANN_acc_overall = np.mean(SCADANN_acc)\n",
    "SCADANN_df = pd.DataFrame(SCADANN_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "SCADANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SCADANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"SCADANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSD</th>\n",
       "      <td>0.575894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.707967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCADANN</th>\n",
       "      <td>0.753072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Overall_Acc\n",
       "TSD         0.575894\n",
       "DANN        0.707967\n",
       "SCADANN     0.753072"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc_df = pd.DataFrame([TSD_acc_overall, DANN_acc_overall, SCADANN_acc_overall],\n",
    "                             index = [\"TSD\", \"DANN\", \"SCADANN\"],\n",
    "                             columns = [\"Overall_Acc\"])\n",
    "overall_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14,14))\n",
    "acc_list = [TSD_df, DANN_df, SCADANN_df, overall_acc_df]\n",
    "title_list = [\"TSD\", \"DANN\", \"SCADANN\", \"Overall\"]\n",
    "for idx, ax in enumerate(axes.reshape(-1)): \n",
    "    acc_list[idx].transpose().plot.bar(ax = ax, rot=0)\n",
    "    ax.set_title(title_list[idx])\n",
    "    ax.set_ylim([0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for 2_only dataset:   \n",
    "* result from STD -> DANN -> SCADANN  \n",
    "    * 10.0 -> 17.9 -> 16.0\n",
    "    * 17.2 -> 17.9 -> 16.9\n",
    "    * 14.3 -> 16.5 -> 14.6\n",
    "    * 12.7 -> 19.0 -> 16.4\n",
    "* maybe this is just a bad data  \n",
    "* percentage_same_gesture_stable=0.65\n",
    "    * maybe too many unstable examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
