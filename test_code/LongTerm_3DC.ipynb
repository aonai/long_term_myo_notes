{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.insert(0,'../../LongTermEMG-master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data\n",
    "* 20 participants total (exclude 10 and 11)\n",
    "* data from 3DC armband (10 channels with 1000 Hz)\n",
    "* 150 ms frames with overlap of 100 ms; band-pass filter between 20-495 Hz using fourth-order butterworth filter\n",
    "* dataset dict\n",
    "    * examples_training\n",
    "    * labels_training\n",
    "    * training_datetimes\n",
    "    * highest_activations\n",
    "    * examples_evaluation\n",
    "    * labels_evaluation\n",
    "    * evaluation_emg_timestamps\n",
    "    * angles_and_timestamps\n",
    "    * evaluation_datetimes\n",
    "* feature_set_function = feature_extraction.getTSD applied to each window \n",
    "    * exclude 0 sEMG recordings \n",
    "    * [1] A. Al-Timemy, R. N. Khushaba, G. Bugmann, and J. Escudero, \"Improving the Performance Against Force Variation of EMG Controlled Multifunctional Upper-Limb Prostheses for Transradial Amputees\", IEEE Transactions on Neural Systems and Rehabilitation Engineering, DOI: 10.1109/TNSRE.2015.2445634, 2015.\n",
    "    * [2] R. N. Khushaba, Maen Takruri, Jaime Valls Miro, and Sarath Kodagoda, \"Towards limb position invariant myoelectric pattern recognition using time-dependent spectral features\", Neural Networks, vol. 55, pp. 42-58, 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm.prepare_dataset_utils import butter_bandpass_filter, \\\n",
    "    show_filtered_signal, load_timestamps_from_participant, get_angles_from_positions_3d_arm\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longterm_dataset_3DC.zip', 'longterm_dataset_3DC', 'README.md', 'LongTermClassificationMain', 'datasets', 'TransferLearning', '.idea', 'Weights_TSD']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/PrepareAndLoadDataLongTerm\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from handcrafted_features_prepare_from_from_raw_dataset import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_participant_training_1_to_skip = [\"Participant0/Training1\", \"Participant0/Evaluation2\", \"Participant0/Evaluation3\",\n",
    "                                       \"Participant2/Training1\", \"Participant2/Evaluation2\", \"Participant2/Evaluation3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_set_name = \"TSD_features_set\"\n",
    "# feature_set_function = feature_extraction.getTSD\n",
    "# read_data_training(path=\"../../datasets/longterm_dataset_3DC\", features_set_name=features_set_name, \\\n",
    "#                 feature_set_function=feature_set_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Temporal-Spatial Descriptors Deep Network (TSD_DNN)\n",
    "* input size = 128 x 3 x 1 = 384\n",
    "* 3 fully connected layers with 200 neurons \n",
    "    * batch normalization\n",
    "    * leaky ReLU (0.1)\n",
    "    * dropout (0.5)\n",
    "* mean cross entropy loss\n",
    "* optimization = ADAM (lr = 0.002515, beta = (0.5, 0.999))\n",
    "* lr_scheduler (1e-8)\n",
    "* dataloader needs\n",
    "    * examples_training\n",
    "    * labels_training\n",
    "   \n",
    "   \n",
    "### Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\n",
    "    * best_state_n.pt (n = # training session)\n",
    "        * epoch: #epochs\n",
    "        * model state_dict\n",
    "        * optimizer state_dict\n",
    "        * scheduler state_dict \n",
    "    * fine-tune from the previous training      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import train_Spectrogram_fine_tuning\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm. \\\n",
    "    load_dataset_spectrogram_in_dataloader import load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.utils_training_and_evaluation import create_confusion_matrix, \\\n",
    "    long_term_classification_graph, long_term_pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from train_tsd_dnn_standard import test_TSD_DNN_on_training_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "\n",
    "algo_name = \"11Gestures_standard_ConvNet_THREE_Cycles_TSD\"\n",
    "path_to_save_to = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "\n",
    "filter_size = [200, 200, 200]      \n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = None\n",
    "number_of_classes = 11                          \n",
    "learning_rate = 0.002515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2674, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2829, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2881, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2821, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2970, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2859, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2837, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2783, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2816, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2888, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2864, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2835, 385)\n",
      "Participant:  0\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686d60>\n",
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.01040122 Acc: 0.61054688\n",
      "val Loss: 0.00583262 Acc: 0.40939597\n",
      "New best validation loss: 0.005832620515119309\n",
      "Epoch 1 of 500 took 0.188s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00508556 Acc: 0.81445312\n",
      "val Loss: 0.01636657 Acc: 0.22483221\n",
      "Epoch 2 of 500 took 0.173s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00393318 Acc: 0.86132812\n",
      "val Loss: 0.00403322 Acc: 0.59731544\n",
      "New best validation loss: 0.0040332178941509065\n",
      "Epoch 3 of 500 took 0.184s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00368152 Acc: 0.8609375\n",
      "val Loss: 0.01370335 Acc: 0.2147651\n",
      "Epoch 4 of 500 took 0.179s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00292674 Acc: 0.89140625\n",
      "val Loss: 0.00521586 Acc: 0.58053691\n",
      "Epoch 5 of 500 took 0.186s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00281392 Acc: 0.89882812\n",
      "val Loss: 0.01330785 Acc: 0.17785235\n",
      "Epoch 6 of 500 took 0.178s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00249873 Acc: 0.90234375\n",
      "val Loss: 0.00441098 Acc: 0.5704698\n",
      "Epoch 7 of 500 took 0.188s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00244283 Acc: 0.90898437\n",
      "val Loss: 0.00215504 Acc: 0.77181208\n",
      "New best validation loss: 0.002155039134441606\n",
      "Epoch 8 of 500 took 0.172s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00216145 Acc: 0.91992188\n",
      "val Loss: 0.00145819 Acc: 0.85234899\n",
      "New best validation loss: 0.0014581927317100884\n",
      "Epoch 9 of 500 took 0.209s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00226082 Acc: 0.91679687\n",
      "val Loss: 0.00761876 Acc: 0.64765101\n",
      "Epoch 10 of 500 took 0.231s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00202414 Acc: 0.92460937\n",
      "val Loss: 0.00714148 Acc: 0.61409396\n",
      "Epoch 11 of 500 took 0.222s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00187181 Acc: 0.92734375\n",
      "val Loss: 0.00171236 Acc: 0.8557047\n",
      "Epoch 12 of 500 took 0.240s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00174342 Acc: 0.93515625\n",
      "val Loss: 0.01006685 Acc: 0.55033557\n",
      "Epoch 13 of 500 took 0.223s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00188855 Acc: 0.9296875\n",
      "val Loss: 0.00667569 Acc: 0.51342282\n",
      "Epoch 14 of 500 took 0.217s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00192508 Acc: 0.92734375\n",
      "val Loss: 0.01509229 Acc: 0.27852349\n",
      "Epoch    15: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 15 of 500 took 0.221s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00151207 Acc: 0.946875\n",
      "val Loss: 0.00060899 Acc: 0.93288591\n",
      "New best validation loss: 0.0006089902564183178\n",
      "Epoch 16 of 500 took 0.184s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00141891 Acc: 0.94921875\n",
      "val Loss: 0.00063353 Acc: 0.93624161\n",
      "Epoch 17 of 500 took 0.197s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00119572 Acc: 0.9578125\n",
      "val Loss: 0.00054304 Acc: 0.95302013\n",
      "New best validation loss: 0.0005430432674068732\n",
      "Epoch 18 of 500 took 0.183s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00117107 Acc: 0.96015625\n",
      "val Loss: 0.00056453 Acc: 0.94630872\n",
      "Epoch 19 of 500 took 0.194s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00113319 Acc: 0.95859375\n",
      "val Loss: 0.00051999 Acc: 0.94295302\n",
      "New best validation loss: 0.0005199915210672673\n",
      "Epoch 20 of 500 took 0.170s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00106820 Acc: 0.95703125\n",
      "val Loss: 0.00051339 Acc: 0.93959732\n",
      "New best validation loss: 0.0005133884565142177\n",
      "Epoch 21 of 500 took 0.174s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00106278 Acc: 0.96445313\n",
      "val Loss: 0.00048921 Acc: 0.93959732\n",
      "New best validation loss: 0.0004892052220018118\n",
      "Epoch 22 of 500 took 0.167s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00104375 Acc: 0.96523437\n",
      "val Loss: 0.00052518 Acc: 0.94295302\n",
      "Epoch 23 of 500 took 0.181s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00104272 Acc: 0.96445313\n",
      "val Loss: 0.00061746 Acc: 0.94966443\n",
      "Epoch 24 of 500 took 0.171s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00102512 Acc: 0.96367187\n",
      "val Loss: 0.00057713 Acc: 0.94630872\n",
      "Epoch 25 of 500 took 0.179s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00103885 Acc: 0.96132812\n",
      "val Loss: 0.00112971 Acc: 0.90604027\n",
      "Epoch 26 of 500 took 0.176s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00106989 Acc: 0.96015625\n",
      "val Loss: 0.00053182 Acc: 0.94630872\n",
      "Epoch 27 of 500 took 0.185s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00082073 Acc: 0.96953125\n",
      "val Loss: 0.00084565 Acc: 0.91610738\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 28 of 500 took 0.167s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00090342 Acc: 0.96796875\n",
      "val Loss: 0.00043769 Acc: 0.95302013\n",
      "New best validation loss: 0.0004376886074975033\n",
      "Epoch 29 of 500 took 0.171s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00091633 Acc: 0.96757812\n",
      "val Loss: 0.00055551 Acc: 0.93959732\n",
      "Epoch 30 of 500 took 0.165s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00088337 Acc: 0.96835938\n",
      "val Loss: 0.00044952 Acc: 0.95973154\n",
      "Epoch 31 of 500 took 0.172s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00088564 Acc: 0.96953125\n",
      "val Loss: 0.00043888 Acc: 0.95302013\n",
      "Epoch 32 of 500 took 0.164s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00085170 Acc: 0.96914062\n",
      "val Loss: 0.00045691 Acc: 0.95302013\n",
      "Epoch 33 of 500 took 0.171s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00078970 Acc: 0.97421875\n",
      "val Loss: 0.00047455 Acc: 0.95637584\n",
      "Epoch 34 of 500 took 0.165s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00085658 Acc: 0.97265625\n",
      "val Loss: 0.00041302 Acc: 0.95637584\n",
      "New best validation loss: 0.00041301938511381213\n",
      "Epoch 35 of 500 took 0.171s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00074636 Acc: 0.971875\n",
      "val Loss: 0.00037254 Acc: 0.96979866\n",
      "New best validation loss: 0.00037253518032547613\n",
      "Epoch 36 of 500 took 0.167s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00077961 Acc: 0.97578125\n",
      "val Loss: 0.00045158 Acc: 0.95637584\n",
      "Epoch 37 of 500 took 0.172s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00085969 Acc: 0.97421875\n",
      "val Loss: 0.00042418 Acc: 0.95973154\n",
      "Epoch 38 of 500 took 0.175s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00091365 Acc: 0.965625\n",
      "val Loss: 0.00040134 Acc: 0.96308725\n",
      "Epoch 39 of 500 took 0.193s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00072500 Acc: 0.97460938\n",
      "val Loss: 0.00051119 Acc: 0.94630872\n",
      "Epoch 40 of 500 took 0.203s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00079105 Acc: 0.97460938\n",
      "val Loss: 0.00037675 Acc: 0.95973154\n",
      "Epoch 41 of 500 took 0.232s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00088663 Acc: 0.9640625\n",
      "val Loss: 0.00047422 Acc: 0.95973154\n",
      "Epoch    42: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 42 of 500 took 0.183s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00083944 Acc: 0.96601563\n",
      "val Loss: 0.00042002 Acc: 0.95302013\n",
      "Epoch 43 of 500 took 0.195s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00078926 Acc: 0.97304687\n",
      "val Loss: 0.00040654 Acc: 0.94630872\n",
      "Epoch 44 of 500 took 0.210s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00083672 Acc: 0.97109375\n",
      "val Loss: 0.00042271 Acc: 0.96308725\n",
      "Epoch 45 of 500 took 0.214s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00085009 Acc: 0.97148437\n",
      "val Loss: 0.00041635 Acc: 0.96644295\n",
      "Epoch 46 of 500 took 0.227s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00074328 Acc: 0.9734375\n",
      "val Loss: 0.00039485 Acc: 0.96644295\n",
      "Epoch 47 of 500 took 0.208s\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val loss: 0.000373\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686d60>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00468821 Acc: 0.81072443\n",
      "val Loss: 0.00904234 Acc: 0.39365079\n",
      "New best validation loss: 0.009042340233212426\n",
      "Epoch 1 of 500 took 0.232s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00300455 Acc: 0.87926136\n",
      "val Loss: 0.02243662 Acc: 0.27936508\n",
      "Epoch 2 of 500 took 0.228s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00238833 Acc: 0.89559659\n",
      "val Loss: 0.00644745 Acc: 0.55555556\n",
      "New best validation loss: 0.006447452212136889\n",
      "Epoch 3 of 500 took 0.231s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00216000 Acc: 0.91335227\n",
      "val Loss: 0.00460074 Acc: 0.63809524\n",
      "New best validation loss: 0.004600739479064942\n",
      "Epoch 4 of 500 took 0.232s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00193003 Acc: 0.92329545\n",
      "val Loss: 0.01963193 Acc: 0.35555556\n",
      "Epoch 5 of 500 took 0.212s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00191848 Acc: 0.92578125\n",
      "val Loss: 0.02435681 Acc: 0.24126984\n",
      "Epoch 6 of 500 took 0.188s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00182858 Acc: 0.9243608\n",
      "val Loss: 0.00628956 Acc: 0.56507937\n",
      "Epoch 7 of 500 took 0.188s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00177113 Acc: 0.92649148\n",
      "val Loss: 0.01104548 Acc: 0.52698413\n",
      "Epoch 8 of 500 took 0.182s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00158813 Acc: 0.93607955\n",
      "val Loss: 0.00507597 Acc: 0.5968254\n",
      "Epoch 9 of 500 took 0.186s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00167112 Acc: 0.93536932\n",
      "val Loss: 0.00190828 Acc: 0.77460317\n",
      "New best validation loss: 0.0019082775191655234\n",
      "Epoch 10 of 500 took 0.215s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00134398 Acc: 0.94424716\n",
      "val Loss: 0.00176773 Acc: 0.78095238\n",
      "New best validation loss: 0.0017677348757547046\n",
      "Epoch 11 of 500 took 0.205s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00141120 Acc: 0.93856534\n",
      "val Loss: 0.00666872 Acc: 0.60952381\n",
      "Epoch 12 of 500 took 0.184s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00122497 Acc: 0.9477983\n",
      "val Loss: 0.00185465 Acc: 0.78095238\n",
      "Epoch 13 of 500 took 0.193s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00123828 Acc: 0.94957386\n",
      "val Loss: 0.00539165 Acc: 0.66984127\n",
      "Epoch 14 of 500 took 0.236s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00112207 Acc: 0.95419034\n",
      "val Loss: 0.00525741 Acc: 0.60952381\n",
      "Epoch 15 of 500 took 0.215s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00127661 Acc: 0.94602273\n",
      "val Loss: 0.01002080 Acc: 0.47301587\n",
      "Epoch 16 of 500 took 0.235s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00124301 Acc: 0.94744318\n",
      "val Loss: 0.00308268 Acc: 0.68571429\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 17 of 500 took 0.186s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00097649 Acc: 0.95987216\n",
      "val Loss: 0.00080824 Acc: 0.88888889\n",
      "New best validation loss: 0.0008082373747749934\n",
      "Epoch 18 of 500 took 0.219s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00089440 Acc: 0.95987216\n",
      "val Loss: 0.00038257 Acc: 0.95873016\n",
      "New best validation loss: 0.0003825667831632826\n",
      "Epoch 19 of 500 took 0.250s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00081648 Acc: 0.96803977\n",
      "val Loss: 0.00106330 Acc: 0.87301587\n",
      "Epoch 20 of 500 took 0.237s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00080762 Acc: 0.96661932\n",
      "val Loss: 0.00026883 Acc: 0.97142857\n",
      "New best validation loss: 0.00026883288981422544\n",
      "Epoch 21 of 500 took 0.248s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00077279 Acc: 0.96590909\n",
      "val Loss: 0.00026683 Acc: 0.97460317\n",
      "New best validation loss: 0.0002668310015920609\n",
      "Epoch 22 of 500 took 0.249s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00080153 Acc: 0.96590909\n",
      "val Loss: 0.00046049 Acc: 0.95238095\n",
      "Epoch 23 of 500 took 0.219s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00082257 Acc: 0.96448864\n",
      "val Loss: 0.00093555 Acc: 0.9015873\n",
      "Epoch 24 of 500 took 0.213s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00079130 Acc: 0.96377841\n",
      "val Loss: 0.00027259 Acc: 0.96825397\n",
      "Epoch 25 of 500 took 0.229s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00075889 Acc: 0.97017045\n",
      "val Loss: 0.00028965 Acc: 0.96507937\n",
      "Epoch 26 of 500 took 0.202s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00068766 Acc: 0.97052557\n",
      "val Loss: 0.00035813 Acc: 0.96190476\n",
      "Epoch 27 of 500 took 0.244s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00075490 Acc: 0.96768466\n",
      "val Loss: 0.00049893 Acc: 0.93968254\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 28 of 500 took 0.210s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00065910 Acc: 0.97230114\n",
      "val Loss: 0.00025945 Acc: 0.96825397\n",
      "New best validation loss: 0.00025944778370478797\n",
      "Epoch 29 of 500 took 0.237s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00069018 Acc: 0.97088068\n",
      "val Loss: 0.00030531 Acc: 0.96825397\n",
      "Epoch 30 of 500 took 0.194s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00068812 Acc: 0.97194602\n",
      "val Loss: 0.00029751 Acc: 0.96825397\n",
      "Epoch 31 of 500 took 0.188s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00061341 Acc: 0.9740767\n",
      "val Loss: 0.00024742 Acc: 0.96825397\n",
      "New best validation loss: 0.00024742067806304445\n",
      "Epoch 32 of 500 took 0.196s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00060512 Acc: 0.9765625\n",
      "val Loss: 0.00026976 Acc: 0.96507937\n",
      "Epoch 33 of 500 took 0.203s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00063826 Acc: 0.97443182\n",
      "val Loss: 0.00023927 Acc: 0.96825397\n",
      "New best validation loss: 0.000239272155458965\n",
      "Epoch 34 of 500 took 0.187s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00066488 Acc: 0.97585227\n",
      "val Loss: 0.00025845 Acc: 0.97142857\n",
      "Epoch 35 of 500 took 0.187s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00066876 Acc: 0.97372159\n",
      "val Loss: 0.00030072 Acc: 0.97142857\n",
      "Epoch 36 of 500 took 0.181s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00063377 Acc: 0.97372159\n",
      "val Loss: 0.00027691 Acc: 0.96825397\n",
      "Epoch 37 of 500 took 0.186s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00065005 Acc: 0.9740767\n",
      "val Loss: 0.00028547 Acc: 0.96825397\n",
      "Epoch 38 of 500 took 0.192s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00069915 Acc: 0.97159091\n",
      "val Loss: 0.00027602 Acc: 0.96825397\n",
      "Epoch 39 of 500 took 0.190s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00056794 Acc: 0.97620739\n",
      "val Loss: 0.00025800 Acc: 0.97460317\n",
      "Epoch    40: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 40 of 500 took 0.182s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00059518 Acc: 0.97443182\n",
      "val Loss: 0.00024031 Acc: 0.97142857\n",
      "Epoch 41 of 500 took 0.187s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00063300 Acc: 0.97230114\n",
      "val Loss: 0.00028573 Acc: 0.96507937\n",
      "Epoch 42 of 500 took 0.181s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00061470 Acc: 0.97620739\n",
      "val Loss: 0.00024478 Acc: 0.97142857\n",
      "Epoch 43 of 500 took 0.186s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00062908 Acc: 0.97585227\n",
      "val Loss: 0.00030410 Acc: 0.96507937\n",
      "Epoch 44 of 500 took 0.183s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00061920 Acc: 0.9740767\n",
      "val Loss: 0.00022622 Acc: 0.97777778\n",
      "New best validation loss: 0.00022621613646310474\n",
      "Epoch 45 of 500 took 0.189s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00057694 Acc: 0.97514205\n",
      "val Loss: 0.00026102 Acc: 0.97460317\n",
      "Epoch 46 of 500 took 0.181s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00060698 Acc: 0.97478693\n",
      "val Loss: 0.00023802 Acc: 0.97460317\n",
      "Epoch 47 of 500 took 0.186s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00053090 Acc: 0.97975852\n",
      "val Loss: 0.00023152 Acc: 0.97460317\n",
      "Epoch 48 of 500 took 0.184s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00061902 Acc: 0.97443182\n",
      "val Loss: 0.00023976 Acc: 0.97142857\n",
      "Epoch 49 of 500 took 0.187s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00070206 Acc: 0.96981534\n",
      "val Loss: 0.00024425 Acc: 0.97777778\n",
      "Epoch 50 of 500 took 0.184s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00061631 Acc: 0.97727273\n",
      "val Loss: 0.00024876 Acc: 0.97460317\n",
      "Epoch    51: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 51 of 500 took 0.187s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.00062646 Acc: 0.97230114\n",
      "val Loss: 0.00025691 Acc: 0.97142857\n",
      "Epoch 52 of 500 took 0.181s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.00056563 Acc: 0.97691761\n",
      "val Loss: 0.00027163 Acc: 0.97460317\n",
      "Epoch 53 of 500 took 0.185s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00060449 Acc: 0.97478693\n",
      "val Loss: 0.00022552 Acc: 0.97777778\n",
      "New best validation loss: 0.00022551691721356103\n",
      "Epoch 54 of 500 took 0.189s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.00060402 Acc: 0.97301136\n",
      "val Loss: 0.00028023 Acc: 0.97142857\n",
      "Epoch 55 of 500 took 0.190s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.00055561 Acc: 0.97798295\n",
      "val Loss: 0.00024398 Acc: 0.97142857\n",
      "Epoch 56 of 500 took 0.184s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.00062981 Acc: 0.97549716\n",
      "val Loss: 0.00026233 Acc: 0.97142857\n",
      "Epoch 57 of 500 took 0.187s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.00063251 Acc: 0.97230114\n",
      "val Loss: 0.00020934 Acc: 0.98095238\n",
      "New best validation loss: 0.00020934430852768914\n",
      "Epoch 58 of 500 took 0.183s\n",
      "Epoch 58/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00060186 Acc: 0.97585227\n",
      "val Loss: 0.00023269 Acc: 0.97777778\n",
      "Epoch 59 of 500 took 0.188s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.00058635 Acc: 0.97691761\n",
      "val Loss: 0.00030730 Acc: 0.96507937\n",
      "Epoch 60 of 500 took 0.181s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.00061123 Acc: 0.97585227\n",
      "val Loss: 0.00026576 Acc: 0.97142857\n",
      "Epoch 61 of 500 took 0.186s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.00064643 Acc: 0.97265625\n",
      "val Loss: 0.00030223 Acc: 0.95873016\n",
      "Epoch 62 of 500 took 0.181s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.00060215 Acc: 0.97443182\n",
      "val Loss: 0.00027749 Acc: 0.97142857\n",
      "Epoch 63 of 500 took 0.185s\n",
      "Epoch 63/499\n",
      "----------\n",
      "train Loss: 0.00065153 Acc: 0.97194602\n",
      "val Loss: 0.00024140 Acc: 0.97142857\n",
      "Epoch    64: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 64 of 500 took 0.182s\n",
      "Epoch 64/499\n",
      "----------\n",
      "train Loss: 0.00057729 Acc: 0.9740767\n",
      "val Loss: 0.00023986 Acc: 0.97142857\n",
      "Epoch 65 of 500 took 0.187s\n",
      "Epoch 65/499\n",
      "----------\n",
      "train Loss: 0.00063646 Acc: 0.97265625\n",
      "val Loss: 0.00024495 Acc: 0.97777778\n",
      "Epoch 66 of 500 took 0.185s\n",
      "Epoch 66/499\n",
      "----------\n",
      "train Loss: 0.00064019 Acc: 0.97230114\n",
      "val Loss: 0.00026599 Acc: 0.97142857\n",
      "Epoch 67 of 500 took 0.185s\n",
      "Epoch 67/499\n",
      "----------\n",
      "train Loss: 0.00062366 Acc: 0.97230114\n",
      "val Loss: 0.00022550 Acc: 0.97142857\n",
      "Epoch 68 of 500 took 0.181s\n",
      "Epoch 68/499\n",
      "----------\n",
      "train Loss: 0.00057998 Acc: 0.97478693\n",
      "val Loss: 0.00025205 Acc: 0.96825397\n",
      "Epoch 69 of 500 took 0.186s\n",
      "\n",
      "Training complete in 0m 14s\n",
      "Best val loss: 0.000209\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_1.pt' (epoch 58)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00314744 Acc: 0.88352273\n",
      "val Loss: 0.00228066 Acc: 0.79750779\n",
      "New best validation loss: 0.002280658464936824\n",
      "Epoch 1 of 500 took 0.188s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00161691 Acc: 0.9350142\n",
      "val Loss: 0.00211622 Acc: 0.78193146\n",
      "New best validation loss: 0.0021162194626353614\n",
      "Epoch 2 of 500 took 0.187s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00121110 Acc: 0.95276989\n",
      "val Loss: 0.00435877 Acc: 0.64485981\n",
      "Epoch 3 of 500 took 0.187s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00117218 Acc: 0.95454545\n",
      "val Loss: 0.00531686 Acc: 0.74766355\n",
      "Epoch 4 of 500 took 0.182s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00089876 Acc: 0.96413352\n",
      "val Loss: 0.00353762 Acc: 0.70716511\n",
      "Epoch 5 of 500 took 0.186s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00096535 Acc: 0.96306818\n",
      "val Loss: 0.00205467 Acc: 0.77570093\n",
      "New best validation loss: 0.002054673860377612\n",
      "Epoch 6 of 500 took 0.184s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00089613 Acc: 0.9634233\n",
      "val Loss: 0.00414480 Acc: 0.76635514\n",
      "Epoch 7 of 500 took 0.190s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00079068 Acc: 0.96448864\n",
      "val Loss: 0.00213867 Acc: 0.85046729\n",
      "Epoch 8 of 500 took 0.182s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00071114 Acc: 0.97443182\n",
      "val Loss: 0.00134243 Acc: 0.88161994\n",
      "New best validation loss: 0.0013424272292128234\n",
      "Epoch 9 of 500 took 0.189s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00060628 Acc: 0.97265625\n",
      "val Loss: 0.00275279 Acc: 0.8411215\n",
      "Epoch 10 of 500 took 0.181s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00054866 Acc: 0.97940341\n",
      "val Loss: 0.00033523 Acc: 0.95950156\n",
      "New best validation loss: 0.000335225922482036\n",
      "Epoch 11 of 500 took 0.189s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00053146 Acc: 0.9765625\n",
      "val Loss: 0.00215501 Acc: 0.80996885\n",
      "Epoch 12 of 500 took 0.187s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00046031 Acc: 0.9818892\n",
      "val Loss: 0.00575251 Acc: 0.69158879\n",
      "Epoch 13 of 500 took 0.191s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00051002 Acc: 0.98011364\n",
      "val Loss: 0.00640931 Acc: 0.69158879\n",
      "Epoch 14 of 500 took 0.182s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00063339 Acc: 0.97514205\n",
      "val Loss: 0.00065730 Acc: 0.93457944\n",
      "Epoch 15 of 500 took 0.188s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00049602 Acc: 0.97940341\n",
      "val Loss: 0.00110440 Acc: 0.88785047\n",
      "Epoch 16 of 500 took 0.182s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00050285 Acc: 0.97620739\n",
      "val Loss: 0.00343582 Acc: 0.76012461\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 17 of 500 took 0.189s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00042327 Acc: 0.98330966\n",
      "val Loss: 0.00029941 Acc: 0.96573209\n",
      "New best validation loss: 0.00029940571276198294\n",
      "Epoch 18 of 500 took 0.188s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00044606 Acc: 0.9818892\n",
      "val Loss: 0.00013156 Acc: 0.98753894\n",
      "New best validation loss: 0.0001315616906803345\n",
      "Epoch 19 of 500 took 0.189s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00033626 Acc: 0.98579545\n",
      "val Loss: 0.00018845 Acc: 0.97819315\n",
      "Epoch 20 of 500 took 0.192s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00028617 Acc: 0.98792614\n",
      "val Loss: 0.00029750 Acc: 0.96573209\n",
      "Epoch 21 of 500 took 0.187s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00032603 Acc: 0.98508523\n",
      "val Loss: 0.00022439 Acc: 0.97196262\n",
      "Epoch 22 of 500 took 0.183s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00027631 Acc: 0.98792614\n",
      "val Loss: 0.00013391 Acc: 0.98753894\n",
      "Epoch 23 of 500 took 0.188s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00025274 Acc: 0.99112216\n",
      "val Loss: 0.00013207 Acc: 0.98442368\n",
      "Epoch 24 of 500 took 0.186s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00028746 Acc: 0.98828125\n",
      "val Loss: 0.00019272 Acc: 0.97507788\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 25 of 500 took 0.228s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00027623 Acc: 0.98828125\n",
      "val Loss: 0.00012078 Acc: 0.99376947\n",
      "New best validation loss: 0.00012077998103011063\n",
      "Epoch 26 of 500 took 0.231s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00027591 Acc: 0.98792614\n",
      "val Loss: 0.00011710 Acc: 0.99376947\n",
      "New best validation loss: 0.00011710322395292026\n",
      "Epoch 27 of 500 took 0.184s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00025447 Acc: 0.99147727\n",
      "val Loss: 0.00015715 Acc: 0.98442368\n",
      "Epoch 28 of 500 took 0.189s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00024782 Acc: 0.99076705\n",
      "val Loss: 0.00011892 Acc: 0.99065421\n",
      "Epoch 29 of 500 took 0.182s\n",
      "Epoch 29/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00026969 Acc: 0.98899148\n",
      "val Loss: 0.00015105 Acc: 0.99065421\n",
      "Epoch 30 of 500 took 0.188s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00020926 Acc: 0.9921875\n",
      "val Loss: 0.00023347 Acc: 0.97507788\n",
      "Epoch 31 of 500 took 0.182s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00025193 Acc: 0.99005682\n",
      "val Loss: 0.00013822 Acc: 0.98753894\n",
      "Epoch 32 of 500 took 0.186s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00024475 Acc: 0.9897017\n",
      "val Loss: 0.00013089 Acc: 0.98753894\n",
      "Epoch    33: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 33 of 500 took 0.183s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00028106 Acc: 0.98899148\n",
      "val Loss: 0.00011790 Acc: 0.99065421\n",
      "Epoch 34 of 500 took 0.187s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00020107 Acc: 0.99289773\n",
      "val Loss: 0.00017625 Acc: 0.97819315\n",
      "Epoch 35 of 500 took 0.181s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00022116 Acc: 0.99112216\n",
      "val Loss: 0.00016495 Acc: 0.98442368\n",
      "Epoch 36 of 500 took 0.188s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00022693 Acc: 0.99147727\n",
      "val Loss: 0.00013157 Acc: 0.98130841\n",
      "Epoch 37 of 500 took 0.185s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00025782 Acc: 0.9897017\n",
      "val Loss: 0.00013282 Acc: 0.98130841\n",
      "Epoch 38 of 500 took 0.192s\n",
      "\n",
      "Training complete in 0m 7s\n",
      "Best val loss: 0.000117\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_2.pt' (epoch 27)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00319671 Acc: 0.9037642\n",
      "val Loss: 0.00275726 Acc: 0.76433121\n",
      "New best validation loss: 0.00275726018437914\n",
      "Epoch 1 of 500 took 0.230s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00167760 Acc: 0.94602273\n",
      "val Loss: 0.00266288 Acc: 0.76751592\n",
      "New best validation loss: 0.002662876609024728\n",
      "Epoch 2 of 500 took 0.184s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00135981 Acc: 0.95383523\n",
      "val Loss: 0.00123216 Acc: 0.89171975\n",
      "New best validation loss: 0.0012321583214838794\n",
      "Epoch 3 of 500 took 0.189s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00104136 Acc: 0.96164773\n",
      "val Loss: 0.00300366 Acc: 0.77070064\n",
      "Epoch 4 of 500 took 0.181s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00099400 Acc: 0.96164773\n",
      "val Loss: 0.00120922 Acc: 0.87898089\n",
      "New best validation loss: 0.0012092189804004255\n",
      "Epoch 5 of 500 took 0.190s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00099107 Acc: 0.96200284\n",
      "val Loss: 0.00268266 Acc: 0.7611465\n",
      "Epoch 6 of 500 took 0.182s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00095311 Acc: 0.96839489\n",
      "val Loss: 0.00288382 Acc: 0.72611465\n",
      "Epoch 7 of 500 took 0.187s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00081380 Acc: 0.97159091\n",
      "val Loss: 0.00111898 Acc: 0.90764331\n",
      "New best validation loss: 0.0011189839073047516\n",
      "Epoch 8 of 500 took 0.184s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00071488 Acc: 0.97478693\n",
      "val Loss: 0.00225523 Acc: 0.76433121\n",
      "Epoch 9 of 500 took 0.187s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00076647 Acc: 0.97194602\n",
      "val Loss: 0.00120855 Acc: 0.87579618\n",
      "Epoch 10 of 500 took 0.183s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00060526 Acc: 0.98011364\n",
      "val Loss: 0.00119093 Acc: 0.88853503\n",
      "Epoch 11 of 500 took 0.188s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00065982 Acc: 0.97585227\n",
      "val Loss: 0.00111559 Acc: 0.90127389\n",
      "New best validation loss: 0.001115585493434007\n",
      "Epoch 12 of 500 took 0.183s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00070845 Acc: 0.97549716\n",
      "val Loss: 0.00078302 Acc: 0.9044586\n",
      "New best validation loss: 0.0007830240828975751\n",
      "Epoch 13 of 500 took 0.187s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00056510 Acc: 0.9765625\n",
      "val Loss: 0.00362865 Acc: 0.79617834\n",
      "Epoch 14 of 500 took 0.182s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00066394 Acc: 0.97798295\n",
      "val Loss: 0.00048017 Acc: 0.96496815\n",
      "New best validation loss: 0.000480165005109872\n",
      "Epoch 15 of 500 took 0.188s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00055369 Acc: 0.9790483\n",
      "val Loss: 0.00042676 Acc: 0.95541401\n",
      "New best validation loss: 0.00042675501981358617\n",
      "Epoch 16 of 500 took 0.184s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00052060 Acc: 0.98295455\n",
      "val Loss: 0.00261596 Acc: 0.81847134\n",
      "Epoch 17 of 500 took 0.189s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00065734 Acc: 0.97869318\n",
      "val Loss: 0.00161422 Acc: 0.86305732\n",
      "Epoch 18 of 500 took 0.182s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00050803 Acc: 0.9790483\n",
      "val Loss: 0.00929640 Acc: 0.4522293\n",
      "Epoch 19 of 500 took 0.186s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00051525 Acc: 0.98117898\n",
      "val Loss: 0.00044658 Acc: 0.95859873\n",
      "Epoch 20 of 500 took 0.181s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00047551 Acc: 0.98259943\n",
      "val Loss: 0.00259899 Acc: 0.81528662\n",
      "Epoch 21 of 500 took 0.188s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00043942 Acc: 0.98330966\n",
      "val Loss: 0.00080273 Acc: 0.93949045\n",
      "Epoch    22: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 22 of 500 took 0.182s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00042254 Acc: 0.98082386\n",
      "val Loss: 0.00026446 Acc: 0.96496815\n",
      "New best validation loss: 0.00026445994806137814\n",
      "Epoch 23 of 500 took 0.188s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00037860 Acc: 0.98863636\n",
      "val Loss: 0.00028423 Acc: 0.97770701\n",
      "Epoch 24 of 500 took 0.181s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00043434 Acc: 0.98224432\n",
      "val Loss: 0.00015690 Acc: 0.98726115\n",
      "New best validation loss: 0.00015689968872981467\n",
      "Epoch 25 of 500 took 0.188s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00033628 Acc: 0.98828125\n",
      "val Loss: 0.00022940 Acc: 0.97452229\n",
      "Epoch 26 of 500 took 0.181s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00027850 Acc: 0.9897017\n",
      "val Loss: 0.00024957 Acc: 0.97452229\n",
      "Epoch 27 of 500 took 0.200s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00036766 Acc: 0.98544034\n",
      "val Loss: 0.00025576 Acc: 0.97133758\n",
      "Epoch 28 of 500 took 0.191s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00026958 Acc: 0.99112216\n",
      "val Loss: 0.00019813 Acc: 0.98089172\n",
      "Epoch 29 of 500 took 0.187s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00023363 Acc: 0.99183239\n",
      "val Loss: 0.00021725 Acc: 0.97452229\n",
      "Epoch 30 of 500 took 0.183s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00027836 Acc: 0.99005682\n",
      "val Loss: 0.00018440 Acc: 0.98407643\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 31 of 500 took 0.187s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00028639 Acc: 0.99112216\n",
      "val Loss: 0.00016327 Acc: 0.98407643\n",
      "Epoch 32 of 500 took 0.183s\n",
      "Epoch 32/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00035276 Acc: 0.98544034\n",
      "val Loss: 0.00017923 Acc: 0.98089172\n",
      "Epoch 33 of 500 took 0.188s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00029395 Acc: 0.99041193\n",
      "val Loss: 0.00016682 Acc: 0.98407643\n",
      "Epoch 34 of 500 took 0.181s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00033626 Acc: 0.98828125\n",
      "val Loss: 0.00021172 Acc: 0.98089172\n",
      "Epoch 35 of 500 took 0.186s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00023677 Acc: 0.99360795\n",
      "val Loss: 0.00019940 Acc: 0.98089172\n",
      "Epoch 36 of 500 took 0.181s\n",
      "\n",
      "Training complete in 0m 7s\n",
      "Best val loss: 0.000157\n",
      "Participant:  1\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00921570 Acc: 0.65930707\n",
      "val Loss: 0.00297897 Acc: 0.65151515\n",
      "New best validation loss: 0.0029789688009204287\n",
      "Epoch 1 of 500 took 0.200s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00374682 Acc: 0.86786685\n",
      "val Loss: 0.00987247 Acc: 0.36060606\n",
      "Epoch 2 of 500 took 0.195s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00265512 Acc: 0.8984375\n",
      "val Loss: 0.01729701 Acc: 0.26060606\n",
      "Epoch 3 of 500 took 0.203s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00203901 Acc: 0.92595109\n",
      "val Loss: 0.00301358 Acc: 0.67575758\n",
      "Epoch 4 of 500 took 0.242s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00183446 Acc: 0.93036685\n",
      "val Loss: 0.00655901 Acc: 0.5\n",
      "Epoch 5 of 500 took 0.238s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00164613 Acc: 0.93851902\n",
      "val Loss: 0.00106532 Acc: 0.86363636\n",
      "New best validation loss: 0.0010653167059927276\n",
      "Epoch 6 of 500 took 0.241s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00159961 Acc: 0.94021739\n",
      "val Loss: 0.00612867 Acc: 0.63333333\n",
      "Epoch 7 of 500 took 0.238s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00159385 Acc: 0.93919837\n",
      "val Loss: 0.00302042 Acc: 0.66969697\n",
      "Epoch 8 of 500 took 0.199s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00133429 Acc: 0.94938859\n",
      "val Loss: 0.00136938 Acc: 0.81818182\n",
      "Epoch 9 of 500 took 0.193s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00128893 Acc: 0.95142663\n",
      "val Loss: 0.00366979 Acc: 0.66666667\n",
      "Epoch 10 of 500 took 0.197s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00132551 Acc: 0.94735054\n",
      "val Loss: 0.00165542 Acc: 0.80606061\n",
      "Epoch 11 of 500 took 0.190s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00120208 Acc: 0.9544837\n",
      "val Loss: 0.00068287 Acc: 0.93636364\n",
      "New best validation loss: 0.0006828727595733874\n",
      "Epoch 12 of 500 took 0.197s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00102177 Acc: 0.96127717\n",
      "val Loss: 0.00285786 Acc: 0.75757576\n",
      "Epoch 13 of 500 took 0.190s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00101740 Acc: 0.95720109\n",
      "val Loss: 0.01069333 Acc: 0.58181818\n",
      "Epoch 14 of 500 took 0.196s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00110591 Acc: 0.9595788\n",
      "val Loss: 0.00267186 Acc: 0.76060606\n",
      "Epoch 15 of 500 took 0.190s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00092726 Acc: 0.96603261\n",
      "val Loss: 0.00121384 Acc: 0.85454545\n",
      "Epoch 16 of 500 took 0.199s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00090931 Acc: 0.9622962\n",
      "val Loss: 0.01491743 Acc: 0.46666667\n",
      "Epoch 17 of 500 took 0.196s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00081756 Acc: 0.97044837\n",
      "val Loss: 0.00131334 Acc: 0.89393939\n",
      "Epoch    18: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 18 of 500 took 0.194s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00070477 Acc: 0.97316576\n",
      "val Loss: 0.00031960 Acc: 0.96363636\n",
      "New best validation loss: 0.00031960272427761195\n",
      "Epoch 19 of 500 took 0.195s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00071222 Acc: 0.96908967\n",
      "val Loss: 0.00022708 Acc: 0.97272727\n",
      "New best validation loss: 0.00022708279165354643\n",
      "Epoch 20 of 500 took 0.191s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00049499 Acc: 0.98233696\n",
      "val Loss: 0.00019393 Acc: 0.98181818\n",
      "New best validation loss: 0.00019393217834559354\n",
      "Epoch 21 of 500 took 0.198s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00051448 Acc: 0.98233696\n",
      "val Loss: 0.00031594 Acc: 0.95757576\n",
      "Epoch 22 of 500 took 0.192s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00049724 Acc: 0.98097826\n",
      "val Loss: 0.00028854 Acc: 0.96969697\n",
      "Epoch 23 of 500 took 0.194s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00053563 Acc: 0.97758152\n",
      "val Loss: 0.00028842 Acc: 0.96969697\n",
      "Epoch 24 of 500 took 0.190s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00045946 Acc: 0.98471467\n",
      "val Loss: 0.00021468 Acc: 0.97272727\n",
      "Epoch 25 of 500 took 0.195s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00052779 Acc: 0.97826087\n",
      "val Loss: 0.00153737 Acc: 0.89393939\n",
      "Epoch 26 of 500 took 0.190s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00047082 Acc: 0.98199728\n",
      "val Loss: 0.00023495 Acc: 0.98181818\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 27 of 500 took 0.196s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00041464 Acc: 0.98403533\n",
      "val Loss: 0.00022180 Acc: 0.98181818\n",
      "Epoch 28 of 500 took 0.190s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00047949 Acc: 0.98097826\n",
      "val Loss: 0.00022124 Acc: 0.98181818\n",
      "Epoch 29 of 500 took 0.195s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00041460 Acc: 0.98539402\n",
      "val Loss: 0.00018124 Acc: 0.98484848\n",
      "New best validation loss: 0.00018123676153746518\n",
      "Epoch 30 of 500 took 0.192s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00039740 Acc: 0.98505435\n",
      "val Loss: 0.00024743 Acc: 0.97878788\n",
      "Epoch 31 of 500 took 0.194s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00041693 Acc: 0.98539402\n",
      "val Loss: 0.00019632 Acc: 0.98181818\n",
      "Epoch 32 of 500 took 0.190s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00046477 Acc: 0.98335598\n",
      "val Loss: 0.00034402 Acc: 0.97575758\n",
      "Epoch 33 of 500 took 0.194s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00042462 Acc: 0.98267663\n",
      "val Loss: 0.00022066 Acc: 0.97878788\n",
      "Epoch 34 of 500 took 0.190s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00045368 Acc: 0.98505435\n",
      "val Loss: 0.00017817 Acc: 0.97878788\n",
      "New best validation loss: 0.0001781673819729776\n",
      "Epoch 35 of 500 took 0.198s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00043998 Acc: 0.9857337\n",
      "val Loss: 0.00028237 Acc: 0.97272727\n",
      "Epoch 36 of 500 took 0.191s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00045334 Acc: 0.98335598\n",
      "val Loss: 0.00017820 Acc: 0.98181818\n",
      "Epoch 37 of 500 took 0.195s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00037616 Acc: 0.98709239\n",
      "val Loss: 0.00019094 Acc: 0.98181818\n",
      "Epoch 38 of 500 took 0.190s\n",
      "Epoch 38/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00035524 Acc: 0.98947011\n",
      "val Loss: 0.00020500 Acc: 0.98181818\n",
      "Epoch 39 of 500 took 0.196s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00036856 Acc: 0.98743207\n",
      "val Loss: 0.00020882 Acc: 0.97878788\n",
      "Epoch 40 of 500 took 0.190s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00034108 Acc: 0.98777174\n",
      "val Loss: 0.00022070 Acc: 0.98181818\n",
      "Epoch    41: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 41 of 500 took 0.201s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00036851 Acc: 0.98811141\n",
      "val Loss: 0.00017531 Acc: 0.98181818\n",
      "New best validation loss: 0.00017530629129120797\n",
      "Epoch 42 of 500 took 0.204s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00042644 Acc: 0.98709239\n",
      "val Loss: 0.00017862 Acc: 0.98484848\n",
      "Epoch 43 of 500 took 0.200s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00033713 Acc: 0.98947011\n",
      "val Loss: 0.00019393 Acc: 0.97272727\n",
      "Epoch 44 of 500 took 0.193s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00035552 Acc: 0.98811141\n",
      "val Loss: 0.00022833 Acc: 0.98181818\n",
      "Epoch 45 of 500 took 0.193s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00032987 Acc: 0.98980978\n",
      "val Loss: 0.00023489 Acc: 0.97878788\n",
      "Epoch 46 of 500 took 0.189s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00045455 Acc: 0.984375\n",
      "val Loss: 0.00023118 Acc: 0.97575758\n",
      "Epoch 47 of 500 took 0.195s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00037963 Acc: 0.98709239\n",
      "val Loss: 0.00016929 Acc: 0.98181818\n",
      "New best validation loss: 0.00016929380821459222\n",
      "Epoch 48 of 500 took 0.191s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00039771 Acc: 0.98471467\n",
      "val Loss: 0.00024560 Acc: 0.97878788\n",
      "Epoch 49 of 500 took 0.194s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00039260 Acc: 0.98879076\n",
      "val Loss: 0.00020657 Acc: 0.97878788\n",
      "Epoch 50 of 500 took 0.190s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00036081 Acc: 0.98505435\n",
      "val Loss: 0.00020731 Acc: 0.98484848\n",
      "Epoch 51 of 500 took 0.192s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.00037273 Acc: 0.9857337\n",
      "val Loss: 0.00019467 Acc: 0.98181818\n",
      "Epoch 52 of 500 took 0.190s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.00038733 Acc: 0.98845109\n",
      "val Loss: 0.00018495 Acc: 0.98181818\n",
      "Epoch 53 of 500 took 0.194s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00038483 Acc: 0.98641304\n",
      "val Loss: 0.00025119 Acc: 0.96969697\n",
      "Epoch    54: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 54 of 500 took 0.191s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.00037247 Acc: 0.98743207\n",
      "val Loss: 0.00017160 Acc: 0.97878788\n",
      "Epoch 55 of 500 took 0.193s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.00041588 Acc: 0.98505435\n",
      "val Loss: 0.00018309 Acc: 0.97878788\n",
      "Epoch 56 of 500 took 0.190s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.00038854 Acc: 0.98539402\n",
      "val Loss: 0.00018705 Acc: 0.98181818\n",
      "Epoch 57 of 500 took 0.194s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.00036913 Acc: 0.9857337\n",
      "val Loss: 0.00017496 Acc: 0.98484848\n",
      "Epoch 58 of 500 took 0.193s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.00031992 Acc: 0.98947011\n",
      "val Loss: 0.00024532 Acc: 0.97878788\n",
      "Epoch 59 of 500 took 0.194s\n",
      "\n",
      "Training complete in 0m 12s\n",
      "Best val loss: 0.000169\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42c8a71f90>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00547320 Acc: 0.80610795\n",
      "val Loss: 0.00700268 Acc: 0.52830189\n",
      "New best validation loss: 0.0070026820560671246\n",
      "Epoch 1 of 500 took 0.186s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00318787 Acc: 0.87713068\n",
      "val Loss: 0.00438741 Acc: 0.63836478\n",
      "New best validation loss: 0.00438740943212929\n",
      "Epoch 2 of 500 took 0.185s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00275822 Acc: 0.89240057\n",
      "val Loss: 0.00156681 Acc: 0.84591195\n",
      "New best validation loss: 0.0015668149264353626\n",
      "Epoch 3 of 500 took 0.217s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00224666 Acc: 0.90980114\n",
      "val Loss: 0.00079007 Acc: 0.91823899\n",
      "New best validation loss: 0.0007900705315032095\n",
      "Epoch 4 of 500 took 0.183s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00241005 Acc: 0.90802557\n",
      "val Loss: 0.00266189 Acc: 0.74213836\n",
      "Epoch 5 of 500 took 0.185s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00204493 Acc: 0.91725852\n",
      "val Loss: 0.00251205 Acc: 0.74842767\n",
      "Epoch 6 of 500 took 0.182s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00169549 Acc: 0.93110795\n",
      "val Loss: 0.00221431 Acc: 0.78616352\n",
      "Epoch 7 of 500 took 0.186s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00189671 Acc: 0.92080966\n",
      "val Loss: 0.00376520 Acc: 0.70754717\n",
      "Epoch 8 of 500 took 0.189s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00175720 Acc: 0.9296875\n",
      "val Loss: 0.00412726 Acc: 0.68867925\n",
      "Epoch 9 of 500 took 0.187s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00149074 Acc: 0.94069602\n",
      "val Loss: 0.00731475 Acc: 0.57861635\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 10 of 500 took 0.189s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00140780 Acc: 0.94211648\n",
      "val Loss: 0.00047070 Acc: 0.94654088\n",
      "New best validation loss: 0.0004707046274868947\n",
      "Epoch 11 of 500 took 0.189s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00116160 Acc: 0.95419034\n",
      "val Loss: 0.00045044 Acc: 0.95597484\n",
      "New best validation loss: 0.0004504371739033633\n",
      "Epoch 12 of 500 took 0.183s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00116517 Acc: 0.95099432\n",
      "val Loss: 0.00035555 Acc: 0.96540881\n",
      "New best validation loss: 0.00035555412371953327\n",
      "Epoch 13 of 500 took 0.205s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00125029 Acc: 0.9506392\n",
      "val Loss: 0.00042169 Acc: 0.96226415\n",
      "Epoch 14 of 500 took 0.190s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00103994 Acc: 0.9584517\n",
      "val Loss: 0.00036232 Acc: 0.9591195\n",
      "Epoch 15 of 500 took 0.187s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00104855 Acc: 0.95738636\n",
      "val Loss: 0.00047283 Acc: 0.95597484\n",
      "Epoch 16 of 500 took 0.182s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00099597 Acc: 0.96235795\n",
      "val Loss: 0.00038147 Acc: 0.95283019\n",
      "Epoch 17 of 500 took 0.186s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00102281 Acc: 0.95454545\n",
      "val Loss: 0.00116530 Acc: 0.87421384\n",
      "Epoch 18 of 500 took 0.181s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00093524 Acc: 0.95951705\n",
      "val Loss: 0.00063126 Acc: 0.93710692\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 19 of 500 took 0.187s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00098420 Acc: 0.95951705\n",
      "val Loss: 0.00033219 Acc: 0.96226415\n",
      "New best validation loss: 0.00033218851723011185\n",
      "Epoch 20 of 500 took 0.183s\n",
      "Epoch 20/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00095607 Acc: 0.96058239\n",
      "val Loss: 0.00035980 Acc: 0.95597484\n",
      "Epoch 21 of 500 took 0.187s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00092379 Acc: 0.96271307\n",
      "val Loss: 0.00037809 Acc: 0.96540881\n",
      "Epoch 22 of 500 took 0.182s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00095211 Acc: 0.96058239\n",
      "val Loss: 0.00035383 Acc: 0.96226415\n",
      "Epoch 23 of 500 took 0.185s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00087096 Acc: 0.96732955\n",
      "val Loss: 0.00033461 Acc: 0.9591195\n",
      "Epoch 24 of 500 took 0.183s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00094254 Acc: 0.96022727\n",
      "val Loss: 0.00033405 Acc: 0.96226415\n",
      "Epoch 25 of 500 took 0.185s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00084861 Acc: 0.96732955\n",
      "val Loss: 0.00032610 Acc: 0.96226415\n",
      "New best validation loss: 0.0003261009711514479\n",
      "Epoch 26 of 500 took 0.182s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00089790 Acc: 0.96235795\n",
      "val Loss: 0.00031806 Acc: 0.96540881\n",
      "New best validation loss: 0.0003180591237245116\n",
      "Epoch 27 of 500 took 0.187s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00094456 Acc: 0.95916193\n",
      "val Loss: 0.00033622 Acc: 0.9591195\n",
      "Epoch 28 of 500 took 0.182s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00089460 Acc: 0.95738636\n",
      "val Loss: 0.00034916 Acc: 0.95283019\n",
      "Epoch 29 of 500 took 0.186s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00109610 Acc: 0.9556108\n",
      "val Loss: 0.00041523 Acc: 0.94968553\n",
      "Epoch 30 of 500 took 0.183s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00087092 Acc: 0.96910511\n",
      "val Loss: 0.00033294 Acc: 0.96226415\n",
      "Epoch 31 of 500 took 0.186s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00085961 Acc: 0.9662642\n",
      "val Loss: 0.00032686 Acc: 0.9591195\n",
      "Epoch 32 of 500 took 0.181s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00070374 Acc: 0.97301136\n",
      "val Loss: 0.00032944 Acc: 0.95597484\n",
      "Epoch    33: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 33 of 500 took 0.187s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00082953 Acc: 0.96981534\n",
      "val Loss: 0.00030849 Acc: 0.96540881\n",
      "New best validation loss: 0.0003084915004811197\n",
      "Epoch 34 of 500 took 0.183s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00086772 Acc: 0.96732955\n",
      "val Loss: 0.00036579 Acc: 0.95597484\n",
      "Epoch 35 of 500 took 0.194s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00074030 Acc: 0.97159091\n",
      "val Loss: 0.00029438 Acc: 0.96226415\n",
      "New best validation loss: 0.00029437836704763977\n",
      "Epoch 36 of 500 took 0.183s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00078061 Acc: 0.97017045\n",
      "val Loss: 0.00029697 Acc: 0.96855346\n",
      "Epoch 37 of 500 took 0.196s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00081215 Acc: 0.96839489\n",
      "val Loss: 0.00032187 Acc: 0.9591195\n",
      "Epoch 38 of 500 took 0.182s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00077315 Acc: 0.97052557\n",
      "val Loss: 0.00035132 Acc: 0.9591195\n",
      "Epoch 39 of 500 took 0.186s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00084462 Acc: 0.96875\n",
      "val Loss: 0.00038709 Acc: 0.95597484\n",
      "Epoch 40 of 500 took 0.181s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00078664 Acc: 0.96448864\n",
      "val Loss: 0.00030667 Acc: 0.96540881\n",
      "Epoch 41 of 500 took 0.187s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00085462 Acc: 0.96306818\n",
      "val Loss: 0.00038725 Acc: 0.95597484\n",
      "Epoch    42: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 42 of 500 took 0.182s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00078252 Acc: 0.96697443\n",
      "val Loss: 0.00037729 Acc: 0.9591195\n",
      "Epoch 43 of 500 took 0.185s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00080844 Acc: 0.97017045\n",
      "val Loss: 0.00031931 Acc: 0.96226415\n",
      "Epoch 44 of 500 took 0.181s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00082271 Acc: 0.96697443\n",
      "val Loss: 0.00031776 Acc: 0.95597484\n",
      "Epoch 45 of 500 took 0.186s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00088325 Acc: 0.96697443\n",
      "val Loss: 0.00031472 Acc: 0.9591195\n",
      "Epoch 46 of 500 took 0.183s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00083211 Acc: 0.96519886\n",
      "val Loss: 0.00063813 Acc: 0.93081761\n",
      "Epoch 47 of 500 took 0.186s\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val loss: 0.000294\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_1.pt' (epoch 36)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00511665 Acc: 0.83309659\n",
      "val Loss: 0.00172039 Acc: 0.83227848\n",
      "New best validation loss: 0.0017203918740719179\n",
      "Epoch 1 of 500 took 0.185s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00314866 Acc: 0.87961648\n",
      "val Loss: 0.00493755 Acc: 0.60126582\n",
      "Epoch 2 of 500 took 0.187s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00258146 Acc: 0.8984375\n",
      "val Loss: 0.00119998 Acc: 0.88291139\n",
      "New best validation loss: 0.0011999804196478445\n",
      "Epoch 3 of 500 took 0.187s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00223647 Acc: 0.91299716\n",
      "val Loss: 0.00205632 Acc: 0.76582278\n",
      "Epoch 4 of 500 took 0.181s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00215702 Acc: 0.91051136\n",
      "val Loss: 0.00113992 Acc: 0.87341772\n",
      "New best validation loss: 0.0011399190259885185\n",
      "Epoch 5 of 500 took 0.187s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00213536 Acc: 0.92223011\n",
      "val Loss: 0.00172501 Acc: 0.83227848\n",
      "Epoch 6 of 500 took 0.182s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00186039 Acc: 0.92400568\n",
      "val Loss: 0.00285773 Acc: 0.7278481\n",
      "Epoch 7 of 500 took 0.188s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00172327 Acc: 0.92684659\n",
      "val Loss: 0.00192911 Acc: 0.78481013\n",
      "Epoch 8 of 500 took 0.181s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00175682 Acc: 0.93039773\n",
      "val Loss: 0.00241228 Acc: 0.76582278\n",
      "Epoch 9 of 500 took 0.187s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00171663 Acc: 0.92826705\n",
      "val Loss: 0.00147886 Acc: 0.83227848\n",
      "Epoch 10 of 500 took 0.181s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00156725 Acc: 0.93643466\n",
      "val Loss: 0.00109943 Acc: 0.88607595\n",
      "New best validation loss: 0.00109943181653566\n",
      "Epoch 11 of 500 took 0.188s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00151266 Acc: 0.94389205\n",
      "val Loss: 0.00547886 Acc: 0.56012658\n",
      "Epoch 12 of 500 took 0.183s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00150068 Acc: 0.94318182\n",
      "val Loss: 0.01631085 Acc: 0.37341772\n",
      "Epoch 13 of 500 took 0.187s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00124798 Acc: 0.94495739\n",
      "val Loss: 0.00126762 Acc: 0.87658228\n",
      "Epoch 14 of 500 took 0.182s\n",
      "Epoch 14/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00127713 Acc: 0.95276989\n",
      "val Loss: 0.00106966 Acc: 0.86708861\n",
      "New best validation loss: 0.0010696573159362697\n",
      "Epoch 15 of 500 took 0.194s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00131984 Acc: 0.94602273\n",
      "val Loss: 0.00218041 Acc: 0.73101266\n",
      "Epoch 16 of 500 took 0.181s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00120282 Acc: 0.95134943\n",
      "val Loss: 0.00367882 Acc: 0.69620253\n",
      "Epoch 17 of 500 took 0.190s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00114152 Acc: 0.95383523\n",
      "val Loss: 0.00173649 Acc: 0.83227848\n",
      "Epoch 18 of 500 took 0.183s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00125347 Acc: 0.94673295\n",
      "val Loss: 0.00568296 Acc: 0.6835443\n",
      "Epoch 19 of 500 took 0.187s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00127234 Acc: 0.95099432\n",
      "val Loss: 0.00045083 Acc: 0.95886076\n",
      "New best validation loss: 0.0004508272756504107\n",
      "Epoch 20 of 500 took 0.184s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00105863 Acc: 0.96164773\n",
      "val Loss: 0.00042553 Acc: 0.96835443\n",
      "New best validation loss: 0.00042553113985665234\n",
      "Epoch 21 of 500 took 0.192s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00108427 Acc: 0.953125\n",
      "val Loss: 0.00068006 Acc: 0.92405063\n",
      "Epoch 22 of 500 took 0.182s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00096016 Acc: 0.95809659\n",
      "val Loss: 0.00161129 Acc: 0.83860759\n",
      "Epoch 23 of 500 took 0.186s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00087885 Acc: 0.96448864\n",
      "val Loss: 0.00745841 Acc: 0.57911392\n",
      "Epoch 24 of 500 took 0.182s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00083936 Acc: 0.96306818\n",
      "val Loss: 0.00123855 Acc: 0.87025316\n",
      "Epoch 25 of 500 took 0.185s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00088659 Acc: 0.96306818\n",
      "val Loss: 0.00096840 Acc: 0.91139241\n",
      "Epoch 26 of 500 took 0.183s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00092374 Acc: 0.96022727\n",
      "val Loss: 0.00342730 Acc: 0.65506329\n",
      "Epoch    27: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 27 of 500 took 0.187s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00084911 Acc: 0.9609375\n",
      "val Loss: 0.00024535 Acc: 0.9778481\n",
      "New best validation loss: 0.00024534898656833023\n",
      "Epoch 28 of 500 took 0.184s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00064868 Acc: 0.97443182\n",
      "val Loss: 0.00029912 Acc: 0.97468354\n",
      "Epoch 29 of 500 took 0.189s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00056163 Acc: 0.97478693\n",
      "val Loss: 0.00028956 Acc: 0.97151899\n",
      "Epoch 30 of 500 took 0.183s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00064396 Acc: 0.9740767\n",
      "val Loss: 0.00037197 Acc: 0.96835443\n",
      "Epoch 31 of 500 took 0.187s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00057913 Acc: 0.97514205\n",
      "val Loss: 0.00026555 Acc: 0.98417722\n",
      "Epoch 32 of 500 took 0.182s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00052630 Acc: 0.97762784\n",
      "val Loss: 0.00027435 Acc: 0.98101266\n",
      "Epoch 33 of 500 took 0.186s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00051326 Acc: 0.9818892\n",
      "val Loss: 0.00020999 Acc: 0.98734177\n",
      "New best validation loss: 0.0002099914547008804\n",
      "Epoch 34 of 500 took 0.184s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00048193 Acc: 0.9818892\n",
      "val Loss: 0.00022337 Acc: 0.98417722\n",
      "Epoch 35 of 500 took 0.187s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00046632 Acc: 0.98295455\n",
      "val Loss: 0.00021904 Acc: 0.98734177\n",
      "Epoch 36 of 500 took 0.182s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00054329 Acc: 0.9790483\n",
      "val Loss: 0.00032484 Acc: 0.97151899\n",
      "Epoch 37 of 500 took 0.188s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00044621 Acc: 0.98330966\n",
      "val Loss: 0.00023563 Acc: 0.98417722\n",
      "Epoch 38 of 500 took 0.181s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00052996 Acc: 0.97833807\n",
      "val Loss: 0.00027629 Acc: 0.98101266\n",
      "Epoch 39 of 500 took 0.186s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00047507 Acc: 0.98117898\n",
      "val Loss: 0.00023996 Acc: 0.98101266\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 40 of 500 took 0.182s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00034783 Acc: 0.98508523\n",
      "val Loss: 0.00026751 Acc: 0.9778481\n",
      "Epoch 41 of 500 took 0.186s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00039906 Acc: 0.98366477\n",
      "val Loss: 0.00019051 Acc: 0.98734177\n",
      "New best validation loss: 0.00019051069747420807\n",
      "Epoch 42 of 500 took 0.189s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00040875 Acc: 0.98508523\n",
      "val Loss: 0.00021572 Acc: 0.98417722\n",
      "Epoch 43 of 500 took 0.187s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00042447 Acc: 0.98259943\n",
      "val Loss: 0.00020405 Acc: 0.98417722\n",
      "Epoch 44 of 500 took 0.187s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00042602 Acc: 0.9818892\n",
      "val Loss: 0.00023993 Acc: 0.98101266\n",
      "Epoch 45 of 500 took 0.188s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00035271 Acc: 0.98863636\n",
      "val Loss: 0.00022428 Acc: 0.98417722\n",
      "Epoch 46 of 500 took 0.182s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00034026 Acc: 0.98863636\n",
      "val Loss: 0.00022243 Acc: 0.98417722\n",
      "Epoch 47 of 500 took 0.186s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00039527 Acc: 0.98259943\n",
      "val Loss: 0.00016277 Acc: 0.99050633\n",
      "New best validation loss: 0.00016276688090985334\n",
      "Epoch 48 of 500 took 0.184s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00035122 Acc: 0.98792614\n",
      "val Loss: 0.00020676 Acc: 0.98417722\n",
      "Epoch 49 of 500 took 0.188s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00045197 Acc: 0.98082386\n",
      "val Loss: 0.00026062 Acc: 0.97468354\n",
      "Epoch 50 of 500 took 0.182s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00042926 Acc: 0.98330966\n",
      "val Loss: 0.00022574 Acc: 0.98734177\n",
      "Epoch 51 of 500 took 0.187s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.00039555 Acc: 0.98366477\n",
      "val Loss: 0.00019908 Acc: 0.98417722\n",
      "Epoch 52 of 500 took 0.182s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.00038464 Acc: 0.98615057\n",
      "val Loss: 0.00024569 Acc: 0.98417722\n",
      "Epoch 53 of 500 took 0.189s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00035484 Acc: 0.98330966\n",
      "val Loss: 0.00023203 Acc: 0.98734177\n",
      "Epoch    54: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 54 of 500 took 0.182s\n",
      "Epoch 54/499\n",
      "----------\n",
      "train Loss: 0.00034800 Acc: 0.98721591\n",
      "val Loss: 0.00024646 Acc: 0.97468354\n",
      "Epoch 55 of 500 took 0.186s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.00044559 Acc: 0.98082386\n",
      "val Loss: 0.00020287 Acc: 0.98734177\n",
      "Epoch 56 of 500 took 0.183s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.00041402 Acc: 0.98259943\n",
      "val Loss: 0.00020626 Acc: 0.99050633\n",
      "Epoch 57 of 500 took 0.187s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.00038462 Acc: 0.98650568\n",
      "val Loss: 0.00018696 Acc: 0.98734177\n",
      "Epoch 58 of 500 took 0.182s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.00046889 Acc: 0.98011364\n",
      "val Loss: 0.00019952 Acc: 0.98417722\n",
      "Epoch 59 of 500 took 0.186s\n",
      "\n",
      "Training complete in 0m 11s\n",
      "Best val loss: 0.000163\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_2.pt' (epoch 48)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00426787 Acc: 0.86123512\n",
      "val Loss: 0.00379864 Acc: 0.72580645\n",
      "New best validation loss: 0.0037986409279607957\n",
      "Epoch 1 of 500 took 0.176s\n",
      "Epoch 1/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00257956 Acc: 0.90327381\n",
      "val Loss: 0.00289021 Acc: 0.80645161\n",
      "New best validation loss: 0.0028902074983043055\n",
      "Epoch 2 of 500 took 0.182s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00222951 Acc: 0.91592262\n",
      "val Loss: 0.00124002 Acc: 0.87741935\n",
      "New best validation loss: 0.0012400186830951322\n",
      "Epoch 3 of 500 took 0.178s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00205674 Acc: 0.93005952\n",
      "val Loss: 0.00219408 Acc: 0.80967742\n",
      "Epoch 4 of 500 took 0.179s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00173031 Acc: 0.9311756\n",
      "val Loss: 0.01446946 Acc: 0.41612903\n",
      "Epoch 5 of 500 took 0.174s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00148954 Acc: 0.93973214\n",
      "val Loss: 0.00298439 Acc: 0.7516129\n",
      "Epoch 6 of 500 took 0.179s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00158552 Acc: 0.93936012\n",
      "val Loss: 0.00128806 Acc: 0.87096774\n",
      "Epoch 7 of 500 took 0.173s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00154613 Acc: 0.93563988\n",
      "val Loss: 0.00904233 Acc: 0.48387097\n",
      "Epoch 8 of 500 took 0.179s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00147574 Acc: 0.94122024\n",
      "val Loss: 0.00765035 Acc: 0.58064516\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 9 of 500 took 0.174s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00127940 Acc: 0.94977679\n",
      "val Loss: 0.00077615 Acc: 0.91935484\n",
      "New best validation loss: 0.0007761475059293931\n",
      "Epoch 10 of 500 took 0.184s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00108889 Acc: 0.95089286\n",
      "val Loss: 0.00076477 Acc: 0.94516129\n",
      "New best validation loss: 0.0007647704212896285\n",
      "Epoch 11 of 500 took 0.178s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00108236 Acc: 0.95349702\n",
      "val Loss: 0.00073275 Acc: 0.93870968\n",
      "New best validation loss: 0.0007327476816792642\n",
      "Epoch 12 of 500 took 0.184s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00100365 Acc: 0.96019345\n",
      "val Loss: 0.00069533 Acc: 0.93548387\n",
      "New best validation loss: 0.0006953281740988454\n",
      "Epoch 13 of 500 took 0.175s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00095744 Acc: 0.95982143\n",
      "val Loss: 0.00074886 Acc: 0.92580645\n",
      "Epoch 14 of 500 took 0.178s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00102516 Acc: 0.96279762\n",
      "val Loss: 0.00072012 Acc: 0.94193548\n",
      "Epoch 15 of 500 took 0.174s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00102292 Acc: 0.96168155\n",
      "val Loss: 0.00094406 Acc: 0.92903226\n",
      "Epoch 16 of 500 took 0.179s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00097944 Acc: 0.96019345\n",
      "val Loss: 0.00071713 Acc: 0.94516129\n",
      "Epoch 17 of 500 took 0.174s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00096413 Acc: 0.96391369\n",
      "val Loss: 0.00070863 Acc: 0.9483871\n",
      "Epoch 18 of 500 took 0.179s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00090158 Acc: 0.96205357\n",
      "val Loss: 0.00109119 Acc: 0.91290323\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 19 of 500 took 0.174s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00076797 Acc: 0.97209821\n",
      "val Loss: 0.00070757 Acc: 0.93225806\n",
      "Epoch 20 of 500 took 0.192s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00081022 Acc: 0.96912202\n",
      "val Loss: 0.00070916 Acc: 0.93225806\n",
      "Epoch 21 of 500 took 0.195s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00095821 Acc: 0.96354167\n",
      "val Loss: 0.00079208 Acc: 0.93548387\n",
      "Epoch 22 of 500 took 0.189s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00080338 Acc: 0.96688988\n",
      "val Loss: 0.00074742 Acc: 0.93548387\n",
      "Epoch 23 of 500 took 0.174s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00080095 Acc: 0.97061012\n",
      "val Loss: 0.00063605 Acc: 0.9483871\n",
      "New best validation loss: 0.0006360480381596473\n",
      "Epoch 24 of 500 took 0.180s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00087404 Acc: 0.96577381\n",
      "val Loss: 0.00066618 Acc: 0.93548387\n",
      "Epoch 25 of 500 took 0.175s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00083130 Acc: 0.96875\n",
      "val Loss: 0.00070059 Acc: 0.93870968\n",
      "Epoch 26 of 500 took 0.178s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00073643 Acc: 0.97321429\n",
      "val Loss: 0.00064487 Acc: 0.94193548\n",
      "Epoch 27 of 500 took 0.175s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00091714 Acc: 0.96465774\n",
      "val Loss: 0.00068983 Acc: 0.9483871\n",
      "Epoch 28 of 500 took 0.180s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00073037 Acc: 0.96912202\n",
      "val Loss: 0.00065134 Acc: 0.94516129\n",
      "Epoch 29 of 500 took 0.174s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00074766 Acc: 0.96949405\n",
      "val Loss: 0.00069213 Acc: 0.94193548\n",
      "Epoch    30: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 30 of 500 took 0.179s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00077800 Acc: 0.97284226\n",
      "val Loss: 0.00069899 Acc: 0.94516129\n",
      "Epoch 31 of 500 took 0.174s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00077826 Acc: 0.97098214\n",
      "val Loss: 0.00071690 Acc: 0.94193548\n",
      "Epoch 32 of 500 took 0.180s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00077715 Acc: 0.97209821\n",
      "val Loss: 0.00075397 Acc: 0.93870968\n",
      "Epoch 33 of 500 took 0.191s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00079595 Acc: 0.96800595\n",
      "val Loss: 0.00077512 Acc: 0.92903226\n",
      "Epoch 34 of 500 took 0.179s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00086414 Acc: 0.96502976\n",
      "val Loss: 0.00071923 Acc: 0.93870968\n",
      "Epoch 35 of 500 took 0.175s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000636\n",
      "Participant:  2\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01143158 Acc: 0.52059659\n",
      "val Loss: 0.01310001 Acc: 0.23003195\n",
      "New best validation loss: 0.013100005567264253\n",
      "Epoch 1 of 500 took 0.190s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00498206 Acc: 0.8203125\n",
      "val Loss: 0.01955990 Acc: 0.23642173\n",
      "Epoch 2 of 500 took 0.181s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00349649 Acc: 0.8647017\n",
      "val Loss: 0.03293356 Acc: 0.10223642\n",
      "Epoch 3 of 500 took 0.193s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00269002 Acc: 0.90198864\n",
      "val Loss: 0.00267057 Acc: 0.7284345\n",
      "New best validation loss: 0.002670565542702477\n",
      "Epoch 4 of 500 took 0.184s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00221373 Acc: 0.92009943\n",
      "val Loss: 0.01275591 Acc: 0.4057508\n",
      "Epoch 5 of 500 took 0.193s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00222343 Acc: 0.91619318\n",
      "val Loss: 0.04155505 Acc: 0.095846645\n",
      "Epoch 6 of 500 took 0.182s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00191284 Acc: 0.92400568\n",
      "val Loss: 0.03760140 Acc: 0.099041534\n",
      "Epoch 7 of 500 took 0.186s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00175456 Acc: 0.9272017\n",
      "val Loss: 0.01609425 Acc: 0.23642173\n",
      "Epoch 8 of 500 took 0.182s\n",
      "Epoch 8/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00167248 Acc: 0.9350142\n",
      "val Loss: 0.00951840 Acc: 0.43450479\n",
      "Epoch 9 of 500 took 0.192s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00146200 Acc: 0.93927557\n",
      "val Loss: 0.00870371 Acc: 0.41214058\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 10 of 500 took 0.182s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00120320 Acc: 0.95383523\n",
      "val Loss: 0.00046692 Acc: 0.95527157\n",
      "New best validation loss: 0.0004669226491794038\n",
      "Epoch 11 of 500 took 0.188s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00097922 Acc: 0.96200284\n",
      "val Loss: 0.00025354 Acc: 0.97444089\n",
      "New best validation loss: 0.00025353578332894906\n",
      "Epoch 12 of 500 took 0.184s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00088623 Acc: 0.96981534\n",
      "val Loss: 0.00023980 Acc: 0.97763578\n",
      "New best validation loss: 0.00023979767442892155\n",
      "Epoch 13 of 500 took 0.189s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00079834 Acc: 0.96981534\n",
      "val Loss: 0.00062083 Acc: 0.94249201\n",
      "Epoch 14 of 500 took 0.183s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00081878 Acc: 0.97088068\n",
      "val Loss: 0.00054499 Acc: 0.93929712\n",
      "Epoch 15 of 500 took 0.187s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00077105 Acc: 0.97088068\n",
      "val Loss: 0.00031831 Acc: 0.97124601\n",
      "Epoch 16 of 500 took 0.183s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00070344 Acc: 0.97372159\n",
      "val Loss: 0.00060801 Acc: 0.93610224\n",
      "Epoch 17 of 500 took 0.187s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00070236 Acc: 0.97443182\n",
      "val Loss: 0.00080898 Acc: 0.92651757\n",
      "Epoch 18 of 500 took 0.181s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00075862 Acc: 0.97514205\n",
      "val Loss: 0.00025050 Acc: 0.97444089\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 19 of 500 took 0.186s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00067030 Acc: 0.97372159\n",
      "val Loss: 0.00027913 Acc: 0.96805112\n",
      "Epoch 20 of 500 took 0.183s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00065159 Acc: 0.97549716\n",
      "val Loss: 0.00019441 Acc: 0.98402556\n",
      "New best validation loss: 0.00019440949915316158\n",
      "Epoch 21 of 500 took 0.187s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00058615 Acc: 0.97940341\n",
      "val Loss: 0.00024051 Acc: 0.97444089\n",
      "Epoch 22 of 500 took 0.183s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00049483 Acc: 0.98259943\n",
      "val Loss: 0.00022210 Acc: 0.97763578\n",
      "Epoch 23 of 500 took 0.189s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00057718 Acc: 0.98082386\n",
      "val Loss: 0.00021453 Acc: 0.97763578\n",
      "Epoch 24 of 500 took 0.183s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00057247 Acc: 0.97833807\n",
      "val Loss: 0.00024363 Acc: 0.97444089\n",
      "Epoch 25 of 500 took 0.192s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00050783 Acc: 0.98401989\n",
      "val Loss: 0.00027418 Acc: 0.97124601\n",
      "Epoch 26 of 500 took 0.182s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00058924 Acc: 0.97940341\n",
      "val Loss: 0.00016989 Acc: 0.98083067\n",
      "New best validation loss: 0.00016988900760873057\n",
      "Epoch 27 of 500 took 0.189s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00051955 Acc: 0.984375\n",
      "val Loss: 0.00019012 Acc: 0.98402556\n",
      "Epoch 28 of 500 took 0.183s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00055118 Acc: 0.98046875\n",
      "val Loss: 0.00020275 Acc: 0.98083067\n",
      "Epoch 29 of 500 took 0.188s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00047309 Acc: 0.9818892\n",
      "val Loss: 0.00020258 Acc: 0.99041534\n",
      "Epoch 30 of 500 took 0.193s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00056194 Acc: 0.9818892\n",
      "val Loss: 0.00023009 Acc: 0.97763578\n",
      "Epoch 31 of 500 took 0.187s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00055782 Acc: 0.98153409\n",
      "val Loss: 0.00020307 Acc: 0.98083067\n",
      "Epoch 32 of 500 took 0.194s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00051312 Acc: 0.98259943\n",
      "val Loss: 0.00018479 Acc: 0.98402556\n",
      "Epoch    33: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 33 of 500 took 0.186s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00050353 Acc: 0.98366477\n",
      "val Loss: 0.00015784 Acc: 0.98402556\n",
      "New best validation loss: 0.00015784158540990787\n",
      "Epoch 34 of 500 took 0.183s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00047700 Acc: 0.98295455\n",
      "val Loss: 0.00014628 Acc: 0.98722045\n",
      "New best validation loss: 0.00014627802248199146\n",
      "Epoch 35 of 500 took 0.199s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00045867 Acc: 0.98401989\n",
      "val Loss: 0.00022555 Acc: 0.97763578\n",
      "Epoch 36 of 500 took 0.181s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00046819 Acc: 0.984375\n",
      "val Loss: 0.00015099 Acc: 0.98083067\n",
      "Epoch 37 of 500 took 0.189s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00046417 Acc: 0.98117898\n",
      "val Loss: 0.00014198 Acc: 0.98402556\n",
      "New best validation loss: 0.00014198200104716487\n",
      "Epoch 38 of 500 took 0.184s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00047190 Acc: 0.98579545\n",
      "val Loss: 0.00018663 Acc: 0.98083067\n",
      "Epoch 39 of 500 took 0.186s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00048732 Acc: 0.98544034\n",
      "val Loss: 0.00016842 Acc: 0.98402556\n",
      "Epoch 40 of 500 took 0.183s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00043327 Acc: 0.98366477\n",
      "val Loss: 0.00019125 Acc: 0.97444089\n",
      "Epoch 41 of 500 took 0.188s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00053311 Acc: 0.97940341\n",
      "val Loss: 0.00020070 Acc: 0.97763578\n",
      "Epoch 42 of 500 took 0.182s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00048801 Acc: 0.98473011\n",
      "val Loss: 0.00016014 Acc: 0.98402556\n",
      "Epoch 43 of 500 took 0.187s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00049325 Acc: 0.98366477\n",
      "val Loss: 0.00017139 Acc: 0.97763578\n",
      "Epoch    44: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 44 of 500 took 0.183s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00052695 Acc: 0.98259943\n",
      "val Loss: 0.00015601 Acc: 0.98402556\n",
      "Epoch 45 of 500 took 0.186s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00048115 Acc: 0.9818892\n",
      "val Loss: 0.00019520 Acc: 0.98083067\n",
      "Epoch 46 of 500 took 0.185s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00043687 Acc: 0.98544034\n",
      "val Loss: 0.00017367 Acc: 0.98083067\n",
      "Epoch 47 of 500 took 0.187s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00048067 Acc: 0.98401989\n",
      "val Loss: 0.00014545 Acc: 0.98722045\n",
      "Epoch 48 of 500 took 0.183s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00051603 Acc: 0.97869318\n",
      "val Loss: 0.00018503 Acc: 0.98722045\n",
      "Epoch 49 of 500 took 0.186s\n",
      "\n",
      "Training complete in 0m 9s\n",
      "Best val loss: 0.000142\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01158323 Acc: 0.61079545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.00928741 Acc: 0.40498442\n",
      "New best validation loss: 0.009287406350964698\n",
      "Epoch 1 of 500 took 0.184s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00435929 Acc: 0.8203125\n",
      "val Loss: 0.00847088 Acc: 0.42990654\n",
      "New best validation loss: 0.008470881393765364\n",
      "Epoch 2 of 500 took 0.189s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00316406 Acc: 0.87215909\n",
      "val Loss: 0.01279752 Acc: 0.3271028\n",
      "Epoch 3 of 500 took 0.189s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00258201 Acc: 0.89275568\n",
      "val Loss: 0.03377479 Acc: 0.21806854\n",
      "Epoch 4 of 500 took 0.182s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00219968 Acc: 0.90980114\n",
      "val Loss: 0.01759820 Acc: 0.29906542\n",
      "Epoch 5 of 500 took 0.189s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00198292 Acc: 0.92045455\n",
      "val Loss: 0.01729672 Acc: 0.35514019\n",
      "Epoch 6 of 500 took 0.183s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00174875 Acc: 0.93181818\n",
      "val Loss: 0.01783872 Acc: 0.34579439\n",
      "Epoch 7 of 500 took 0.186s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00162705 Acc: 0.93359375\n",
      "val Loss: 0.00663123 Acc: 0.5482866\n",
      "New best validation loss: 0.006631227297203563\n",
      "Epoch 8 of 500 took 0.189s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00150154 Acc: 0.94069602\n",
      "val Loss: 0.00317611 Acc: 0.65732087\n",
      "New best validation loss: 0.0031761131554006415\n",
      "Epoch 9 of 500 took 0.190s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00133341 Acc: 0.94708807\n",
      "val Loss: 0.01881648 Acc: 0.28660436\n",
      "Epoch 10 of 500 took 0.185s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00118859 Acc: 0.953125\n",
      "val Loss: 0.01355981 Acc: 0.23987539\n",
      "Epoch 11 of 500 took 0.186s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00104609 Acc: 0.9584517\n",
      "val Loss: 0.00591984 Acc: 0.49221184\n",
      "Epoch 12 of 500 took 0.181s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00136270 Acc: 0.94673295\n",
      "val Loss: 0.00772364 Acc: 0.56074766\n",
      "Epoch 13 of 500 took 0.187s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00126881 Acc: 0.95205966\n",
      "val Loss: 0.00383835 Acc: 0.61993769\n",
      "Epoch 14 of 500 took 0.183s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00111924 Acc: 0.95738636\n",
      "val Loss: 0.00463681 Acc: 0.60747664\n",
      "Epoch    15: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 15 of 500 took 0.186s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00089423 Acc: 0.96413352\n",
      "val Loss: 0.00058514 Acc: 0.94080997\n",
      "New best validation loss: 0.0005851386120757582\n",
      "Epoch 16 of 500 took 0.183s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00082752 Acc: 0.96839489\n",
      "val Loss: 0.00041753 Acc: 0.95327103\n",
      "New best validation loss: 0.0004175290975986611\n",
      "Epoch 17 of 500 took 0.189s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00077400 Acc: 0.96981534\n",
      "val Loss: 0.00070230 Acc: 0.9376947\n",
      "Epoch 18 of 500 took 0.181s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00070898 Acc: 0.97265625\n",
      "val Loss: 0.00036663 Acc: 0.96261682\n",
      "New best validation loss: 0.00036662810038183335\n",
      "Epoch 19 of 500 took 0.189s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00070779 Acc: 0.97620739\n",
      "val Loss: 0.00032107 Acc: 0.96573209\n",
      "New best validation loss: 0.00032107081740073327\n",
      "Epoch 20 of 500 took 0.184s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00063779 Acc: 0.97727273\n",
      "val Loss: 0.00046387 Acc: 0.9470405\n",
      "Epoch 21 of 500 took 0.186s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00068475 Acc: 0.97585227\n",
      "val Loss: 0.00076946 Acc: 0.92211838\n",
      "Epoch 22 of 500 took 0.183s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00065214 Acc: 0.97620739\n",
      "val Loss: 0.00047257 Acc: 0.94392523\n",
      "Epoch 23 of 500 took 0.186s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00059398 Acc: 0.97585227\n",
      "val Loss: 0.00037530 Acc: 0.96573209\n",
      "Epoch 24 of 500 took 0.184s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00053636 Acc: 0.98153409\n",
      "val Loss: 0.00068719 Acc: 0.91588785\n",
      "Epoch 25 of 500 took 0.187s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00056125 Acc: 0.98153409\n",
      "val Loss: 0.00037040 Acc: 0.95638629\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 26 of 500 took 0.182s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00054152 Acc: 0.98082386\n",
      "val Loss: 0.00030092 Acc: 0.97507788\n",
      "New best validation loss: 0.00030091978214982887\n",
      "Epoch 27 of 500 took 0.186s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00056138 Acc: 0.97869318\n",
      "val Loss: 0.00038591 Acc: 0.95950156\n",
      "Epoch 28 of 500 took 0.182s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00057697 Acc: 0.97869318\n",
      "val Loss: 0.00031635 Acc: 0.96884735\n",
      "Epoch 29 of 500 took 0.203s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00048706 Acc: 0.9818892\n",
      "val Loss: 0.00035671 Acc: 0.96573209\n",
      "Epoch 30 of 500 took 0.182s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00050705 Acc: 0.98224432\n",
      "val Loss: 0.00032269 Acc: 0.96884735\n",
      "Epoch 31 of 500 took 0.187s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00043480 Acc: 0.98508523\n",
      "val Loss: 0.00032938 Acc: 0.96884735\n",
      "Epoch 32 of 500 took 0.182s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00053110 Acc: 0.98295455\n",
      "val Loss: 0.00037069 Acc: 0.96884735\n",
      "Epoch    33: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 33 of 500 took 0.187s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00050732 Acc: 0.98259943\n",
      "val Loss: 0.00033717 Acc: 0.96884735\n",
      "Epoch 34 of 500 took 0.182s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00051271 Acc: 0.97975852\n",
      "val Loss: 0.00033420 Acc: 0.97196262\n",
      "Epoch 35 of 500 took 0.193s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00048296 Acc: 0.98330966\n",
      "val Loss: 0.00033636 Acc: 0.96573209\n",
      "Epoch 36 of 500 took 0.187s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00047859 Acc: 0.9818892\n",
      "val Loss: 0.00031554 Acc: 0.96573209\n",
      "Epoch 37 of 500 took 0.207s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00048150 Acc: 0.98508523\n",
      "val Loss: 0.00030222 Acc: 0.96573209\n",
      "Epoch 38 of 500 took 0.192s\n",
      "\n",
      "Training complete in 0m 7s\n",
      "Best val loss: 0.000301\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42c8a71f90>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_1.pt' (epoch 27)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00619441 Acc: 0.78799716\n",
      "val Loss: 0.00422600 Acc: 0.63009404\n",
      "New best validation loss: 0.004226001826199618\n",
      "Epoch 1 of 500 took 0.185s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00210749 Acc: 0.91832386\n",
      "val Loss: 0.01253875 Acc: 0.39811912\n",
      "Epoch 2 of 500 took 0.193s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.00154801 Acc: 0.93785511\n",
      "val Loss: 0.02298913 Acc: 0.40125392\n",
      "Epoch 3 of 500 took 0.183s\n",
      "Epoch 3/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00134692 Acc: 0.94247159\n",
      "val Loss: 0.00179846 Acc: 0.81191223\n",
      "New best validation loss: 0.001798457299654013\n",
      "Epoch 4 of 500 took 0.190s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00126289 Acc: 0.94673295\n",
      "val Loss: 0.00271672 Acc: 0.68338558\n",
      "Epoch 5 of 500 took 0.182s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00113194 Acc: 0.95383523\n",
      "val Loss: 0.00146148 Acc: 0.84639498\n",
      "New best validation loss: 0.0014614793574174744\n",
      "Epoch 6 of 500 took 0.194s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00091017 Acc: 0.95703125\n",
      "val Loss: 0.00501778 Acc: 0.60815047\n",
      "Epoch 7 of 500 took 0.182s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00092100 Acc: 0.96129261\n",
      "val Loss: 0.01406068 Acc: 0.4984326\n",
      "Epoch 8 of 500 took 0.187s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00090963 Acc: 0.96484375\n",
      "val Loss: 0.01720036 Acc: 0.36050157\n",
      "Epoch 9 of 500 took 0.182s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00079465 Acc: 0.96661932\n",
      "val Loss: 0.00172910 Acc: 0.8338558\n",
      "Epoch 10 of 500 took 0.187s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00091788 Acc: 0.96484375\n",
      "val Loss: 0.00561063 Acc: 0.61442006\n",
      "Epoch 11 of 500 took 0.182s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00069186 Acc: 0.96839489\n",
      "val Loss: 0.00398272 Acc: 0.69905956\n",
      "Epoch    12: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 12 of 500 took 0.186s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00070106 Acc: 0.97301136\n",
      "val Loss: 0.00082317 Acc: 0.90909091\n",
      "New best validation loss: 0.0008231690124284511\n",
      "Epoch 13 of 500 took 0.183s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00050759 Acc: 0.98082386\n",
      "val Loss: 0.00056568 Acc: 0.95297806\n",
      "New best validation loss: 0.0005656772272713879\n",
      "Epoch 14 of 500 took 0.188s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00052522 Acc: 0.98224432\n",
      "val Loss: 0.00035682 Acc: 0.96865204\n",
      "New best validation loss: 0.0003568177406317014\n",
      "Epoch 15 of 500 took 0.184s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00046452 Acc: 0.98259943\n",
      "val Loss: 0.00032059 Acc: 0.95611285\n",
      "New best validation loss: 0.00032059339146629025\n",
      "Epoch 16 of 500 took 0.188s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00045296 Acc: 0.98046875\n",
      "val Loss: 0.00028048 Acc: 0.97492163\n",
      "New best validation loss: 0.00028048317914472476\n",
      "Epoch 17 of 500 took 0.183s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00041151 Acc: 0.98366477\n",
      "val Loss: 0.00054893 Acc: 0.95297806\n",
      "Epoch 18 of 500 took 0.192s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00043089 Acc: 0.98259943\n",
      "val Loss: 0.00021258 Acc: 0.97805643\n",
      "New best validation loss: 0.00021258360913554704\n",
      "Epoch 19 of 500 took 0.185s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00035702 Acc: 0.98579545\n",
      "val Loss: 0.00069715 Acc: 0.93103448\n",
      "Epoch 20 of 500 took 0.187s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00040882 Acc: 0.9818892\n",
      "val Loss: 0.00028268 Acc: 0.97178683\n",
      "Epoch 21 of 500 took 0.181s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00038902 Acc: 0.98259943\n",
      "val Loss: 0.00034255 Acc: 0.95611285\n",
      "Epoch 22 of 500 took 0.187s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00040519 Acc: 0.98153409\n",
      "val Loss: 0.00023185 Acc: 0.97805643\n",
      "Epoch 23 of 500 took 0.188s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00032397 Acc: 0.98615057\n",
      "val Loss: 0.00032024 Acc: 0.97492163\n",
      "Epoch 24 of 500 took 0.187s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00027803 Acc: 0.98934659\n",
      "val Loss: 0.00024140 Acc: 0.98119122\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 25 of 500 took 0.186s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00024720 Acc: 0.98934659\n",
      "val Loss: 0.00023977 Acc: 0.98119122\n",
      "Epoch 26 of 500 took 0.187s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00033947 Acc: 0.98721591\n",
      "val Loss: 0.00021080 Acc: 0.98119122\n",
      "New best validation loss: 0.00021080037456321118\n",
      "Epoch 27 of 500 took 0.183s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00034855 Acc: 0.98401989\n",
      "val Loss: 0.00021793 Acc: 0.98432602\n",
      "Epoch 28 of 500 took 0.187s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00031236 Acc: 0.98792614\n",
      "val Loss: 0.00020866 Acc: 0.97805643\n",
      "New best validation loss: 0.00020866474387787727\n",
      "Epoch 29 of 500 took 0.184s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00027865 Acc: 0.98828125\n",
      "val Loss: 0.00019335 Acc: 0.98432602\n",
      "New best validation loss: 0.00019335484009551403\n",
      "Epoch 30 of 500 took 0.189s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00022440 Acc: 0.99183239\n",
      "val Loss: 0.00024931 Acc: 0.97805643\n",
      "Epoch 31 of 500 took 0.181s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00028904 Acc: 0.98792614\n",
      "val Loss: 0.00021939 Acc: 0.98119122\n",
      "Epoch 32 of 500 took 0.187s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00032836 Acc: 0.98544034\n",
      "val Loss: 0.00020196 Acc: 0.97805643\n",
      "Epoch 33 of 500 took 0.182s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00029550 Acc: 0.99005682\n",
      "val Loss: 0.00025932 Acc: 0.97178683\n",
      "Epoch 34 of 500 took 0.193s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00028346 Acc: 0.98863636\n",
      "val Loss: 0.00026205 Acc: 0.97805643\n",
      "Epoch 35 of 500 took 0.186s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00022087 Acc: 0.99254261\n",
      "val Loss: 0.00021759 Acc: 0.98119122\n",
      "Epoch    36: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 36 of 500 took 0.188s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00028229 Acc: 0.98899148\n",
      "val Loss: 0.00023945 Acc: 0.97805643\n",
      "Epoch 37 of 500 took 0.183s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00034552 Acc: 0.98544034\n",
      "val Loss: 0.00022430 Acc: 0.97805643\n",
      "Epoch 38 of 500 took 0.187s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00029493 Acc: 0.98615057\n",
      "val Loss: 0.00021647 Acc: 0.98119122\n",
      "Epoch 39 of 500 took 0.182s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00028794 Acc: 0.98828125\n",
      "val Loss: 0.00024498 Acc: 0.98119122\n",
      "Epoch 40 of 500 took 0.186s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00026564 Acc: 0.98863636\n",
      "val Loss: 0.00020207 Acc: 0.98119122\n",
      "Epoch 41 of 500 took 0.182s\n",
      "\n",
      "Training complete in 0m 8s\n",
      "Best val loss: 0.000193\n",
      "Session:  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "<generator object Module.parameters at 0x7f42ca686f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_2.pt' (epoch 30)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.00337296 Acc: 0.89453125\n",
      "val Loss: 0.01773179 Acc: 0.3015873\n",
      "New best validation loss: 0.017731787666441904\n",
      "Epoch 1 of 500 took 0.189s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.00183914 Acc: 0.93465909\n",
      "val Loss: 0.00587046 Acc: 0.57142857\n",
      "New best validation loss: 0.005870457679506332\n",
      "Epoch 2 of 500 took 0.182s\n",
      "Epoch 2/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00144974 Acc: 0.94744318\n",
      "val Loss: 0.01247073 Acc: 0.44126984\n",
      "Epoch 3 of 500 took 0.188s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00139636 Acc: 0.94992898\n",
      "val Loss: 0.00846860 Acc: 0.53015873\n",
      "Epoch 4 of 500 took 0.185s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00137506 Acc: 0.94744318\n",
      "val Loss: 0.01112496 Acc: 0.44126984\n",
      "Epoch 5 of 500 took 0.228s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00113839 Acc: 0.95596591\n",
      "val Loss: 0.01911497 Acc: 0.27619048\n",
      "Epoch 6 of 500 took 0.230s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00102500 Acc: 0.96164773\n",
      "val Loss: 0.00301892 Acc: 0.71111111\n",
      "New best validation loss: 0.0030189220867459735\n",
      "Epoch 7 of 500 took 0.191s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00088655 Acc: 0.96803977\n",
      "val Loss: 0.00155098 Acc: 0.81904762\n",
      "New best validation loss: 0.0015509754892379518\n",
      "Epoch 8 of 500 took 0.187s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00093557 Acc: 0.96590909\n",
      "val Loss: 0.00768515 Acc: 0.47301587\n",
      "Epoch 9 of 500 took 0.188s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00093357 Acc: 0.96164773\n",
      "val Loss: 0.00201482 Acc: 0.78095238\n",
      "Epoch 10 of 500 took 0.229s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00092069 Acc: 0.96164773\n",
      "val Loss: 0.04910868 Acc: 0.053968254\n",
      "Epoch 11 of 500 took 0.183s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00081789 Acc: 0.96910511\n",
      "val Loss: 0.00530689 Acc: 0.72380952\n",
      "Epoch 12 of 500 took 0.187s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00079787 Acc: 0.96946023\n",
      "val Loss: 0.00311735 Acc: 0.72698413\n",
      "Epoch 13 of 500 took 0.181s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00084534 Acc: 0.96768466\n",
      "val Loss: 0.00264383 Acc: 0.73650794\n",
      "Epoch    14: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 14 of 500 took 0.186s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00064390 Acc: 0.97514205\n",
      "val Loss: 0.00034328 Acc: 0.97142857\n",
      "New best validation loss: 0.0003432798480230664\n",
      "Epoch 15 of 500 took 0.183s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00057084 Acc: 0.97869318\n",
      "val Loss: 0.00036453 Acc: 0.96507937\n",
      "Epoch 16 of 500 took 0.186s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00053833 Acc: 0.98046875\n",
      "val Loss: 0.00039704 Acc: 0.97460317\n",
      "Epoch 17 of 500 took 0.181s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00045868 Acc: 0.98117898\n",
      "val Loss: 0.00036507 Acc: 0.97142857\n",
      "Epoch 18 of 500 took 0.186s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00037928 Acc: 0.98473011\n",
      "val Loss: 0.00025843 Acc: 0.97777778\n",
      "New best validation loss: 0.0002584300817005218\n",
      "Epoch 19 of 500 took 0.185s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00045108 Acc: 0.98473011\n",
      "val Loss: 0.00033294 Acc: 0.97142857\n",
      "Epoch 20 of 500 took 0.189s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00038221 Acc: 0.9868608\n",
      "val Loss: 0.00023378 Acc: 0.97777778\n",
      "New best validation loss: 0.00023378363204380824\n",
      "Epoch 21 of 500 took 0.185s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00041193 Acc: 0.9818892\n",
      "val Loss: 0.00058434 Acc: 0.93650794\n",
      "Epoch 22 of 500 took 0.186s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00038669 Acc: 0.984375\n",
      "val Loss: 0.00052002 Acc: 0.95555556\n",
      "Epoch 23 of 500 took 0.182s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00042601 Acc: 0.98224432\n",
      "val Loss: 0.00038565 Acc: 0.96190476\n",
      "Epoch 24 of 500 took 0.186s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00031291 Acc: 0.98828125\n",
      "val Loss: 0.00035903 Acc: 0.96825397\n",
      "Epoch 25 of 500 took 0.184s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00035561 Acc: 0.98721591\n",
      "val Loss: 0.00052298 Acc: 0.95238095\n",
      "Epoch 26 of 500 took 0.186s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00038808 Acc: 0.98544034\n",
      "val Loss: 0.00035630 Acc: 0.97460317\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 27 of 500 took 0.182s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00030268 Acc: 0.9868608\n",
      "val Loss: 0.00027953 Acc: 0.97777778\n",
      "Epoch 28 of 500 took 0.187s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00035288 Acc: 0.98615057\n",
      "val Loss: 0.00035865 Acc: 0.97460317\n",
      "Epoch 29 of 500 took 0.181s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00034614 Acc: 0.98579545\n",
      "val Loss: 0.00028630 Acc: 0.96825397\n",
      "Epoch 30 of 500 took 0.187s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00034117 Acc: 0.98757102\n",
      "val Loss: 0.00030601 Acc: 0.97142857\n",
      "Epoch 31 of 500 took 0.237s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00030456 Acc: 0.99076705\n",
      "val Loss: 0.00027818 Acc: 0.97460317\n",
      "Epoch 32 of 500 took 0.232s\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val loss: 0.000234\n"
     ]
    }
   ],
   "source": [
    "train_Spectrogram_fine_tuning(examples_datasets_train, labels_datasets_train, filter_size=None,\n",
    "                              num_kernels=filter_size, number_of_cycle_for_first_training=4,\n",
    "                              number_of_cycles_rest_of_training=4, path_weight_to_save_to=path_to_save_to,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_classes,\n",
    "                              batch_size=128, spectrogram_model=False,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1854, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1899, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1938, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1780, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1981, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1809, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1928, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1902, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  0  Accuracy:  0.9980276134122288\n",
      "Participant:  0  Accuracy:  0.5260570304818093\n",
      "Participant:  0  Accuracy:  0.6132958801498127\n",
      "Participant:  0  Accuracy:  0.5281220209723546\n",
      "ACCURACY PARTICIPANT:  [0.9980276134122288, 0.5260570304818093, 0.6132958801498127, 0.5281220209723546]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  1  Accuracy:  0.9954627949183303\n",
      "Participant:  1  Accuracy:  0.6096408317580341\n",
      "Participant:  1  Accuracy:  0.7123420796890184\n",
      "Participant:  1  Accuracy:  0.8860510805500982\n",
      "ACCURACY PARTICIPANT:  [0.9954627949183303, 0.6096408317580341, 0.7123420796890184, 0.8860510805500982]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  2  Accuracy:  0.9970149253731343\n",
      "Participant:  2  Accuracy:  0.12791783380018673\n",
      "Participant:  2  Accuracy:  0.6494360902255639\n",
      "Participant:  2  Accuracy:  0.5075046904315197\n",
      "ACCURACY PARTICIPANT:  [0.9970149253731343, 0.12791783380018673, 0.6494360902255639, 0.5075046904315197]\n",
      "[0.99802761 0.52605703 0.61329588 0.52812202 0.99546279 0.60964083\n",
      " 0.71234208 0.88605108 0.99701493 0.12791783 0.64943609 0.50750469]\n",
      "[0.9980276134122288, 0.5260570304818093, 0.6132958801498127, 0.5281220209723546, 0.9954627949183303, 0.6096408317580341, 0.7123420796890184, 0.8860510805500982, 0.9970149253731343, 0.12791783380018673, 0.6494360902255639, 0.5075046904315197]\n",
      "OVERALL ACCURACY: 0.6792394059801742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "test_TSD_DNN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=filter_size, use_only_first_training=True,\n",
    "                                  path_weights=path_to_save_to,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  algo_name=algo_name, gestures_to_remove=gestures_to_remove,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.526057</td>\n",
       "      <td>0.613296</td>\n",
       "      <td>0.528122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_1</th>\n",
       "      <td>0.995463</td>\n",
       "      <td>0.609641</td>\n",
       "      <td>0.712342</td>\n",
       "      <td>0.886051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_2</th>\n",
       "      <td>0.997015</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.649436</td>\n",
       "      <td>0.507505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0   0.998028   0.526057   0.613296   0.528122\n",
       "Participant_1   0.995463   0.609641   0.712342   0.886051\n",
       "Participant_2   0.997015   0.127918   0.649436   0.507505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "TSD_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    TSD_acc[i] = acc\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Domain Adverserial Neural Network (DANN)\n",
    "* 2 domians : source(0) and target(1) (output_domain includes 2 features)\n",
    "    * source / validation: labeled; first training\n",
    "    * target: unlabeled; others\n",
    "    * train using one source and one target\n",
    "* start training using TSD_DNN model params \n",
    "* DANN loss (domain_loss_weight=1e-1)\n",
    "    * loss_domain_source = crossEntropyLoss(pred_domain_source, label_source_domain)\n",
    "    * loss_main_source = (0.5 * loss_source_class + domain_loss_weight * loss_domain_source)\n",
    "    * loss_domain_target = 0.5 * (crossEntropyLoss(pred_domain_target, label_target_domain))\n",
    "    * loss_domain_target = 0.5 * domain_loss_weight * loss_domain_target\n",
    "    * loss_main = loss_main_source + loss_domain_target\n",
    "    * loss_domain = loss_domain_source + loss_domain_target\n",
    "   \n",
    "### Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD\n",
    "    * beat_state_n.pt (n = # training session)\n",
    "        * epoch: #epochs\n",
    "        * model state_dict\n",
    "        * optimizer state_dict\n",
    "        * scheduler state_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.TrainingsAndEvaluations.ForTrainingSessions.TSD_DNN.train_tsd_dnn_standard import \\\n",
    "    test_TSD_DNN_on_training_sessions\n",
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import train_DA_spectrograms\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm. \\\n",
    "    load_dataset_spectrogram_in_dataloader import load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.utils_training_and_evaluation import create_confusion_matrix, \\\n",
    "    long_term_classification_graph, long_term_pointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from train_tsd_dnn_DA import test_network_DA_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [200, 200, 200]\n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = [5, 6, 9, 10]\n",
    "gestures_to_remove = None\n",
    "number_of_class = 11\n",
    "number_of_cycle_for_first_training = 4\n",
    "number_of_cycles_rest_of_training = 4\n",
    "learning_rate = 0.002515\n",
    "\n",
    "path_weights_fine_tuning = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "algo_name = \"DANN_THREE_CYCLES_11Gestures_TSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2674, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2829, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2881, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2821, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2970, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2859, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2837, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2783, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (2816, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (2888, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (2864, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (2835, 385)\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.968359, main loss classifier 0.140560, source classification loss 0.110537, loss domain distinction 0.626641, accuracy domain distinction 0.494922\n",
      "VALIDATION Loss: 0.25888336 Acc: 0.91610738\n",
      "New best validation loss:  0.25888335704803467\n",
      "Epoch 1 of 500 took 0.438s\n",
      "Accuracy source 0.966406, main loss classifier 0.131958, source classification loss 0.114855, loss domain distinction 0.449899, accuracy domain distinction 0.495312\n",
      "VALIDATION Loss: 0.17342398 Acc: 0.93959732\n",
      "New best validation loss:  0.17342397570610046\n",
      "Epoch 2 of 500 took 0.410s\n",
      "Accuracy source 0.966797, main loss classifier 0.126764, source classification loss 0.111667, loss domain distinction 0.345650, accuracy domain distinction 0.498437\n",
      "VALIDATION Loss: 0.22564840 Acc: 0.92281879\n",
      "Epoch 3 of 500 took 0.363s\n",
      "Accuracy source 0.970313, main loss classifier 0.125047, source classification loss 0.110951, loss domain distinction 0.290067, accuracy domain distinction 0.504102\n",
      "VALIDATION Loss: 0.17773525 Acc: 0.93959732\n",
      "Epoch 4 of 500 took 0.358s\n",
      "Accuracy source 0.967969, main loss classifier 0.127666, source classification loss 0.113254, loss domain distinction 0.259117, accuracy domain distinction 0.503516\n",
      "VALIDATION Loss: 0.21386892 Acc: 0.9261745\n",
      "Epoch 5 of 500 took 0.357s\n",
      "Accuracy source 0.963672, main loss classifier 0.133946, source classification loss 0.126997, loss domain distinction 0.235779, accuracy domain distinction 0.501172\n",
      "VALIDATION Loss: 0.13972759 Acc: 0.93288591\n",
      "Epoch    42: reducing learning rate of group 0 to 2.0120e-05.\n",
      "New best validation loss:  0.13972759246826172\n",
      "Epoch 6 of 500 took 0.362s\n",
      "Accuracy source 0.969922, main loss classifier 0.126117, source classification loss 0.109799, loss domain distinction 0.229841, accuracy domain distinction 0.500586\n",
      "VALIDATION Loss: 0.25982293 Acc: 0.91610738\n",
      "Epoch 7 of 500 took 0.360s\n",
      "Accuracy source 0.966016, main loss classifier 0.130480, source classification loss 0.119060, loss domain distinction 0.223333, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.23911536 Acc: 0.90939597\n",
      "Epoch 8 of 500 took 0.363s\n",
      "Accuracy source 0.971875, main loss classifier 0.127848, source classification loss 0.113338, loss domain distinction 0.223016, accuracy domain distinction 0.498242\n",
      "VALIDATION Loss: 0.20180623 Acc: 0.91946309\n",
      "Epoch 9 of 500 took 0.356s\n",
      "Accuracy source 0.961328, main loss classifier 0.130112, source classification loss 0.117166, loss domain distinction 0.219608, accuracy domain distinction 0.498828\n",
      "VALIDATION Loss: 0.19695187 Acc: 0.9261745\n",
      "Epoch 10 of 500 took 0.358s\n",
      "Accuracy source 0.968359, main loss classifier 0.127323, source classification loss 0.111688, loss domain distinction 0.217658, accuracy domain distinction 0.499609\n",
      "VALIDATION Loss: 0.30272746 Acc: 0.90939597\n",
      "Epoch 11 of 500 took 0.358s\n",
      "Accuracy source 0.966406, main loss classifier 0.131137, source classification loss 0.119366, loss domain distinction 0.212294, accuracy domain distinction 0.498633\n",
      "VALIDATION Loss: 0.32799783 Acc: 0.88590604\n",
      "Epoch    48: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 12 of 500 took 0.357s\n",
      "Accuracy source 0.967969, main loss classifier 0.128676, source classification loss 0.115046, loss domain distinction 0.213724, accuracy domain distinction 0.501367\n",
      "VALIDATION Loss: 0.17817919 Acc: 0.93288591\n",
      "Epoch 13 of 500 took 0.370s\n",
      "Accuracy source 0.967187, main loss classifier 0.128340, source classification loss 0.114251, loss domain distinction 0.213537, accuracy domain distinction 0.500977\n",
      "VALIDATION Loss: 0.27944326 Acc: 0.91946309\n",
      "Epoch 14 of 500 took 0.358s\n",
      "Accuracy source 0.969922, main loss classifier 0.125269, source classification loss 0.108581, loss domain distinction 0.211288, accuracy domain distinction 0.499609\n",
      "VALIDATION Loss: 0.28944135 Acc: 0.90604027\n",
      "Epoch 15 of 500 took 0.357s\n",
      "Accuracy source 0.965625, main loss classifier 0.128702, source classification loss 0.114322, loss domain distinction 0.215178, accuracy domain distinction 0.498828\n",
      "VALIDATION Loss: 0.23786473 Acc: 0.91946309\n",
      "Epoch 16 of 500 took 0.358s\n",
      "Accuracy source 0.968359, main loss classifier 0.129028, source classification loss 0.115334, loss domain distinction 0.213489, accuracy domain distinction 0.500195\n",
      "VALIDATION Loss: 0.19743951 Acc: 0.93624161\n",
      "Training complete in 0m 6s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.965625, main loss classifier 0.147801, source classification loss 0.124181, loss domain distinction 0.630400, accuracy domain distinction 0.491992\n",
      "VALIDATION Loss: 0.32975507 Acc: 0.90604027\n",
      "New best validation loss:  0.3297550678253174\n",
      "Epoch 1 of 500 took 0.360s\n",
      "Accuracy source 0.962891, main loss classifier 0.140333, source classification loss 0.129381, loss domain distinction 0.452247, accuracy domain distinction 0.487305\n",
      "VALIDATION Loss: 0.18711984 Acc: 0.94630872\n",
      "New best validation loss:  0.18711984157562256\n",
      "Epoch 2 of 500 took 0.360s\n",
      "Accuracy source 0.971094, main loss classifier 0.125033, source classification loss 0.107222, loss domain distinction 0.352448, accuracy domain distinction 0.493359\n",
      "VALIDATION Loss: 0.28424057 Acc: 0.90604027\n",
      "Epoch 3 of 500 took 0.357s\n",
      "Accuracy source 0.962500, main loss classifier 0.134852, source classification loss 0.129568, loss domain distinction 0.292333, accuracy domain distinction 0.496680\n",
      "VALIDATION Loss: 0.23534290 Acc: 0.92281879\n",
      "Epoch 4 of 500 took 0.360s\n",
      "Accuracy source 0.967578, main loss classifier 0.129672, source classification loss 0.116989, loss domain distinction 0.263420, accuracy domain distinction 0.496875\n",
      "VALIDATION Loss: 0.33861396 Acc: 0.88255034\n",
      "Epoch 5 of 500 took 0.358s\n",
      "Accuracy source 0.967969, main loss classifier 0.126440, source classification loss 0.110270, loss domain distinction 0.233632, accuracy domain distinction 0.498633\n",
      "VALIDATION Loss: 0.39439049 Acc: 0.86577181\n",
      "Epoch    42: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 6 of 500 took 0.358s\n",
      "Accuracy source 0.961328, main loss classifier 0.139097, source classification loss 0.134944, loss domain distinction 0.225720, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 0.34864813 Acc: 0.88590604\n",
      "Epoch 7 of 500 took 0.400s\n",
      "Accuracy source 0.964063, main loss classifier 0.132321, source classification loss 0.120749, loss domain distinction 0.226862, accuracy domain distinction 0.499023\n",
      "VALIDATION Loss: 0.31508473 Acc: 0.89932886\n",
      "Epoch 8 of 500 took 0.364s\n",
      "Accuracy source 0.973047, main loss classifier 0.121057, source classification loss 0.099160, loss domain distinction 0.223239, accuracy domain distinction 0.500586\n",
      "VALIDATION Loss: 0.30138439 Acc: 0.89932886\n",
      "Epoch 9 of 500 took 0.376s\n",
      "Accuracy source 0.968359, main loss classifier 0.129765, source classification loss 0.115628, loss domain distinction 0.223556, accuracy domain distinction 0.498828\n",
      "VALIDATION Loss: 0.29497680 Acc: 0.90268456\n",
      "Epoch 10 of 500 took 0.371s\n",
      "Accuracy source 0.966016, main loss classifier 0.128367, source classification loss 0.112443, loss domain distinction 0.220199, accuracy domain distinction 0.499609\n",
      "VALIDATION Loss: 0.30604684 Acc: 0.90268456\n",
      "Epoch 11 of 500 took 0.387s\n",
      "Accuracy source 0.967578, main loss classifier 0.128585, source classification loss 0.112197, loss domain distinction 0.217076, accuracy domain distinction 0.499219\n",
      "VALIDATION Loss: 0.28921589 Acc: 0.90604027\n",
      "Epoch    48: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 12 of 500 took 0.359s\n",
      "Accuracy source 0.967187, main loss classifier 0.134204, source classification loss 0.124476, loss domain distinction 0.213858, accuracy domain distinction 0.498633\n",
      "VALIDATION Loss: 0.32059187 Acc: 0.89597315\n",
      "Training complete in 0m 5s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.964063, main loss classifier 0.150166, source classification loss 0.128225, loss domain distinction 0.636073, accuracy domain distinction 0.502539\n",
      "VALIDATION Loss: 0.34697026 Acc: 0.89261745\n",
      "New best validation loss:  0.34697026014328003\n",
      "Epoch 1 of 500 took 0.360s\n",
      "Accuracy source 0.964844, main loss classifier 0.135440, source classification loss 0.120665, loss domain distinction 0.450575, accuracy domain distinction 0.502539\n",
      "VALIDATION Loss: 0.41459000 Acc: 0.86577181\n",
      "Epoch 2 of 500 took 0.360s\n",
      "Accuracy source 0.968359, main loss classifier 0.126252, source classification loss 0.109576, loss domain distinction 0.353520, accuracy domain distinction 0.502734\n",
      "VALIDATION Loss: 0.19557582 Acc: 0.9261745\n",
      "New best validation loss:  0.19557581841945648\n",
      "Epoch 3 of 500 took 0.360s\n",
      "Accuracy source 0.964453, main loss classifier 0.133145, source classification loss 0.126492, loss domain distinction 0.291595, accuracy domain distinction 0.501367\n",
      "VALIDATION Loss: 0.30724552 Acc: 0.90604027\n",
      "Epoch 4 of 500 took 0.369s\n",
      "Accuracy source 0.962500, main loss classifier 0.133315, source classification loss 0.126913, loss domain distinction 0.257443, accuracy domain distinction 0.501758\n",
      "VALIDATION Loss: 0.40370134 Acc: 0.87919463\n",
      "Epoch 5 of 500 took 0.358s\n",
      "Accuracy source 0.970313, main loss classifier 0.126498, source classification loss 0.111079, loss domain distinction 0.238051, accuracy domain distinction 0.497266\n",
      "VALIDATION Loss: 0.24326739 Acc: 0.91946309\n",
      "Epoch    42: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 6 of 500 took 0.358s\n",
      "Accuracy source 0.972266, main loss classifier 0.123729, source classification loss 0.105836, loss domain distinction 0.227538, accuracy domain distinction 0.500195\n",
      "VALIDATION Loss: 0.33268133 Acc: 0.88926174\n",
      "Epoch 7 of 500 took 0.360s\n",
      "Accuracy source 0.968750, main loss classifier 0.127967, source classification loss 0.113311, loss domain distinction 0.228257, accuracy domain distinction 0.498828\n",
      "VALIDATION Loss: 0.37437806 Acc: 0.88926174\n",
      "Epoch 8 of 500 took 0.358s\n",
      "Accuracy source 0.968359, main loss classifier 0.124445, source classification loss 0.104796, loss domain distinction 0.224853, accuracy domain distinction 0.498437\n",
      "VALIDATION Loss: 0.24017347 Acc: 0.91946309\n",
      "Epoch 9 of 500 took 0.360s\n",
      "Accuracy source 0.966797, main loss classifier 0.130159, source classification loss 0.118254, loss domain distinction 0.216218, accuracy domain distinction 0.500781\n",
      "VALIDATION Loss: 0.23106648 Acc: 0.92281879\n",
      "Epoch 10 of 500 took 0.366s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.964063, main loss classifier 0.130986, source classification loss 0.118535, loss domain distinction 0.219826, accuracy domain distinction 0.499023\n",
      "VALIDATION Loss: 0.31954473 Acc: 0.90268456\n",
      "Epoch 11 of 500 took 0.366s\n",
      "Accuracy source 0.975000, main loss classifier 0.124739, source classification loss 0.107369, loss domain distinction 0.213471, accuracy domain distinction 0.499414\n",
      "VALIDATION Loss: 0.32862502 Acc: 0.89261745\n",
      "Epoch    48: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 12 of 500 took 0.358s\n",
      "Accuracy source 0.963672, main loss classifier 0.131391, source classification loss 0.120329, loss domain distinction 0.214582, accuracy domain distinction 0.498828\n",
      "VALIDATION Loss: 0.33730108 Acc: 0.89932886\n",
      "Epoch 13 of 500 took 0.361s\n",
      "Accuracy source 0.971875, main loss classifier 0.126166, source classification loss 0.109382, loss domain distinction 0.212088, accuracy domain distinction 0.499805\n",
      "VALIDATION Loss: 0.30506587 Acc: 0.90604027\n",
      "Training complete in 0m 5s\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.981179, main loss classifier 0.132190, source classification loss 0.057222, loss domain distinction 0.836560, accuracy domain distinction 0.491477\n",
      "VALIDATION Loss: 0.09334292 Acc: 0.97575758\n",
      "New best validation loss:  0.09334291517734528\n",
      "Epoch 1 of 500 took 0.397s\n",
      "Accuracy source 0.982244, main loss classifier 0.125223, source classification loss 0.053216, loss domain distinction 0.771526, accuracy domain distinction 0.492188\n",
      "VALIDATION Loss: 0.06411848 Acc: 0.98787879\n",
      "New best validation loss:  0.06411848217248917\n",
      "Epoch 2 of 500 took 0.397s\n",
      "Accuracy source 0.982244, main loss classifier 0.126314, source classification loss 0.062496, loss domain distinction 0.713303, accuracy domain distinction 0.483310\n",
      "VALIDATION Loss: 0.06658202 Acc: 0.98484848\n",
      "Epoch 3 of 500 took 0.395s\n",
      "Accuracy source 0.987926, main loss classifier 0.114340, source classification loss 0.047012, loss domain distinction 0.654516, accuracy domain distinction 0.489347\n",
      "VALIDATION Loss: 0.05451003 Acc: 0.98484848\n",
      "New best validation loss:  0.05451003089547157\n",
      "Epoch 4 of 500 took 0.397s\n",
      "Accuracy source 0.985085, main loss classifier 0.114433, source classification loss 0.048421, loss domain distinction 0.630664, accuracy domain distinction 0.485263\n",
      "VALIDATION Loss: 0.05838371 Acc: 0.98787879\n",
      "Epoch 5 of 500 took 0.394s\n",
      "Accuracy source 0.984020, main loss classifier 0.109492, source classification loss 0.048077, loss domain distinction 0.573048, accuracy domain distinction 0.491122\n",
      "VALIDATION Loss: 0.04190163 Acc: 0.99090909\n",
      "Epoch    54: reducing learning rate of group 0 to 4.0240e-06.\n",
      "New best validation loss:  0.04190163314342499\n",
      "Epoch 6 of 500 took 0.399s\n",
      "Accuracy source 0.985085, main loss classifier 0.111836, source classification loss 0.052359, loss domain distinction 0.562845, accuracy domain distinction 0.489879\n",
      "VALIDATION Loss: 0.05300178 Acc: 0.98787879\n",
      "Epoch 7 of 500 took 0.394s\n",
      "Accuracy source 0.985085, main loss classifier 0.112892, source classification loss 0.055444, loss domain distinction 0.552544, accuracy domain distinction 0.485085\n",
      "VALIDATION Loss: 0.05021614 Acc: 0.98787879\n",
      "Epoch 8 of 500 took 0.396s\n",
      "Accuracy source 0.983665, main loss classifier 0.110024, source classification loss 0.051468, loss domain distinction 0.541570, accuracy domain distinction 0.493075\n",
      "VALIDATION Loss: 0.04974869 Acc: 0.98787879\n",
      "Epoch 9 of 500 took 0.399s\n",
      "Accuracy source 0.986151, main loss classifier 0.108375, source classification loss 0.051147, loss domain distinction 0.527108, accuracy domain distinction 0.490057\n",
      "VALIDATION Loss: 0.03805583 Acc: 0.99090909\n",
      "New best validation loss:  0.03805582597851753\n",
      "Epoch 10 of 500 took 0.399s\n",
      "Accuracy source 0.987571, main loss classifier 0.110373, source classification loss 0.052188, loss domain distinction 0.533844, accuracy domain distinction 0.489169\n",
      "VALIDATION Loss: 0.10092379 Acc: 0.96666667\n",
      "Epoch 11 of 500 took 0.397s\n",
      "Accuracy source 0.980114, main loss classifier 0.115976, source classification loss 0.065102, loss domain distinction 0.522095, accuracy domain distinction 0.496449\n",
      "VALIDATION Loss: 0.06046687 Acc: 0.98181818\n",
      "Epoch    60: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.394s\n",
      "Accuracy source 0.984375, main loss classifier 0.111054, source classification loss 0.057468, loss domain distinction 0.511586, accuracy domain distinction 0.492720\n",
      "VALIDATION Loss: 0.06178487 Acc: 0.97878788\n",
      "Epoch 13 of 500 took 0.395s\n",
      "Accuracy source 0.982244, main loss classifier 0.113115, source classification loss 0.060508, loss domain distinction 0.511869, accuracy domain distinction 0.490412\n",
      "VALIDATION Loss: 0.03763021 Acc: 0.99090909\n",
      "New best validation loss:  0.03763021156191826\n",
      "Epoch 14 of 500 took 0.398s\n",
      "Accuracy source 0.985440, main loss classifier 0.108017, source classification loss 0.049493, loss domain distinction 0.519314, accuracy domain distinction 0.486506\n",
      "VALIDATION Loss: 0.04634348 Acc: 0.99090909\n",
      "Epoch 15 of 500 took 0.423s\n",
      "Accuracy source 0.985440, main loss classifier 0.112931, source classification loss 0.061159, loss domain distinction 0.508079, accuracy domain distinction 0.493075\n",
      "VALIDATION Loss: 0.08505905 Acc: 0.97272727\n",
      "Epoch 16 of 500 took 0.475s\n",
      "Accuracy source 0.982599, main loss classifier 0.112900, source classification loss 0.058860, loss domain distinction 0.522137, accuracy domain distinction 0.484730\n",
      "VALIDATION Loss: 0.05005337 Acc: 0.99090909\n",
      "Epoch 17 of 500 took 0.447s\n",
      "Accuracy source 0.984375, main loss classifier 0.107584, source classification loss 0.049436, loss domain distinction 0.510164, accuracy domain distinction 0.493786\n",
      "VALIDATION Loss: 0.05799226 Acc: 0.98484848\n",
      "Epoch    66: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.396s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.985085, main loss classifier 0.107260, source classification loss 0.052097, loss domain distinction 0.498805, accuracy domain distinction 0.492010\n",
      "VALIDATION Loss: 0.05942513 Acc: 0.98181818\n",
      "Epoch 19 of 500 took 0.395s\n",
      "Accuracy source 0.983665, main loss classifier 0.109930, source classification loss 0.054488, loss domain distinction 0.510078, accuracy domain distinction 0.498402\n",
      "VALIDATION Loss: 0.06378748 Acc: 0.97878788\n",
      "Epoch 20 of 500 took 0.394s\n",
      "Accuracy source 0.979403, main loss classifier 0.114489, source classification loss 0.061978, loss domain distinction 0.514666, accuracy domain distinction 0.490589\n",
      "VALIDATION Loss: 0.08037190 Acc: 0.97272727\n",
      "Epoch 21 of 500 took 0.401s\n",
      "Accuracy source 0.987926, main loss classifier 0.105916, source classification loss 0.046753, loss domain distinction 0.503803, accuracy domain distinction 0.491122\n",
      "VALIDATION Loss: 0.07590169 Acc: 0.96969697\n",
      "Epoch 22 of 500 took 0.397s\n",
      "Accuracy source 0.986151, main loss classifier 0.105773, source classification loss 0.049304, loss domain distinction 0.494963, accuracy domain distinction 0.497514\n",
      "VALIDATION Loss: 0.05961413 Acc: 0.98181818\n",
      "Epoch 23 of 500 took 0.397s\n",
      "Accuracy source 0.984020, main loss classifier 0.107608, source classification loss 0.053783, loss domain distinction 0.486050, accuracy domain distinction 0.496094\n",
      "VALIDATION Loss: 0.14415208 Acc: 0.95151515\n",
      "Epoch    72: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 24 of 500 took 0.396s\n",
      "Accuracy source 0.984375, main loss classifier 0.108957, source classification loss 0.052822, loss domain distinction 0.508248, accuracy domain distinction 0.486151\n",
      "VALIDATION Loss: 0.06063037 Acc: 0.97575758\n",
      "Training complete in 0m 10s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.984375, main loss classifier 0.130528, source classification loss 0.054473, loss domain distinction 0.831126, accuracy domain distinction 0.498224\n",
      "VALIDATION Loss: 0.06074906 Acc: 0.98181818\n",
      "New best validation loss:  0.06074906140565872\n",
      "Epoch 1 of 500 took 0.403s\n",
      "Accuracy source 0.982955, main loss classifier 0.130356, source classification loss 0.063554, loss domain distinction 0.760860, accuracy domain distinction 0.491477\n",
      "VALIDATION Loss: 0.06080519 Acc: 0.98181818\n",
      "Epoch 2 of 500 took 0.395s\n",
      "Accuracy source 0.986151, main loss classifier 0.119388, source classification loss 0.049774, loss domain distinction 0.706283, accuracy domain distinction 0.491122\n",
      "VALIDATION Loss: 0.05676516 Acc: 0.98484848\n",
      "New best validation loss:  0.05676515772938728\n",
      "Epoch 3 of 500 took 0.396s\n",
      "Accuracy source 0.982244, main loss classifier 0.118353, source classification loss 0.052189, loss domain distinction 0.665640, accuracy domain distinction 0.491832\n",
      "VALIDATION Loss: 0.07763586 Acc: 0.97575758\n",
      "Epoch 4 of 500 took 0.443s\n",
      "Accuracy source 0.984730, main loss classifier 0.117034, source classification loss 0.054803, loss domain distinction 0.622540, accuracy domain distinction 0.494496\n",
      "VALIDATION Loss: 0.05396177 Acc: 0.98181818\n",
      "New best validation loss:  0.05396176502108574\n",
      "Epoch 5 of 500 took 0.399s\n",
      "Accuracy source 0.982599, main loss classifier 0.119699, source classification loss 0.065601, loss domain distinction 0.577778, accuracy domain distinction 0.491300\n",
      "VALIDATION Loss: 0.06146991 Acc: 0.97878788\n",
      "Epoch    54: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.397s\n",
      "Accuracy source 0.983310, main loss classifier 0.112827, source classification loss 0.054252, loss domain distinction 0.560844, accuracy domain distinction 0.493786\n",
      "VALIDATION Loss: 0.04521694 Acc: 0.98484848\n",
      "New best validation loss:  0.045216940343379974\n",
      "Epoch 7 of 500 took 0.396s\n",
      "Accuracy source 0.986151, main loss classifier 0.112739, source classification loss 0.055620, loss domain distinction 0.545256, accuracy domain distinction 0.498757\n",
      "VALIDATION Loss: 0.04327040 Acc: 0.98484848\n",
      "New best validation loss:  0.043270401656627655\n",
      "Epoch 8 of 500 took 0.398s\n",
      "Accuracy source 0.987216, main loss classifier 0.111322, source classification loss 0.052076, loss domain distinction 0.545545, accuracy domain distinction 0.495028\n",
      "VALIDATION Loss: 0.04652402 Acc: 0.98484848\n",
      "Epoch 9 of 500 took 0.408s\n",
      "Accuracy source 0.986151, main loss classifier 0.110921, source classification loss 0.051065, loss domain distinction 0.546751, accuracy domain distinction 0.491477\n",
      "VALIDATION Loss: 0.09050350 Acc: 0.96969697\n",
      "Epoch 10 of 500 took 0.398s\n",
      "Accuracy source 0.987926, main loss classifier 0.107815, source classification loss 0.047604, loss domain distinction 0.527608, accuracy domain distinction 0.494318\n",
      "VALIDATION Loss: 0.06630909 Acc: 0.98181818\n",
      "Epoch 11 of 500 took 0.397s\n",
      "Accuracy source 0.982244, main loss classifier 0.113681, source classification loss 0.058483, loss domain distinction 0.531284, accuracy domain distinction 0.488104\n",
      "VALIDATION Loss: 0.05531412 Acc: 0.98484848\n",
      "Epoch    60: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.396s\n",
      "Accuracy source 0.984375, main loss classifier 0.109239, source classification loss 0.050266, loss domain distinction 0.521077, accuracy domain distinction 0.492898\n",
      "VALIDATION Loss: 0.06673362 Acc: 0.98181818\n",
      "Epoch 13 of 500 took 0.397s\n",
      "Accuracy source 0.981179, main loss classifier 0.110457, source classification loss 0.054090, loss domain distinction 0.517516, accuracy domain distinction 0.498402\n",
      "VALIDATION Loss: 0.05607534 Acc: 0.98181818\n",
      "Epoch 14 of 500 took 0.406s\n",
      "Accuracy source 0.986506, main loss classifier 0.108532, source classification loss 0.047114, loss domain distinction 0.532055, accuracy domain distinction 0.492188\n",
      "VALIDATION Loss: 0.05670878 Acc: 0.98484848\n",
      "Epoch 15 of 500 took 0.396s\n",
      "Accuracy source 0.986506, main loss classifier 0.108669, source classification loss 0.050434, loss domain distinction 0.516805, accuracy domain distinction 0.490767\n",
      "VALIDATION Loss: 0.06245062 Acc: 0.98181818\n",
      "Epoch 16 of 500 took 0.396s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.982955, main loss classifier 0.110761, source classification loss 0.055418, loss domain distinction 0.511972, accuracy domain distinction 0.492898\n",
      "VALIDATION Loss: 0.06692187 Acc: 0.97878788\n",
      "Epoch 17 of 500 took 0.396s\n",
      "Accuracy source 0.986151, main loss classifier 0.112231, source classification loss 0.056018, loss domain distinction 0.521002, accuracy domain distinction 0.484020\n",
      "VALIDATION Loss: 0.06169170 Acc: 0.97878788\n",
      "Epoch    66: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.396s\n",
      "Accuracy source 0.985440, main loss classifier 0.110109, source classification loss 0.052787, loss domain distinction 0.516749, accuracy domain distinction 0.495561\n",
      "VALIDATION Loss: 0.13805977 Acc: 0.95151515\n",
      "Training complete in 0m 8s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.983631, main loss classifier 0.131504, source classification loss 0.056671, loss domain distinction 0.827722, accuracy domain distinction 0.494048\n",
      "VALIDATION Loss: 0.07046968 Acc: 0.97878788\n",
      "New best validation loss:  0.0704696848988533\n",
      "Epoch 1 of 500 took 0.378s\n",
      "Accuracy source 0.985119, main loss classifier 0.127959, source classification loss 0.057016, loss domain distinction 0.777467, accuracy domain distinction 0.492374\n",
      "VALIDATION Loss: 0.04276945 Acc: 0.98787879\n",
      "New best validation loss:  0.042769450694322586\n",
      "Epoch 2 of 500 took 0.387s\n",
      "Accuracy source 0.984375, main loss classifier 0.125217, source classification loss 0.060108, loss domain distinction 0.717049, accuracy domain distinction 0.500186\n",
      "VALIDATION Loss: 0.03387914 Acc: 0.99090909\n",
      "New best validation loss:  0.03387913852930069\n",
      "Epoch 3 of 500 took 0.385s\n",
      "Accuracy source 0.984747, main loss classifier 0.120803, source classification loss 0.054530, loss domain distinction 0.680583, accuracy domain distinction 0.493676\n",
      "VALIDATION Loss: 0.04616614 Acc: 0.98787879\n",
      "Epoch 4 of 500 took 0.378s\n",
      "Accuracy source 0.986235, main loss classifier 0.118021, source classification loss 0.056072, loss domain distinction 0.628434, accuracy domain distinction 0.496652\n",
      "VALIDATION Loss: 0.03617726 Acc: 0.99090909\n",
      "Epoch 5 of 500 took 0.378s\n",
      "Accuracy source 0.984747, main loss classifier 0.113292, source classification loss 0.052306, loss domain distinction 0.584875, accuracy domain distinction 0.497954\n",
      "VALIDATION Loss: 0.07993288 Acc: 0.96969697\n",
      "Epoch    54: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.377s\n",
      "Accuracy source 0.983259, main loss classifier 0.113637, source classification loss 0.052409, loss domain distinction 0.579536, accuracy domain distinction 0.494048\n",
      "VALIDATION Loss: 0.03347118 Acc: 0.99090909\n",
      "New best validation loss:  0.033471181988716125\n",
      "Epoch 7 of 500 took 0.382s\n",
      "Accuracy source 0.987351, main loss classifier 0.111749, source classification loss 0.052875, loss domain distinction 0.558806, accuracy domain distinction 0.494606\n",
      "VALIDATION Loss: 0.03607520 Acc: 0.98787879\n",
      "Epoch 8 of 500 took 0.377s\n",
      "Accuracy source 0.984003, main loss classifier 0.114563, source classification loss 0.056184, loss domain distinction 0.559418, accuracy domain distinction 0.499442\n",
      "VALIDATION Loss: 0.03209422 Acc: 0.99393939\n",
      "New best validation loss:  0.03209422156214714\n",
      "Epoch 9 of 500 took 0.380s\n",
      "Accuracy source 0.989211, main loss classifier 0.110306, source classification loss 0.046170, loss domain distinction 0.562819, accuracy domain distinction 0.489583\n",
      "VALIDATION Loss: 0.03815694 Acc: 0.98787879\n",
      "Epoch 10 of 500 took 0.376s\n",
      "Accuracy source 0.986979, main loss classifier 0.108207, source classification loss 0.047804, loss domain distinction 0.530080, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.04199118 Acc: 0.98787879\n",
      "Epoch 11 of 500 took 0.378s\n",
      "Accuracy source 0.983631, main loss classifier 0.112723, source classification loss 0.056239, loss domain distinction 0.533398, accuracy domain distinction 0.494792\n",
      "VALIDATION Loss: 0.04319983 Acc: 0.98787879\n",
      "Epoch    60: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.377s\n",
      "Accuracy source 0.982887, main loss classifier 0.112734, source classification loss 0.059059, loss domain distinction 0.516763, accuracy domain distinction 0.501674\n",
      "VALIDATION Loss: 0.03695730 Acc: 0.99090909\n",
      "Epoch 13 of 500 took 0.378s\n",
      "Accuracy source 0.984747, main loss classifier 0.109861, source classification loss 0.051032, loss domain distinction 0.526702, accuracy domain distinction 0.496280\n",
      "VALIDATION Loss: 0.03295403 Acc: 0.98787879\n",
      "Epoch 14 of 500 took 0.382s\n",
      "Accuracy source 0.983259, main loss classifier 0.112352, source classification loss 0.055052, loss domain distinction 0.533196, accuracy domain distinction 0.489769\n",
      "VALIDATION Loss: 0.05924530 Acc: 0.97575758\n",
      "Epoch 15 of 500 took 0.384s\n",
      "Accuracy source 0.986235, main loss classifier 0.110246, source classification loss 0.053594, loss domain distinction 0.521128, accuracy domain distinction 0.493862\n",
      "VALIDATION Loss: 0.03111822 Acc: 0.99090909\n",
      "New best validation loss:  0.03111821971833706\n",
      "Epoch 16 of 500 took 0.384s\n",
      "Accuracy source 0.982887, main loss classifier 0.114361, source classification loss 0.060745, loss domain distinction 0.521394, accuracy domain distinction 0.498884\n",
      "VALIDATION Loss: 0.04188246 Acc: 0.98787879\n",
      "Epoch 17 of 500 took 0.377s\n",
      "Accuracy source 0.986235, main loss classifier 0.107952, source classification loss 0.047293, loss domain distinction 0.522906, accuracy domain distinction 0.500744\n",
      "VALIDATION Loss: 0.04529936 Acc: 0.98787879\n",
      "Epoch    66: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 18 of 500 took 0.378s\n",
      "Accuracy source 0.984003, main loss classifier 0.110090, source classification loss 0.052490, loss domain distinction 0.522707, accuracy domain distinction 0.501674\n",
      "VALIDATION Loss: 0.04248297 Acc: 0.99090909\n",
      "Epoch 19 of 500 took 0.377s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.986979, main loss classifier 0.106260, source classification loss 0.045601, loss domain distinction 0.517735, accuracy domain distinction 0.500186\n",
      "VALIDATION Loss: 0.11156059 Acc: 0.96060606\n",
      "Epoch 20 of 500 took 0.378s\n",
      "Accuracy source 0.983259, main loss classifier 0.110275, source classification loss 0.052800, loss domain distinction 0.522826, accuracy domain distinction 0.499070\n",
      "VALIDATION Loss: 0.02874412 Acc: 0.99393939\n",
      "New best validation loss:  0.02874411642551422\n",
      "Epoch 21 of 500 took 0.381s\n",
      "Accuracy source 0.986979, main loss classifier 0.108276, source classification loss 0.050858, loss domain distinction 0.509632, accuracy domain distinction 0.503906\n",
      "VALIDATION Loss: 0.04489513 Acc: 0.99090909\n",
      "Epoch 22 of 500 took 0.378s\n",
      "Accuracy source 0.984747, main loss classifier 0.110125, source classification loss 0.053611, loss domain distinction 0.515095, accuracy domain distinction 0.496466\n",
      "VALIDATION Loss: 0.05642430 Acc: 0.98181818\n",
      "Epoch 23 of 500 took 0.379s\n",
      "Accuracy source 0.985863, main loss classifier 0.112783, source classification loss 0.057246, loss domain distinction 0.523744, accuracy domain distinction 0.498326\n",
      "VALIDATION Loss: 0.03836938 Acc: 0.99393939\n",
      "Epoch    72: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 24 of 500 took 0.379s\n",
      "Accuracy source 0.984003, main loss classifier 0.112312, source classification loss 0.056939, loss domain distinction 0.519978, accuracy domain distinction 0.497954\n",
      "VALIDATION Loss: 0.08555297 Acc: 0.97575758\n",
      "Epoch 25 of 500 took 0.376s\n",
      "Accuracy source 0.985491, main loss classifier 0.108909, source classification loss 0.050001, loss domain distinction 0.519164, accuracy domain distinction 0.496280\n",
      "VALIDATION Loss: 0.03385485 Acc: 0.99090909\n",
      "Epoch 26 of 500 took 0.379s\n",
      "Accuracy source 0.988467, main loss classifier 0.108196, source classification loss 0.048342, loss domain distinction 0.517066, accuracy domain distinction 0.499256\n",
      "VALIDATION Loss: 0.05596722 Acc: 0.98181818\n",
      "Epoch 27 of 500 took 0.378s\n",
      "Accuracy source 0.985491, main loss classifier 0.107010, source classification loss 0.046968, loss domain distinction 0.520211, accuracy domain distinction 0.497024\n",
      "VALIDATION Loss: 0.04670120 Acc: 0.98484848\n",
      "Epoch 28 of 500 took 0.377s\n",
      "Accuracy source 0.984375, main loss classifier 0.108961, source classification loss 0.050288, loss domain distinction 0.520122, accuracy domain distinction 0.500372\n",
      "VALIDATION Loss: 0.04336294 Acc: 0.99090909\n",
      "Epoch 29 of 500 took 0.393s\n",
      "Accuracy source 0.985119, main loss classifier 0.108504, source classification loss 0.048097, loss domain distinction 0.523905, accuracy domain distinction 0.494792\n",
      "VALIDATION Loss: 0.03745738 Acc: 0.99090909\n",
      "Epoch    78: reducing learning rate of group 0 to 6.4384e-09.\n",
      "Epoch 30 of 500 took 0.378s\n",
      "Accuracy source 0.982887, main loss classifier 0.111344, source classification loss 0.055161, loss domain distinction 0.517683, accuracy domain distinction 0.498884\n",
      "VALIDATION Loss: 0.06193341 Acc: 0.97878788\n",
      "Epoch 31 of 500 took 0.378s\n",
      "Accuracy source 0.981771, main loss classifier 0.115999, source classification loss 0.065730, loss domain distinction 0.515826, accuracy domain distinction 0.500558\n",
      "VALIDATION Loss: 0.03548977 Acc: 0.99393939\n",
      "Training complete in 0m 12s\n",
      "SHAPE SESSIONS:  (4,)\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.978693, main loss classifier 0.136873, source classification loss 0.076485, loss domain distinction 0.795528, accuracy domain distinction 0.492720\n",
      "VALIDATION Loss: 2.54679632 Acc: 0.55271565\n",
      "New best validation loss:  2.5467963218688965\n",
      "Epoch 1 of 500 took 0.397s\n",
      "Accuracy source 0.984730, main loss classifier 0.127407, source classification loss 0.070399, loss domain distinction 0.717813, accuracy domain distinction 0.501598\n",
      "VALIDATION Loss: 2.73413873 Acc: 0.56230032\n",
      "Epoch 2 of 500 took 0.398s\n",
      "Accuracy source 0.976918, main loss classifier 0.128415, source classification loss 0.076745, loss domain distinction 0.677876, accuracy domain distinction 0.498402\n",
      "VALIDATION Loss: 3.43754601 Acc: 0.54313099\n",
      "Epoch 3 of 500 took 0.396s\n",
      "Accuracy source 0.982244, main loss classifier 0.116210, source classification loss 0.061402, loss domain distinction 0.618104, accuracy domain distinction 0.495028\n",
      "VALIDATION Loss: 2.29047251 Acc: 0.59105431\n",
      "New best validation loss:  2.2904725074768066\n",
      "Epoch 4 of 500 took 0.397s\n",
      "Accuracy source 0.975497, main loss classifier 0.120793, source classification loss 0.075373, loss domain distinction 0.576784, accuracy domain distinction 0.502308\n",
      "VALIDATION Loss: 2.94204140 Acc: 0.5399361\n",
      "Epoch 5 of 500 took 0.395s\n",
      "Accuracy source 0.980469, main loss classifier 0.117567, source classification loss 0.071566, loss domain distinction 0.545710, accuracy domain distinction 0.495739\n",
      "VALIDATION Loss: 2.92048240 Acc: 0.55271565\n",
      "Epoch    44: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.395s\n",
      "Accuracy source 0.982244, main loss classifier 0.113181, source classification loss 0.066797, loss domain distinction 0.518024, accuracy domain distinction 0.501243\n",
      "VALIDATION Loss: 3.02399993 Acc: 0.54952077\n",
      "Epoch 7 of 500 took 0.395s\n",
      "Accuracy source 0.976918, main loss classifier 0.116561, source classification loss 0.075361, loss domain distinction 0.505011, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 2.62955260 Acc: 0.56230032\n",
      "Epoch 8 of 500 took 0.397s\n",
      "Accuracy source 0.982244, main loss classifier 0.115621, source classification loss 0.073130, loss domain distinction 0.503306, accuracy domain distinction 0.500533\n",
      "VALIDATION Loss: 2.48671198 Acc: 0.57507987\n",
      "Epoch 9 of 500 took 0.401s\n",
      "Accuracy source 0.976918, main loss classifier 0.118740, source classification loss 0.079776, loss domain distinction 0.497508, accuracy domain distinction 0.497692\n",
      "VALIDATION Loss: 2.59792757 Acc: 0.57507987\n",
      "Epoch 10 of 500 took 0.402s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.976918, main loss classifier 0.115756, source classification loss 0.076393, loss domain distinction 0.481283, accuracy domain distinction 0.501243\n",
      "VALIDATION Loss: 2.65735507 Acc: 0.57188498\n",
      "Epoch 11 of 500 took 0.396s\n",
      "Accuracy source 0.980824, main loss classifier 0.111532, source classification loss 0.067135, loss domain distinction 0.479075, accuracy domain distinction 0.492720\n",
      "VALIDATION Loss: 2.40660620 Acc: 0.58466454\n",
      "Epoch    50: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.397s\n",
      "Accuracy source 0.977983, main loss classifier 0.115177, source classification loss 0.077556, loss domain distinction 0.464795, accuracy domain distinction 0.502841\n",
      "VALIDATION Loss: 2.86122680 Acc: 0.54952077\n",
      "Epoch 13 of 500 took 0.396s\n",
      "Accuracy source 0.982244, main loss classifier 0.109027, source classification loss 0.063560, loss domain distinction 0.472772, accuracy domain distinction 0.496804\n",
      "VALIDATION Loss: 2.74755597 Acc: 0.55591054\n",
      "Epoch 14 of 500 took 0.395s\n",
      "Accuracy source 0.979759, main loss classifier 0.111581, source classification loss 0.068950, loss domain distinction 0.469459, accuracy domain distinction 0.499467\n",
      "VALIDATION Loss: 2.39008784 Acc: 0.59744409\n",
      "Training complete in 0m 6s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "STARTING TRAINING\n",
      "Accuracy source 0.977273, main loss classifier 0.136583, source classification loss 0.075493, loss domain distinction 0.795005, accuracy domain distinction 0.502841\n",
      "VALIDATION Loss: 0.13042329 Acc: 0.93929712\n",
      "New best validation loss:  0.13042329251766205\n",
      "Epoch 1 of 500 took 0.397s\n",
      "Accuracy source 0.977983, main loss classifier 0.131639, source classification loss 0.073489, loss domain distinction 0.744407, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.25448141 Acc: 0.88498403\n",
      "Epoch 2 of 500 took 0.395s\n",
      "Accuracy source 0.977983, main loss classifier 0.125450, source classification loss 0.070734, loss domain distinction 0.675443, accuracy domain distinction 0.505327\n",
      "VALIDATION Loss: 0.25875130 Acc: 0.90734824\n",
      "Epoch 3 of 500 took 0.394s\n",
      "Accuracy source 0.980469, main loss classifier 0.118643, source classification loss 0.066480, loss domain distinction 0.617837, accuracy domain distinction 0.511541\n",
      "VALIDATION Loss: 0.19233917 Acc: 0.92651757\n",
      "Epoch 4 of 500 took 0.396s\n",
      "Accuracy source 0.984730, main loss classifier 0.115496, source classification loss 0.064288, loss domain distinction 0.574787, accuracy domain distinction 0.508523\n",
      "VALIDATION Loss: 0.20697333 Acc: 0.90415335\n",
      "Epoch 5 of 500 took 0.395s\n",
      "Accuracy source 0.977273, main loss classifier 0.117994, source classification loss 0.073755, loss domain distinction 0.539790, accuracy domain distinction 0.494673\n",
      "VALIDATION Loss: 0.28420037 Acc: 0.87539936\n",
      "Epoch    44: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.394s\n",
      "Accuracy source 0.982244, main loss classifier 0.113112, source classification loss 0.067435, loss domain distinction 0.511856, accuracy domain distinction 0.499645\n",
      "VALIDATION Loss: 0.27798963 Acc: 0.89456869\n",
      "Epoch 7 of 500 took 0.407s\n",
      "Accuracy source 0.981534, main loss classifier 0.113370, source classification loss 0.068442, loss domain distinction 0.504453, accuracy domain distinction 0.494318\n",
      "VALIDATION Loss: 0.15763967 Acc: 0.92651757\n",
      "Epoch 8 of 500 took 0.399s\n",
      "Accuracy source 0.978693, main loss classifier 0.115590, source classification loss 0.071913, loss domain distinction 0.507273, accuracy domain distinction 0.495561\n",
      "VALIDATION Loss: 0.23139612 Acc: 0.91054313\n",
      "Epoch 9 of 500 took 0.395s\n",
      "Accuracy source 0.985085, main loss classifier 0.108985, source classification loss 0.060422, loss domain distinction 0.493019, accuracy domain distinction 0.502663\n",
      "VALIDATION Loss: 0.20741898 Acc: 0.91373802\n",
      "Epoch 10 of 500 took 0.396s\n",
      "Accuracy source 0.979759, main loss classifier 0.117045, source classification loss 0.076890, loss domain distinction 0.490599, accuracy domain distinction 0.503729\n",
      "VALIDATION Loss: 0.36644590 Acc: 0.85623003\n",
      "Epoch 11 of 500 took 0.396s\n",
      "Accuracy source 0.982955, main loss classifier 0.110875, source classification loss 0.066744, loss domain distinction 0.474503, accuracy domain distinction 0.500000\n",
      "VALIDATION Loss: 0.26729658 Acc: 0.88498403\n",
      "Epoch    50: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Training complete in 0m 5s\n",
      "()\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy source 0.979403, main loss classifier 0.134644, source classification loss 0.071646, loss domain distinction 0.795857, accuracy domain distinction 0.499822\n",
      "VALIDATION Loss: 0.21237849 Acc: 0.91054313\n",
      "New best validation loss:  0.21237848699092865\n",
      "Epoch 1 of 500 took 0.397s\n",
      "Accuracy source 0.980114, main loss classifier 0.130679, source classification loss 0.074968, loss domain distinction 0.728075, accuracy domain distinction 0.508523\n",
      "VALIDATION Loss: 0.31271115 Acc: 0.87220447\n",
      "Epoch 2 of 500 took 0.393s\n",
      "Accuracy source 0.981179, main loss classifier 0.120492, source classification loss 0.062804, loss domain distinction 0.667305, accuracy domain distinction 0.507102\n",
      "VALIDATION Loss: 0.22237128 Acc: 0.91373802\n",
      "Epoch 3 of 500 took 0.392s\n",
      "Accuracy source 0.981179, main loss classifier 0.121640, source classification loss 0.069545, loss domain distinction 0.626223, accuracy domain distinction 0.493430\n",
      "VALIDATION Loss: 0.21701893 Acc: 0.91054313\n",
      "Epoch 4 of 500 took 0.394s\n",
      "Accuracy source 0.980114, main loss classifier 0.118640, source classification loss 0.071138, loss domain distinction 0.573701, accuracy domain distinction 0.502841\n",
      "VALIDATION Loss: 0.39771169 Acc: 0.85303514\n",
      "Epoch 5 of 500 took 0.394s\n",
      "Accuracy source 0.981179, main loss classifier 0.114094, source classification loss 0.064883, loss domain distinction 0.543272, accuracy domain distinction 0.491477\n",
      "VALIDATION Loss: 0.27851260 Acc: 0.8913738\n",
      "Epoch    44: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 6 of 500 took 0.394s\n",
      "Accuracy source 0.979048, main loss classifier 0.114175, source classification loss 0.068858, loss domain distinction 0.519431, accuracy domain distinction 0.497514\n",
      "VALIDATION Loss: 0.11029149 Acc: 0.96166134\n",
      "New best validation loss:  0.110291488468647\n",
      "Epoch 7 of 500 took 0.403s\n",
      "Accuracy source 0.979048, main loss classifier 0.116370, source classification loss 0.074572, loss domain distinction 0.506202, accuracy domain distinction 0.504261\n",
      "VALIDATION Loss: 0.17230657 Acc: 0.92651757\n",
      "Epoch 8 of 500 took 0.398s\n",
      "Accuracy source 0.979759, main loss classifier 0.113177, source classification loss 0.069181, loss domain distinction 0.497026, accuracy domain distinction 0.504972\n",
      "VALIDATION Loss: 0.25400010 Acc: 0.90095847\n",
      "Epoch 9 of 500 took 0.424s\n",
      "Accuracy source 0.984730, main loss classifier 0.108783, source classification loss 0.061296, loss domain distinction 0.487648, accuracy domain distinction 0.498935\n",
      "VALIDATION Loss: 0.23834170 Acc: 0.91054313\n",
      "Epoch 10 of 500 took 0.423s\n",
      "Accuracy source 0.984375, main loss classifier 0.109577, source classification loss 0.062760, loss domain distinction 0.486539, accuracy domain distinction 0.500178\n",
      "VALIDATION Loss: 0.49302712 Acc: 0.84345048\n",
      "Epoch 11 of 500 took 0.395s\n",
      "Accuracy source 0.980469, main loss classifier 0.113176, source classification loss 0.071235, loss domain distinction 0.477116, accuracy domain distinction 0.497159\n",
      "VALIDATION Loss: 0.43213168 Acc: 0.84664537\n",
      "Epoch    50: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.396s\n",
      "Accuracy source 0.979759, main loss classifier 0.110051, source classification loss 0.066380, loss domain distinction 0.465842, accuracy domain distinction 0.506392\n",
      "VALIDATION Loss: 0.23525511 Acc: 0.90415335\n",
      "Epoch 13 of 500 took 0.395s\n",
      "Accuracy source 0.978693, main loss classifier 0.113060, source classification loss 0.072378, loss domain distinction 0.471489, accuracy domain distinction 0.502663\n",
      "VALIDATION Loss: 0.38293442 Acc: 0.85942492\n",
      "Epoch 14 of 500 took 0.395s\n",
      "Accuracy source 0.979759, main loss classifier 0.112533, source classification loss 0.069509, loss domain distinction 0.472554, accuracy domain distinction 0.501065\n",
      "VALIDATION Loss: 0.37769055 Acc: 0.85942492\n",
      "Epoch 15 of 500 took 0.395s\n",
      "Accuracy source 0.981534, main loss classifier 0.112047, source classification loss 0.068931, loss domain distinction 0.473600, accuracy domain distinction 0.504084\n",
      "VALIDATION Loss: 0.26871130 Acc: 0.88178914\n",
      "Epoch 16 of 500 took 0.396s\n",
      "Accuracy source 0.980824, main loss classifier 0.109785, source classification loss 0.065916, loss domain distinction 0.465039, accuracy domain distinction 0.499290\n",
      "VALIDATION Loss: 0.20859638 Acc: 0.91054313\n",
      "Epoch 17 of 500 took 0.395s\n",
      "Accuracy source 0.982599, main loss classifier 0.109735, source classification loss 0.065033, loss domain distinction 0.468663, accuracy domain distinction 0.505682\n",
      "VALIDATION Loss: 0.28689733 Acc: 0.88498403\n",
      "Epoch    56: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Training complete in 0m 7s\n"
     ]
    }
   ],
   "source": [
    "train_DA_spectrograms(examples_datasets_train, labels_datasets_train, filter_size=None,\n",
    "                      num_kernels=num_neurons, algo_name=algo_name,\n",
    "                      path_weights_fine_tuning=path_weights_fine_tuning,\n",
    "                      gestures_to_remove=gestures_to_remove, number_of_classes=number_of_class,\n",
    "                      number_of_cycle_for_first_training=number_of_cycle_for_first_training,\n",
    "                      number_of_cycles_rest_of_training=number_of_cycles_rest_of_training,\n",
    "                      batch_size=128, spectrogram_model=False,\n",
    "                      feature_vector_input_length=feature_vector_input_length,\n",
    "                      path_weights_to_save_to=\"Weights_TSD/weights_\", learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1854, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1899, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1938, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1780, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1981, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1809, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1928, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1902, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  0  Session ID:  0  Accuracy:  0.9980276134122288\n",
      "Participant ID:  0  Session ID:  1  Accuracy:  0.6106194690265486\n",
      "Participant ID:  0  Session ID:  2  Accuracy:  0.7827715355805244\n",
      "Participant ID:  0  Session ID:  3  Accuracy:  0.6453765490943756\n",
      "ACCURACY PARTICIPANT:  [0.9980276134122288, 0.6106194690265486, 0.7827715355805244, 0.6453765490943756]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  1  Session ID:  0  Accuracy:  0.9954627949183303\n",
      "Participant ID:  1  Session ID:  1  Accuracy:  0.666351606805293\n",
      "Participant ID:  1  Session ID:  2  Accuracy:  0.7463556851311953\n",
      "Participant ID:  1  Session ID:  3  Accuracy:  0.8831041257367387\n",
      "ACCURACY PARTICIPANT:  [0.9954627949183303, 0.666351606805293, 0.7463556851311953, 0.8831041257367387]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "(4,)\n",
      "Participant ID:  2  Session ID:  0  Accuracy:  0.9970149253731343\n",
      "Participant ID:  2  Session ID:  1  Accuracy:  0.17366946778711484\n",
      "Participant ID:  2  Session ID:  2  Accuracy:  0.8430451127819549\n",
      "Participant ID:  2  Session ID:  3  Accuracy:  0.776735459662289\n",
      "ACCURACY PARTICIPANT:  [0.9970149253731343, 0.17366946778711484, 0.8430451127819549, 0.776735459662289]\n",
      "[0.99802761 0.61061947 0.78277154 0.64537655 0.99546279 0.66635161\n",
      " 0.74635569 0.88310413 0.99701493 0.17366947 0.84304511 0.77673546]\n",
      "[0.9980276134122288, 0.6106194690265486, 0.7827715355805244, 0.6453765490943756, 0.9954627949183303, 0.666351606805293, 0.7463556851311953, 0.8831041257367387, 0.9970149253731343, 0.17366946778711484, 0.8430451127819549, 0.776735459662289]\n",
      "OVERALL ACCURACY: 0.759877862109144\n"
     ]
    }
   ],
   "source": [
    "np.warnings.filterwarnings('error', category=np.VisibleDeprecationWarning)   \n",
    "test_network_DA_algorithm(examples_datasets_train, labels_datasets_train,\n",
    "                              feature_vector_input_length=feature_vector_input_length,\n",
    "                              num_neurons=num_neurons, path_weights_DA='Weights_TSD/weights_' + algo_name,\n",
    "                              algo_name=algo_name,\n",
    "                              path_weights_normal=path_weights_fine_tuning,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_class,\n",
    "                              cycle_to_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.610619</td>\n",
       "      <td>0.782772</td>\n",
       "      <td>0.645377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_1</th>\n",
       "      <td>0.995463</td>\n",
       "      <td>0.666352</td>\n",
       "      <td>0.746356</td>\n",
       "      <td>0.883104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_2</th>\n",
       "      <td>0.997015</td>\n",
       "      <td>0.173669</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>0.776735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0   0.998028   0.610619   0.782772   0.645377\n",
       "Participant_1   0.995463   0.666352   0.746356   0.883104\n",
       "Participant_2   0.997015   0.173669   0.843045   0.776735"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \".npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "DANN_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    DANN_acc[i] = acc\n",
    "DANN_acc_overall = np.mean(DANN_acc)\n",
    "DANN_df = pd.DataFrame(DANN_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "DANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"DANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SCADANN\n",
    "* start training using TSD_DNN model params for the first training seesion, then using DANN model params \n",
    "* first traning = labeled, others = pseudo labels \n",
    "    * train using one lebaled and n psuedo labeled (n = #session)\n",
    "* use all training data at once\n",
    "* pseudo_labels_heuristic\n",
    "    * window_stable_mode_length = 30 (hold stable for 1.5s)\n",
    "    * percentage_same_gesture_now_stable = 65% (remove examples that are likely to generate false pseudo labels)\n",
    "    * maximum_length_instability_gesture_transition = 40\n",
    "    * maximum_length_instability_same_gesture = 40 (remove examples that are unstable for more than 2s)\n",
    "* SCADANN loss (domain_loss_weight=1e-1)\n",
    "    * loss_domain_source = ((1 - alpha) * crossEntropyLoss(pred_domain_source, label_source_domain))\n",
    "    * loss_main_source = (0.5 * loss_source_class + domain_loss_weight * loss_domain_source)\n",
    "    * loss_domain_target = 0.5 * (crossEntropyLoss(pred_domain_target, label_target_domain))\n",
    "    * loss_main_target = (0.5 * loss_target_class + domain_loss_weight * loss_domain_target)\n",
    "    * loss_main = loss_main_source + loss_main_target\n",
    "    * loss_domain = loss_domain_source + loss_domain_target\n",
    "\n",
    "   \n",
    "\n",
    "### Weights_TSD/weights_THREE_CYCLES_11Gestures_SCADANN\n",
    "* beat_state_n.pt (n = # training session)\n",
    "    * epoch: #epochs\n",
    "    * model state_dict\n",
    "    * optimizer state_dict\n",
    "    * scheduler state_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LongTermClassificationMain.Models.TSD_neural_network import TSD_Network\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.training_loops_preparations import load_checkpoint\n",
    "from LongTermClassificationMain.PrepareAndLoadDataLongTerm.load_dataset_spectrogram_in_dataloader import \\\n",
    "    load_dataloaders_training_sessions\n",
    "from LongTermClassificationMain.TrainingsAndEvaluations.self_learning.self_learning_utils import \\\n",
    "    generate_dataloaders_for_SCADANN\n",
    "from LongTermClassificationMain.Models.model_training_self_learning import SCADANN_BN_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self_learning', 'utils_training_and_evaluation.py', 'training_loops_preparations.py', 'ForTrainingSessions', 'test_polar_plot.py', '__pycache__', 'ForEvaluationSessions']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG-master/LongTermClassificationMain/TrainingsAndEvaluations/ForTrainingSessions/TSD_DNN\")\n",
    "print(os.listdir(\"../../\"))\n",
    "from SCADANN_TSD_DNN_training_session import run_SCADANN_training_sessions, test_network_SLADANN\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Processed_datasets/TSD_features_set_training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "labels_datasets_train = dataset_training['labels_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [200, 200, 200]\n",
    "learning_rate = 0.002515\n",
    "feature_vector_input_length = 385\n",
    "gestures_to_remove = None\n",
    "number_of_classes = 11\n",
    "percentage_same_gesture_stable = 0.65  # 0.65 for 11 gestures, 0.85 for 7 gestures\n",
    "path_weight_to_save_to = \"Weights_TSD/weights_THREE_CYCLES_11Gestures_SCADANN\"\n",
    "path_weights_start_with = \"Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD\"\n",
    "path_weights_Normal_training = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "algo_name = \"SCADANN_THREE_CYCLES_11Gestures_TSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (2972, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3144, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3202, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3135, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (3300, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3177, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3153, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3093, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (3129, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (3209, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (3183, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (3150, 385)\n",
      "participants_train =  3\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42c83d1c10>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 6)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 6)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.5567010309278351   AFTER:  0.589041095890411  len before:  97   len after:  73\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5051546391752577   AFTER:  0.5694444444444444  len before:  97   len after:  72\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  43\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6494845360824743   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.0  len before:  97   len after:  54\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  0.8617021276595744   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  95   len after:  95\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6597938144329897  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.5344827586206896   AFTER:  1.0  len before:  58   len after:  31\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.38144329896907214   AFTER:  1.0  len before:  97   len after:  64\n",
      "BEFORE:  0.5773195876288659   AFTER:  0.6494845360824743  len before:  97   len after:  97\n",
      "BEFORE:  0.31683168316831684   AFTER:  0.0  len before:  101   len after:  80\n",
      "ACCURACY MODEL:  0.6618956743002544   Accuracy pseudo: 0.7978084128667373  len pseudo:  2829    len predictions 3144\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.848437, main loss classifier 0.729141, source accuracy 0.955357 source classification loss 0.150292, target accuracy 0.741518 target loss 1.061565 accuracy domain distinction 0.501786 loss domain distinction 1.232123,\n",
      "VALIDATION Loss: 0.80074780 Acc: 0.79328622\n",
      "New best validation loss:  0.8007477985488044\n",
      "Epoch 2 of 500 took 0.587s\n",
      "Accuracy total 0.855580, main loss classifier 0.643970, source accuracy 0.952679 source classification loss 0.150483, target accuracy 0.758482 target loss 0.896634 accuracy domain distinction 0.502679 loss domain distinction 1.204111,\n",
      "VALIDATION Loss: 0.65404900 Acc: 0.82155477\n",
      "New best validation loss:  0.6540490024619632\n",
      "Epoch 3 of 500 took 0.589s\n",
      "Accuracy total 0.871429, main loss classifier 0.590092, source accuracy 0.956696 source classification loss 0.135578, target accuracy 0.786161 target loss 0.807744 accuracy domain distinction 0.502009 loss domain distinction 1.184314,\n",
      "VALIDATION Loss: 0.56276954 Acc: 0.84275618\n",
      "New best validation loss:  0.5627695437934663\n",
      "Epoch 4 of 500 took 0.588s\n",
      "Accuracy total 0.871429, main loss classifier 0.601638, source accuracy 0.952679 source classification loss 0.153016, target accuracy 0.790179 target loss 0.814736 accuracy domain distinction 0.501563 loss domain distinction 1.177623,\n",
      "VALIDATION Loss: 0.61232045 Acc: 0.82685512\n",
      "Epoch 5 of 500 took 0.584s\n",
      "Accuracy total 0.876563, main loss classifier 0.582703, source accuracy 0.957143 source classification loss 0.146758, target accuracy 0.795982 target loss 0.785461 accuracy domain distinction 0.496875 loss domain distinction 1.165932,\n",
      "VALIDATION Loss: 0.59906783 Acc: 0.83038869\n",
      "Epoch 6 of 500 took 0.583s\n",
      "Accuracy total 0.877232, main loss classifier 0.588784, source accuracy 0.956696 source classification loss 0.152637, target accuracy 0.797768 target loss 0.793251 accuracy domain distinction 0.496875 loss domain distinction 1.158398,\n",
      "VALIDATION Loss: 0.56705825 Acc: 0.83922261\n",
      "Epoch 7 of 500 took 0.581s\n",
      "Accuracy total 0.882143, main loss classifier 0.545952, source accuracy 0.958929 source classification loss 0.146445, target accuracy 0.805357 target loss 0.716866 accuracy domain distinction 0.499330 loss domain distinction 1.142960,\n",
      "VALIDATION Loss: 0.53981689 Acc: 0.83568905\n",
      "New best validation loss:  0.5398168894979689\n",
      "Epoch 8 of 500 took 0.585s\n",
      "Accuracy total 0.880357, main loss classifier 0.544908, source accuracy 0.954911 source classification loss 0.149946, target accuracy 0.805804 target loss 0.712656 accuracy domain distinction 0.499554 loss domain distinction 1.136069,\n",
      "VALIDATION Loss: 0.58166632 Acc: 0.83922261\n",
      "Epoch 9 of 500 took 0.593s\n",
      "Accuracy total 0.887277, main loss classifier 0.518805, source accuracy 0.945982 source classification loss 0.157311, target accuracy 0.828571 target loss 0.655279 accuracy domain distinction 0.499554 loss domain distinction 1.125097,\n",
      "VALIDATION Loss: 0.55238887 Acc: 0.84982332\n",
      "Epoch 10 of 500 took 0.587s\n",
      "Accuracy total 0.884152, main loss classifier 0.552544, source accuracy 0.957589 source classification loss 0.165290, target accuracy 0.810714 target loss 0.713989 accuracy domain distinction 0.497991 loss domain distinction 1.129048,\n",
      "VALIDATION Loss: 0.53747267 Acc: 0.85865724\n",
      "New best validation loss:  0.5374726661377482\n",
      "Epoch 11 of 500 took 0.588s\n",
      "Accuracy total 0.890625, main loss classifier 0.521779, source accuracy 0.959821 source classification loss 0.162333, target accuracy 0.821429 target loss 0.655324 accuracy domain distinction 0.499107 loss domain distinction 1.129501,\n",
      "VALIDATION Loss: 0.57925862 Acc: 0.82155477\n",
      "Epoch 12 of 500 took 0.583s\n",
      "Accuracy total 0.884821, main loss classifier 0.536117, source accuracy 0.958929 source classification loss 0.156357, target accuracy 0.810714 target loss 0.692950 accuracy domain distinction 0.503348 loss domain distinction 1.114634,\n",
      "VALIDATION Loss: 0.52264614 Acc: 0.83922261\n",
      "New best validation loss:  0.5226461357540555\n",
      "Epoch 13 of 500 took 0.585s\n",
      "Accuracy total 0.886830, main loss classifier 0.513578, source accuracy 0.957589 source classification loss 0.156747, target accuracy 0.816071 target loss 0.645645 accuracy domain distinction 0.497991 loss domain distinction 1.123826,\n",
      "VALIDATION Loss: 0.59032189 Acc: 0.81978799\n",
      "Epoch 14 of 500 took 0.583s\n",
      "Accuracy total 0.885045, main loss classifier 0.512243, source accuracy 0.953571 source classification loss 0.157144, target accuracy 0.816518 target loss 0.645348 accuracy domain distinction 0.499554 loss domain distinction 1.109965,\n",
      "VALIDATION Loss: 0.55230167 Acc: 0.85512367\n",
      "Epoch 15 of 500 took 0.582s\n",
      "Accuracy total 0.886830, main loss classifier 0.514127, source accuracy 0.948661 source classification loss 0.160491, target accuracy 0.825000 target loss 0.644298 accuracy domain distinction 0.498437 loss domain distinction 1.117326,\n",
      "VALIDATION Loss: 0.49628110 Acc: 0.84452297\n",
      "New best validation loss:  0.49628110064400566\n",
      "Epoch 16 of 500 took 0.582s\n",
      "Accuracy total 0.895089, main loss classifier 0.494506, source accuracy 0.958929 source classification loss 0.146883, target accuracy 0.831250 target loss 0.619348 accuracy domain distinction 0.497545 loss domain distinction 1.113907,\n",
      "VALIDATION Loss: 0.49809281 Acc: 0.85159011\n",
      "Epoch 17 of 500 took 0.580s\n",
      "Accuracy total 0.896429, main loss classifier 0.490665, source accuracy 0.961161 source classification loss 0.146080, target accuracy 0.831696 target loss 0.611561 accuracy domain distinction 0.496875 loss domain distinction 1.118448,\n",
      "VALIDATION Loss: 0.58239477 Acc: 0.82862191\n",
      "Epoch 18 of 500 took 0.596s\n",
      "Accuracy total 0.888393, main loss classifier 0.509770, source accuracy 0.952232 source classification loss 0.165018, target accuracy 0.824554 target loss 0.635093 accuracy domain distinction 0.501339 loss domain distinction 1.097143,\n",
      "VALIDATION Loss: 0.46521399 Acc: 0.85512367\n",
      "New best validation loss:  0.4652139941851298\n",
      "Epoch 19 of 500 took 0.609s\n",
      "Accuracy total 0.892411, main loss classifier 0.494273, source accuracy 0.955357 source classification loss 0.151767, target accuracy 0.829464 target loss 0.615672 accuracy domain distinction 0.501786 loss domain distinction 1.105535,\n",
      "VALIDATION Loss: 0.46371654 Acc: 0.86219081\n",
      "New best validation loss:  0.4637165367603302\n",
      "Epoch 20 of 500 took 0.585s\n",
      "Accuracy total 0.895089, main loss classifier 0.484323, source accuracy 0.962500 source classification loss 0.144259, target accuracy 0.827679 target loss 0.603642 accuracy domain distinction 0.497321 loss domain distinction 1.103725,\n",
      "VALIDATION Loss: 0.51901333 Acc: 0.83568905\n",
      "Epoch 21 of 500 took 0.582s\n",
      "Accuracy total 0.896652, main loss classifier 0.485377, source accuracy 0.955804 source classification loss 0.144976, target accuracy 0.837500 target loss 0.603895 accuracy domain distinction 0.496429 loss domain distinction 1.109420,\n",
      "VALIDATION Loss: 0.43016869 Acc: 0.86042403\n",
      "New best validation loss:  0.4301686916086409\n",
      "Epoch 22 of 500 took 0.583s\n",
      "Accuracy total 0.888839, main loss classifier 0.485918, source accuracy 0.953125 source classification loss 0.158912, target accuracy 0.824554 target loss 0.592183 accuracy domain distinction 0.498437 loss domain distinction 1.103709,\n",
      "VALIDATION Loss: 0.49600812 Acc: 0.83922261\n",
      "Epoch 23 of 500 took 0.581s\n",
      "Accuracy total 0.893304, main loss classifier 0.481705, source accuracy 0.958929 source classification loss 0.155157, target accuracy 0.827679 target loss 0.588568 accuracy domain distinction 0.499107 loss domain distinction 1.098421,\n",
      "VALIDATION Loss: 0.44858260 Acc: 0.87102473\n",
      "Epoch 24 of 500 took 0.581s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.891071, main loss classifier 0.494064, source accuracy 0.958929 source classification loss 0.142988, target accuracy 0.823214 target loss 0.624358 accuracy domain distinction 0.499107 loss domain distinction 1.103915,\n",
      "VALIDATION Loss: 0.44557138 Acc: 0.8639576\n",
      "Epoch 25 of 500 took 0.581s\n",
      "Accuracy total 0.898884, main loss classifier 0.468244, source accuracy 0.959821 source classification loss 0.152708, target accuracy 0.837946 target loss 0.565766 accuracy domain distinction 0.501116 loss domain distinction 1.090069,\n",
      "VALIDATION Loss: 0.47632386 Acc: 0.86572438\n",
      "Epoch 26 of 500 took 0.588s\n",
      "Accuracy total 0.900000, main loss classifier 0.474855, source accuracy 0.958482 source classification loss 0.146848, target accuracy 0.841518 target loss 0.580906 accuracy domain distinction 0.501116 loss domain distinction 1.109779,\n",
      "VALIDATION Loss: 0.45290990 Acc: 0.84628975\n",
      "Epoch 27 of 500 took 0.586s\n",
      "Accuracy total 0.894866, main loss classifier 0.474374, source accuracy 0.955804 source classification loss 0.161878, target accuracy 0.833929 target loss 0.567664 accuracy domain distinction 0.499777 loss domain distinction 1.096028,\n",
      "VALIDATION Loss: 0.41474534 Acc: 0.86925795\n",
      "New best validation loss:  0.4147453424003389\n",
      "Epoch 28 of 500 took 0.587s\n",
      "Accuracy total 0.894420, main loss classifier 0.483612, source accuracy 0.951339 source classification loss 0.162097, target accuracy 0.837500 target loss 0.586972 accuracy domain distinction 0.501563 loss domain distinction 1.090773,\n",
      "VALIDATION Loss: 0.46695076 Acc: 0.84452297\n",
      "Epoch 29 of 500 took 0.581s\n",
      "Accuracy total 0.895759, main loss classifier 0.468614, source accuracy 0.961607 source classification loss 0.141899, target accuracy 0.829911 target loss 0.577696 accuracy domain distinction 0.500446 loss domain distinction 1.088161,\n",
      "VALIDATION Loss: 0.43790806 Acc: 0.84982332\n",
      "Epoch 30 of 500 took 0.582s\n",
      "Accuracy total 0.897321, main loss classifier 0.470072, source accuracy 0.957589 source classification loss 0.148984, target accuracy 0.837054 target loss 0.571067 accuracy domain distinction 0.497991 loss domain distinction 1.100472,\n",
      "VALIDATION Loss: 0.41462055 Acc: 0.86925795\n",
      "New best validation loss:  0.4146205501423942\n",
      "Epoch 31 of 500 took 0.582s\n",
      "Accuracy total 0.894420, main loss classifier 0.472552, source accuracy 0.959375 source classification loss 0.148574, target accuracy 0.829464 target loss 0.577725 accuracy domain distinction 0.499554 loss domain distinction 1.094023,\n",
      "VALIDATION Loss: 0.47805525 Acc: 0.86219081\n",
      "Epoch 32 of 500 took 0.581s\n",
      "Accuracy total 0.895536, main loss classifier 0.474012, source accuracy 0.955357 source classification loss 0.156790, target accuracy 0.835714 target loss 0.572341 accuracy domain distinction 0.501563 loss domain distinction 1.094467,\n",
      "VALIDATION Loss: 0.48420522 Acc: 0.86749117\n",
      "Epoch 33 of 500 took 0.583s\n",
      "Accuracy total 0.899330, main loss classifier 0.455520, source accuracy 0.955357 source classification loss 0.156907, target accuracy 0.843304 target loss 0.534211 accuracy domain distinction 0.497768 loss domain distinction 1.099611,\n",
      "VALIDATION Loss: 0.45229261 Acc: 0.84805654\n",
      "Epoch 34 of 500 took 0.583s\n",
      "Accuracy total 0.897321, main loss classifier 0.463092, source accuracy 0.952232 source classification loss 0.172006, target accuracy 0.842411 target loss 0.534700 accuracy domain distinction 0.500223 loss domain distinction 1.097387,\n",
      "VALIDATION Loss: 0.42819598 Acc: 0.85689046\n",
      "Epoch 35 of 500 took 0.594s\n",
      "Accuracy total 0.897321, main loss classifier 0.481130, source accuracy 0.954464 source classification loss 0.158365, target accuracy 0.840179 target loss 0.583194 accuracy domain distinction 0.498214 loss domain distinction 1.103505,\n",
      "VALIDATION Loss: 0.42557724 Acc: 0.87102473\n",
      "Epoch 36 of 500 took 0.585s\n",
      "Accuracy total 0.895536, main loss classifier 0.469176, source accuracy 0.955357 source classification loss 0.159243, target accuracy 0.835714 target loss 0.559862 accuracy domain distinction 0.498884 loss domain distinction 1.096233,\n",
      "VALIDATION Loss: 0.38848030 Acc: 0.87279152\n",
      "New best validation loss:  0.3884803007046382\n",
      "Epoch 37 of 500 took 0.583s\n",
      "Accuracy total 0.899554, main loss classifier 0.464473, source accuracy 0.962500 source classification loss 0.140500, target accuracy 0.836607 target loss 0.570548 accuracy domain distinction 0.496205 loss domain distinction 1.089492,\n",
      "VALIDATION Loss: 0.45214665 Acc: 0.85335689\n",
      "Epoch 38 of 500 took 0.613s\n",
      "Accuracy total 0.899107, main loss classifier 0.451972, source accuracy 0.957143 source classification loss 0.152904, target accuracy 0.841071 target loss 0.533853 accuracy domain distinction 0.499554 loss domain distinction 1.085929,\n",
      "VALIDATION Loss: 0.43385956 Acc: 0.85512367\n",
      "Epoch 39 of 500 took 0.582s\n",
      "Accuracy total 0.898214, main loss classifier 0.451122, source accuracy 0.958929 source classification loss 0.149218, target accuracy 0.837500 target loss 0.536054 accuracy domain distinction 0.499777 loss domain distinction 1.084859,\n",
      "VALIDATION Loss: 0.41444171 Acc: 0.85865724\n",
      "Epoch 40 of 500 took 0.589s\n",
      "Accuracy total 0.899554, main loss classifier 0.446583, source accuracy 0.958036 source classification loss 0.148785, target accuracy 0.841071 target loss 0.526678 accuracy domain distinction 0.498884 loss domain distinction 1.088511,\n",
      "VALIDATION Loss: 0.40762227 Acc: 0.87809187\n",
      "Epoch 41 of 500 took 0.598s\n",
      "Accuracy total 0.899107, main loss classifier 0.449797, source accuracy 0.958482 source classification loss 0.152915, target accuracy 0.839732 target loss 0.529693 accuracy domain distinction 0.502009 loss domain distinction 1.084928,\n",
      "VALIDATION Loss: 0.49365892 Acc: 0.8409894\n",
      "Epoch 42 of 500 took 0.584s\n",
      "Accuracy total 0.908259, main loss classifier 0.431335, source accuracy 0.963393 source classification loss 0.138283, target accuracy 0.853125 target loss 0.507123 accuracy domain distinction 0.498214 loss domain distinction 1.086317,\n",
      "VALIDATION Loss: 0.50320875 Acc: 0.85865724\n",
      "Epoch    42: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 43 of 500 took 0.588s\n",
      "Accuracy total 0.900446, main loss classifier 0.450531, source accuracy 0.960268 source classification loss 0.146031, target accuracy 0.840625 target loss 0.538413 accuracy domain distinction 0.500670 loss domain distinction 1.083099,\n",
      "VALIDATION Loss: 0.38923390 Acc: 0.87102473\n",
      "Epoch 44 of 500 took 0.588s\n",
      "Accuracy total 0.903571, main loss classifier 0.445539, source accuracy 0.961161 source classification loss 0.146332, target accuracy 0.845982 target loss 0.528045 accuracy domain distinction 0.497098 loss domain distinction 1.083503,\n",
      "VALIDATION Loss: 0.46817443 Acc: 0.85335689\n",
      "Epoch 45 of 500 took 0.587s\n",
      "Accuracy total 0.896429, main loss classifier 0.449210, source accuracy 0.956696 source classification loss 0.146658, target accuracy 0.836161 target loss 0.535160 accuracy domain distinction 0.501116 loss domain distinction 1.083012,\n",
      "VALIDATION Loss: 0.40757445 Acc: 0.8639576\n",
      "Epoch 46 of 500 took 0.592s\n",
      "Accuracy total 0.903571, main loss classifier 0.454676, source accuracy 0.959821 source classification loss 0.140948, target accuracy 0.847321 target loss 0.550700 accuracy domain distinction 0.499107 loss domain distinction 1.088512,\n",
      "VALIDATION Loss: 0.40708485 Acc: 0.86925795\n",
      "Epoch 47 of 500 took 0.586s\n",
      "Accuracy total 0.904018, main loss classifier 0.435361, source accuracy 0.956250 source classification loss 0.158436, target accuracy 0.851786 target loss 0.494334 accuracy domain distinction 0.498661 loss domain distinction 1.089762,\n",
      "VALIDATION Loss: 0.43568156 Acc: 0.85512367\n",
      "Epoch 48 of 500 took 0.584s\n",
      "Training complete in 0m 28s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42c8d13b30>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 6)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 2)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.5567010309278351   AFTER:  0.589041095890411  len before:  97   len after:  73\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5051546391752577   AFTER:  0.5694444444444444  len before:  97   len after:  72\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  43\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6494845360824743   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.0  len before:  97   len after:  54\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8617021276595744   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  95   len after:  95\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6597938144329897  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.5344827586206896   AFTER:  1.0  len before:  58   len after:  31\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.38144329896907214   AFTER:  1.0  len before:  97   len after:  64\n",
      "BEFORE:  0.5773195876288659   AFTER:  0.6494845360824743  len before:  97   len after:  97\n",
      "BEFORE:  0.31683168316831684   AFTER:  0.0  len before:  101   len after:  80\n",
      "ACCURACY MODEL:  0.6618956743002544   Accuracy pseudo: 0.7978084128667373  len pseudo:  2829    len predictions 3144\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.3917525773195876   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.16494845360824742   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5288461538461539   AFTER:  0.3557692307692308  len before:  104   len after:  104\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5567010309278351   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.7932542161149282   Accuracy pseudo: 0.8383233532934131  len pseudo:  3006    len predictions 3202\n",
      "STARTING TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/laiy/.local/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.863176, main loss classifier 0.596946, source accuracy 0.845861 source classification loss 0.565268, target accuracy 0.880490 target loss 0.407493 accuracy domain distinction 0.494721 loss domain distinction 1.105657,\n",
      "VALIDATION Loss: 0.24803407 Acc: 0.93853821\n",
      "New best validation loss:  0.24803407043218612\n",
      "Epoch 2 of 500 took 0.623s\n",
      "Accuracy total 0.881757, main loss classifier 0.511560, source accuracy 0.864443 source classification loss 0.457709, target accuracy 0.899071 target loss 0.340847 accuracy domain distinction 0.497889 loss domain distinction 1.122815,\n",
      "VALIDATION Loss: 0.22878025 Acc: 0.93023256\n",
      "New best validation loss:  0.22878025397658347\n",
      "Epoch 3 of 500 took 0.619s\n",
      "Accuracy total 0.897804, main loss classifier 0.460349, source accuracy 0.885135 source classification loss 0.409046, target accuracy 0.910473 target loss 0.287741 accuracy domain distinction 0.498944 loss domain distinction 1.119552,\n",
      "VALIDATION Loss: 0.18879838 Acc: 0.9551495\n",
      "New best validation loss:  0.18879837691783904\n",
      "Epoch 4 of 500 took 0.629s\n",
      "Accuracy total 0.899071, main loss classifier 0.462169, source accuracy 0.888936 source classification loss 0.421824, target accuracy 0.909206 target loss 0.279818 accuracy domain distinction 0.497255 loss domain distinction 1.113487,\n",
      "VALIDATION Loss: 0.18278724 Acc: 0.94850498\n",
      "New best validation loss:  0.1827872395515442\n",
      "Epoch 5 of 500 took 0.627s\n",
      "Accuracy total 0.898649, main loss classifier 0.438464, source accuracy 0.889780 source classification loss 0.371365, target accuracy 0.907517 target loss 0.285677 accuracy domain distinction 0.502534 loss domain distinction 1.099434,\n",
      "VALIDATION Loss: 0.22208767 Acc: 0.94352159\n",
      "Epoch 6 of 500 took 0.630s\n",
      "Accuracy total 0.909206, main loss classifier 0.407944, source accuracy 0.897382 source classification loss 0.349771, target accuracy 0.921030 target loss 0.246488 accuracy domain distinction 0.497044 loss domain distinction 1.098137,\n",
      "VALIDATION Loss: 0.19527368 Acc: 0.94518272\n",
      "Epoch 7 of 500 took 0.617s\n",
      "Accuracy total 0.910051, main loss classifier 0.408850, source accuracy 0.897804 source classification loss 0.343416, target accuracy 0.922297 target loss 0.254774 accuracy domain distinction 0.500422 loss domain distinction 1.097548,\n",
      "VALIDATION Loss: 0.20082473 Acc: 0.94352159\n",
      "Epoch 8 of 500 took 0.623s\n",
      "Accuracy total 0.906250, main loss classifier 0.417111, source accuracy 0.891470 source classification loss 0.364734, target accuracy 0.921030 target loss 0.250051 accuracy domain distinction 0.499578 loss domain distinction 1.097184,\n",
      "VALIDATION Loss: 0.28953443 Acc: 0.89700997\n",
      "Epoch 9 of 500 took 0.616s\n",
      "Accuracy total 0.896748, main loss classifier 0.435626, source accuracy 0.876689 source classification loss 0.394031, target accuracy 0.916807 target loss 0.258713 accuracy domain distinction 0.500000 loss domain distinction 1.092542,\n",
      "VALIDATION Loss: 0.23393497 Acc: 0.93189369\n",
      "Epoch 10 of 500 took 0.623s\n",
      "Accuracy total 0.910473, main loss classifier 0.384201, source accuracy 0.897382 source classification loss 0.317562, target accuracy 0.923564 target loss 0.234460 accuracy domain distinction 0.498733 loss domain distinction 1.081899,\n",
      "VALIDATION Loss: 0.13874100 Acc: 0.96345515\n",
      "New best validation loss:  0.13874100260436534\n",
      "Epoch 11 of 500 took 0.620s\n",
      "Accuracy total 0.911106, main loss classifier 0.400028, source accuracy 0.896959 source classification loss 0.341740, target accuracy 0.925253 target loss 0.241681 accuracy domain distinction 0.500211 loss domain distinction 1.083170,\n",
      "VALIDATION Loss: 0.19322564 Acc: 0.96345515\n",
      "Epoch 12 of 500 took 0.632s\n",
      "Accuracy total 0.913429, main loss classifier 0.402135, source accuracy 0.902872 source classification loss 0.331783, target accuracy 0.923986 target loss 0.254948 accuracy domain distinction 0.499578 loss domain distinction 1.087697,\n",
      "VALIDATION Loss: 0.19815486 Acc: 0.92857143\n",
      "Epoch 13 of 500 took 0.618s\n",
      "Accuracy total 0.917652, main loss classifier 0.370472, source accuracy 0.904983 source classification loss 0.304031, target accuracy 0.930321 target loss 0.220604 accuracy domain distinction 0.500211 loss domain distinction 1.081546,\n",
      "VALIDATION Loss: 0.15017914 Acc: 0.95847176\n",
      "Epoch 14 of 500 took 0.618s\n",
      "Accuracy total 0.922720, main loss classifier 0.376321, source accuracy 0.911740 source classification loss 0.309950, target accuracy 0.933699 target loss 0.225102 accuracy domain distinction 0.501478 loss domain distinction 1.087953,\n",
      "VALIDATION Loss: 0.15674118 Acc: 0.96013289\n",
      "Epoch 15 of 500 took 0.618s\n",
      "Accuracy total 0.918708, main loss classifier 0.375465, source accuracy 0.908361 source classification loss 0.304362, target accuracy 0.929054 target loss 0.230300 accuracy domain distinction 0.499155 loss domain distinction 1.081343,\n",
      "VALIDATION Loss: 0.17987195 Acc: 0.93853821\n",
      "Epoch 16 of 500 took 0.616s\n",
      "Accuracy total 0.923986, main loss classifier 0.354241, source accuracy 0.906672 source classification loss 0.296887, target accuracy 0.941301 target loss 0.196596 accuracy domain distinction 0.498944 loss domain distinction 1.074991,\n",
      "VALIDATION Loss: 0.17616286 Acc: 0.94684385\n",
      "Epoch    16: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 17 of 500 took 0.617s\n",
      "Accuracy total 0.922086, main loss classifier 0.362215, source accuracy 0.911318 source classification loss 0.287938, target accuracy 0.932855 target loss 0.221180 accuracy domain distinction 0.500211 loss domain distinction 1.076560,\n",
      "VALIDATION Loss: 0.12530022 Acc: 0.96345515\n",
      "New best validation loss:  0.12530022040009497\n",
      "Epoch 18 of 500 took 0.620s\n",
      "Accuracy total 0.923564, main loss classifier 0.365348, source accuracy 0.907095 source classification loss 0.294311, target accuracy 0.940034 target loss 0.221167 accuracy domain distinction 0.499367 loss domain distinction 1.076083,\n",
      "VALIDATION Loss: 0.16569000 Acc: 0.94850498\n",
      "Epoch 19 of 500 took 0.614s\n",
      "Accuracy total 0.917230, main loss classifier 0.366670, source accuracy 0.900338 source classification loss 0.306992, target accuracy 0.934122 target loss 0.211040 accuracy domain distinction 0.500000 loss domain distinction 1.076540,\n",
      "VALIDATION Loss: 0.13092995 Acc: 0.96677741\n",
      "Epoch 20 of 500 took 0.631s\n",
      "Accuracy total 0.918708, main loss classifier 0.377181, source accuracy 0.905405 source classification loss 0.329849, target accuracy 0.932010 target loss 0.208425 accuracy domain distinction 0.498944 loss domain distinction 1.080437,\n",
      "VALIDATION Loss: 0.17408450 Acc: 0.94684385\n",
      "Epoch 21 of 500 took 0.618s\n",
      "Accuracy total 0.920186, main loss classifier 0.362415, source accuracy 0.902449 source classification loss 0.307586, target accuracy 0.937922 target loss 0.202326 accuracy domain distinction 0.499578 loss domain distinction 1.074589,\n",
      "VALIDATION Loss: 0.15659979 Acc: 0.94850498\n",
      "Epoch 22 of 500 took 0.618s\n",
      "Accuracy total 0.920608, main loss classifier 0.371842, source accuracy 0.902872 source classification loss 0.313579, target accuracy 0.938345 target loss 0.217219 accuracy domain distinction 0.500211 loss domain distinction 1.064428,\n",
      "VALIDATION Loss: 0.16724344 Acc: 0.96179402\n",
      "Epoch 23 of 500 took 0.618s\n",
      "Accuracy total 0.920397, main loss classifier 0.362488, source accuracy 0.900338 source classification loss 0.314510, target accuracy 0.940456 target loss 0.197854 accuracy domain distinction 0.501056 loss domain distinction 1.063059,\n",
      "VALIDATION Loss: 0.14088996 Acc: 0.96677741\n",
      "Epoch    23: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 24 of 500 took 0.615s\n",
      "Accuracy total 0.923564, main loss classifier 0.364907, source accuracy 0.913851 source classification loss 0.305364, target accuracy 0.933277 target loss 0.209953 accuracy domain distinction 0.499155 loss domain distinction 1.072480,\n",
      "VALIDATION Loss: 0.15068818 Acc: 0.95016611\n",
      "Epoch 25 of 500 took 0.617s\n",
      "Accuracy total 0.921875, main loss classifier 0.365033, source accuracy 0.905828 source classification loss 0.299612, target accuracy 0.937922 target loss 0.215902 accuracy domain distinction 0.500000 loss domain distinction 1.072754,\n",
      "VALIDATION Loss: 0.20332046 Acc: 0.93687708\n",
      "Epoch 26 of 500 took 0.616s\n",
      "Accuracy total 0.926520, main loss classifier 0.351320, source accuracy 0.918497 source classification loss 0.280465, target accuracy 0.934544 target loss 0.209118 accuracy domain distinction 0.500000 loss domain distinction 1.065281,\n",
      "VALIDATION Loss: 0.16189340 Acc: 0.95681063\n",
      "Epoch 27 of 500 took 0.616s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.923142, main loss classifier 0.361149, source accuracy 0.908784 source classification loss 0.298888, target accuracy 0.937500 target loss 0.208120 accuracy domain distinction 0.499155 loss domain distinction 1.076449,\n",
      "VALIDATION Loss: 0.13833303 Acc: 0.95681063\n",
      "Epoch 28 of 500 took 0.624s\n",
      "Accuracy total 0.920186, main loss classifier 0.361484, source accuracy 0.905405 source classification loss 0.301806, target accuracy 0.934966 target loss 0.207309 accuracy domain distinction 0.500422 loss domain distinction 1.069266,\n",
      "VALIDATION Loss: 0.14072871 Acc: 0.96013289\n",
      "Epoch 29 of 500 took 0.621s\n",
      "Training complete in 0m 17s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42c8a71f20>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt' (epoch 3)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_0/best_state_0.pt' (epoch 36)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_1.pt' (epoch 6)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_2.pt' (epoch 2)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_0/best_state_3.pt' (epoch 3)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.5567010309278351   AFTER:  0.589041095890411  len before:  97   len after:  73\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5051546391752577   AFTER:  0.5694444444444444  len before:  97   len after:  72\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  43\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.989247311827957   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6494845360824743   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.23711340206185566   AFTER:  0.0  len before:  97   len after:  54\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8617021276595744   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  95   len after:  95\n",
      "BEFORE:  0.5360824742268041   AFTER:  0.6597938144329897  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  73\n",
      "BEFORE:  0.5344827586206896   AFTER:  1.0  len before:  58   len after:  31\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.38144329896907214   AFTER:  1.0  len before:  97   len after:  64\n",
      "BEFORE:  0.5773195876288659   AFTER:  0.6494845360824743  len before:  97   len after:  97\n",
      "BEFORE:  0.31683168316831684   AFTER:  0.0  len before:  101   len after:  80\n",
      "ACCURACY MODEL:  0.6618956743002544   Accuracy pseudo: 0.7978084128667373  len pseudo:  2829    len predictions 3144\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.3917525773195876   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.16494845360824742   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7319587628865979   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5288461538461539   AFTER:  0.3557692307692308  len before:  104   len after:  104\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9042553191489362   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.6808510638297872   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5567010309278351   AFTER:  0.6804123711340206  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.7932542161149282   Accuracy pseudo: 0.8383233532934131  len pseudo:  3006    len predictions 3202\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  77\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  44   len after:  44\n",
      "BEFORE:  0.7835051546391752   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6701030927835051   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.26804123711340205   AFTER:  0.5  len before:  97   len after:  60\n",
      "BEFORE:  0.8247422680412371   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.14432989690721648   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8316831683168316   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8829787234042553   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8846153846153846   AFTER:  1.0  len before:  104   len after:  104\n",
      "BEFORE:  0.6804123711340206   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.4714285714285714  len before:  97   len after:  70\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.21649484536082475   AFTER:  0.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7010309278350515   AFTER:  1.0  len before:  97   len after:  32\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9603960396039604   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5970149253731343   AFTER:  1.0  len before:  67   len after:  41\n",
      "BEFORE:  0.40594059405940597   AFTER:  0.4342105263157895  len before:  101   len after:  76\n",
      "BEFORE:  0.28865979381443296   AFTER:  0.44776119402985076  len before:  97   len after:  67\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.31958762886597936  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  70\n",
      "BEFORE:  0.0297029702970297   AFTER:  0.0  len before:  101   len after:  101\n",
      "ACCURACY MODEL:  0.7342902711323764   Accuracy pseudo: 0.8307045215562566  len pseudo:  2853    len predictions 3135\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.848214, main loss classifier 0.692682, source accuracy 0.855357 source classification loss 0.570876, target accuracy 0.841071 target loss 0.588379 accuracy domain distinction 0.501116 loss domain distinction 1.130546,\n",
      "VALIDATION Loss: 0.35734118 Acc: 0.89842382\n",
      "New best validation loss:  0.35734118190076614\n",
      "Epoch 2 of 500 took 0.587s\n",
      "Accuracy total 0.868527, main loss classifier 0.567676, source accuracy 0.865179 source classification loss 0.451178, target accuracy 0.871875 target loss 0.459559 accuracy domain distinction 0.498214 loss domain distinction 1.123070,\n",
      "VALIDATION Loss: 0.24562193 Acc: 0.92469352\n",
      "New best validation loss:  0.24562193039390776\n",
      "Epoch 3 of 500 took 0.588s\n",
      "Accuracy total 0.877009, main loss classifier 0.522588, source accuracy 0.879464 source classification loss 0.410363, target accuracy 0.874554 target loss 0.412589 accuracy domain distinction 0.502679 loss domain distinction 1.111118,\n",
      "VALIDATION Loss: 0.27432781 Acc: 0.90542907\n",
      "Epoch 4 of 500 took 0.591s\n",
      "Accuracy total 0.879241, main loss classifier 0.511023, source accuracy 0.876786 source classification loss 0.401680, target accuracy 0.881696 target loss 0.400856 accuracy domain distinction 0.498214 loss domain distinction 1.097551,\n",
      "VALIDATION Loss: 0.18874948 Acc: 0.94045534\n",
      "New best validation loss:  0.18874947643942303\n",
      "Epoch 5 of 500 took 0.588s\n",
      "Accuracy total 0.890625, main loss classifier 0.486218, source accuracy 0.893304 source classification loss 0.368991, target accuracy 0.887946 target loss 0.384557 accuracy domain distinction 0.499330 loss domain distinction 1.094436,\n",
      "VALIDATION Loss: 0.21241319 Acc: 0.92644483\n",
      "Epoch 6 of 500 took 0.586s\n",
      "Accuracy total 0.888616, main loss classifier 0.484019, source accuracy 0.884821 source classification loss 0.382483, target accuracy 0.892411 target loss 0.364222 accuracy domain distinction 0.498214 loss domain distinction 1.106666,\n",
      "VALIDATION Loss: 0.23097068 Acc: 0.92294221\n",
      "Epoch 7 of 500 took 0.588s\n",
      "Accuracy total 0.901116, main loss classifier 0.444671, source accuracy 0.899554 source classification loss 0.346269, target accuracy 0.902679 target loss 0.323158 accuracy domain distinction 0.500000 loss domain distinction 1.099571,\n",
      "VALIDATION Loss: 0.20468751 Acc: 0.92994746\n",
      "Epoch 8 of 500 took 0.596s\n",
      "Accuracy total 0.898214, main loss classifier 0.444062, source accuracy 0.887054 source classification loss 0.362573, target accuracy 0.909375 target loss 0.306766 accuracy domain distinction 0.498884 loss domain distinction 1.093916,\n",
      "VALIDATION Loss: 0.17672636 Acc: 0.94220665\n",
      "New best validation loss:  0.17672635863224664\n",
      "Epoch 9 of 500 took 0.589s\n",
      "Accuracy total 0.894420, main loss classifier 0.455221, source accuracy 0.890625 source classification loss 0.339202, target accuracy 0.898214 target loss 0.354887 accuracy domain distinction 0.498214 loss domain distinction 1.081768,\n",
      "VALIDATION Loss: 0.21215187 Acc: 0.93870403\n",
      "Epoch 10 of 500 took 0.586s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.903795, main loss classifier 0.436596, source accuracy 0.893304 source classification loss 0.351960, target accuracy 0.914286 target loss 0.305665 accuracy domain distinction 0.500893 loss domain distinction 1.077833,\n",
      "VALIDATION Loss: 0.19737449 Acc: 0.94045534\n",
      "Epoch 11 of 500 took 0.595s\n",
      "Accuracy total 0.907366, main loss classifier 0.405145, source accuracy 0.908482 source classification loss 0.289143, target accuracy 0.906250 target loss 0.304169 accuracy domain distinction 0.498884 loss domain distinction 1.084888,\n",
      "VALIDATION Loss: 0.17096031 Acc: 0.95271454\n",
      "New best validation loss:  0.17096030629343456\n",
      "Epoch 12 of 500 took 0.588s\n",
      "Accuracy total 0.909598, main loss classifier 0.415642, source accuracy 0.907589 source classification loss 0.319890, target accuracy 0.911607 target loss 0.293123 accuracy domain distinction 0.500223 loss domain distinction 1.091354,\n",
      "VALIDATION Loss: 0.19582330 Acc: 0.9352014\n",
      "Epoch 13 of 500 took 0.591s\n",
      "Accuracy total 0.900000, main loss classifier 0.435045, source accuracy 0.899554 source classification loss 0.332448, target accuracy 0.900446 target loss 0.322622 accuracy domain distinction 0.498214 loss domain distinction 1.075100,\n",
      "VALIDATION Loss: 0.19545953 Acc: 0.94570928\n",
      "Epoch 14 of 500 took 0.588s\n",
      "Accuracy total 0.901786, main loss classifier 0.430127, source accuracy 0.895982 source classification loss 0.352406, target accuracy 0.907589 target loss 0.292161 accuracy domain distinction 0.500000 loss domain distinction 1.078442,\n",
      "VALIDATION Loss: 0.15208793 Acc: 0.95621716\n",
      "New best validation loss:  0.15208793017599317\n",
      "Epoch 15 of 500 took 0.588s\n",
      "Accuracy total 0.909821, main loss classifier 0.405088, source accuracy 0.902679 source classification loss 0.307219, target accuracy 0.916964 target loss 0.286081 accuracy domain distinction 0.498884 loss domain distinction 1.084380,\n",
      "VALIDATION Loss: 0.22035905 Acc: 0.93345009\n",
      "Epoch 16 of 500 took 0.594s\n",
      "Accuracy total 0.909821, main loss classifier 0.418072, source accuracy 0.899107 source classification loss 0.353533, target accuracy 0.920536 target loss 0.268263 accuracy domain distinction 0.499107 loss domain distinction 1.071741,\n",
      "VALIDATION Loss: 0.16680940 Acc: 0.94570928\n",
      "Epoch 17 of 500 took 0.591s\n",
      "Accuracy total 0.916295, main loss classifier 0.395255, source accuracy 0.908929 source classification loss 0.301127, target accuracy 0.923661 target loss 0.276050 accuracy domain distinction 0.501116 loss domain distinction 1.066665,\n",
      "VALIDATION Loss: 0.22183026 Acc: 0.94045534\n",
      "Epoch 18 of 500 took 0.588s\n",
      "Accuracy total 0.914509, main loss classifier 0.401191, source accuracy 0.911607 source classification loss 0.303541, target accuracy 0.917411 target loss 0.286167 accuracy domain distinction 0.498437 loss domain distinction 1.063370,\n",
      "VALIDATION Loss: 0.15512305 Acc: 0.95271454\n",
      "Epoch 19 of 500 took 0.588s\n",
      "Accuracy total 0.905357, main loss classifier 0.416096, source accuracy 0.898661 source classification loss 0.329060, target accuracy 0.912054 target loss 0.289348 accuracy domain distinction 0.500000 loss domain distinction 1.068927,\n",
      "VALIDATION Loss: 0.16231924 Acc: 0.95621716\n",
      "Epoch 20 of 500 took 0.589s\n",
      "Accuracy total 0.908705, main loss classifier 0.408676, source accuracy 0.901786 source classification loss 0.334204, target accuracy 0.915625 target loss 0.268771 accuracy domain distinction 0.499777 loss domain distinction 1.071886,\n",
      "VALIDATION Loss: 0.14585262 Acc: 0.95796848\n",
      "New best validation loss:  0.14585262330041993\n",
      "Epoch 21 of 500 took 0.590s\n",
      "Accuracy total 0.920312, main loss classifier 0.378708, source accuracy 0.916964 source classification loss 0.285377, target accuracy 0.923661 target loss 0.258275 accuracy domain distinction 0.499554 loss domain distinction 1.068825,\n",
      "VALIDATION Loss: 0.16597179 Acc: 0.9474606\n",
      "Epoch 22 of 500 took 0.587s\n",
      "Accuracy total 0.909375, main loss classifier 0.398649, source accuracy 0.907143 source classification loss 0.293251, target accuracy 0.911607 target loss 0.292243 accuracy domain distinction 0.500446 loss domain distinction 1.059022,\n",
      "VALIDATION Loss: 0.19801821 Acc: 0.94921191\n",
      "Epoch 23 of 500 took 0.586s\n",
      "Accuracy total 0.921429, main loss classifier 0.383065, source accuracy 0.909375 source classification loss 0.297168, target accuracy 0.933482 target loss 0.255723 accuracy domain distinction 0.500446 loss domain distinction 1.066192,\n",
      "VALIDATION Loss: 0.15706508 Acc: 0.94921191\n",
      "Epoch 24 of 500 took 0.596s\n",
      "Accuracy total 0.911384, main loss classifier 0.400860, source accuracy 0.900446 source classification loss 0.322561, target accuracy 0.922321 target loss 0.266985 accuracy domain distinction 0.500446 loss domain distinction 1.060867,\n",
      "VALIDATION Loss: 0.14966086 Acc: 0.96322242\n",
      "Epoch 25 of 500 took 0.592s\n",
      "Accuracy total 0.922098, main loss classifier 0.382202, source accuracy 0.911607 source classification loss 0.293784, target accuracy 0.932589 target loss 0.258033 accuracy domain distinction 0.499554 loss domain distinction 1.062938,\n",
      "VALIDATION Loss: 0.17204182 Acc: 0.95271454\n",
      "Epoch 26 of 500 took 0.587s\n",
      "Accuracy total 0.915179, main loss classifier 0.391448, source accuracy 0.902679 source classification loss 0.327022, target accuracy 0.927679 target loss 0.244968 accuracy domain distinction 0.500000 loss domain distinction 1.054533,\n",
      "VALIDATION Loss: 0.18042032 Acc: 0.94570928\n",
      "Epoch    26: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 27 of 500 took 0.586s\n",
      "Accuracy total 0.917411, main loss classifier 0.374701, source accuracy 0.911607 source classification loss 0.280292, target accuracy 0.923214 target loss 0.258994 accuracy domain distinction 0.500223 loss domain distinction 1.050585,\n",
      "VALIDATION Loss: 0.13743382 Acc: 0.9614711\n",
      "New best validation loss:  0.13743381533357832\n",
      "Epoch 28 of 500 took 0.585s\n",
      "Accuracy total 0.920089, main loss classifier 0.364434, source accuracy 0.908929 source classification loss 0.288419, target accuracy 0.931250 target loss 0.229986 accuracy domain distinction 0.500223 loss domain distinction 1.052315,\n",
      "VALIDATION Loss: 0.15073125 Acc: 0.95971979\n",
      "Epoch 29 of 500 took 0.584s\n",
      "Accuracy total 0.923214, main loss classifier 0.353150, source accuracy 0.921429 source classification loss 0.260853, target accuracy 0.925000 target loss 0.235783 accuracy domain distinction 0.499554 loss domain distinction 1.048320,\n",
      "VALIDATION Loss: 0.15861700 Acc: 0.95621716\n",
      "Epoch 30 of 500 took 0.586s\n",
      "Accuracy total 0.917634, main loss classifier 0.370821, source accuracy 0.906250 source classification loss 0.289330, target accuracy 0.929018 target loss 0.241808 accuracy domain distinction 0.499330 loss domain distinction 1.052522,\n",
      "VALIDATION Loss: 0.16350012 Acc: 0.95271454\n",
      "Epoch 31 of 500 took 0.590s\n",
      "Accuracy total 0.926116, main loss classifier 0.357254, source accuracy 0.918304 source classification loss 0.266583, target accuracy 0.933929 target loss 0.237153 accuracy domain distinction 0.500000 loss domain distinction 1.053866,\n",
      "VALIDATION Loss: 0.20092296 Acc: 0.93169877\n",
      "Epoch 32 of 500 took 0.637s\n",
      "Accuracy total 0.916071, main loss classifier 0.383050, source accuracy 0.911607 source classification loss 0.297746, target accuracy 0.920536 target loss 0.257609 accuracy domain distinction 0.500446 loss domain distinction 1.053729,\n",
      "VALIDATION Loss: 0.15899647 Acc: 0.95446585\n",
      "Epoch 33 of 500 took 0.597s\n",
      "Accuracy total 0.923438, main loss classifier 0.351799, source accuracy 0.912946 source classification loss 0.270946, target accuracy 0.933929 target loss 0.221835 accuracy domain distinction 0.499554 loss domain distinction 1.054081,\n",
      "VALIDATION Loss: 0.14678636 Acc: 0.95621716\n",
      "Epoch    33: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 34 of 500 took 0.584s\n",
      "Accuracy total 0.920982, main loss classifier 0.363118, source accuracy 0.911161 source classification loss 0.284868, target accuracy 0.930804 target loss 0.230958 accuracy domain distinction 0.500446 loss domain distinction 1.052047,\n",
      "VALIDATION Loss: 0.14555877 Acc: 0.95446585\n",
      "Epoch 35 of 500 took 0.586s\n",
      "Accuracy total 0.925893, main loss classifier 0.360233, source accuracy 0.924107 source classification loss 0.259748, target accuracy 0.927679 target loss 0.250520 accuracy domain distinction 0.500223 loss domain distinction 1.050982,\n",
      "VALIDATION Loss: 0.15340066 Acc: 0.95271454\n",
      "Epoch 36 of 500 took 0.587s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.912500, main loss classifier 0.393433, source accuracy 0.900446 source classification loss 0.322773, target accuracy 0.924554 target loss 0.252542 accuracy domain distinction 0.500223 loss domain distinction 1.057759,\n",
      "VALIDATION Loss: 0.14942522 Acc: 0.95621716\n",
      "Epoch 37 of 500 took 0.585s\n",
      "Accuracy total 0.919866, main loss classifier 0.375445, source accuracy 0.908036 source classification loss 0.294249, target accuracy 0.931696 target loss 0.245478 accuracy domain distinction 0.500223 loss domain distinction 1.055819,\n",
      "VALIDATION Loss: 0.15799122 Acc: 0.95446585\n",
      "Epoch 38 of 500 took 0.584s\n",
      "Accuracy total 0.924777, main loss classifier 0.363091, source accuracy 0.918304 source classification loss 0.276734, target accuracy 0.931250 target loss 0.240497 accuracy domain distinction 0.501563 loss domain distinction 1.044760,\n",
      "VALIDATION Loss: 0.15468513 Acc: 0.95621716\n",
      "Epoch 39 of 500 took 0.584s\n",
      "Training complete in 0m 22s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42bcca8dd0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 14)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 14)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.7659574468085106   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.6702127659574468   AFTER:  1.0  len before:  94   len after:  69\n",
      "BEFORE:  0.18085106382978725   AFTER:  0.0  len before:  94   len after:  94\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.30927835051546393  len before:  97   len after:  97\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7872340425531915   AFTER:  1.0  len before:  94   len after:  66\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  0.9489795918367347   AFTER:  1.0  len before:  98   len after:  98\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9439252336448598   AFTER:  1.0  len before:  107   len after:  87\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6276595744680851   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.4931506849315068  len before:  97   len after:  73\n",
      "BEFORE:  0.35106382978723405   AFTER:  0.20212765957446807  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6597938144329897   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6741573033707865   AFTER:  1.0  len before:  89   len after:  47\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8617021276595744   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.5463917525773195   AFTER:  0.47058823529411764  len before:  97   len after:  68\n",
      "BEFORE:  0.6494845360824743   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  77\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3191489361702128   AFTER:  0.6  len before:  94   len after:  50\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.6984576644633302   Accuracy pseudo: 0.7887576083064805  len pseudo:  2793    len predictions 3177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Accuracy total 0.872013, main loss classifier 0.683488, source accuracy 0.984835 source classification loss 0.056084, target accuracy 0.759191 target loss 1.075270 accuracy domain distinction 0.494715 loss domain distinction 1.178109,\n",
      "VALIDATION Loss: 0.67427704 Acc: 0.82468694\n",
      "New best validation loss:  0.674277040693495\n",
      "Epoch 2 of 500 took 0.574s\n",
      "Accuracy total 0.868566, main loss classifier 0.674376, source accuracy 0.976562 source classification loss 0.067395, target accuracy 0.760570 target loss 1.048449 accuracy domain distinction 0.492647 loss domain distinction 1.164541,\n",
      "VALIDATION Loss: 1.17536616 Acc: 0.74060823\n",
      "Epoch 3 of 500 took 0.574s\n",
      "Accuracy total 0.874770, main loss classifier 0.657232, source accuracy 0.978860 source classification loss 0.065549, target accuracy 0.770680 target loss 1.015242 accuracy domain distinction 0.497243 loss domain distinction 1.168364,\n",
      "VALIDATION Loss: 1.16692461 Acc: 0.74060823\n",
      "Epoch 4 of 500 took 0.572s\n",
      "Accuracy total 0.871553, main loss classifier 0.690074, source accuracy 0.980699 source classification loss 0.060522, target accuracy 0.762408 target loss 1.082441 accuracy domain distinction 0.484835 loss domain distinction 1.185924,\n",
      "VALIDATION Loss: 1.03637018 Acc: 0.75670841\n",
      "Epoch 5 of 500 took 0.572s\n",
      "Accuracy total 0.870175, main loss classifier 0.659138, source accuracy 0.977022 source classification loss 0.068135, target accuracy 0.763327 target loss 1.011178 accuracy domain distinction 0.485754 loss domain distinction 1.194814,\n",
      "VALIDATION Loss: 0.92394310 Acc: 0.78711986\n",
      "Epoch 6 of 500 took 0.567s\n",
      "Accuracy total 0.872013, main loss classifier 0.646483, source accuracy 0.977941 source classification loss 0.073055, target accuracy 0.766085 target loss 0.983006 accuracy domain distinction 0.490579 loss domain distinction 1.184528,\n",
      "VALIDATION Loss: 0.93270399 Acc: 0.78890877\n",
      "Epoch 7 of 500 took 0.570s\n",
      "Accuracy total 0.875689, main loss classifier 0.663570, source accuracy 0.982077 source classification loss 0.057875, target accuracy 0.769301 target loss 1.036135 accuracy domain distinction 0.486673 loss domain distinction 1.165653,\n",
      "VALIDATION Loss: 0.69693569 Acc: 0.82110912\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6096e-07.\n",
      "Epoch 8 of 500 took 0.571s\n",
      "Accuracy total 0.876379, main loss classifier 0.661532, source accuracy 0.984375 source classification loss 0.049704, target accuracy 0.768382 target loss 1.038781 accuracy domain distinction 0.494715 loss domain distinction 1.172895,\n",
      "VALIDATION Loss: 1.01452891 Acc: 0.75849732\n",
      "Epoch 9 of 500 took 0.570s\n",
      "Accuracy total 0.877987, main loss classifier 0.640844, source accuracy 0.981158 source classification loss 0.069108, target accuracy 0.774816 target loss 0.977942 accuracy domain distinction 0.488511 loss domain distinction 1.173193,\n",
      "VALIDATION Loss: 0.92259978 Acc: 0.7763864\n",
      "Epoch 10 of 500 took 0.571s\n",
      "Accuracy total 0.876379, main loss classifier 0.649777, source accuracy 0.981618 source classification loss 0.066574, target accuracy 0.771140 target loss 0.998660 accuracy domain distinction 0.495175 loss domain distinction 1.171596,\n",
      "VALIDATION Loss: 0.69979404 Acc: 0.83005367\n",
      "Epoch 11 of 500 took 0.569s\n",
      "Accuracy total 0.880055, main loss classifier 0.639376, source accuracy 0.983456 source classification loss 0.049779, target accuracy 0.776654 target loss 0.993986 accuracy domain distinction 0.490579 loss domain distinction 1.174938,\n",
      "VALIDATION Loss: 0.66382276 Acc: 0.83899821\n",
      "New best validation loss:  0.663822763495975\n",
      "Epoch 12 of 500 took 0.579s\n",
      "Accuracy total 0.873851, main loss classifier 0.670370, source accuracy 0.981158 source classification loss 0.068616, target accuracy 0.766544 target loss 1.032500 accuracy domain distinction 0.486213 loss domain distinction 1.198118,\n",
      "VALIDATION Loss: 0.71217455 Acc: 0.83363148\n",
      "Epoch 13 of 500 took 0.569s\n",
      "Accuracy total 0.876149, main loss classifier 0.651716, source accuracy 0.979779 source classification loss 0.064776, target accuracy 0.772518 target loss 1.004262 accuracy domain distinction 0.491728 loss domain distinction 1.171969,\n",
      "VALIDATION Loss: 1.03450447 Acc: 0.76923077\n",
      "Epoch 14 of 500 took 0.572s\n",
      "Accuracy total 0.872702, main loss classifier 0.639676, source accuracy 0.982537 source classification loss 0.059573, target accuracy 0.762868 target loss 0.983655 accuracy domain distinction 0.486903 loss domain distinction 1.180621,\n",
      "VALIDATION Loss: 0.95399397 Acc: 0.77280859\n",
      "Epoch 15 of 500 took 0.569s\n",
      "Accuracy total 0.875230, main loss classifier 0.662844, source accuracy 0.980239 source classification loss 0.063809, target accuracy 0.770221 target loss 1.025301 accuracy domain distinction 0.485064 loss domain distinction 1.182897,\n",
      "VALIDATION Loss: 0.84321135 Acc: 0.79964222\n",
      "Epoch 16 of 500 took 0.571s\n",
      "Accuracy total 0.876379, main loss classifier 0.653751, source accuracy 0.977022 source classification loss 0.072503, target accuracy 0.775735 target loss 0.996921 accuracy domain distinction 0.493336 loss domain distinction 1.190390,\n",
      "VALIDATION Loss: 0.78284618 Acc: 0.79785331\n",
      "Epoch 17 of 500 took 0.572s\n",
      "Accuracy total 0.882353, main loss classifier 0.636234, source accuracy 0.981618 source classification loss 0.062095, target accuracy 0.783088 target loss 0.973240 accuracy domain distinction 0.490579 loss domain distinction 1.185659,\n",
      "VALIDATION Loss: 0.93508956 Acc: 0.78354204\n",
      "Epoch    17: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 18 of 500 took 0.570s\n",
      "Accuracy total 0.871553, main loss classifier 0.646502, source accuracy 0.979320 source classification loss 0.059222, target accuracy 0.763787 target loss 0.998360 accuracy domain distinction 0.494256 loss domain distinction 1.177110,\n",
      "VALIDATION Loss: 0.69998993 Acc: 0.83899821\n",
      "Epoch 19 of 500 took 0.570s\n",
      "Accuracy total 0.874770, main loss classifier 0.666944, source accuracy 0.984375 source classification loss 0.059420, target accuracy 0.765165 target loss 1.038329 accuracy domain distinction 0.493566 loss domain distinction 1.180696,\n",
      "VALIDATION Loss: 0.64254477 Acc: 0.84257603\n",
      "New best validation loss:  0.6425447695785098\n",
      "Epoch 20 of 500 took 0.572s\n",
      "Accuracy total 0.876149, main loss classifier 0.638831, source accuracy 0.979779 source classification loss 0.067846, target accuracy 0.772518 target loss 0.972748 accuracy domain distinction 0.490119 loss domain distinction 1.185341,\n",
      "VALIDATION Loss: 0.90811343 Acc: 0.77996422\n",
      "Epoch 21 of 500 took 0.580s\n",
      "Accuracy total 0.877757, main loss classifier 0.662171, source accuracy 0.983456 source classification loss 0.063981, target accuracy 0.772059 target loss 1.025057 accuracy domain distinction 0.500689 loss domain distinction 1.176519,\n",
      "VALIDATION Loss: 0.78174361 Acc: 0.80143113\n",
      "Epoch 22 of 500 took 0.569s\n",
      "Accuracy total 0.873851, main loss classifier 0.656247, source accuracy 0.985754 source classification loss 0.058578, target accuracy 0.761949 target loss 1.018952 accuracy domain distinction 0.495404 loss domain distinction 1.174817,\n",
      "VALIDATION Loss: 0.88391658 Acc: 0.79069767\n",
      "Epoch 23 of 500 took 0.569s\n",
      "Accuracy total 0.881664, main loss classifier 0.640611, source accuracy 0.981618 source classification loss 0.062349, target accuracy 0.781710 target loss 0.981056 accuracy domain distinction 0.485294 loss domain distinction 1.189090,\n",
      "VALIDATION Loss: 0.89450737 Acc: 0.77817531\n",
      "Epoch 24 of 500 took 0.570s\n",
      "Accuracy total 0.870404, main loss classifier 0.643112, source accuracy 0.982996 source classification loss 0.066132, target accuracy 0.757812 target loss 0.984059 accuracy domain distinction 0.489430 loss domain distinction 1.180169,\n",
      "VALIDATION Loss: 0.80045560 Acc: 0.80322004\n",
      "Epoch 25 of 500 took 0.567s\n",
      "Accuracy total 0.875689, main loss classifier 0.637798, source accuracy 0.978860 source classification loss 0.065096, target accuracy 0.772518 target loss 0.972357 accuracy domain distinction 0.486213 loss domain distinction 1.190716,\n",
      "VALIDATION Loss: 0.63425466 Acc: 0.85867621\n",
      "New best validation loss:  0.6342546575599246\n",
      "Epoch 26 of 500 took 0.571s\n",
      "Accuracy total 0.875460, main loss classifier 0.646561, source accuracy 0.977941 source classification loss 0.075452, target accuracy 0.772978 target loss 0.984682 accuracy domain distinction 0.496553 loss domain distinction 1.164936,\n",
      "VALIDATION Loss: 0.73430525 Acc: 0.8157424\n",
      "Epoch 27 of 500 took 0.569s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.877757, main loss classifier 0.633004, source accuracy 0.979779 source classification loss 0.063057, target accuracy 0.775735 target loss 0.966736 accuracy domain distinction 0.491039 loss domain distinction 1.181076,\n",
      "VALIDATION Loss: 0.70365380 Acc: 0.83899821\n",
      "Epoch 28 of 500 took 0.570s\n",
      "Accuracy total 0.871094, main loss classifier 0.668156, source accuracy 0.980699 source classification loss 0.067698, target accuracy 0.761489 target loss 1.031463 accuracy domain distinction 0.487592 loss domain distinction 1.185762,\n",
      "VALIDATION Loss: 0.93777250 Acc: 0.76565295\n",
      "Epoch 29 of 500 took 0.578s\n",
      "Accuracy total 0.875689, main loss classifier 0.628527, source accuracy 0.984375 source classification loss 0.053477, target accuracy 0.767004 target loss 0.969924 accuracy domain distinction 0.495175 loss domain distinction 1.168260,\n",
      "VALIDATION Loss: 0.77455992 Acc: 0.81216458\n",
      "Epoch 30 of 500 took 0.573s\n",
      "Accuracy total 0.884421, main loss classifier 0.626963, source accuracy 0.988511 source classification loss 0.049381, target accuracy 0.780331 target loss 0.970713 accuracy domain distinction 0.498621 loss domain distinction 1.169165,\n",
      "VALIDATION Loss: 0.69340088 Acc: 0.82826476\n",
      "Epoch 31 of 500 took 0.572s\n",
      "Accuracy total 0.877987, main loss classifier 0.658107, source accuracy 0.980699 source classification loss 0.070974, target accuracy 0.775276 target loss 1.008365 accuracy domain distinction 0.485294 loss domain distinction 1.184373,\n",
      "VALIDATION Loss: 0.93951157 Acc: 0.79248658\n",
      "Epoch    31: reducing learning rate of group 0 to 6.4384e-09.\n",
      "Epoch 32 of 500 took 0.571s\n",
      "Accuracy total 0.875689, main loss classifier 0.656182, source accuracy 0.980699 source classification loss 0.064753, target accuracy 0.770680 target loss 1.011304 accuracy domain distinction 0.490579 loss domain distinction 1.181532,\n",
      "VALIDATION Loss: 0.81468644 Acc: 0.81037567\n",
      "Epoch 33 of 500 took 0.567s\n",
      "Accuracy total 0.875230, main loss classifier 0.668127, source accuracy 0.979779 source classification loss 0.063446, target accuracy 0.770680 target loss 1.037337 accuracy domain distinction 0.487822 loss domain distinction 1.177359,\n",
      "VALIDATION Loss: 0.67685625 Acc: 0.84973166\n",
      "Epoch 34 of 500 took 0.569s\n",
      "Accuracy total 0.876608, main loss classifier 0.648043, source accuracy 0.981158 source classification loss 0.064413, target accuracy 0.772059 target loss 0.997270 accuracy domain distinction 0.480699 loss domain distinction 1.172013,\n",
      "VALIDATION Loss: 0.93168881 Acc: 0.76923077\n",
      "Epoch 35 of 500 took 0.569s\n",
      "Accuracy total 0.874770, main loss classifier 0.658062, source accuracy 0.980239 source classification loss 0.064757, target accuracy 0.769301 target loss 1.018174 accuracy domain distinction 0.495634 loss domain distinction 1.165965,\n",
      "VALIDATION Loss: 0.59115596 Acc: 0.85509839\n",
      "New best validation loss:  0.591155962811576\n",
      "Epoch 36 of 500 took 0.575s\n",
      "Accuracy total 0.877068, main loss classifier 0.644874, source accuracy 0.984835 source classification loss 0.055118, target accuracy 0.769301 target loss 0.999867 accuracy domain distinction 0.493566 loss domain distinction 1.173815,\n",
      "VALIDATION Loss: 0.92129478 Acc: 0.7745975\n",
      "Epoch 37 of 500 took 0.576s\n",
      "Accuracy total 0.866958, main loss classifier 0.658436, source accuracy 0.977022 source classification loss 0.068940, target accuracy 0.756893 target loss 1.011206 accuracy domain distinction 0.494256 loss domain distinction 1.183634,\n",
      "VALIDATION Loss: 0.89144423 Acc: 0.78890877\n",
      "Epoch 38 of 500 took 0.577s\n",
      "Accuracy total 0.875689, main loss classifier 0.651554, source accuracy 0.979320 source classification loss 0.069660, target accuracy 0.772059 target loss 0.996453 accuracy domain distinction 0.488971 loss domain distinction 1.184975,\n",
      "VALIDATION Loss: 0.86850571 Acc: 0.7960644\n",
      "Epoch 39 of 500 took 0.573s\n",
      "Accuracy total 0.876838, main loss classifier 0.652599, source accuracy 0.980239 source classification loss 0.063588, target accuracy 0.773438 target loss 1.007101 accuracy domain distinction 0.496553 loss domain distinction 1.172539,\n",
      "VALIDATION Loss: 1.09971865 Acc: 0.76207513\n",
      "Epoch 40 of 500 took 0.569s\n",
      "Accuracy total 0.873621, main loss classifier 0.642190, source accuracy 0.972886 source classification loss 0.079691, target accuracy 0.774357 target loss 0.967159 accuracy domain distinction 0.486673 loss domain distinction 1.187652,\n",
      "VALIDATION Loss: 1.19520655 Acc: 0.74239714\n",
      "Epoch 41 of 500 took 0.564s\n",
      "Accuracy total 0.876838, main loss classifier 0.643258, source accuracy 0.979320 source classification loss 0.064430, target accuracy 0.774357 target loss 0.985754 accuracy domain distinction 0.490579 loss domain distinction 1.181656,\n",
      "VALIDATION Loss: 0.72877629 Acc: 0.81037567\n",
      "Epoch 42 of 500 took 0.568s\n",
      "Accuracy total 0.879366, main loss classifier 0.651865, source accuracy 0.983915 source classification loss 0.058940, target accuracy 0.774816 target loss 1.005479 accuracy domain distinction 0.482077 loss domain distinction 1.196551,\n",
      "VALIDATION Loss: 0.89318254 Acc: 0.78890877\n",
      "Epoch 43 of 500 took 0.570s\n",
      "Accuracy total 0.874081, main loss classifier 0.654436, source accuracy 0.978401 source classification loss 0.066760, target accuracy 0.769761 target loss 1.002777 accuracy domain distinction 0.482537 loss domain distinction 1.196676,\n",
      "VALIDATION Loss: 0.69765260 Acc: 0.82826476\n",
      "Epoch 44 of 500 took 0.566s\n",
      "Accuracy total 0.871783, main loss classifier 0.652404, source accuracy 0.984375 source classification loss 0.044589, target accuracy 0.759191 target loss 1.022786 accuracy domain distinction 0.489660 loss domain distinction 1.187165,\n",
      "VALIDATION Loss: 1.09508687 Acc: 0.75849732\n",
      "Epoch 45 of 500 took 0.569s\n",
      "Accuracy total 0.881204, main loss classifier 0.640436, source accuracy 0.980699 source classification loss 0.068434, target accuracy 0.781710 target loss 0.980423 accuracy domain distinction 0.497013 loss domain distinction 1.160079,\n",
      "VALIDATION Loss: 1.08236839 Acc: 0.77101968\n",
      "Epoch 46 of 500 took 0.704s\n",
      "Accuracy total 0.880055, main loss classifier 0.645163, source accuracy 0.981158 source classification loss 0.065743, target accuracy 0.778952 target loss 0.987791 accuracy domain distinction 0.485754 loss domain distinction 1.183961,\n",
      "VALIDATION Loss: 0.84440241 Acc: 0.7960644\n",
      "Epoch 47 of 500 took 0.638s\n",
      "Training complete in 0m 26s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42bcca8890>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt' (epoch 8)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 14)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt' (epoch 8)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.7659574468085106   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.6702127659574468   AFTER:  1.0  len before:  94   len after:  69\n",
      "BEFORE:  0.18085106382978725   AFTER:  0.0  len before:  94   len after:  94\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.30927835051546393  len before:  97   len after:  97\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7872340425531915   AFTER:  1.0  len before:  94   len after:  66\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  0.9489795918367347   AFTER:  1.0  len before:  98   len after:  98\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9439252336448598   AFTER:  1.0  len before:  107   len after:  87\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6276595744680851   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.4931506849315068  len before:  97   len after:  73\n",
      "BEFORE:  0.35106382978723405   AFTER:  0.20212765957446807  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6597938144329897   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6741573033707865   AFTER:  1.0  len before:  89   len after:  47\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8617021276595744   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.5463917525773195   AFTER:  0.47058823529411764  len before:  97   len after:  68\n",
      "BEFORE:  0.6494845360824743   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  77\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3191489361702128   AFTER:  0.6  len before:  94   len after:  50\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.6984576644633302   Accuracy pseudo: 0.7887576083064805  len pseudo:  2793    len predictions 3177\n",
      "HANDLING NEW SESSION  2\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.4536082474226804   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.4722222222222222  len before:  97   len after:  72\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.41237113402061853   AFTER:  0.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9285714285714286   AFTER:  1.0  len before:  98   len after:  71\n",
      "BEFORE:  0.422680412371134   AFTER:  0.4189189189189189  len before:  97   len after:  74\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.022222222222222223   AFTER:  0.0  len before:  90   len after:  66\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8723404255319149   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.963302752293578   AFTER:  1.0  len before:  109   len after:  109\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.978021978021978   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8020833333333334   AFTER:  1.0  len before:  96   len after:  75\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  65\n",
      "BEFORE:  0.4536082474226804   AFTER:  0.4805194805194805  len before:  97   len after:  77\n",
      "BEFORE:  0.8404255319148937   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  71   len after:  71\n",
      "BEFORE:  0.4639175257731959   AFTER:  1.0  len before:  97   len after:  32\n",
      "BEFORE:  0.9222222222222223   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.9801980198019802   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6494845360824743   AFTER:  0.5979381443298969  len before:  97   len after:  97\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9574468085106383   AFTER:  1.0  len before:  94   len after:  94\n",
      "ACCURACY MODEL:  0.78813828100222   Accuracy pseudo: 0.8585750089509488  len pseudo:  2793    len predictions 3153\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.857537, main loss classifier 0.739990, source accuracy 0.875919 source classification loss 0.506705, target accuracy 0.839154 target loss 0.734243 accuracy domain distinction 0.487822 loss domain distinction 1.195161,\n",
      "VALIDATION Loss: 0.60860666 Acc: 0.86046512\n",
      "New best validation loss:  0.6086066597037845\n",
      "Epoch 2 of 500 took 0.572s\n",
      "Accuracy total 0.859145, main loss classifier 0.719809, source accuracy 0.881893 source classification loss 0.472089, target accuracy 0.836397 target loss 0.730403 accuracy domain distinction 0.491039 loss domain distinction 1.185634,\n",
      "VALIDATION Loss: 0.57475285 Acc: 0.86583184\n",
      "New best validation loss:  0.5747528523206711\n",
      "Epoch 3 of 500 took 0.567s\n",
      "Accuracy total 0.864200, main loss classifier 0.706269, source accuracy 0.881434 source classification loss 0.446427, target accuracy 0.846967 target loss 0.727991 accuracy domain distinction 0.503217 loss domain distinction 1.190600,\n",
      "VALIDATION Loss: 0.54148237 Acc: 0.86940966\n",
      "New best validation loss:  0.5414823724163903\n",
      "Epoch 4 of 500 took 0.568s\n",
      "Accuracy total 0.867417, main loss classifier 0.705465, source accuracy 0.885110 source classification loss 0.456098, target accuracy 0.849724 target loss 0.718152 accuracy domain distinction 0.501608 loss domain distinction 1.183398,\n",
      "VALIDATION Loss: 0.61273979 Acc: 0.85867621\n",
      "Epoch 5 of 500 took 0.576s\n",
      "Accuracy total 0.860983, main loss classifier 0.719006, source accuracy 0.885110 source classification loss 0.471982, target accuracy 0.836857 target loss 0.727733 accuracy domain distinction 0.500460 loss domain distinction 1.191483,\n",
      "VALIDATION Loss: 0.48146829 Acc: 0.88550984\n",
      "New best validation loss:  0.48146828677919173\n",
      "Epoch 6 of 500 took 0.569s\n",
      "Accuracy total 0.869256, main loss classifier 0.689605, source accuracy 0.896599 source classification loss 0.423563, target accuracy 0.841912 target loss 0.719392 accuracy domain distinction 0.503447 loss domain distinction 1.181272,\n",
      "VALIDATION Loss: 0.50595044 Acc: 0.8765653\n",
      "Epoch 7 of 500 took 0.567s\n",
      "Accuracy total 0.865809, main loss classifier 0.662430, source accuracy 0.890625 source classification loss 0.391523, target accuracy 0.840993 target loss 0.696168 accuracy domain distinction 0.502298 loss domain distinction 1.185844,\n",
      "VALIDATION Loss: 0.56033396 Acc: 0.87119857\n",
      "Epoch 8 of 500 took 0.565s\n",
      "Accuracy total 0.867647, main loss classifier 0.684264, source accuracy 0.894301 source classification loss 0.424791, target accuracy 0.840993 target loss 0.709039 accuracy domain distinction 0.505055 loss domain distinction 1.173486,\n",
      "VALIDATION Loss: 0.48995042 Acc: 0.87119857\n",
      "Epoch 9 of 500 took 0.586s\n",
      "Accuracy total 0.865349, main loss classifier 0.665298, source accuracy 0.884191 source classification loss 0.418536, target accuracy 0.846507 target loss 0.673428 accuracy domain distinction 0.497702 loss domain distinction 1.193155,\n",
      "VALIDATION Loss: 0.59725440 Acc: 0.86046512\n",
      "Epoch 10 of 500 took 0.567s\n",
      "Accuracy total 0.873392, main loss classifier 0.653775, source accuracy 0.894301 source classification loss 0.399080, target accuracy 0.852482 target loss 0.675226 accuracy domain distinction 0.502987 loss domain distinction 1.166219,\n",
      "VALIDATION Loss: 0.51829436 Acc: 0.88014311\n",
      "Epoch 11 of 500 took 0.566s\n",
      "Accuracy total 0.866958, main loss classifier 0.707220, source accuracy 0.890165 source classification loss 0.434375, target accuracy 0.843750 target loss 0.745333 accuracy domain distinction 0.503906 loss domain distinction 1.173665,\n",
      "VALIDATION Loss: 0.56818636 Acc: 0.86940966\n",
      "Epoch    11: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 12 of 500 took 0.566s\n",
      "Accuracy total 0.865119, main loss classifier 0.680997, source accuracy 0.890165 source classification loss 0.419906, target accuracy 0.840074 target loss 0.710409 accuracy domain distinction 0.508502 loss domain distinction 1.158396,\n",
      "VALIDATION Loss: 0.56500176 Acc: 0.87119857\n",
      "Epoch 13 of 500 took 0.565s\n",
      "Accuracy total 0.858686, main loss classifier 0.721298, source accuracy 0.885570 source classification loss 0.441063, target accuracy 0.831801 target loss 0.767456 accuracy domain distinction 0.506664 loss domain distinction 1.170381,\n",
      "VALIDATION Loss: 0.50890225 Acc: 0.88372093\n",
      "Epoch 14 of 500 took 0.567s\n",
      "Accuracy total 0.861443, main loss classifier 0.701267, source accuracy 0.881893 source classification loss 0.453286, target accuracy 0.840993 target loss 0.712432 accuracy domain distinction 0.500230 loss domain distinction 1.184079,\n",
      "VALIDATION Loss: 0.51151947 Acc: 0.89087657\n",
      "Epoch 15 of 500 took 0.566s\n",
      "Accuracy total 0.861903, main loss classifier 0.705328, source accuracy 0.881893 source classification loss 0.451539, target accuracy 0.841912 target loss 0.726723 accuracy domain distinction 0.500689 loss domain distinction 1.161966,\n",
      "VALIDATION Loss: 0.50685772 Acc: 0.90161002\n",
      "Epoch 16 of 500 took 0.568s\n",
      "Accuracy total 0.875919, main loss classifier 0.657030, source accuracy 0.907629 source classification loss 0.377523, target accuracy 0.844210 target loss 0.702019 accuracy domain distinction 0.506664 loss domain distinction 1.172589,\n",
      "VALIDATION Loss: 0.50644670 Acc: 0.88014311\n",
      "Epoch 17 of 500 took 0.575s\n",
      "Training complete in 0m 9s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42bcca8a50>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt' (epoch 21)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_1/best_state_0.pt' (epoch 48)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_1.pt' (epoch 14)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_2.pt' (epoch 8)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_1/best_state_3.pt' (epoch 21)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.7659574468085106   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.6702127659574468   AFTER:  1.0  len before:  94   len after:  69\n",
      "BEFORE:  0.18085106382978725   AFTER:  0.0  len before:  94   len after:  94\n",
      "BEFORE:  0.3402061855670103   AFTER:  0.30927835051546393  len before:  97   len after:  97\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7872340425531915   AFTER:  1.0  len before:  94   len after:  66\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  0.9489795918367347   AFTER:  1.0  len before:  98   len after:  98\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9439252336448598   AFTER:  1.0  len before:  107   len after:  87\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6276595744680851   AFTER:  1.0  len before:  94   len after:  70\n",
      "BEFORE:  0.20618556701030927   AFTER:  0.4931506849315068  len before:  97   len after:  73\n",
      "BEFORE:  0.35106382978723405   AFTER:  0.20212765957446807  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6597938144329897   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6741573033707865   AFTER:  1.0  len before:  89   len after:  47\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8617021276595744   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.5463917525773195   AFTER:  0.47058823529411764  len before:  97   len after:  68\n",
      "BEFORE:  0.6494845360824743   AFTER:  0.6907216494845361  len before:  97   len after:  97\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  77\n",
      "BEFORE:  0.18556701030927836   AFTER:  0.0  len before:  97   len after:  37\n",
      "BEFORE:  0.9361702127659575   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.845360824742268   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3191489361702128   AFTER:  0.6  len before:  94   len after:  50\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.6984576644633302   Accuracy pseudo: 0.7887576083064805  len pseudo:  2793    len predictions 3177\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.4536082474226804   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3917525773195876   AFTER:  0.4722222222222222  len before:  97   len after:  72\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.7938144329896907   AFTER:  1.0  len before:  97   len after:  73\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.41237113402061853   AFTER:  0.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9285714285714286   AFTER:  1.0  len before:  98   len after:  71\n",
      "BEFORE:  0.422680412371134   AFTER:  0.4189189189189189  len before:  97   len after:  74\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.022222222222222223   AFTER:  0.0  len before:  90   len after:  66\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8723404255319149   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.963302752293578   AFTER:  1.0  len before:  109   len after:  109\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.978021978021978   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8020833333333334   AFTER:  1.0  len before:  96   len after:  75\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  65\n",
      "BEFORE:  0.4536082474226804   AFTER:  0.4805194805194805  len before:  97   len after:  77\n",
      "BEFORE:  0.8404255319148937   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  71   len after:  71\n",
      "BEFORE:  0.4639175257731959   AFTER:  1.0  len before:  97   len after:  32\n",
      "BEFORE:  0.9222222222222223   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.9801980198019802   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6494845360824743   AFTER:  0.5979381443298969  len before:  97   len after:  97\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9574468085106383   AFTER:  1.0  len before:  94   len after:  94\n",
      "ACCURACY MODEL:  0.78813828100222   Accuracy pseudo: 0.8585750089509488  len pseudo:  2793    len predictions 3153\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  0.8762886597938144   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.961038961038961   AFTER:  1.0  len before:  77   len after:  77\n",
      "BEFORE:  0.96875   AFTER:  1.0  len before:  96   len after:  96\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8555555555555555   AFTER:  1.0  len before:  90   len after:  65\n",
      "BEFORE:  0.865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9222222222222223   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.6595744680851063   AFTER:  0.6808510638297872  len before:  94   len after:  94\n",
      "BEFORE:  0.9468085106382979   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.8505747126436781   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.989010989010989   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.3711340206185567   AFTER:  0.3402061855670103  len before:  97   len after:  97\n",
      "BEFORE:  0.5876288659793815   AFTER:  0.6597938144329897  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8901098901098901   AFTER:  1.0  len before:  91   len after:  91\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9603960396039604   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8041237113402062   AFTER:  1.0  len before:  97   len after:  69\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.875   AFTER:  1.0  len before:  80   len after:  80\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5172413793103449   AFTER:  0.49230769230769234  len before:  87   len after:  65\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9468085106382979   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.6547619047619048   AFTER:  1.0  len before:  84   len after:  84\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  97\n",
      "ACCURACY MODEL:  0.8567733591981894   Accuracy pseudo: 0.9148442677269715  len pseudo:  3018    len predictions 3093\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.856419, main loss classifier 0.770020, source accuracy 0.865287 source classification loss 0.568998, target accuracy 0.847551 target loss 0.735191 accuracy domain distinction 0.502323 loss domain distinction 1.179257,\n",
      "VALIDATION Loss: 0.41238825 Acc: 0.91390728\n",
      "New best validation loss:  0.4123882457613945\n",
      "Epoch 2 of 500 took 0.640s\n",
      "Accuracy total 0.860642, main loss classifier 0.779266, source accuracy 0.856841 source classification loss 0.599387, target accuracy 0.864443 target loss 0.721373 accuracy domain distinction 0.506757 loss domain distinction 1.188863,\n",
      "VALIDATION Loss: 0.33406610 Acc: 0.91390728\n",
      "New best validation loss:  0.3340660989284515\n",
      "Epoch 3 of 500 took 0.621s\n",
      "Accuracy total 0.871622, main loss classifier 0.739743, source accuracy 0.877956 source classification loss 0.528490, target accuracy 0.865287 target loss 0.714947 accuracy domain distinction 0.501056 loss domain distinction 1.180248,\n",
      "VALIDATION Loss: 0.40390126 Acc: 0.91556291\n",
      "Epoch 4 of 500 took 0.620s\n",
      "Accuracy total 0.863176, main loss classifier 0.736398, source accuracy 0.870355 source classification loss 0.513005, target accuracy 0.855997 target loss 0.720901 accuracy domain distinction 0.506334 loss domain distinction 1.194450,\n",
      "VALIDATION Loss: 0.38035626 Acc: 0.90397351\n",
      "Epoch 5 of 500 took 0.621s\n",
      "Accuracy total 0.870777, main loss classifier 0.719621, source accuracy 0.880490 source classification loss 0.513967, target accuracy 0.861064 target loss 0.688233 accuracy domain distinction 0.502534 loss domain distinction 1.185211,\n",
      "VALIDATION Loss: 0.34388564 Acc: 0.91556291\n",
      "Epoch 6 of 500 took 0.619s\n",
      "Accuracy total 0.865921, main loss classifier 0.715663, source accuracy 0.864865 source classification loss 0.517700, target accuracy 0.866976 target loss 0.674580 accuracy domain distinction 0.505068 loss domain distinction 1.195230,\n",
      "VALIDATION Loss: 0.36934348 Acc: 0.90562914\n",
      "Epoch 7 of 500 took 0.621s\n",
      "Accuracy total 0.861909, main loss classifier 0.775891, source accuracy 0.860220 source classification loss 0.578100, target accuracy 0.863598 target loss 0.737025 accuracy domain distinction 0.507812 loss domain distinction 1.183287,\n",
      "VALIDATION Loss: 0.42069353 Acc: 0.90562914\n",
      "Epoch 8 of 500 took 0.618s\n",
      "Accuracy total 0.873522, main loss classifier 0.737543, source accuracy 0.872044 source classification loss 0.539055, target accuracy 0.875000 target loss 0.696145 accuracy domain distinction 0.503590 loss domain distinction 1.199429,\n",
      "VALIDATION Loss: 0.35437174 Acc: 0.91225166\n",
      "Epoch     8: reducing learning rate of group 0 to 3.2192e-08.\n",
      "Epoch 9 of 500 took 0.626s\n",
      "Accuracy total 0.867821, main loss classifier 0.718084, source accuracy 0.869932 source classification loss 0.482923, target accuracy 0.865709 target loss 0.717250 accuracy domain distinction 0.509713 loss domain distinction 1.179970,\n",
      "VALIDATION Loss: 0.36030674 Acc: 0.89900662\n",
      "Epoch 10 of 500 took 0.621s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.861698, main loss classifier 0.754842, source accuracy 0.861486 source classification loss 0.561953, target accuracy 0.861909 target loss 0.708605 accuracy domain distinction 0.505490 loss domain distinction 1.195629,\n",
      "VALIDATION Loss: 0.38067925 Acc: 0.91059603\n",
      "Epoch 11 of 500 took 0.621s\n",
      "Accuracy total 0.865921, main loss classifier 0.733128, source accuracy 0.876689 source classification loss 0.496411, target accuracy 0.855152 target loss 0.732276 accuracy domain distinction 0.508868 loss domain distinction 1.187843,\n",
      "VALIDATION Loss: 0.37801141 Acc: 0.90562914\n",
      "Epoch 12 of 500 took 0.626s\n",
      "Accuracy total 0.864231, main loss classifier 0.754139, source accuracy 0.859797 source classification loss 0.577487, target accuracy 0.868666 target loss 0.691488 accuracy domain distinction 0.501478 loss domain distinction 1.196508,\n",
      "VALIDATION Loss: 0.28702136 Acc: 0.91887417\n",
      "New best validation loss:  0.2870213627815247\n",
      "Epoch 13 of 500 took 0.620s\n",
      "Accuracy total 0.860853, main loss classifier 0.766516, source accuracy 0.868243 source classification loss 0.532317, target accuracy 0.853463 target loss 0.763351 accuracy domain distinction 0.498311 loss domain distinction 1.186825,\n",
      "VALIDATION Loss: 0.32901066 Acc: 0.91721854\n",
      "Epoch 14 of 500 took 0.621s\n",
      "Accuracy total 0.859797, main loss classifier 0.765097, source accuracy 0.863598 source classification loss 0.591667, target accuracy 0.855997 target loss 0.699590 accuracy domain distinction 0.500845 loss domain distinction 1.194682,\n",
      "VALIDATION Loss: 0.38575690 Acc: 0.90066225\n",
      "Epoch 15 of 500 took 0.625s\n",
      "Accuracy total 0.867821, main loss classifier 0.731216, source accuracy 0.872466 source classification loss 0.533528, target accuracy 0.863176 target loss 0.690304 accuracy domain distinction 0.500000 loss domain distinction 1.192995,\n",
      "VALIDATION Loss: 0.34244815 Acc: 0.90066225\n",
      "Epoch 16 of 500 took 0.621s\n",
      "Accuracy total 0.865709, main loss classifier 0.756575, source accuracy 0.860220 source classification loss 0.586117, target accuracy 0.871199 target loss 0.687530 accuracy domain distinction 0.503378 loss domain distinction 1.197519,\n",
      "VALIDATION Loss: 0.49961885 Acc: 0.89403974\n",
      "Epoch 17 of 500 took 0.632s\n",
      "Accuracy total 0.865921, main loss classifier 0.751164, source accuracy 0.866554 source classification loss 0.564644, target accuracy 0.865287 target loss 0.701165 accuracy domain distinction 0.495355 loss domain distinction 1.182592,\n",
      "VALIDATION Loss: 0.35687940 Acc: 0.9089404\n",
      "Epoch 18 of 500 took 0.618s\n",
      "Accuracy total 0.867821, main loss classifier 0.747252, source accuracy 0.869932 source classification loss 0.539508, target accuracy 0.865709 target loss 0.718939 accuracy domain distinction 0.501478 loss domain distinction 1.180282,\n",
      "VALIDATION Loss: 0.32419624 Acc: 0.91390728\n",
      "Epoch    18: reducing learning rate of group 0 to 6.4384e-09.\n",
      "Epoch 19 of 500 took 0.620s\n",
      "Accuracy total 0.866765, main loss classifier 0.773160, source accuracy 0.872889 source classification loss 0.549547, target accuracy 0.860642 target loss 0.756071 accuracy domain distinction 0.494088 loss domain distinction 1.203506,\n",
      "VALIDATION Loss: 0.32772669 Acc: 0.91225166\n",
      "Epoch 20 of 500 took 0.620s\n",
      "Accuracy total 0.864865, main loss classifier 0.746532, source accuracy 0.861064 source classification loss 0.550571, target accuracy 0.868666 target loss 0.704416 accuracy domain distinction 0.500633 loss domain distinction 1.190380,\n",
      "VALIDATION Loss: 0.39169416 Acc: 0.9089404\n",
      "Epoch 21 of 500 took 0.618s\n",
      "Accuracy total 0.861486, main loss classifier 0.783101, source accuracy 0.865709 source classification loss 0.574950, target accuracy 0.857264 target loss 0.753120 accuracy domain distinction 0.499155 loss domain distinction 1.190660,\n",
      "VALIDATION Loss: 0.32057386 Acc: 0.91887417\n",
      "Epoch 22 of 500 took 0.619s\n",
      "Accuracy total 0.871622, main loss classifier 0.747237, source accuracy 0.869932 source classification loss 0.588090, target accuracy 0.873311 target loss 0.669959 accuracy domain distinction 0.501900 loss domain distinction 1.182125,\n",
      "VALIDATION Loss: 0.39187334 Acc: 0.91225166\n",
      "Epoch 23 of 500 took 0.619s\n",
      "Accuracy total 0.869932, main loss classifier 0.727079, source accuracy 0.875422 source classification loss 0.545858, target accuracy 0.864443 target loss 0.669646 accuracy domain distinction 0.504012 loss domain distinction 1.193276,\n",
      "VALIDATION Loss: 0.30020908 Acc: 0.91059603\n",
      "Epoch 24 of 500 took 0.619s\n",
      "Training complete in 0m 14s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42c7ac95f0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 4)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 4)\n",
      "models_array =  (2,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  60\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  39\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  101\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  70\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  33\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  11\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4948453608247423   AFTER:  0.1111111111111111  len before:  97   len after:  18\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  62\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.29896907216494845   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.28865979381443296   AFTER:  0.15463917525773196  len before:  97   len after:  97\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  7\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  52\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  44\n",
      "BEFORE:  0.5773195876288659   AFTER:  0.5616438356164384  len before:  97   len after:  73\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0594059405940594   AFTER:  0.0  len before:  101   len after:  37\n",
      "ACCURACY MODEL:  0.190713617949517   Accuracy pseudo: 0.17131110095934216  len pseudo:  2189    len predictions 3209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING TRAINING\n",
      "Accuracy total 0.767361, main loss classifier 1.148564, source accuracy 0.974537 source classification loss 0.078297, target accuracy 0.560185 target loss 1.991136 accuracy domain distinction 0.493924 loss domain distinction 1.138468,\n",
      "VALIDATION Loss: 0.98626638 Acc: 0.72374429\n",
      "New best validation loss:  0.986266383102962\n",
      "Epoch 2 of 500 took 0.503s\n",
      "Accuracy total 0.800637, main loss classifier 0.964093, source accuracy 0.968171 source classification loss 0.097764, target accuracy 0.633102 target loss 1.607708 accuracy domain distinction 0.503183 loss domain distinction 1.113567,\n",
      "VALIDATION Loss: 0.73080934 Acc: 0.79452055\n",
      "New best validation loss:  0.7308093394551959\n",
      "Epoch 3 of 500 took 0.452s\n",
      "Accuracy total 0.813368, main loss classifier 0.878555, source accuracy 0.976273 source classification loss 0.090434, target accuracy 0.650463 target loss 1.443227 accuracy domain distinction 0.515046 loss domain distinction 1.117246,\n",
      "VALIDATION Loss: 1.01572244 Acc: 0.71004566\n",
      "Epoch 4 of 500 took 0.452s\n",
      "Accuracy total 0.825231, main loss classifier 0.805019, source accuracy 0.963542 source classification loss 0.111321, target accuracy 0.686921 target loss 1.276001 accuracy domain distinction 0.523148 loss domain distinction 1.113586,\n",
      "VALIDATION Loss: 0.68405208 Acc: 0.80136986\n",
      "New best validation loss:  0.6840520756585258\n",
      "Epoch 5 of 500 took 0.461s\n",
      "Accuracy total 0.839699, main loss classifier 0.748396, source accuracy 0.968171 source classification loss 0.095128, target accuracy 0.711227 target loss 1.178148 accuracy domain distinction 0.506366 loss domain distinction 1.117579,\n",
      "VALIDATION Loss: 0.84593698 Acc: 0.78995434\n",
      "Epoch 6 of 500 took 0.452s\n",
      "Accuracy total 0.831887, main loss classifier 0.750292, source accuracy 0.967593 source classification loss 0.102270, target accuracy 0.696181 target loss 1.174985 accuracy domain distinction 0.515625 loss domain distinction 1.116642,\n",
      "VALIDATION Loss: 0.53625522 Acc: 0.83105023\n",
      "New best validation loss:  0.5362552234104702\n",
      "Epoch 7 of 500 took 0.455s\n",
      "Accuracy total 0.828704, main loss classifier 0.764479, source accuracy 0.953704 source classification loss 0.144460, target accuracy 0.703704 target loss 1.162448 accuracy domain distinction 0.515046 loss domain distinction 1.110248,\n",
      "VALIDATION Loss: 0.76242703 Acc: 0.79908676\n",
      "Epoch 8 of 500 took 0.454s\n",
      "Accuracy total 0.841435, main loss classifier 0.716393, source accuracy 0.965856 source classification loss 0.111220, target accuracy 0.717014 target loss 1.100570 accuracy domain distinction 0.516782 loss domain distinction 1.104979,\n",
      "VALIDATION Loss: 0.67321364 Acc: 0.80821918\n",
      "Epoch 9 of 500 took 0.450s\n",
      "Accuracy total 0.848669, main loss classifier 0.688979, source accuracy 0.966435 source classification loss 0.114931, target accuracy 0.730903 target loss 1.040105 accuracy domain distinction 0.510995 loss domain distinction 1.114614,\n",
      "VALIDATION Loss: 0.66481137 Acc: 0.80593607\n",
      "Epoch 10 of 500 took 0.461s\n",
      "Accuracy total 0.848669, main loss classifier 0.690318, source accuracy 0.967593 source classification loss 0.104280, target accuracy 0.729745 target loss 1.050742 accuracy domain distinction 0.503472 loss domain distinction 1.128072,\n",
      "VALIDATION Loss: 0.51756468 Acc: 0.83333333\n",
      "New best validation loss:  0.5175646756376538\n",
      "Epoch 11 of 500 took 0.453s\n",
      "Accuracy total 0.847801, main loss classifier 0.687008, source accuracy 0.959491 source classification loss 0.122045, target accuracy 0.736111 target loss 1.024029 accuracy domain distinction 0.510127 loss domain distinction 1.139705,\n",
      "VALIDATION Loss: 0.60607062 Acc: 0.83105023\n",
      "Epoch 12 of 500 took 0.475s\n",
      "Accuracy total 0.853299, main loss classifier 0.651409, source accuracy 0.962384 source classification loss 0.117241, target accuracy 0.744213 target loss 0.963364 accuracy domain distinction 0.513600 loss domain distinction 1.111065,\n",
      "VALIDATION Loss: 0.71380442 Acc: 0.80593607\n",
      "Epoch 13 of 500 took 0.462s\n",
      "Accuracy total 0.848958, main loss classifier 0.648864, source accuracy 0.964120 source classification loss 0.110632, target accuracy 0.733796 target loss 0.965722 accuracy domain distinction 0.516493 loss domain distinction 1.106871,\n",
      "VALIDATION Loss: 0.48333361 Acc: 0.83789954\n",
      "New best validation loss:  0.4833336089338575\n",
      "Epoch 14 of 500 took 0.457s\n",
      "Accuracy total 0.855324, main loss classifier 0.631416, source accuracy 0.965278 source classification loss 0.117383, target accuracy 0.745370 target loss 0.920173 accuracy domain distinction 0.505787 loss domain distinction 1.126385,\n",
      "VALIDATION Loss: 0.56378757 Acc: 0.87671233\n",
      "Epoch 15 of 500 took 0.455s\n",
      "Accuracy total 0.853299, main loss classifier 0.616335, source accuracy 0.957755 source classification loss 0.117264, target accuracy 0.748843 target loss 0.888836 accuracy domain distinction 0.505208 loss domain distinction 1.132850,\n",
      "VALIDATION Loss: 0.49021665 Acc: 0.8652968\n",
      "Epoch 16 of 500 took 0.454s\n",
      "Accuracy total 0.848669, main loss classifier 0.658957, source accuracy 0.962384 source classification loss 0.126314, target accuracy 0.734954 target loss 0.967116 accuracy domain distinction 0.511574 loss domain distinction 1.122421,\n",
      "VALIDATION Loss: 0.59626438 Acc: 0.82876712\n",
      "Epoch 17 of 500 took 0.453s\n",
      "Accuracy total 0.845486, main loss classifier 0.660820, source accuracy 0.965278 source classification loss 0.113342, target accuracy 0.725694 target loss 0.983978 accuracy domain distinction 0.508102 loss domain distinction 1.121598,\n",
      "VALIDATION Loss: 0.75763898 Acc: 0.80821918\n",
      "Epoch 18 of 500 took 0.457s\n",
      "Accuracy total 0.857639, main loss classifier 0.615142, source accuracy 0.958912 source classification loss 0.133301, target accuracy 0.756366 target loss 0.874487 accuracy domain distinction 0.510417 loss domain distinction 1.112481,\n",
      "VALIDATION Loss: 0.48490726 Acc: 0.8630137\n",
      "Epoch 19 of 500 took 0.480s\n",
      "Accuracy total 0.864294, main loss classifier 0.594376, source accuracy 0.960648 source classification loss 0.123748, target accuracy 0.767940 target loss 0.839730 accuracy domain distinction 0.502315 loss domain distinction 1.126372,\n",
      "VALIDATION Loss: 0.47263708 Acc: 0.85616438\n",
      "New best validation loss:  0.47263707859175547\n",
      "Epoch 20 of 500 took 0.456s\n",
      "Accuracy total 0.850694, main loss classifier 0.609809, source accuracy 0.953704 source classification loss 0.136537, target accuracy 0.747685 target loss 0.860033 accuracy domain distinction 0.502604 loss domain distinction 1.115235,\n",
      "VALIDATION Loss: 0.49779885 Acc: 0.84246575\n",
      "Epoch 21 of 500 took 0.453s\n",
      "Accuracy total 0.857350, main loss classifier 0.589547, source accuracy 0.960069 source classification loss 0.124297, target accuracy 0.754630 target loss 0.831491 accuracy domain distinction 0.502025 loss domain distinction 1.116534,\n",
      "VALIDATION Loss: 0.54951664 Acc: 0.84703196\n",
      "Epoch 22 of 500 took 0.464s\n",
      "Accuracy total 0.865451, main loss classifier 0.599219, source accuracy 0.967593 source classification loss 0.128683, target accuracy 0.763310 target loss 0.845882 accuracy domain distinction 0.504919 loss domain distinction 1.119371,\n",
      "VALIDATION Loss: 0.46744303 Acc: 0.86073059\n",
      "New best validation loss:  0.4674430340528488\n",
      "Epoch 23 of 500 took 0.457s\n",
      "Accuracy total 0.863137, main loss classifier 0.576363, source accuracy 0.967593 source classification loss 0.107461, target accuracy 0.758681 target loss 0.820922 accuracy domain distinction 0.504630 loss domain distinction 1.121717,\n",
      "VALIDATION Loss: 0.40916965 Acc: 0.88584475\n",
      "New best validation loss:  0.40916964624609264\n",
      "Epoch 24 of 500 took 0.458s\n",
      "Accuracy total 0.866030, main loss classifier 0.598554, source accuracy 0.962384 source classification loss 0.124500, target accuracy 0.769676 target loss 0.846565 accuracy domain distinction 0.500868 loss domain distinction 1.130216,\n",
      "VALIDATION Loss: 0.44952876 Acc: 0.88584475\n",
      "Epoch 25 of 500 took 0.451s\n",
      "Accuracy total 0.863715, main loss classifier 0.608388, source accuracy 0.964120 source classification loss 0.117363, target accuracy 0.763310 target loss 0.875382 accuracy domain distinction 0.502315 loss domain distinction 1.120157,\n",
      "VALIDATION Loss: 0.43066154 Acc: 0.88127854\n",
      "Epoch 26 of 500 took 0.452s\n",
      "Accuracy total 0.867188, main loss classifier 0.571873, source accuracy 0.958333 source classification loss 0.133349, target accuracy 0.776042 target loss 0.783685 accuracy domain distinction 0.501157 loss domain distinction 1.133563,\n",
      "VALIDATION Loss: 0.50097386 Acc: 0.85616438\n",
      "Epoch 27 of 500 took 0.455s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.862558, main loss classifier 0.589961, source accuracy 0.961227 source classification loss 0.134833, target accuracy 0.763889 target loss 0.820638 accuracy domain distinction 0.504630 loss domain distinction 1.122252,\n",
      "VALIDATION Loss: 0.47760792 Acc: 0.87214612\n",
      "Epoch 28 of 500 took 0.451s\n",
      "Accuracy total 0.864005, main loss classifier 0.549679, source accuracy 0.959491 source classification loss 0.121818, target accuracy 0.768519 target loss 0.753741 accuracy domain distinction 0.500000 loss domain distinction 1.119000,\n",
      "VALIDATION Loss: 0.51913896 Acc: 0.85616438\n",
      "Epoch 29 of 500 took 0.452s\n",
      "Accuracy total 0.868345, main loss classifier 0.552918, source accuracy 0.958333 source classification loss 0.127381, target accuracy 0.778356 target loss 0.757313 accuracy domain distinction 0.500579 loss domain distinction 1.105711,\n",
      "VALIDATION Loss: 0.41361846 Acc: 0.88127854\n",
      "Epoch    29: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 30 of 500 took 0.452s\n",
      "Accuracy total 0.869792, main loss classifier 0.552311, source accuracy 0.959491 source classification loss 0.125117, target accuracy 0.780093 target loss 0.754341 accuracy domain distinction 0.500868 loss domain distinction 1.125821,\n",
      "VALIDATION Loss: 0.44756087 Acc: 0.86986301\n",
      "Epoch 31 of 500 took 0.452s\n",
      "Accuracy total 0.872106, main loss classifier 0.567939, source accuracy 0.968171 source classification loss 0.113221, target accuracy 0.776042 target loss 0.797423 accuracy domain distinction 0.505208 loss domain distinction 1.126169,\n",
      "VALIDATION Loss: 0.57722020 Acc: 0.82876712\n",
      "Epoch 32 of 500 took 0.456s\n",
      "Accuracy total 0.874711, main loss classifier 0.548640, source accuracy 0.962384 source classification loss 0.123495, target accuracy 0.787037 target loss 0.751172 accuracy domain distinction 0.506076 loss domain distinction 1.113065,\n",
      "VALIDATION Loss: 0.42953811 Acc: 0.85844749\n",
      "Epoch 33 of 500 took 0.453s\n",
      "Accuracy total 0.865162, main loss classifier 0.567371, source accuracy 0.967593 source classification loss 0.102755, target accuracy 0.762731 target loss 0.808233 accuracy domain distinction 0.500289 loss domain distinction 1.118773,\n",
      "VALIDATION Loss: 0.43064514 Acc: 0.87214612\n",
      "Epoch 34 of 500 took 0.459s\n",
      "Accuracy total 0.867766, main loss classifier 0.554054, source accuracy 0.954861 source classification loss 0.141938, target accuracy 0.780671 target loss 0.743560 accuracy domain distinction 0.505498 loss domain distinction 1.113046,\n",
      "VALIDATION Loss: 0.43958207 Acc: 0.87442922\n",
      "Epoch 35 of 500 took 0.456s\n",
      "Training complete in 0m 16s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42c7ac95f0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt' (epoch 1)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 4)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt' (epoch 1)\n",
      "models_array =  (3,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  60\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  39\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  101\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  70\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  33\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  11\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4948453608247423   AFTER:  0.1111111111111111  len before:  97   len after:  18\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  62\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.29896907216494845   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.28865979381443296   AFTER:  0.15463917525773196  len before:  97   len after:  97\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  7\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  52\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  44\n",
      "BEFORE:  0.5773195876288659   AFTER:  0.5616438356164384  len before:  97   len after:  73\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0594059405940594   AFTER:  0.0  len before:  101   len after:  37\n",
      "ACCURACY MODEL:  0.190713617949517   Accuracy pseudo: 0.17131110095934216  len pseudo:  2189    len predictions 3209\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.422680412371134   AFTER:  1.0  len before:  97   len after:  61\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6170212765957447   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.851063829787234   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5773195876288659   AFTER:  1.0  len before:  97   len after:  51\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7010309278350515   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9247311827956989   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6382978723404256   AFTER:  0.6808510638297872  len before:  94   len after:  94\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5051546391752577   AFTER:  1.0  len before:  97   len after:  41\n",
      "ACCURACY MODEL:  0.8564247565190072   Accuracy pseudo: 0.9898477157360406  len pseudo:  2955    len predictions 3183\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.782986, main loss classifier 0.990452, source accuracy 0.709635 source classification loss 1.214545, target accuracy 0.856337 target loss 0.534980 accuracy domain distinction 0.509115 loss domain distinction 1.156894,\n",
      "VALIDATION Loss: 0.42719142 Acc: 0.87986464\n",
      "New best validation loss:  0.4271914154291153\n",
      "Epoch 2 of 500 took 0.617s\n",
      "Accuracy total 0.813802, main loss classifier 0.785380, source accuracy 0.783854 source classification loss 0.813569, target accuracy 0.843750 target loss 0.531378 accuracy domain distinction 0.498481 loss domain distinction 1.129065,\n",
      "VALIDATION Loss: 0.44053577 Acc: 0.87817259\n",
      "Epoch 3 of 500 took 0.604s\n",
      "Accuracy total 0.828776, main loss classifier 0.704590, source accuracy 0.808160 source classification loss 0.689295, target accuracy 0.849392 target loss 0.496283 accuracy domain distinction 0.494792 loss domain distinction 1.118005,\n",
      "VALIDATION Loss: 0.40035789 Acc: 0.9001692\n",
      "New best validation loss:  0.400357885658741\n",
      "Epoch 4 of 500 took 0.605s\n",
      "Accuracy total 0.837891, main loss classifier 0.691224, source accuracy 0.815972 source classification loss 0.660349, target accuracy 0.859809 target loss 0.498210 accuracy domain distinction 0.496528 loss domain distinction 1.119441,\n",
      "VALIDATION Loss: 0.41173203 Acc: 0.9035533\n",
      "Epoch 5 of 500 took 0.605s\n",
      "Accuracy total 0.845920, main loss classifier 0.641942, source accuracy 0.832899 source classification loss 0.578769, target accuracy 0.858941 target loss 0.483941 accuracy domain distinction 0.495226 loss domain distinction 1.105866,\n",
      "VALIDATION Loss: 0.40090090 Acc: 0.88324873\n",
      "Epoch 6 of 500 took 0.618s\n",
      "Accuracy total 0.845703, main loss classifier 0.642678, source accuracy 0.822483 source classification loss 0.607831, target accuracy 0.868924 target loss 0.458185 accuracy domain distinction 0.492405 loss domain distinction 1.096697,\n",
      "VALIDATION Loss: 0.35198753 Acc: 0.90862944\n",
      "New best validation loss:  0.3519875258207321\n",
      "Epoch 7 of 500 took 0.601s\n",
      "Accuracy total 0.853082, main loss classifier 0.600849, source accuracy 0.840278 source classification loss 0.542519, target accuracy 0.865885 target loss 0.438375 accuracy domain distinction 0.496962 loss domain distinction 1.104016,\n",
      "VALIDATION Loss: 0.33040156 Acc: 0.91032149\n",
      "New best validation loss:  0.3304015573114157\n",
      "Epoch 8 of 500 took 0.609s\n",
      "Accuracy total 0.852214, main loss classifier 0.595325, source accuracy 0.842014 source classification loss 0.497732, target accuracy 0.862413 target loss 0.472252 accuracy domain distinction 0.495009 loss domain distinction 1.103324,\n",
      "VALIDATION Loss: 0.35417930 Acc: 0.89509306\n",
      "Epoch 9 of 500 took 0.600s\n",
      "Accuracy total 0.864583, main loss classifier 0.572456, source accuracy 0.852865 source classification loss 0.505045, target accuracy 0.876302 target loss 0.415836 accuracy domain distinction 0.494575 loss domain distinction 1.120158,\n",
      "VALIDATION Loss: 0.28288917 Acc: 0.91708968\n",
      "New best validation loss:  0.2828891731798649\n",
      "Epoch 10 of 500 took 0.604s\n",
      "Accuracy total 0.861545, main loss classifier 0.581258, source accuracy 0.851997 source classification loss 0.508210, target accuracy 0.871094 target loss 0.431555 accuracy domain distinction 0.495660 loss domain distinction 1.113750,\n",
      "VALIDATION Loss: 0.38234240 Acc: 0.89678511\n",
      "Epoch 11 of 500 took 0.647s\n",
      "Accuracy total 0.865234, main loss classifier 0.556580, source accuracy 0.857639 source classification loss 0.485977, target accuracy 0.872830 target loss 0.401218 accuracy domain distinction 0.493707 loss domain distinction 1.129825,\n",
      "VALIDATION Loss: 0.31599571 Acc: 0.9001692\n",
      "Epoch 12 of 500 took 0.620s\n",
      "Accuracy total 0.869141, main loss classifier 0.560400, source accuracy 0.855903 source classification loss 0.502875, target accuracy 0.882378 target loss 0.390865 accuracy domain distinction 0.496745 loss domain distinction 1.135294,\n",
      "VALIDATION Loss: 0.32290392 Acc: 0.91201354\n",
      "Epoch 13 of 500 took 0.603s\n",
      "Accuracy total 0.869141, main loss classifier 0.539376, source accuracy 0.852865 source classification loss 0.477425, target accuracy 0.885417 target loss 0.376544 accuracy domain distinction 0.496745 loss domain distinction 1.123917,\n",
      "VALIDATION Loss: 0.28515396 Acc: 0.90862944\n",
      "Epoch 14 of 500 took 0.619s\n",
      "Accuracy total 0.870226, main loss classifier 0.543564, source accuracy 0.860677 source classification loss 0.453282, target accuracy 0.879774 target loss 0.405722 accuracy domain distinction 0.498915 loss domain distinction 1.140614,\n",
      "VALIDATION Loss: 0.31294535 Acc: 0.90693739\n",
      "Epoch 15 of 500 took 0.653s\n",
      "Accuracy total 0.878906, main loss classifier 0.518394, source accuracy 0.870660 source classification loss 0.424631, target accuracy 0.887153 target loss 0.385677 accuracy domain distinction 0.497396 loss domain distinction 1.132404,\n",
      "VALIDATION Loss: 0.34201979 Acc: 0.9001692\n",
      "Epoch    15: reducing learning rate of group 0 to 4.0240e-06.\n",
      "Epoch 16 of 500 took 0.617s\n",
      "Accuracy total 0.874566, main loss classifier 0.538021, source accuracy 0.859809 source classification loss 0.469344, target accuracy 0.889323 target loss 0.378749 accuracy domain distinction 0.491536 loss domain distinction 1.139747,\n",
      "VALIDATION Loss: 0.28391506 Acc: 0.90524535\n",
      "Epoch 17 of 500 took 0.604s\n",
      "Accuracy total 0.869575, main loss classifier 0.527157, source accuracy 0.862413 source classification loss 0.441903, target accuracy 0.876736 target loss 0.385959 accuracy domain distinction 0.500217 loss domain distinction 1.132256,\n",
      "VALIDATION Loss: 0.33066304 Acc: 0.9035533\n",
      "Epoch 18 of 500 took 0.605s\n",
      "Accuracy total 0.874566, main loss classifier 0.517466, source accuracy 0.871094 source classification loss 0.418592, target accuracy 0.878038 target loss 0.390958 accuracy domain distinction 0.499566 loss domain distinction 1.126910,\n",
      "VALIDATION Loss: 0.32598607 Acc: 0.90186125\n",
      "Epoch 19 of 500 took 0.656s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.873481, main loss classifier 0.518239, source accuracy 0.865451 source classification loss 0.434163, target accuracy 0.881510 target loss 0.377009 accuracy domain distinction 0.502821 loss domain distinction 1.126529,\n",
      "VALIDATION Loss: 0.29028089 Acc: 0.91878173\n",
      "Epoch 20 of 500 took 0.602s\n",
      "Accuracy total 0.876736, main loss classifier 0.509754, source accuracy 0.866319 source classification loss 0.422011, target accuracy 0.887153 target loss 0.372258 accuracy domain distinction 0.500868 loss domain distinction 1.126200,\n",
      "VALIDATION Loss: 0.32315260 Acc: 0.9035533\n",
      "Epoch 21 of 500 took 0.601s\n",
      "Training complete in 0m 12s\n",
      "['participant_1', 'participant_2', 'participant_0']\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Optimizer =  <generator object Module.parameters at 0x7f42c7ac95f0>\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt'\n",
      "Loading Optimizer\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt' (epoch 7)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures/participant_2/best_state_0.pt' (epoch 38)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_1.pt' (epoch 4)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_2.pt' (epoch 1)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "=> loading checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt'\n",
      "=> loaded checkpoint 'Weights_TSD/weights_DANN_THREE_CYCLES_11Gestures_TSD/participant_2/best_state_3.pt' (epoch 7)\n",
      "models_array =  (4,)\n",
      "HANDLING NEW SESSION  0\n",
      "HANDLING NEW SESSION  1\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  nan  len before:  97   len after:  0\n",
      "BEFORE:  0.8969072164948454   AFTER:  1.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  60\n",
      "BEFORE:  0.09278350515463918   AFTER:  0.0  len before:  97   len after:  39\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.08247422680412371   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  101   len after:  101\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  70\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  33\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  11\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  74\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.4948453608247423   AFTER:  0.1111111111111111  len before:  97   len after:  18\n",
      "BEFORE:  0.10309278350515463   AFTER:  0.0  len before:  97   len after:  62\n",
      "BEFORE:  0.010309278350515464   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.29896907216494845   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.28865979381443296   AFTER:  0.15463917525773196  len before:  97   len after:  97\n",
      "BEFORE:  0.1958762886597938   AFTER:  0.0  len before:  97   len after:  69\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  7\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.030927835051546393   AFTER:  0.0  len before:  97   len after:  52\n",
      "BEFORE:  0.13402061855670103   AFTER:  0.0  len before:  97   len after:  71\n",
      "BEFORE:  0.020618556701030927   AFTER:  0.0  len before:  97   len after:  44\n",
      "BEFORE:  0.5773195876288659   AFTER:  0.5616438356164384  len before:  97   len after:  73\n",
      "BEFORE:  0.0   AFTER:  0.0  len before:  97   len after:  97\n",
      "BEFORE:  0.1134020618556701   AFTER:  0.0  len before:  97   len after:  38\n",
      "BEFORE:  0.0594059405940594   AFTER:  0.0  len before:  101   len after:  37\n",
      "ACCURACY MODEL:  0.190713617949517   Accuracy pseudo: 0.17131110095934216  len pseudo:  2189    len predictions 3209\n",
      "HANDLING NEW SESSION  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9680851063829787   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7422680412371134   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.422680412371134   AFTER:  1.0  len before:  97   len after:  61\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6170212765957447   AFTER:  1.0  len before:  94   len after:  74\n",
      "BEFORE:  0.9278350515463918   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5257731958762887   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9893617021276596   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9072164948453608   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.851063829787234   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9690721649484536   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5773195876288659   AFTER:  1.0  len before:  97   len after:  51\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7010309278350515   AFTER:  1.0  len before:  97   len after:  72\n",
      "BEFORE:  0.9247311827956989   AFTER:  1.0  len before:  93   len after:  93\n",
      "BEFORE:  0.9381443298969072   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9896907216494846   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  75\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  101   len after:  101\n",
      "BEFORE:  0.6382978723404256   AFTER:  0.6808510638297872  len before:  94   len after:  94\n",
      "BEFORE:  0.8556701030927835   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5051546391752577   AFTER:  1.0  len before:  97   len after:  41\n",
      "ACCURACY MODEL:  0.8564247565190072   Accuracy pseudo: 0.9898477157360406  len pseudo:  2955    len predictions 3183\n",
      "HANDLING NEW SESSION  3\n",
      "Finish segment dataset\n",
      "Finish pseudo_labels\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.8865979381443299   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7555555555555555   AFTER:  1.0  len before:  90   len after:  66\n",
      "BEFORE:  0.7731958762886598   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7525773195876289   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.5051546391752577   AFTER:  1.0  len before:  97   len after:  63\n",
      "BEFORE:  0.8247422680412371   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  90   len after:  90\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  59\n",
      "BEFORE:  0.9787234042553191   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7640449438202247   AFTER:  1.0  len before:  89   len after:  69\n",
      "BEFORE:  0.7954545454545454   AFTER:  1.0  len before:  88   len after:  88\n",
      "BEFORE:  0.4329896907216495   AFTER:  1.0  len before:  97   len after:  31\n",
      "BEFORE:  0.8850574712643678   AFTER:  1.0  len before:  87   len after:  87\n",
      "BEFORE:  0.7872340425531915   AFTER:  1.0  len before:  94   len after:  94\n",
      "BEFORE:  0.16494845360824742   AFTER:  0.0  len before:  97   len after:  70\n",
      "BEFORE:  0.6907216494845361   AFTER:  0.6288659793814433  len before:  97   len after:  97\n",
      "BEFORE:  1.0   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.9587628865979382   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.979381443298969   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.711340206185567   AFTER:  1.0  len before:  97   len after:  74\n",
      "BEFORE:  0.9484536082474226   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.21649484536082475   AFTER:  0.04054054054054054  len before:  97   len after:  74\n",
      "BEFORE:  0.8144329896907216   AFTER:  1.0  len before:  97   len after:  68\n",
      "BEFORE:  0.9175257731958762   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.7628865979381443   AFTER:  1.0  len before:  97   len after:  76\n",
      "BEFORE:  0.6288659793814433   AFTER:  1.0  len before:  97   len after:  97\n",
      "BEFORE:  0.6041666666666666   AFTER:  1.0  len before:  96   len after:  72\n",
      "ACCURACY MODEL:  0.7895238095238095   Accuracy pseudo: 0.9367857142857143  len pseudo:  2800    len predictions 3150\n",
      "STARTING TRAINING\n",
      "Accuracy total 0.741071, main loss classifier 1.228097, source accuracy 0.702232 source classification loss 1.407076, target accuracy 0.779911 target loss 0.828436 accuracy domain distinction 0.514062 loss domain distinction 1.103403,\n",
      "VALIDATION Loss: 0.55465535 Acc: 0.83928571\n",
      "New best validation loss:  0.5546553532282511\n",
      "Epoch 2 of 500 took 0.593s\n",
      "Accuracy total 0.754018, main loss classifier 1.174510, source accuracy 0.719196 source classification loss 1.309928, target accuracy 0.788839 target loss 0.816097 accuracy domain distinction 0.500223 loss domain distinction 1.114978,\n",
      "VALIDATION Loss: 0.48001006 Acc: 0.85\n",
      "New best validation loss:  0.4800100558333927\n",
      "Epoch 3 of 500 took 0.591s\n",
      "Accuracy total 0.757812, main loss classifier 1.130645, source accuracy 0.721429 source classification loss 1.241637, target accuracy 0.794196 target loss 0.798213 accuracy domain distinction 0.503348 loss domain distinction 1.107207,\n",
      "VALIDATION Loss: 0.62149616 Acc: 0.8375\n",
      "Epoch 4 of 500 took 0.587s\n",
      "Accuracy total 0.773214, main loss classifier 1.051383, source accuracy 0.751786 source classification loss 1.115728, target accuracy 0.794643 target loss 0.765427 accuracy domain distinction 0.503571 loss domain distinction 1.108053,\n",
      "VALIDATION Loss: 0.45086555 Acc: 0.86607143\n",
      "New best validation loss:  0.45086554686228436\n",
      "Epoch 5 of 500 took 0.587s\n",
      "Accuracy total 0.763170, main loss classifier 1.086075, source accuracy 0.728571 source classification loss 1.178746, target accuracy 0.797768 target loss 0.771585 accuracy domain distinction 0.511161 loss domain distinction 1.109091,\n",
      "VALIDATION Loss: 0.43823332 Acc: 0.88214286\n",
      "New best validation loss:  0.43823332256740993\n",
      "Epoch 6 of 500 took 0.582s\n",
      "Accuracy total 0.764509, main loss classifier 1.084045, source accuracy 0.727679 source classification loss 1.213236, target accuracy 0.801339 target loss 0.732730 accuracy domain distinction 0.508705 loss domain distinction 1.110624,\n",
      "VALIDATION Loss: 0.47940237 Acc: 0.87142857\n",
      "Epoch 7 of 500 took 0.592s\n",
      "Accuracy total 0.770536, main loss classifier 1.074820, source accuracy 0.741518 source classification loss 1.152133, target accuracy 0.799554 target loss 0.775724 accuracy domain distinction 0.504241 loss domain distinction 1.108916,\n",
      "VALIDATION Loss: 0.46733162 Acc: 0.86607143\n",
      "Epoch 8 of 500 took 0.590s\n",
      "Accuracy total 0.771205, main loss classifier 1.013626, source accuracy 0.735268 source classification loss 1.091231, target accuracy 0.807143 target loss 0.712191 accuracy domain distinction 0.498437 loss domain distinction 1.119153,\n",
      "VALIDATION Loss: 0.52957923 Acc: 0.86428571\n",
      "Epoch 9 of 500 took 0.584s\n",
      "Accuracy total 0.776339, main loss classifier 1.023550, source accuracy 0.751786 source classification loss 1.063488, target accuracy 0.800893 target loss 0.760614 accuracy domain distinction 0.501563 loss domain distinction 1.114986,\n",
      "VALIDATION Loss: 0.50793295 Acc: 0.85714286\n",
      "Epoch 10 of 500 took 0.584s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total 0.769196, main loss classifier 1.028904, source accuracy 0.737054 source classification loss 1.112061, target accuracy 0.801339 target loss 0.723455 accuracy domain distinction 0.497098 loss domain distinction 1.111456,\n",
      "VALIDATION Loss: 0.41706422 Acc: 0.88035714\n",
      "New best validation loss:  0.41706422136889565\n",
      "Epoch 11 of 500 took 0.588s\n",
      "Accuracy total 0.779911, main loss classifier 0.992862, source accuracy 0.756250 source classification loss 1.024390, target accuracy 0.803571 target loss 0.739234 accuracy domain distinction 0.496652 loss domain distinction 1.110496,\n",
      "VALIDATION Loss: 0.40697444 Acc: 0.88392857\n",
      "New best validation loss:  0.406974443131023\n",
      "Epoch 12 of 500 took 0.601s\n",
      "Accuracy total 0.785714, main loss classifier 0.957813, source accuracy 0.754018 source classification loss 0.999517, target accuracy 0.817411 target loss 0.695694 accuracy domain distinction 0.499554 loss domain distinction 1.102072,\n",
      "VALIDATION Loss: 0.42588275 Acc: 0.87321429\n",
      "Epoch 13 of 500 took 0.582s\n",
      "Accuracy total 0.780804, main loss classifier 0.968465, source accuracy 0.749554 source classification loss 1.019010, target accuracy 0.812054 target loss 0.693772 accuracy domain distinction 0.493304 loss domain distinction 1.120739,\n",
      "VALIDATION Loss: 0.51717146 Acc: 0.84107143\n",
      "Epoch 14 of 500 took 0.585s\n",
      "Accuracy total 0.776116, main loss classifier 0.990453, source accuracy 0.753125 source classification loss 1.007328, target accuracy 0.799107 target loss 0.754071 accuracy domain distinction 0.506920 loss domain distinction 1.097533,\n",
      "VALIDATION Loss: 0.38957320 Acc: 0.88214286\n",
      "New best validation loss:  0.3895731998814477\n",
      "Epoch 15 of 500 took 0.586s\n",
      "Accuracy total 0.788616, main loss classifier 0.938693, source accuracy 0.759375 source classification loss 0.983901, target accuracy 0.817857 target loss 0.669906 accuracy domain distinction 0.493973 loss domain distinction 1.117892,\n",
      "VALIDATION Loss: 0.46340605 Acc: 0.87321429\n",
      "Epoch 16 of 500 took 0.583s\n",
      "Accuracy total 0.796652, main loss classifier 0.916898, source accuracy 0.770982 source classification loss 0.937196, target accuracy 0.822321 target loss 0.673313 accuracy domain distinction 0.499107 loss domain distinction 1.116434,\n",
      "VALIDATION Loss: 0.42895311 Acc: 0.87142857\n",
      "Epoch 17 of 500 took 0.585s\n",
      "Accuracy total 0.778571, main loss classifier 0.973431, source accuracy 0.754911 source classification loss 0.960456, target accuracy 0.802232 target loss 0.762687 accuracy domain distinction 0.500446 loss domain distinction 1.118596,\n",
      "VALIDATION Loss: 0.51810516 Acc: 0.86607143\n",
      "Epoch 18 of 500 took 0.583s\n",
      "Accuracy total 0.784821, main loss classifier 0.934224, source accuracy 0.762500 source classification loss 0.964267, target accuracy 0.807143 target loss 0.683480 accuracy domain distinction 0.495089 loss domain distinction 1.103506,\n",
      "VALIDATION Loss: 0.45787485 Acc: 0.87142857\n",
      "Epoch 19 of 500 took 0.587s\n",
      "Accuracy total 0.791741, main loss classifier 0.900605, source accuracy 0.780357 source classification loss 0.873888, target accuracy 0.803125 target loss 0.704895 accuracy domain distinction 0.500223 loss domain distinction 1.112135,\n",
      "VALIDATION Loss: 0.38289720 Acc: 0.87678571\n",
      "New best validation loss:  0.38289720482296413\n",
      "Epoch 20 of 500 took 0.593s\n",
      "Accuracy total 0.791518, main loss classifier 0.936950, source accuracy 0.773214 source classification loss 0.935945, target accuracy 0.809821 target loss 0.717718 accuracy domain distinction 0.496652 loss domain distinction 1.101180,\n",
      "VALIDATION Loss: 0.48149459 Acc: 0.85178571\n",
      "Epoch 21 of 500 took 0.587s\n",
      "Accuracy total 0.797098, main loss classifier 0.896979, source accuracy 0.769196 source classification loss 0.907955, target accuracy 0.825000 target loss 0.662846 accuracy domain distinction 0.493750 loss domain distinction 1.115783,\n",
      "VALIDATION Loss: 0.42171602 Acc: 0.88035714\n",
      "Epoch 22 of 500 took 0.582s\n",
      "Accuracy total 0.787500, main loss classifier 0.915290, source accuracy 0.770536 source classification loss 0.912041, target accuracy 0.804464 target loss 0.697053 accuracy domain distinction 0.497098 loss domain distinction 1.107431,\n",
      "VALIDATION Loss: 0.51985494 Acc: 0.8625\n",
      "Epoch 23 of 500 took 0.584s\n",
      "Accuracy total 0.799330, main loss classifier 0.866767, source accuracy 0.780804 source classification loss 0.844788, target accuracy 0.817857 target loss 0.668333 accuracy domain distinction 0.501786 loss domain distinction 1.102066,\n",
      "VALIDATION Loss: 0.42518725 Acc: 0.87857143\n",
      "Epoch 24 of 500 took 0.585s\n",
      "Accuracy total 0.799330, main loss classifier 0.870186, source accuracy 0.785268 source classification loss 0.841330, target accuracy 0.813393 target loss 0.675337 accuracy domain distinction 0.496875 loss domain distinction 1.118528,\n",
      "VALIDATION Loss: 0.50066167 Acc: 0.84464286\n",
      "Epoch 25 of 500 took 0.586s\n",
      "Accuracy total 0.790848, main loss classifier 0.881979, source accuracy 0.773214 source classification loss 0.847565, target accuracy 0.808482 target loss 0.690900 accuracy domain distinction 0.494866 loss domain distinction 1.127462,\n",
      "VALIDATION Loss: 0.41100402 Acc: 0.88035714\n",
      "Epoch    25: reducing learning rate of group 0 to 8.0480e-07.\n",
      "Epoch 26 of 500 took 0.581s\n",
      "Accuracy total 0.789955, main loss classifier 0.890268, source accuracy 0.766518 source classification loss 0.878790, target accuracy 0.813393 target loss 0.677859 accuracy domain distinction 0.497545 loss domain distinction 1.119436,\n",
      "VALIDATION Loss: 0.45901787 Acc: 0.87321429\n",
      "Epoch 27 of 500 took 0.584s\n",
      "Accuracy total 0.803795, main loss classifier 0.871781, source accuracy 0.791964 source classification loss 0.831938, target accuracy 0.815625 target loss 0.690461 accuracy domain distinction 0.500893 loss domain distinction 1.105815,\n",
      "VALIDATION Loss: 0.43766494 Acc: 0.8625\n",
      "Epoch 28 of 500 took 0.584s\n",
      "Accuracy total 0.786607, main loss classifier 0.914453, source accuracy 0.767857 source classification loss 0.886715, target accuracy 0.805357 target loss 0.716228 accuracy domain distinction 0.491964 loss domain distinction 1.129817,\n",
      "VALIDATION Loss: 0.41016403 Acc: 0.86785714\n",
      "Epoch 29 of 500 took 0.595s\n",
      "Accuracy total 0.800893, main loss classifier 0.870904, source accuracy 0.775446 source classification loss 0.854327, target accuracy 0.826339 target loss 0.663389 accuracy domain distinction 0.500446 loss domain distinction 1.120462,\n",
      "VALIDATION Loss: 0.44611639 Acc: 0.86964286\n",
      "Epoch 30 of 500 took 0.583s\n",
      "Accuracy total 0.797768, main loss classifier 0.861216, source accuracy 0.779911 source classification loss 0.833655, target accuracy 0.815625 target loss 0.664328 accuracy domain distinction 0.495982 loss domain distinction 1.122240,\n",
      "VALIDATION Loss: 0.41350126 Acc: 0.88928571\n",
      "Epoch 31 of 500 took 0.586s\n",
      "Training complete in 0m 18s\n",
      "['participant_1', 'participant_2', 'participant_0']\n"
     ]
    }
   ],
   "source": [
    "run_SCADANN_training_sessions(examples_datasets=examples_datasets_train, labels_datasets=labels_datasets_train,\n",
    "                              num_neurons=num_neurons, feature_vector_input_length=feature_vector_input_length,\n",
    "                              path_weights_to_save_to=path_weight_to_save_to,\n",
    "                              path_weights_Adversarial_training=path_weights_start_with,\n",
    "                              path_weights_Normal_training=path_weights_Normal_training,\n",
    "                              number_of_cycle_for_first_training=4, number_of_cycles_rest_of_training=4,\n",
    "                              gestures_to_remove=gestures_to_remove, number_of_classes=number_of_classes,\n",
    "                              learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)   0\n",
      "SHAPE X:  (1854, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1899, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1938, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1780, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1981, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1884, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1809, 385)\n",
      "(4,)   0\n",
      "SHAPE X:  (1746, 385)\n",
      "(4,)   1\n",
      "SHAPE X:  (1928, 385)\n",
      "(4,)   2\n",
      "SHAPE X:  (1912, 385)\n",
      "(4,)   3\n",
      "SHAPE X:  (1902, 385)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  0  Accuracy:  0.9980276134122288\n",
      "Participant:  0  Accuracy:  0.711897738446411\n",
      "Participant:  0  Accuracy:  0.8099250936329588\n",
      "Participant:  0  Accuracy:  0.7025738798856054\n",
      "ACCURACY PARTICIPANT:  [0.9980276134122288, 0.711897738446411, 0.8099250936329588, 0.7025738798856054]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  1  Accuracy:  0.9954627949183303\n",
      "Participant:  1  Accuracy:  0.6862003780718336\n",
      "Participant:  1  Accuracy:  0.7725947521865889\n",
      "Participant:  1  Accuracy:  0.8801571709233792\n",
      "ACCURACY PARTICIPANT:  [0.9954627949183303, 0.6862003780718336, 0.7725947521865889, 0.8801571709233792]\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=385, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=385, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=11, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  162013\n",
      "Participant:  2  Accuracy:  0.9970149253731343\n",
      "Participant:  2  Accuracy:  0.14939309056956115\n",
      "Participant:  2  Accuracy:  0.8994360902255639\n",
      "Participant:  2  Accuracy:  0.8133208255159474\n",
      "ACCURACY PARTICIPANT:  [0.9970149253731343, 0.14939309056956115, 0.8994360902255639, 0.8133208255159474]\n",
      "[0.998 0.712 0.81  0.703 0.995 0.686 0.773 0.88  0.997 0.149 0.899 0.813]\n",
      "[0.9980276134122288, 0.711897738446411, 0.8099250936329588, 0.7025738798856054, 0.9954627949183303, 0.6862003780718336, 0.7725947521865889, 0.8801571709233792, 0.9970149253731343, 0.14939309056956115, 0.8994360902255639, 0.8133208255159474]\n",
      "OVERALL ACCURACY: 0.7846670294301288\n"
     ]
    }
   ],
   "source": [
    "path_weights_normal_training = \"Weights_TSD/weights_THREE_CYCLES_TSD_ELEVEN_Gestures\"\n",
    "test_network_SLADANN(examples_datasets_train=examples_datasets_train, labels_datasets_train=labels_datasets_train,\n",
    "                     num_neurons=num_neurons, feature_vector_input_length=feature_vector_input_length,\n",
    "                     path_weights_ASR=path_weight_to_save_to, path_weights_normal=path_weights_normal_training,\n",
    "                     algo_name=algo_name, cycle_test=3, gestures_to_remove=gestures_to_remove,\n",
    "                     number_of_classes=number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_0</th>\n",
       "      <th>Session_1</th>\n",
       "      <th>Session_2</th>\n",
       "      <th>Session_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Participant_0</th>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.711898</td>\n",
       "      <td>0.809925</td>\n",
       "      <td>0.702574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_1</th>\n",
       "      <td>0.995463</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>0.772595</td>\n",
       "      <td>0.880157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant_2</th>\n",
       "      <td>0.997015</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>0.899436</td>\n",
       "      <td>0.813321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Session_0  Session_1  Session_2  Session_3\n",
       "Participant_0   0.998028   0.711898   0.809925   0.702574\n",
       "Participant_1   0.995463   0.686200   0.772595   0.880157\n",
       "Participant_2   0.997015   0.149393   0.899436   0.813321"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = \"results_tsd/predictions_training_session_\" + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "ground_truths = results[0]\n",
    "predictions = results[1]\n",
    "\n",
    "SCADANN_acc = np.zeros(ground_truths.shape)\n",
    "for i, ground in np.ndenumerate(ground_truths):\n",
    "    acc = np.mean(np.array(ground) == np.array(predictions[i]))\n",
    "    SCADANN_acc[i] = acc\n",
    "SCADANN_acc_overall = np.mean(SCADANN_acc)\n",
    "SCADANN_df = pd.DataFrame(SCADANN_acc, \n",
    "                       columns = [f'Session_{i}' for i in range(ground_truths.shape[1])],\n",
    "                        index = [f'Participant_{j}' for j in range(ground_truths.shape[0])])\n",
    "SCADANN_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SCADANN_df.transpose().plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"SCADANN Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSD</th>\n",
       "      <td>0.679239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DANN</th>\n",
       "      <td>0.759878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCADANN</th>\n",
       "      <td>0.784667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Overall_Acc\n",
       "TSD         0.679239\n",
       "DANN        0.759878\n",
       "SCADANN     0.784667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_acc_df = pd.DataFrame([TSD_acc_overall, DANN_acc_overall, SCADANN_acc_overall],\n",
    "                             index = [\"TSD\", \"DANN\", \"SCADANN\"],\n",
    "                             columns = [\"Overall_Acc\"])\n",
    "overall_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14,14))\n",
    "acc_list = [TSD_df, DANN_df, SCADANN_df, overall_acc_df]\n",
    "title_list = [\"TSD\", \"DANN\", \"SCADANN\", \"Overall\"]\n",
    "for idx, ax in enumerate(axes.reshape(-1)): \n",
    "    acc_list[idx].transpose().plot.bar(ax = ax, rot=0)\n",
    "    ax.set_title(title_list[idx])\n",
    "    ax.set_ylim([0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
