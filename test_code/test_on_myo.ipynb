{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo\")\n",
    "from PrepareAndLoadData.process_data import read_data_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/laiy/gitrepos/msr_final/Wearable_Sensor_Long-term_sEMG_Dataset/data\"\n",
    "processed_data_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Processed_datasets\"\n",
    "code_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo\"\n",
    "save_dir = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = data_dir\n",
    "store_path = processed_data_dir\n",
    "# read_data_training(path=data_dir, store_path = store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TSD_DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainingsAndEvaluations.ForTrainingSessions.train_tsd_dnn_standard import \\\n",
    "            test_TSD_DNN_on_training_sessions, train_fine_tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning examples  (1, 3, 40, 572, 50, 8)\n",
      "traning labels  (1, 3, 40, 572)\n"
     ]
    }
   ],
   "source": [
    "# check stored pickle \n",
    "with open(store_path + \"/training_session.pickle\", 'rb') as f:\n",
    "    dataset_training = pickle.load(file=f)\n",
    "\n",
    "examples_datasets_train = dataset_training['examples_training']\n",
    "print('traning examples ', np.shape(examples_datasets_train))\n",
    "labels_datasets_train = dataset_training['labels_training']\n",
    "print('traning labels ', np.shape(labels_datasets_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_to = \"Weights_TSD/TSD\"\n",
    "num_kernels=[200, 200, 200]                        # model layer size \n",
    "number_of_cycle_for_first_training=4               # #session\n",
    "number_of_cycles_rest_of_training=4     \n",
    "path_to_save_to=\"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_TSD/TSD\"\n",
    "number_of_classes=22\n",
    "batch_size=128          \n",
    "feature_vector_input_length=400                     # size of one example \n",
    "learning_rate=0.002515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 50, 8)\n",
      "   GET one training_index_examples  (40, 572, 50, 8)  at  0\n",
      "   GOT one group XY  (22880, 400)    (22880,)\n",
      "       one group XY test  (0,)    (0,)\n",
      "       one group XY train (20592, 400)    (20592,)\n",
      "       one group XY valid (2288, 400)    (2288, 400)\n",
      "   GET one training_index_examples  (40, 572, 50, 8)  at  1\n",
      "   GOT one group XY  (22880, 400)    (22880,)\n",
      "       one group XY test  (0,)    (0,)\n",
      "       one group XY train (20592, 400)    (20592,)\n",
      "       one group XY valid (2288, 400)    (2288, 400)\n",
      "   GET one training_index_examples  (40, 572, 50, 8)  at  2\n",
      "   GOT one group XY  (22880, 400)    (22880,)\n",
      "       one group XY test  (0,)    (0,)\n",
      "       one group XY train (20592, 400)    (20592,)\n",
      "       one group XY valid (2288, 400)    (2288, 400)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 0)\n",
      "START TRAINING\n",
      "Participant:  0\n",
      "Session:  0\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=22, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  167224\n",
      "<generator object Module.parameters at 0x7f81445a7ba0>\n",
      "Epoch 0/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laiy/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.02146887 Acc: 0.14428711\n",
      "val Loss: 0.00099017 Acc: 0.23557692\n",
      "New best validation loss: 0.000990167051762134\n",
      "Epoch 1 of 500 took 1.509s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.01752786 Acc: 0.2309082\n",
      "val Loss: 0.00087059 Acc: 0.30463287\n",
      "New best validation loss: 0.0008705903391738038\n",
      "Epoch 2 of 500 took 1.572s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.01568067 Acc: 0.296875\n",
      "val Loss: 0.00073806 Acc: 0.39816434\n",
      "New best validation loss: 0.0007380602972490804\n",
      "Epoch 3 of 500 took 1.499s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.01426989 Acc: 0.35751953\n",
      "val Loss: 0.00066723 Acc: 0.45979021\n",
      "New best validation loss: 0.0006672290863690677\n",
      "Epoch 4 of 500 took 1.533s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.01336666 Acc: 0.39067383\n",
      "val Loss: 0.00059305 Acc: 0.50218531\n",
      "New best validation loss: 0.0005930504807225474\n",
      "Epoch 5 of 500 took 1.458s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.01256744 Acc: 0.42207031\n",
      "val Loss: 0.00055557 Acc: 0.55157343\n",
      "New best validation loss: 0.0005555666097394236\n",
      "Epoch 6 of 500 took 1.702s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.01212522 Acc: 0.44443359\n",
      "val Loss: 0.00054183 Acc: 0.5708042\n",
      "New best validation loss: 0.0005418295626873737\n",
      "Epoch 7 of 500 took 1.579s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.01164138 Acc: 0.46000977\n",
      "val Loss: 0.00049603 Acc: 0.59702797\n",
      "New best validation loss: 0.0004960302706364985\n",
      "Epoch 8 of 500 took 1.754s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.01123900 Acc: 0.48051758\n",
      "val Loss: 0.00050902 Acc: 0.5826049\n",
      "Epoch 9 of 500 took 1.507s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.01098145 Acc: 0.49301758\n",
      "val Loss: 0.00047585 Acc: 0.62106643\n",
      "New best validation loss: 0.00047584701251316737\n",
      "Epoch 10 of 500 took 1.472s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.01061204 Acc: 0.51049805\n",
      "val Loss: 0.00047180 Acc: 0.62019231\n",
      "New best validation loss: 0.00047180400444911077\n",
      "Epoch 11 of 500 took 1.430s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.01047059 Acc: 0.51650391\n",
      "val Loss: 0.00045282 Acc: 0.63243007\n",
      "New best validation loss: 0.00045282362432746623\n",
      "Epoch 12 of 500 took 1.355s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.01032724 Acc: 0.52333984\n",
      "val Loss: 0.00046879 Acc: 0.62631119\n",
      "Epoch 13 of 500 took 1.336s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.01004490 Acc: 0.53320312\n",
      "val Loss: 0.00043919 Acc: 0.64947552\n",
      "New best validation loss: 0.00043919218795282857\n",
      "Epoch 14 of 500 took 1.345s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00981119 Acc: 0.54223633\n",
      "val Loss: 0.00041946 Acc: 0.64816434\n",
      "New best validation loss: 0.00041945940339481913\n",
      "Epoch 15 of 500 took 1.334s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00967868 Acc: 0.5496582\n",
      "val Loss: 0.00044093 Acc: 0.62674825\n",
      "Epoch 16 of 500 took 1.329s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00956559 Acc: 0.5534668\n",
      "val Loss: 0.00044304 Acc: 0.62412587\n",
      "Epoch 17 of 500 took 1.329s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00935087 Acc: 0.56494141\n",
      "val Loss: 0.00041020 Acc: 0.65865385\n",
      "New best validation loss: 0.0004101977064892962\n",
      "Epoch 18 of 500 took 1.409s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00934119 Acc: 0.56308594\n",
      "val Loss: 0.00040147 Acc: 0.67045455\n",
      "New best validation loss: 0.0004014746917711271\n",
      "Epoch 19 of 500 took 1.332s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00915657 Acc: 0.57314453\n",
      "val Loss: 0.00041633 Acc: 0.65777972\n",
      "Epoch 20 of 500 took 1.337s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00914793 Acc: 0.57470703\n",
      "val Loss: 0.00039399 Acc: 0.67526224\n",
      "New best validation loss: 0.000393991026428196\n",
      "Epoch 21 of 500 took 1.337s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00888199 Acc: 0.58701172\n",
      "val Loss: 0.00039971 Acc: 0.66477273\n",
      "Epoch 22 of 500 took 1.333s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00885928 Acc: 0.58720703\n",
      "val Loss: 0.00038994 Acc: 0.67395105\n",
      "New best validation loss: 0.0003899359307089052\n",
      "Epoch 23 of 500 took 1.368s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00879167 Acc: 0.59023437\n",
      "val Loss: 0.00039124 Acc: 0.66826923\n",
      "Epoch 24 of 500 took 1.355s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00873980 Acc: 0.59726563\n",
      "val Loss: 0.00037880 Acc: 0.68006993\n",
      "New best validation loss: 0.0003787979639910318\n",
      "Epoch 25 of 500 took 1.367s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00857076 Acc: 0.60161133\n",
      "val Loss: 0.00038298 Acc: 0.67482517\n",
      "Epoch 26 of 500 took 1.351s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00845271 Acc: 0.60556641\n",
      "val Loss: 0.00036959 Acc: 0.69187063\n",
      "New best validation loss: 0.00036959337083609787\n",
      "Epoch 27 of 500 took 1.352s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00840757 Acc: 0.61333008\n",
      "val Loss: 0.00036856 Acc: 0.6791958\n",
      "New best validation loss: 0.0003685597460586708\n",
      "Epoch 28 of 500 took 1.403s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00837190 Acc: 0.60991211\n",
      "val Loss: 0.00036013 Acc: 0.70629371\n",
      "New best validation loss: 0.00036013227972117335\n",
      "Epoch 29 of 500 took 1.366s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00827663 Acc: 0.61508789\n",
      "val Loss: 0.00036936 Acc: 0.69449301\n",
      "Epoch 30 of 500 took 1.371s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00823568 Acc: 0.61821289\n",
      "val Loss: 0.00034502 Acc: 0.71809441\n",
      "New best validation loss: 0.0003450221375568763\n",
      "Epoch 31 of 500 took 1.358s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00822367 Acc: 0.61777344\n",
      "val Loss: 0.00035292 Acc: 0.7076049\n",
      "Epoch 32 of 500 took 1.358s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00812979 Acc: 0.62001953\n",
      "val Loss: 0.00035258 Acc: 0.69798951\n",
      "Epoch 33 of 500 took 1.336s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00808728 Acc: 0.62133789\n",
      "val Loss: 0.00034932 Acc: 0.71066434\n",
      "Epoch 34 of 500 took 1.333s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00800990 Acc: 0.62695312\n",
      "val Loss: 0.00033449 Acc: 0.72770979\n",
      "New best validation loss: 0.00033449475373421514\n",
      "Epoch 35 of 500 took 1.333s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00791334 Acc: 0.63652344\n",
      "val Loss: 0.00035189 Acc: 0.71765734\n",
      "Epoch 36 of 500 took 1.343s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00800147 Acc: 0.62973633\n",
      "val Loss: 0.00036224 Acc: 0.70323427\n",
      "Epoch 37 of 500 took 1.339s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00782596 Acc: 0.63442383\n",
      "val Loss: 0.00037765 Acc: 0.68094406\n",
      "Epoch 38 of 500 took 1.383s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00785222 Acc: 0.63203125\n",
      "val Loss: 0.00035740 Acc: 0.70716783\n",
      "Epoch 39 of 500 took 1.337s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00772802 Acc: 0.63935547\n",
      "val Loss: 0.00035300 Acc: 0.70410839\n",
      "Epoch 40 of 500 took 1.350s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00774072 Acc: 0.64326172\n",
      "val Loss: 0.00033509 Acc: 0.72814685\n",
      "Epoch    41: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 41 of 500 took 1.336s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00735787 Acc: 0.66254883\n",
      "val Loss: 0.00031089 Acc: 0.74694056\n",
      "New best validation loss: 0.0003108935026855735\n",
      "Epoch 42 of 500 took 1.336s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00718350 Acc: 0.66645508\n",
      "val Loss: 0.00035539 Acc: 0.69536713\n",
      "Epoch 43 of 500 took 1.341s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00714832 Acc: 0.66928711\n",
      "val Loss: 0.00031652 Acc: 0.7465035\n",
      "Epoch 44 of 500 took 1.352s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00709412 Acc: 0.67114258\n",
      "val Loss: 0.00032436 Acc: 0.73645105\n",
      "Epoch 45 of 500 took 1.338s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00694814 Acc: 0.67651367\n",
      "val Loss: 0.00030122 Acc: 0.75043706\n",
      "New best validation loss: 0.0003012172044157148\n",
      "Epoch 46 of 500 took 1.339s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00687294 Acc: 0.68193359\n",
      "val Loss: 0.00030821 Acc: 0.74038462\n",
      "Epoch 47 of 500 took 1.340s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00676784 Acc: 0.68842773\n",
      "val Loss: 0.00031188 Acc: 0.7416958\n",
      "Epoch 48 of 500 took 1.383s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00672605 Acc: 0.68696289\n",
      "val Loss: 0.00030396 Acc: 0.75131119\n",
      "Epoch 49 of 500 took 1.359s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00670219 Acc: 0.684375\n",
      "val Loss: 0.00030670 Acc: 0.74475524\n",
      "Epoch 50 of 500 took 1.354s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00671485 Acc: 0.69106445\n",
      "val Loss: 0.00033136 Acc: 0.72115385\n",
      "Epoch 51 of 500 took 1.347s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.00660563 Acc: 0.69238281\n",
      "val Loss: 0.00028917 Acc: 0.75568182\n",
      "New best validation loss: 0.00028917297616705195\n",
      "Epoch 52 of 500 took 1.339s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.00660522 Acc: 0.69023437\n",
      "val Loss: 0.00033118 Acc: 0.72202797\n",
      "Epoch 53 of 500 took 1.336s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00657705 Acc: 0.69472656\n",
      "val Loss: 0.00030858 Acc: 0.74694056\n",
      "Epoch 54 of 500 took 1.339s\n",
      "Epoch 54/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00657283 Acc: 0.690625\n",
      "val Loss: 0.00030223 Acc: 0.75087413\n",
      "Epoch 55 of 500 took 1.344s\n",
      "Epoch 55/499\n",
      "----------\n",
      "train Loss: 0.00654665 Acc: 0.69375\n",
      "val Loss: 0.00034354 Acc: 0.71416084\n",
      "Epoch 56 of 500 took 1.334s\n",
      "Epoch 56/499\n",
      "----------\n",
      "train Loss: 0.00656558 Acc: 0.68979492\n",
      "val Loss: 0.00029949 Acc: 0.74562937\n",
      "Epoch 57 of 500 took 1.329s\n",
      "Epoch 57/499\n",
      "----------\n",
      "train Loss: 0.00654331 Acc: 0.68989258\n",
      "val Loss: 0.00037890 Acc: 0.68269231\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 58 of 500 took 1.341s\n",
      "Epoch 58/499\n",
      "----------\n",
      "train Loss: 0.00633703 Acc: 0.7034668\n",
      "val Loss: 0.00032311 Acc: 0.74694056\n",
      "Epoch 59 of 500 took 1.400s\n",
      "Epoch 59/499\n",
      "----------\n",
      "train Loss: 0.00633975 Acc: 0.70527344\n",
      "val Loss: 0.00029754 Acc: 0.75131119\n",
      "Epoch 60 of 500 took 1.331s\n",
      "Epoch 60/499\n",
      "----------\n",
      "train Loss: 0.00640558 Acc: 0.70175781\n",
      "val Loss: 0.00032264 Acc: 0.72945804\n",
      "Epoch 61 of 500 took 1.334s\n",
      "Epoch 61/499\n",
      "----------\n",
      "train Loss: 0.00633103 Acc: 0.70810547\n",
      "val Loss: 0.00031206 Acc: 0.73776224\n",
      "Epoch 62 of 500 took 1.349s\n",
      "Epoch 62/499\n",
      "----------\n",
      "train Loss: 0.00630821 Acc: 0.70605469\n",
      "val Loss: 0.00029435 Acc: 0.75393357\n",
      "Epoch 63 of 500 took 1.334s\n",
      "\n",
      "Training complete in 1m 27s\n",
      "Best val loss: 0.000289\n",
      "Session:  1\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=22, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  167224\n",
      "<generator object Module.parameters at 0x7f814478fa50>\n",
      "=> loading checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_TSD/TSD/participant_0/best_state_0.pt'\n",
      "=> loaded checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_TSD/TSD/participant_0/best_state_0.pt' (epoch 52)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01211198 Acc: 0.49331055\n",
      "val Loss: 0.00043447 Acc: 0.6791958\n",
      "New best validation loss: 0.0004344702652701131\n",
      "Epoch 1 of 500 took 1.339s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.01035765 Acc: 0.53613281\n",
      "val Loss: 0.00041291 Acc: 0.69318182\n",
      "New best validation loss: 0.0004129098741324631\n",
      "Epoch 2 of 500 took 1.345s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.01004696 Acc: 0.54384766\n",
      "val Loss: 0.00039862 Acc: 0.70935315\n",
      "New best validation loss: 0.00039861908742597885\n",
      "Epoch 3 of 500 took 1.584s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.00973899 Acc: 0.56269531\n",
      "val Loss: 0.00040112 Acc: 0.69886364\n",
      "Epoch 4 of 500 took 1.349s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00942156 Acc: 0.57631836\n",
      "val Loss: 0.00036843 Acc: 0.72246503\n",
      "New best validation loss: 0.00036842946510214905\n",
      "Epoch 5 of 500 took 1.354s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00921309 Acc: 0.58134766\n",
      "val Loss: 0.00037547 Acc: 0.71503497\n",
      "Epoch 6 of 500 took 1.398s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00916808 Acc: 0.5878418\n",
      "val Loss: 0.00036034 Acc: 0.73339161\n",
      "New best validation loss: 0.00036034245903675374\n",
      "Epoch 7 of 500 took 1.343s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00885956 Acc: 0.59741211\n",
      "val Loss: 0.00035463 Acc: 0.71503497\n",
      "New best validation loss: 0.0003546305990719295\n",
      "Epoch 8 of 500 took 1.337s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00889467 Acc: 0.59824219\n",
      "val Loss: 0.00034005 Acc: 0.72770979\n",
      "New best validation loss: 0.00034004527997303675\n",
      "Epoch 9 of 500 took 1.337s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00875955 Acc: 0.60209961\n",
      "val Loss: 0.00036572 Acc: 0.72333916\n",
      "Epoch 10 of 500 took 1.352s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00851606 Acc: 0.61308594\n",
      "val Loss: 0.00038325 Acc: 0.73426573\n",
      "Epoch 11 of 500 took 1.333s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00842399 Acc: 0.61694336\n",
      "val Loss: 0.00035971 Acc: 0.71678322\n",
      "Epoch 12 of 500 took 1.335s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00839991 Acc: 0.62177734\n",
      "val Loss: 0.00034813 Acc: 0.72596154\n",
      "Epoch 13 of 500 took 1.334s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00847600 Acc: 0.61499023\n",
      "val Loss: 0.00033506 Acc: 0.7347028\n",
      "New best validation loss: 0.0003350585751183383\n",
      "Epoch 14 of 500 took 1.349s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00829715 Acc: 0.62583008\n",
      "val Loss: 0.00035126 Acc: 0.72770979\n",
      "Epoch 15 of 500 took 1.336s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00821281 Acc: 0.6293457\n",
      "val Loss: 0.00036204 Acc: 0.70891608\n",
      "Epoch 16 of 500 took 1.382s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00808223 Acc: 0.63081055\n",
      "val Loss: 0.00032061 Acc: 0.74038462\n",
      "New best validation loss: 0.00032060538659562597\n",
      "Epoch 17 of 500 took 1.442s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00811397 Acc: 0.6277832\n",
      "val Loss: 0.00032602 Acc: 0.7416958\n",
      "Epoch 18 of 500 took 1.335s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00792962 Acc: 0.64165039\n",
      "val Loss: 0.00036092 Acc: 0.6909965\n",
      "Epoch 19 of 500 took 1.329s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00791107 Acc: 0.64038086\n",
      "val Loss: 0.00034064 Acc: 0.72333916\n",
      "Epoch 20 of 500 took 1.328s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00794905 Acc: 0.63740234\n",
      "val Loss: 0.00032490 Acc: 0.74825175\n",
      "Epoch 21 of 500 took 1.351s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00789275 Acc: 0.64165039\n",
      "val Loss: 0.00035651 Acc: 0.70673077\n",
      "Epoch 22 of 500 took 1.339s\n",
      "Epoch 22/499\n",
      "----------\n",
      "train Loss: 0.00778496 Acc: 0.6480957\n",
      "val Loss: 0.00033089 Acc: 0.74300699\n",
      "Epoch    23: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 23 of 500 took 1.337s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00737973 Acc: 0.66586914\n",
      "val Loss: 0.00033736 Acc: 0.73513986\n",
      "Epoch 24 of 500 took 1.329s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00729905 Acc: 0.66743164\n",
      "val Loss: 0.00031938 Acc: 0.74694056\n",
      "New best validation loss: 0.0003193835695306738\n",
      "Epoch 25 of 500 took 1.340s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00713555 Acc: 0.67519531\n",
      "val Loss: 0.00031010 Acc: 0.75087413\n",
      "New best validation loss: 0.00031010282935796087\n",
      "Epoch 26 of 500 took 1.392s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00705932 Acc: 0.68457031\n",
      "val Loss: 0.00031316 Acc: 0.75480769\n",
      "Epoch 27 of 500 took 1.409s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00715250 Acc: 0.678125\n",
      "val Loss: 0.00031594 Acc: 0.75699301\n",
      "Epoch 28 of 500 took 1.494s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00696710 Acc: 0.68237305\n",
      "val Loss: 0.00030211 Acc: 0.76267483\n",
      "New best validation loss: 0.0003021138010325132\n",
      "Epoch 29 of 500 took 1.336s\n",
      "Epoch 29/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00689436 Acc: 0.68500977\n",
      "val Loss: 0.00031585 Acc: 0.73120629\n",
      "Epoch 30 of 500 took 1.347s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00691168 Acc: 0.68554688\n",
      "val Loss: 0.00031966 Acc: 0.74300699\n",
      "Epoch 31 of 500 took 1.334s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00687395 Acc: 0.68422852\n",
      "val Loss: 0.00031913 Acc: 0.74431818\n",
      "Epoch 32 of 500 took 1.341s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00687324 Acc: 0.68657227\n",
      "val Loss: 0.00031228 Acc: 0.74431818\n",
      "Epoch 33 of 500 took 1.323s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00681486 Acc: 0.69208984\n",
      "val Loss: 0.00030230 Acc: 0.7465035\n",
      "Epoch 34 of 500 took 1.323s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00680328 Acc: 0.69179687\n",
      "val Loss: 0.00029231 Acc: 0.76617133\n",
      "New best validation loss: 0.000292308498304207\n",
      "Epoch 35 of 500 took 1.411s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00679650 Acc: 0.68999023\n",
      "val Loss: 0.00031087 Acc: 0.76223776\n",
      "Epoch 36 of 500 took 1.436s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00682596 Acc: 0.68837891\n",
      "val Loss: 0.00032603 Acc: 0.73776224\n",
      "Epoch 37 of 500 took 1.326s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00675473 Acc: 0.69428711\n",
      "val Loss: 0.00032103 Acc: 0.73033217\n",
      "Epoch 38 of 500 took 1.326s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00673126 Acc: 0.69545898\n",
      "val Loss: 0.00031542 Acc: 0.74082168\n",
      "Epoch 39 of 500 took 1.323s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00664392 Acc: 0.69956055\n",
      "val Loss: 0.00030961 Acc: 0.75305944\n",
      "Epoch 40 of 500 took 1.341s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00664459 Acc: 0.69648438\n",
      "val Loss: 0.00029973 Acc: 0.76354895\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 41 of 500 took 1.321s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00655420 Acc: 0.70258789\n",
      "val Loss: 0.00029461 Acc: 0.75961538\n",
      "Epoch 42 of 500 took 1.321s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00653891 Acc: 0.70092773\n",
      "val Loss: 0.00030041 Acc: 0.76048951\n",
      "Epoch 43 of 500 took 1.326s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00655834 Acc: 0.70732422\n",
      "val Loss: 0.00031649 Acc: 0.73513986\n",
      "Epoch 44 of 500 took 1.334s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00660156 Acc: 0.70336914\n",
      "val Loss: 0.00029631 Acc: 0.76398601\n",
      "Epoch 45 of 500 took 1.321s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00659975 Acc: 0.70351562\n",
      "val Loss: 0.00032103 Acc: 0.73863636\n",
      "Epoch 46 of 500 took 1.322s\n",
      "\n",
      "Training complete in 1m 2s\n",
      "Best val loss: 0.000292\n",
      "Session:  2\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=22, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  167224\n",
      "<generator object Module.parameters at 0x7f81445a7cf0>\n",
      "=> loading checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_TSD/TSD/participant_0/best_state_1.pt'\n",
      "=> loaded checkpoint '/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/Weights_TSD/TSD/participant_0/best_state_1.pt' (epoch 35)\n",
      "Epoch 0/499\n",
      "----------\n",
      "train Loss: 0.01396530 Acc: 0.43408203\n",
      "val Loss: 0.00046955 Acc: 0.61888112\n",
      "New best validation loss: 0.00046954621801843175\n",
      "Epoch 1 of 500 took 1.433s\n",
      "Epoch 1/499\n",
      "----------\n",
      "train Loss: 0.01114395 Acc: 0.49750977\n",
      "val Loss: 0.00042492 Acc: 0.65122378\n",
      "New best validation loss: 0.0004249155729800671\n",
      "Epoch 2 of 500 took 1.329s\n",
      "Epoch 2/499\n",
      "----------\n",
      "train Loss: 0.01050050 Acc: 0.52416992\n",
      "val Loss: 0.00043141 Acc: 0.67657343\n",
      "Epoch 3 of 500 took 1.326s\n",
      "Epoch 3/499\n",
      "----------\n",
      "train Loss: 0.01012869 Acc: 0.5387207\n",
      "val Loss: 0.00041184 Acc: 0.68531469\n",
      "New best validation loss: 0.0004118395174716736\n",
      "Epoch 4 of 500 took 1.335s\n",
      "Epoch 4/499\n",
      "----------\n",
      "train Loss: 0.00991208 Acc: 0.54770508\n",
      "val Loss: 0.00042750 Acc: 0.65777972\n",
      "Epoch 5 of 500 took 1.338s\n",
      "Epoch 5/499\n",
      "----------\n",
      "train Loss: 0.00960302 Acc: 0.56206055\n",
      "val Loss: 0.00038980 Acc: 0.71022727\n",
      "New best validation loss: 0.0003898005698110674\n",
      "Epoch 6 of 500 took 1.332s\n",
      "Epoch 6/499\n",
      "----------\n",
      "train Loss: 0.00944563 Acc: 0.56396484\n",
      "val Loss: 0.00036967 Acc: 0.69973776\n",
      "New best validation loss: 0.0003696735818069298\n",
      "Epoch 7 of 500 took 1.330s\n",
      "Epoch 7/499\n",
      "----------\n",
      "train Loss: 0.00920987 Acc: 0.57705078\n",
      "val Loss: 0.00036478 Acc: 0.71066434\n",
      "New best validation loss: 0.0003647846723353112\n",
      "Epoch 8 of 500 took 1.329s\n",
      "Epoch 8/499\n",
      "----------\n",
      "train Loss: 0.00906364 Acc: 0.58232422\n",
      "val Loss: 0.00038737 Acc: 0.67875874\n",
      "Epoch 9 of 500 took 1.345s\n",
      "Epoch 9/499\n",
      "----------\n",
      "train Loss: 0.00895749 Acc: 0.58740234\n",
      "val Loss: 0.00037555 Acc: 0.70061189\n",
      "Epoch 10 of 500 took 1.328s\n",
      "Epoch 10/499\n",
      "----------\n",
      "train Loss: 0.00880661 Acc: 0.59321289\n",
      "val Loss: 0.00036961 Acc: 0.6993007\n",
      "Epoch 11 of 500 took 1.373s\n",
      "Epoch 11/499\n",
      "----------\n",
      "train Loss: 0.00882588 Acc: 0.59404297\n",
      "val Loss: 0.00040128 Acc: 0.66870629\n",
      "Epoch 12 of 500 took 1.332s\n",
      "Epoch 12/499\n",
      "----------\n",
      "train Loss: 0.00861908 Acc: 0.60263672\n",
      "val Loss: 0.00036207 Acc: 0.70061189\n",
      "New best validation loss: 0.00036206867519792145\n",
      "Epoch 13 of 500 took 1.348s\n",
      "Epoch 13/499\n",
      "----------\n",
      "train Loss: 0.00858036 Acc: 0.60146484\n",
      "val Loss: 0.00035838 Acc: 0.6958042\n",
      "New best validation loss: 0.00035837555786112803\n",
      "Epoch 14 of 500 took 1.330s\n",
      "Epoch 14/499\n",
      "----------\n",
      "train Loss: 0.00843607 Acc: 0.61147461\n",
      "val Loss: 0.00038547 Acc: 0.68968531\n",
      "Epoch 15 of 500 took 1.328s\n",
      "Epoch 15/499\n",
      "----------\n",
      "train Loss: 0.00838570 Acc: 0.61391602\n",
      "val Loss: 0.00037535 Acc: 0.67875874\n",
      "Epoch 16 of 500 took 1.415s\n",
      "Epoch 16/499\n",
      "----------\n",
      "train Loss: 0.00841384 Acc: 0.61000977\n",
      "val Loss: 0.00035587 Acc: 0.71372378\n",
      "New best validation loss: 0.000355872240933505\n",
      "Epoch 17 of 500 took 1.356s\n",
      "Epoch 17/499\n",
      "----------\n",
      "train Loss: 0.00827964 Acc: 0.61733398\n",
      "val Loss: 0.00034789 Acc: 0.70847902\n",
      "New best validation loss: 0.00034789316408284063\n",
      "Epoch 18 of 500 took 1.351s\n",
      "Epoch 18/499\n",
      "----------\n",
      "train Loss: 0.00826742 Acc: 0.61591797\n",
      "val Loss: 0.00035384 Acc: 0.70061189\n",
      "Epoch 19 of 500 took 1.507s\n",
      "Epoch 19/499\n",
      "----------\n",
      "train Loss: 0.00814275 Acc: 0.62104492\n",
      "val Loss: 0.00034138 Acc: 0.71284965\n",
      "New best validation loss: 0.00034137810026849065\n",
      "Epoch 20 of 500 took 1.361s\n",
      "Epoch 20/499\n",
      "----------\n",
      "train Loss: 0.00803733 Acc: 0.62714844\n",
      "val Loss: 0.00036135 Acc: 0.69493007\n",
      "Epoch 21 of 500 took 1.386s\n",
      "Epoch 21/499\n",
      "----------\n",
      "train Loss: 0.00805577 Acc: 0.62260742\n",
      "val Loss: 0.00034385 Acc: 0.70847902\n",
      "Epoch 22 of 500 took 1.336s\n",
      "Epoch 22/499\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.00798710 Acc: 0.63178711\n",
      "val Loss: 0.00037065 Acc: 0.69711538\n",
      "Epoch 23 of 500 took 1.344s\n",
      "Epoch 23/499\n",
      "----------\n",
      "train Loss: 0.00791184 Acc: 0.63671875\n",
      "val Loss: 0.00037238 Acc: 0.67132867\n",
      "Epoch 24 of 500 took 1.330s\n",
      "Epoch 24/499\n",
      "----------\n",
      "train Loss: 0.00795066 Acc: 0.62739258\n",
      "val Loss: 0.00034578 Acc: 0.7027972\n",
      "Epoch 25 of 500 took 1.331s\n",
      "Epoch 25/499\n",
      "----------\n",
      "train Loss: 0.00777979 Acc: 0.640625\n",
      "val Loss: 0.00034343 Acc: 0.69798951\n",
      "Epoch    26: reducing learning rate of group 0 to 5.0300e-04.\n",
      "Epoch 26 of 500 took 1.353s\n",
      "Epoch 26/499\n",
      "----------\n",
      "train Loss: 0.00763168 Acc: 0.64243164\n",
      "val Loss: 0.00032938 Acc: 0.71853147\n",
      "New best validation loss: 0.00032937683008767507\n",
      "Epoch 27 of 500 took 1.427s\n",
      "Epoch 27/499\n",
      "----------\n",
      "train Loss: 0.00751972 Acc: 0.64775391\n",
      "val Loss: 0.00032991 Acc: 0.72858392\n",
      "Epoch 28 of 500 took 1.358s\n",
      "Epoch 28/499\n",
      "----------\n",
      "train Loss: 0.00730410 Acc: 0.6609375\n",
      "val Loss: 0.00031427 Acc: 0.72902098\n",
      "New best validation loss: 0.0003142704132136765\n",
      "Epoch 29 of 500 took 1.344s\n",
      "Epoch 29/499\n",
      "----------\n",
      "train Loss: 0.00739360 Acc: 0.6543457\n",
      "val Loss: 0.00033877 Acc: 0.69842657\n",
      "Epoch 30 of 500 took 1.358s\n",
      "Epoch 30/499\n",
      "----------\n",
      "train Loss: 0.00727711 Acc: 0.65869141\n",
      "val Loss: 0.00032791 Acc: 0.72945804\n",
      "Epoch 31 of 500 took 1.514s\n",
      "Epoch 31/499\n",
      "----------\n",
      "train Loss: 0.00715707 Acc: 0.66826172\n",
      "val Loss: 0.00032926 Acc: 0.72071678\n",
      "Epoch 32 of 500 took 1.385s\n",
      "Epoch 32/499\n",
      "----------\n",
      "train Loss: 0.00715903 Acc: 0.66826172\n",
      "val Loss: 0.00032530 Acc: 0.72377622\n",
      "Epoch 33 of 500 took 1.449s\n",
      "Epoch 33/499\n",
      "----------\n",
      "train Loss: 0.00723340 Acc: 0.66152344\n",
      "val Loss: 0.00032035 Acc: 0.71809441\n",
      "Epoch 34 of 500 took 1.346s\n",
      "Epoch 34/499\n",
      "----------\n",
      "train Loss: 0.00712726 Acc: 0.6690918\n",
      "val Loss: 0.00031539 Acc: 0.73120629\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0060e-04.\n",
      "Epoch 35 of 500 took 1.334s\n",
      "Epoch 35/499\n",
      "----------\n",
      "train Loss: 0.00706388 Acc: 0.6730957\n",
      "val Loss: 0.00034460 Acc: 0.70629371\n",
      "Epoch 36 of 500 took 1.372s\n",
      "Epoch 36/499\n",
      "----------\n",
      "train Loss: 0.00707357 Acc: 0.66586914\n",
      "val Loss: 0.00032779 Acc: 0.71809441\n",
      "Epoch 37 of 500 took 1.421s\n",
      "Epoch 37/499\n",
      "----------\n",
      "train Loss: 0.00695700 Acc: 0.675\n",
      "val Loss: 0.00030647 Acc: 0.7381993\n",
      "New best validation loss: 0.0003064672325874542\n",
      "Epoch 38 of 500 took 1.363s\n",
      "Epoch 38/499\n",
      "----------\n",
      "train Loss: 0.00709426 Acc: 0.67006836\n",
      "val Loss: 0.00032509 Acc: 0.72421329\n",
      "Epoch 39 of 500 took 1.336s\n",
      "Epoch 39/499\n",
      "----------\n",
      "train Loss: 0.00705759 Acc: 0.67114258\n",
      "val Loss: 0.00031585 Acc: 0.73907343\n",
      "Epoch 40 of 500 took 1.447s\n",
      "Epoch 40/499\n",
      "----------\n",
      "train Loss: 0.00707149 Acc: 0.66943359\n",
      "val Loss: 0.00033017 Acc: 0.71765734\n",
      "Epoch 41 of 500 took 1.683s\n",
      "Epoch 41/499\n",
      "----------\n",
      "train Loss: 0.00698825 Acc: 0.66987305\n",
      "val Loss: 0.00031634 Acc: 0.74256993\n",
      "Epoch 42 of 500 took 1.542s\n",
      "Epoch 42/499\n",
      "----------\n",
      "train Loss: 0.00702439 Acc: 0.67119141\n",
      "val Loss: 0.00030236 Acc: 0.73688811\n",
      "New best validation loss: 0.00030235555413719655\n",
      "Epoch 43 of 500 took 1.466s\n",
      "Epoch 43/499\n",
      "----------\n",
      "train Loss: 0.00699223 Acc: 0.67480469\n",
      "val Loss: 0.00032052 Acc: 0.73776224\n",
      "Epoch 44 of 500 took 1.449s\n",
      "Epoch 44/499\n",
      "----------\n",
      "train Loss: 0.00696993 Acc: 0.67578125\n",
      "val Loss: 0.00033116 Acc: 0.72202797\n",
      "Epoch 45 of 500 took 1.459s\n",
      "Epoch 45/499\n",
      "----------\n",
      "train Loss: 0.00699630 Acc: 0.67299805\n",
      "val Loss: 0.00033559 Acc: 0.72377622\n",
      "Epoch 46 of 500 took 1.488s\n",
      "Epoch 46/499\n",
      "----------\n",
      "train Loss: 0.00700107 Acc: 0.67329102\n",
      "val Loss: 0.00030912 Acc: 0.74300699\n",
      "Epoch 47 of 500 took 1.569s\n",
      "Epoch 47/499\n",
      "----------\n",
      "train Loss: 0.00701048 Acc: 0.67558594\n",
      "val Loss: 0.00032296 Acc: 0.73295455\n",
      "Epoch 48 of 500 took 1.539s\n",
      "Epoch 48/499\n",
      "----------\n",
      "train Loss: 0.00697999 Acc: 0.67207031\n",
      "val Loss: 0.00033114 Acc: 0.71197552\n",
      "Epoch    49: reducing learning rate of group 0 to 2.0120e-05.\n",
      "Epoch 49 of 500 took 1.449s\n",
      "Epoch 49/499\n",
      "----------\n",
      "train Loss: 0.00687830 Acc: 0.67851562\n",
      "val Loss: 0.00032013 Acc: 0.72814685\n",
      "Epoch 50 of 500 took 1.513s\n",
      "Epoch 50/499\n",
      "----------\n",
      "train Loss: 0.00683547 Acc: 0.67958984\n",
      "val Loss: 0.00034514 Acc: 0.70541958\n",
      "Epoch 51 of 500 took 1.669s\n",
      "Epoch 51/499\n",
      "----------\n",
      "train Loss: 0.00684744 Acc: 0.68100586\n",
      "val Loss: 0.00031276 Acc: 0.72552448\n",
      "Epoch 52 of 500 took 1.404s\n",
      "Epoch 52/499\n",
      "----------\n",
      "train Loss: 0.00680503 Acc: 0.68212891\n",
      "val Loss: 0.00031715 Acc: 0.72552448\n",
      "Epoch 53 of 500 took 1.446s\n",
      "Epoch 53/499\n",
      "----------\n",
      "train Loss: 0.00687843 Acc: 0.67460937\n",
      "val Loss: 0.00030781 Acc: 0.74256993\n",
      "Epoch 54 of 500 took 1.475s\n",
      "\n",
      "Training complete in 1m 16s\n",
      "Best val loss: 0.000302\n"
     ]
    }
   ],
   "source": [
    "train_fine_tuning(examples_datasets_train, labels_datasets_train,\n",
    "                  num_kernels=num_kernels, path_weight_to_save_to=path_to_save_to,\n",
    "                  number_of_classes=number_of_classes,\n",
    "                  batch_size=batch_size,\n",
    "                  feature_vector_input_length=feature_vector_input_length,\n",
    "                  learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET one participant_examples  (3, 40, 572, 50, 8)\n",
      "   GET one training_index_examples  (40, 572, 50, 8)  at  0\n",
      "   GOT one group XY  (22880, 400)    (22880,)\n",
      "       one group XY test  (5720, 400)    (5720, 400)\n",
      "       one group XY train (20592, 400)    (20592,)\n",
      "       one group XY valid (2288, 400)    (2288, 400)\n",
      "   GET one training_index_examples  (40, 572, 50, 8)  at  1\n",
      "   GOT one group XY  (22880, 400)    (22880,)\n",
      "       one group XY test  (5720, 400)    (5720, 400)\n",
      "       one group XY train (20592, 400)    (20592,)\n",
      "       one group XY valid (2288, 400)    (2288, 400)\n",
      "   GET one training_index_examples  (40, 572, 50, 8)  at  2\n",
      "   GOT one group XY  (22880, 400)    (22880,)\n",
      "       one group XY test  (5720, 400)    (5720, 400)\n",
      "       one group XY train (20592, 400)    (20592,)\n",
      "       one group XY valid (2288, 400)    (2288, 400)\n",
      "dataloaders: \n",
      "   train  (1, 3)\n",
      "   valid  (1, 3)\n",
      "   test  (1, 3)\n",
      "TSD_Network(\n",
      "  (_network): ModuleList(\n",
      "    (0): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=400, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=400, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): LinearBlocks(\n",
      "      (fully_connected_1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (batch_norm1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "      (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      (dropout1): Dropout(p=0.5, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (1): BatchNorm1d(200, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (_output): Linear(in_features=200, out_features=22, bias=True)\n",
      "  (_output_discriminator): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "Number Parameters:  167224\n",
      "0  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.8828671328671329\n",
      "1  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.5164335664335664\n",
      "2  SESSION   data =  5720\n",
      "Participant:  0  Accuracy:  0.5458041958041958\n",
      "ACCURACY PARTICIPANT  0 :  [0.8828671328671329, 0.5164335664335664, 0.5458041958041958]\n",
      "[0.8828671328671329, 0.5164335664335664, 0.5458041958041958]\n",
      "OVERALL ACCURACY: 0.6483682983682985\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/laiy/gitrepos/msr_final/LongTermEMG_myo/TrainingsAndEvaluations/ForTrainingSessions/results_tsd\"\n",
    "algo_name = \"standard_TSD\"\n",
    "test_TSD_DNN_on_training_sessions(examples_datasets_train, labels_datasets_train,\n",
    "                                  num_neurons=num_kernels, use_only_first_training=True,\n",
    "                                  path_weights=path_to_save_to,\n",
    "                                  feature_vector_input_length=feature_vector_input_length,\n",
    "                                  save_path = save_path, algo_name=algo_name,\n",
    "                                  number_of_classes=number_of_classes, cycle_for_test=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Session_0</th>\n",
       "      <td>0.882867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session_1</th>\n",
       "      <td>0.516434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session_2</th>\n",
       "      <td>0.545804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Participant_0\n",
       "Session_0       0.882867\n",
       "Session_1       0.516434\n",
       "Session_2       0.545804"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_filename = save_path + '/predictions_' + algo_name + \"_no_retraining.npy\"\n",
    "results = np.load(results_filename, allow_pickle=True)\n",
    "TSD_acc = results[0]\n",
    "TSD_acc_overall = np.mean(TSD_acc)\n",
    "TSD_df = pd.DataFrame(TSD_acc.transpose(), \n",
    "                       index = [f'Session_{i}' for i in range(TSD_acc.shape[0])],\n",
    "                        columns = [f'Participant_{j}' for j in range(1)])\n",
    "TSD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSD_df.plot.bar(rot=0, figsize=(10,5))\n",
    "plt.title(\"TSD Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
